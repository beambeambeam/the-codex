from typing import Union

from pydantic import BaseModel, Field

from ..collection.schemas import (
    CollectionChatCreate,
    CollectionChatHistoryBase,
    CollectionChatResponse,
)
from ..document.schemas import (
    ChunkSearchResponse,
    DocumentChatCreate,
    DocumentChatHistoryBase,
    DocumentChatResponse,
)
from ..models.user import User
from .pocketflow_custom import ShareStoreBase


class ChatMessage(CollectionChatHistoryBase, DocumentChatHistoryBase):
    """Schema for chat messages in the RAG system."""

    pass


class ChatHistory(BaseModel):
    """Schema for a list of chat messages."""

    messages: list[ChatMessage] = Field(
        default_factory=list, description="List of chat messages in the conversation"
    )

    def to_list(self) -> list[dict]:
        """
        Convert the ChatMessageList to a list of dictionaries.
        This is useful for serialization or further processing.
        """
        return [message.model.dump() for message in self.messages]


# NodeTypes = Literal["EmbedChunksNode", "StoreInPgvectorNode", "SearchPgvectorNode", "GenerateResponseNode"]


class AgentResponse(BaseModel):
    """Schema for the response from the RAG agent."""

    # answer: ChatMessage = Field(
    #     ..., description="The answer generated by the RAG agent"
    # )
    chat_history: ChatHistory = Field(
        default_factory=ChatHistory,
        description="Conversation history including user questions and assistant responses",
    )
    retrieved_contexts: list[ChunkSearchResponse] = Field(
        default_factory=list,
        description="List of retrieved document chunks based on the query embedding",
    )


class SharedStore(ShareStoreBase):
    # Offline Indexing Flow
    input_file_paths: list[str] = Field(
        default_factory=list, description="List of file paths to be indexed"
    )
    parsed_chunks_for_embedding: list[ChunkSearchResponse] = Field(
        default_factory=list,
        description="List of parsed document chunks ready for embedding",
    )
    processed_chunks: list[ChunkSearchResponse] = Field(
        default_factory=list,
        description="List of processed document chunks with embeddings",
    )

    # Online Querying Flow
    user_question: str = Field(
        None, description="User's question or query for the RAG system"
    )
    query_embedding: list[float] = Field(
        None, description="Embedding vector of the user's question"
    )
    retrieved_contexts: list[ChunkSearchResponse] = Field(
        default_factory=list,
        description="List of retrieved document chunks based on the query embedding",
    )
    llm_answer: ChatMessage = Field(
        None,
        description="Final answer generated by the LLM based on the retrieved contexts",
    )

    # General / Conversational
    chat_history: ChatHistory = Field(
        default_factory=ChatHistory,
        description="Conversation history including user questions and assistant responses",
    )
    system_instructions: str = Field(
        None,
        description="System instructions or context to guide the LLM's responses",
    )

    # Node Status
    current_node: str = Field(
        None, description="Name of the current node being executed in the flow"
    )

    # Session
    chat_session: Union[CollectionChatResponse, DocumentChatResponse] = Field(
        None, description="Chat collection for storing conversation history"
    )
    current_user: User = Field(
        None, description="ID of the current user interacting with the RAG system"
    )

    class Config:
        arbitrary_types_allowed = True
