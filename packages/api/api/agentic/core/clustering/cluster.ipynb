{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5824c8",
   "metadata": {},
   "source": [
    "# Topic Cluster For Document Chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadc53e",
   "metadata": {},
   "source": [
    "This is task for cluster document with visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b38ef",
   "metadata": {},
   "source": [
    "### Data Fetching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af9cff",
   "metadata": {},
   "source": [
    "Fetch embeddings of each chunk from Postgres Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76983c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb1656d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from api.database import get_db\n",
    "from api.document.dependencies import get_document_service\n",
    "from api.document.schemas import ChunkResponse, DocumentResponse\n",
    "\n",
    "collection_id = \"9f27817f-2382-424d-9df2-8a18b67d6251\"\n",
    "\n",
    "\n",
    "def get_collection_document_embeddings(collection_id):\n",
    "    \"\"\"Fetches document embeddings (average value) for a given collection.\"\"\"\n",
    "    service = get_document_service(next(get_db()))\n",
    "    documents = service.get_collection_documents(collection_id=collection_id)\n",
    "\n",
    "    doc_embeddings = defaultdict(list)\n",
    "\n",
    "    for doc in documents:\n",
    "        chunks = service.get_document_chunks(document_id=doc.id)\n",
    "        for chunk in chunks:\n",
    "            if chunk.embedding is not None:\n",
    "                doc_embeddings[doc.id].append(chunk.embedding)\n",
    "\n",
    "    document_vectors = {}\n",
    "\n",
    "    for doc_id, chunk_embeds in doc_embeddings.items():\n",
    "        if chunk_embeds:  # if there are any embeddings\n",
    "            document_vectors[doc_id] = np.mean(chunk_embeds, axis=0)\n",
    "\n",
    "    return document_vectors\n",
    "\n",
    "\n",
    "class DocumentChunk(ChunkResponse):\n",
    "    file_name: str\n",
    "\n",
    "\n",
    "def get_collection_chunk_embeddings(collection_id) -> dict[str, list[DocumentChunk]]:\n",
    "    \"\"\"Fetches chunk embeddings for a given collection.\"\"\"\n",
    "    service = get_document_service(next(get_db()))\n",
    "    documents = service.get_collection_documents(collection_id=collection_id)\n",
    "    documents = [DocumentResponse.model_validate(doc) for doc in documents]\n",
    "\n",
    "    chunk_embeddings = defaultdict(list)\n",
    "\n",
    "    for doc in documents:\n",
    "        chunks = service.get_document_chunks(document_id=doc.id)\n",
    "        chunks = [ChunkResponse.model_validate(chunk) for chunk in chunks]\n",
    "\n",
    "        for chunk in chunks:\n",
    "            if chunk.embedding is not None:\n",
    "                chunk_embeddings[doc.id].append(\n",
    "                    DocumentChunk(**chunk.model_dump(), file_name=doc.file_name)\n",
    "                )\n",
    "\n",
    "    return chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e63e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = get_collection_chunk_embeddings(collection_id)\n",
    "\n",
    "chunk_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fcc443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12b22df8-a310-4c67-82e1-e0a8a9b60d48',\n",
       " '2664dd5f-aa91-4c08-b30a-57b41e94e600',\n",
       " '3fecf9b1-d101-41cf-862c-433d3c4ffe58',\n",
       " '43531378-8340-494d-80d5-a5388e654029',\n",
       " '495fb9ae-61b7-45cd-9062-ef93cdba65aa',\n",
       " '4b46efdf-0db0-42e2-af04-c03cd2d9058a',\n",
       " 'b21ef601-e9b2-4354-95f5-1d83ae6f4a3a',\n",
       " 'd21282d0-6699-43b7-bc19-32e41ac54a99'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(chunk_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcc0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_texts = []\n",
    "embeddings = []\n",
    "doc_labels = []\n",
    "doc_ids = []\n",
    "\n",
    "for doc_key, chunk_list in chunk_embeddings.items():\n",
    "    for chunk in chunk_list:\n",
    "        chunk_texts.append(chunk.chunk_text)  # This is the chunk text\n",
    "        embeddings.append(chunk.embedding)\n",
    "        doc_ids.append(doc_key)  # This is the document ID\n",
    "        doc_labels.append(chunk.file_name)  # This is the document file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0076fa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try pick one\n",
    "\n",
    "len(chunk_embeddings[\"12b22df8-a310-4c67-82e1-e0a8a9b60d48\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "\n",
    "def plot_embedding_2d_by_doc(\n",
    "    embedding_2d, doc_labels, title=\"UMAP of Chunk Embeddings\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a 2D embedding with points colored by document labels.\n",
    "\n",
    "    Args:\n",
    "        embedding_2d (ndarray): 2D numpy array of shape (n_samples, 2).\n",
    "        doc_labels (list): List of document keys corresponding to each point.\n",
    "        title (str): Plot title.\n",
    "    \"\"\"\n",
    "    unique_docs = list(set(doc_labels))\n",
    "    doc_to_int = {doc: i for i, doc in enumerate(unique_docs)}\n",
    "    numeric_labels = [doc_to_int[label] for label in doc_labels]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(\n",
    "        embedding_2d[:, 0], embedding_2d[:, 1], c=numeric_labels, cmap=\"tab10\", s=20\n",
    "    )\n",
    "\n",
    "    # Legend setup\n",
    "    handles = []\n",
    "    cmap = get_cmap(\"tab10\")\n",
    "    for i, doc in enumerate(unique_docs):\n",
    "        handles.append(\n",
    "            plt.Line2D([], [], marker=\"o\", linestyle=\"\", color=cmap(i), label=doc)\n",
    "        )\n",
    "\n",
    "    plt.legend(\n",
    "        handles=handles, title=\"Documents\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_embedding_2d_with_hdbscan(embedding_2d, min_cluster_size=10, title=\"HDBSCAN Clustering on Embedding\"):\n",
    "    \"\"\"\n",
    "    Applies HDBSCAN clustering to a 2D embedding and visualizes the clusters.\n",
    "\n",
    "    Args:\n",
    "        embedding_2d (ndarray): 2D numpy array of shape (n_samples, 2).\n",
    "        min_cluster_size (int): The minimum size of clusters.\n",
    "        title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    # Apply HDBSCAN\n",
    "    HDBSCAN_model = HDBSCAN(\n",
    "    min_cluster_size=3,\n",
    "    max_cluster_size=10,\n",
    "    cluster_selection_epsilon=0.4,\n",
    "    prediction_data=True,\n",
    ")\n",
    "    cluster_labels = HDBSCAN_model.fit_predict(embedding_2d)\n",
    "\n",
    "    print(\"labels\", \",\".join(map(str, set(cluster_labels))))\n",
    "\n",
    "    # Number of clusters (excluding outliers)\n",
    "    n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    print(f\"Detected {n_clusters} clusters (excluding outliers).\")\n",
    "\n",
    "    # Plot setup\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Color map\n",
    "    cmap = get_cmap(\"tab10\")\n",
    "    unique_labels = set(cluster_labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        mask = (cluster_labels == label)\n",
    "        color = \"black\" if label == -1 else cmap(label % 10)\n",
    "        label_name = \"Outlier\" if label == -1 else f\"Cluster {label}\"\n",
    "        plt.scatter(\n",
    "            embedding_2d[mask, 0],\n",
    "            embedding_2d[mask, 1],\n",
    "            c=color,\n",
    "            label=label_name,\n",
    "            s=30,\n",
    "            edgecolors=\"none\",\n",
    "        )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"Clusters\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131298dd",
   "metadata": {},
   "source": [
    "### Fit Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ffed8",
   "metadata": {},
   "source": [
    "- use UMAP to reduce the dimensionality of the embeddings\n",
    "- 2D visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa9161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from api.agentic.dependencies import get_text_embedder\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15, metric=\"cosine\", random_state=42, n_components=2)\n",
    "\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "plot_embedding_2d_by_doc(\n",
    "    embedding_2d, doc_labels, title=\"Chunk Embedding UMAP Projection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a652d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels 0,1,2,3,4,5,6,7,8,9,-1\n",
      "Detected 10 clusters (excluding outliers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_embedding_2d_with_hdbscan(\n",
    "    embedding_2d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad3fcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HDBSCAN_model = HDBSCAN(\n",
    "    min_cluster_size=3,\n",
    "    max_cluster_size=10,\n",
    "    cluster_selection_epsilon=0.4,\n",
    "    prediction_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d77c8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-06 16:03:07.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapi.agentic.core.embedding.embedding\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mLoading embedding model: FlukeTJ/bge-m3-m2v-distilled-256 using backend: model2vec\u001b[0m\n",
      "\u001b[32m2025-07-06 16:03:13.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapi.agentic.core.embedding.embedding\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mEmbedding model loaded successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "embedder = get_text_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired  # noqa: F401\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedder.model,\n",
    "    hdbscan_model=HDBSCAN_model,\n",
    "    umap_model=reducer,\n",
    "    calculate_probabilities=True,\n",
    "    zeroshot_topic_list=[\"Large Language Models\", \"Clustering\", \"Topic Modeling\"],\n",
    "    zeroshot_min_similarity=.85,\n",
    "    # representation_model=KeyBERTInspired(),\n",
    "    top_n_words=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16926803",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_topics, probs = topic_model.fit_transform(chunk_texts, np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26f9a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├─as_all_the_of_are\n",
      "│    ├─as_of_is_are_the\n",
      "│    │    ├─■──cx_xtx_nxxt_of_xˆvi ── Topic: 6\n",
      "│    │    └─of_as_is_are_the\n",
      "│    │         ├─■──of_as_is_are_xj ── Topic: 1\n",
      "│    │         └─■──as_of_the_scaling_in ── Topic: 3\n",
      "│    └─as_in_the_are_is\n",
      "│         ├─as_in_the_are_is\n",
      "│         │    ├─■──as_similarity_topics_subtopics_the ── Topic: 5\n",
      "│         │    └─■──as_in_the_are_is ── Topic: 0\n",
      "│         └─■──refined_as_refinement_cot_is ── Topic: 9\n",
      "└─huang_liu_wu_zhang_yu\n",
      "     ├─huang_zhao_liu_wu_zhang\n",
      "     │    ├─■──are_of_33_as_sailor ── Topic: 7\n",
      "     │    └─huang_zhao_zhu_liu_wu\n",
      "     │         ├─■──huang_zhao_zhu_liu_jiang ── Topic: 2\n",
      "     │         └─■──biorxiv_2017_acl_david_2016 ── Topic: 4\n",
      "     └─■──017_014_015_013_005 ── Topic: 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(chunk_texts)\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8533d84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAADIUeGgca/XP8hR4aBxr9c/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAALsAAAAAAAAAuwAAAAAAAADnAAAAAAAAAOcA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAADMMUxz+inhP8wxTHP6KeE/yFHhoHGv1z8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAFMAAAAAAAAAUwAAAAAAAADTAAAAAAAAANMA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAD85eckNJbgP/zl5yQ0luA/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAACAQcAAAAAAAIBBwAAAAAAAgEbAAAAAAACARsA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "/OXnJDSW4D9fCWaNMhvmP18JZo0yG+Y/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAARMAAAAAAAABEwAAAAAAAgEvAAAAAAACAS8A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "zDFMc/op4T+K61IuLhjoP4rrUi4uGOg/XwlmjTIb5j8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAKcAAAAAAAAApwAAAAAAAwEfAAAAAAADAR8A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAABCa3XUsZbhP0JrddSxluE/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAADAUsAAAAAAAMBSwAAAAAAAQFXAAAAAAABAVcA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAw55NaVzfsPzDnk1pXN+w/Qmt11LGW4T8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAABAUMAAAAAAAEBQwAAAAAAAAFTAAAAAAAAAVMA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "MOeTWlc37D8G6N+3HiLwPwbo37ceIvA/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAgUsAAAAAAACBSwAAAAAAAwFfAAAAAAADAV8A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": {
          "bdata": "iutSLi4Y6D+fSNTabjzxP59I1NpuPPE/Bujftx4i8D8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAPsAAAAAAAAA+wAAAAAAA8FTAAAAAAADwVMA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "height": 350,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -100,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "6_cx_xtx_nxxt",
          "1_of_as_is",
          "3_as_of_the",
          "5_as_similarity_topics",
          "0_as_in_the",
          "9_refined_as_refinement",
          "7_are_of_33",
          "2_huang_zhao_zhu",
          "4_biorxiv_2017_acl",
          "8_017_014_015"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "146e6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 277, 277, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(chunk_texts), len(chunk_topics), len(hierarchical_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95f5b415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertext": "<b>Topic -1</b>:the_is_as_are_this_of_that_all_how",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "mt70PiTM8j6ihfE+cVLxPnGK6z7NZtg+1PDWPmoz1D4o4M8+HSjLPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 0</b>:as_in_the_are_is_of_typhoon2_only_m",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "CrLaPtTYtz5/SLc+trS2PsgGsT5at60+TrCrPjijqz5qmqs++PijPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 1</b>:of_as_is_are_xj_in_𝑠0_the_that_one",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "lCvkPrPP3j4aL9w+wiXNPvJgyD7YRb8+eUG/PloOvz6Qkrw+lGu8Pg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 2</b>:huang_zhao_zhu_liu_jiang_2024_wu_zh",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "hKX2PlCR8T4sf+Y+fXngPqwg3T7X29A+L0rNPvFeyz4pMMo+QtS4Pg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 3</b>:as_of_the_scaling_in_are_is_not_by_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "AnPqPv2L0z6wI8o+NADKPoIjyD5apsc+YBPHPhyVtz73Abc+FLiyPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 4</b>:biorxiv_2017_acl_david_2016_2020_ge",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "KlO6PtqOrD7oRaw+u2OqPqosoz7yOqI+kbKgPufpnz4NpZw+pLuXPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 5</b>:as_similarity_topics_subtopics_the_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "Mp7hPgLPzz6u9sc+E9XDPpvRwj5ogsI+4k7APgLcuj52Crg+VtWzPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 6</b>:cx_xtx_nxxt_of_xˆvi_is_ˆv1_are_ˆv2_",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "d3EOP5hKBj8iz/Q+Ep70PjDU8z7E3uQ+1HTjPhT82j4cMtY+eMLQPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 7</b>:are_of_33_as_sailor_and_21_dou_post",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "TZyGPvoZhj6awWg+NUllPmkdTj6LYj0+Z3s1PoTEMj5e7C4+qbEtPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 8</b>:017_014_015_013_005_002_023_951_003",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "GhMVP2jcET8lGw4/8VX7Pvel+T75OOk+eSPpPu7Z5z5TY+M+QkbgPg==",
          "dtype": "f4"
         }
        },
        {
         "hovertext": "<b>Topic 9</b>:refined_as_refinement_cot_is_correc",
         "line": {
          "color": "black",
          "width": 1.5
         },
         "mode": "lines+lines",
         "name": "",
         "opacity": 0.1,
         "type": "scatter",
         "x": {
          "bdata": "AQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAA==",
          "dtype": "i4"
         },
         "y": {
          "bdata": "MxvOPv1iwj53U7s+WdW1PgrIsT78R7E+WlWwPpHzrD7yNqo+J5KoPg==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 500,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Term score decline per Topic</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "dtick": 2,
         "range": [
          0,
          10
         ],
         "tick0": 1,
         "title": {
          "text": "Term Rank"
         }
        },
        "yaxis": {
         "title": {
          "text": "c-TF-IDF score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b094b10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           0,
           "as | in | the | are | is",
           90
          ],
          [
           1,
           "of | as | is | are | xj",
           40
          ],
          [
           2,
           "huang | zhao | zhu | liu | jiang",
           36
          ],
          [
           3,
           "as | of | the | scaling | in",
           22
          ],
          [
           4,
           "biorxiv | 2017 | acl | david | 2016",
           20
          ],
          [
           5,
           "as | similarity | topics | subtopics | the",
           17
          ],
          [
           6,
           "cx | xtx | nxxt | of | xˆvi",
           14
          ],
          [
           7,
           "are | of | 33 | as | sailor",
           6
          ],
          [
           8,
           "017 | 014 | 015 | 013 | 005",
           5
          ],
          [
           9,
           "refined | as | refinement | cot | is",
           4
          ]
         ],
         "hovertemplate": "<b>Topic %{customdata[0]}</b><br>%{customdata[1]}<br>Size: %{customdata[2]}",
         "legendgroup": "",
         "marker": {
          "color": "#B0BEC5",
          "line": {
           "color": "DarkSlateGrey",
           "width": 2
          },
          "size": {
           "bdata": "WigkFhQRDgYFBA==",
           "dtype": "i1"
          },
          "sizemode": "area",
          "sizeref": 0.05625,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "t7FpQC7vUMEVU4ZAyt2OQRLFa0BE64tBod5KwUytRcGe8kZAQ0WJQQ==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "iJxYwDwsgUFKJ3HAS2VYQKzBfsCiy0BABDWEQb7MhkEeCHvAHZ8rQA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -15.017152500152587,
          "y": 7.399905562400817,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 2.7599436283111576,
          "xshift": 10,
          "y": 19.377467536926268
         }
        ],
        "height": 650,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 2.7599436283111576,
          "x1": 2.7599436283111576,
          "y0": -4.577656412124634,
          "y1": 19.377467536926268
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -15.017152500152587,
          "x1": 20.537039756774902,
          "y0": 7.399905562400817,
          "y1": 7.399905562400817
         }
        ],
        "sliders": [
         {
          "active": 0,
          "pad": {
           "t": 50
          },
          "steps": [
           {
            "args": [
             {
              "marker.color": [
               [
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 0",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 1",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 2",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 3",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 4",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 5",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 6",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 7",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red",
                "#B0BEC5"
               ]
              ]
             }
            ],
            "label": "Topic 8",
            "method": "update"
           },
           {
            "args": [
             {
              "marker.color": [
               [
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "#B0BEC5",
                "red"
               ]
              ]
             }
            ],
            "label": "Topic 9",
            "method": "update"
           }
          ]
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Intertopic Distance Map</b>",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 650,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -15.017152500152587,
          20.537039756774902
         ],
         "title": {
          "text": ""
         },
         "visible": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -4.577656412124634,
          19.377467536926268
         ],
         "title": {
          "text": ""
         },
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "021ee40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "<pad>\n<pad>\n<pad>\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\n13\n\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\nand 6. Note that the attentions are very sharp for this word.\n14\n\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\n",
          "cies.\nFor instance, if prior knowledge is known about the\nproblem, then a nonlinearity (i.e. kernel) might be applied\nto the data to transform the data to a more appropriate naive\nbasis. For instance, in Figure 6a, one might examine the po-\nlar coordinate representation of the data. This parametric ap-\nproach is often termed kernel PCA.\nAnother direction is to impose more general statistical deﬁni-\ntions of dependency within a data set, e.g. requiring that data\nalong reduced dimensions be statistically independent. This\nclass of algorithms, termed, independent component analysis\n(ICA), has been demonstrated to succeed in many domains\nwhere PCA fails. ICA has been applied to many areas of sig-\nnal and image processing, but suffers from the fact that solu-\ntions are (sometimes) difﬁcult to compute.\nWriting this paper has been an extremely instructional expe-\nrience for me. I hope that this paper helps to demystify the\nmotivation and results of PCA, and the underlying assump-\ntions behind this important analysis technique. Please send\nme a note if this has been useful to you as it inspires me to\nkeep writing!\n7 When are second order dependencies sufﬁcient for revealing all dependen-\ncies in a data set? This statistical condition is met when the ﬁrst and second\norder statistics are sufﬁcient statistics of the data. This occurs, for instance,\nwhen a data set is Gaussian distributed.\nAppendix A: Linear Algebra\nThis section proves a few unapparent theorems in linear\nalgebra, which are crucial to this paper.\n1. The inverse of an orthogonal matrix is its transpose.\nLet A be an m×n orthogonal matrix where ai is the ith column\nvector. The ijth element of ATA is\n(ATA)ij = aiTaj =\n\u001a\n1 if i = j\n0 otherwise\nTherefore, because ATA = I, it follows that A−1 = AT.\n2. For any matrix A, ATA and AAT are symmetric.\n(AAT)T = ATTAT = AAT\n(ATA)T = ATATT = ATA\n",
          "x\ny\nFIG. 2 Simulated data of (x,y) for camera A. The signal and noise\nvariances σ2\nsignal and σ2\nnoise are graphically represented by the two\nlines subtending the cloud of data. Note that the largest direction\nof variance does not lie along the basis of the recording (xA,yA) but\nrather along the best-ﬁt line.\nLet’s take a closer examination of the data from camera\nA in Figure 2.\nRemembering that the spring travels in a\nstraight line, every individual camera should record motion in\na straight line as well. Therefore, any spread deviating from\nstraight-line motion is noise. The variance due to the signal\nand noise are indicated by each line in the diagram. The ratio\nof the two lengths measures how skinny the cloud is: possibil-\nities include a thin line (SNR ≫1), a circle (SNR = 1) or even\nworse. By positing reasonably good measurements, quantita-\ntively we assume that directions with largest variances in our\nmeasurement space contain the dynamics of interest. In Fig-\nure 2 the direction with the largest variance is not ˆxA = (1,0)\nnor ˆyA = (0,1), but the direction along the long axis of the\ncloud. Thus, by assumption the dynamics of interest exist\nalong directions with largest variance and presumably high-\nest SNR.\nOur assumption suggests that the basis for which we are\nsearching is not the naive basis because these directions (i.e.\n(xA,yA)) do not correspond to the directions of largest vari-\nance. Maximizing the variance (and by assumption the SNR)\ncorresponds to ﬁnding the appropriate rotation of the naive\nbasis. This intuition corresponds to ﬁnding the direction indi-\ncated by the line σ2\nsignal in Figure 2. In the 2-dimensional case\nof Figure 2 the direction of largest variance corresponds to the\nbest-ﬁt line for the data cloud. Thus, rotating the naive basis\nto lie parallel to the best-ﬁt line would reveal the direction of\nmotion of the spring for the 2-D case. How do we generalize\n",
          "%\nsignals - MxN matrix of projected data\n%\nPC - each column is a PC\n%\nV - Mx1 matrix of variances\n[M,N] = size(data);\n% subtract off the mean for each dimension\nmn =\nmean(data,2);\ndata = data - repmat(mn,1,N);\n% calculate the covariance matrix\ncovariance = 1 / (N-1) * data * data’;\n% find the eigenvectors and eigenvalues\n8 http://www.mathworks.com\n\n12\n[PC, V] = eig(covariance);\n% extract diagonal of matrix as vector\nV = diag(V);\n% sort the variances in decreasing order\n[junk, rindices] = sort(-1*V);\nV\n= V(rindices);\nPC = PC(:,rindices);\n% project the original data set\nsignals = PC’ * data;\nThis second version follows section 6 computing PCA\nthrough SVD.\nfunction [signals,PC,V] = pca2(data)\n% PCA2: Perform PCA using SVD.\n%\ndata - MxN matrix of input data\n%\n(M dimensions, N trials)\n%\nsignals - MxN matrix of projected data\n%\nPC - each column is a PC\n%\nV - Mx1 matrix of variances\n[M,N] = size(data);\n% subtract off the mean for each dimension\nmn =\nmean(data,2);\ndata = data - repmat(mn,1,N);\n% construct the matrix Y\nY = data’ / sqrt(N-1);\n% SVD does it all\n[u,S,PC] = svd(Y);\n% calculate the variances\nS = diag(S);\nV = S .* S;\n% project the original data\nsignals = PC’ * data;\n\n",
          "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n3\n\nScaled Dot-Product Attention\nMulti-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.\n3.2.1\nScaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\nthe matrix of outputs as:\nAttention(Q, K, V ) = softmax(QKT\n√dk\n)V\n(1)\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof\n1\n√dk . Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients 4. To counteract this effect, we scale the dot products by\n1\n√dk .\n3.2.2\nMulti-Head Attention\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\n",
          "1\n√nX must also be the principal\ncomponents.\nA\nB\nx\ny\nx\ny\nz\nθ\nFIG. 6 Example of when PCA fails (red lines). (a) Tracking a per-\nson on a ferris wheel (black dots). All dynamics can be described\nby the phase of the wheel θ, a non-linear combination of the naive\nbasis. (b) In this example data set, non-Gaussian distributed data and\nnon-orthogonal axes causes PCA to fail. The axes with the largest\nvariance do not correspond to the appropriate answer.\nprinciple component provides a means for comparing the rel-\native importance of each dimension. An implicit hope behind\nemploying this method is that the variance along a small num-\nber of principal components (i.e. less than the number of mea-\nsurement types) provides a reasonable characterization of the\ncomplete data set. This statement is the precise intuition be-\nhind any method of dimensional reduction – a vast arena of\nactive research. In the example of the spring, PCA identi-\nﬁes that a majority of variation exists along a single dimen-\nsion (the direction of motion ˆx), eventhough 6 dimensions are\nrecorded.\nAlthough PCA “works” on a multitude of real world prob-\nlems, any diligent scientist or engineer must ask when does\nPCA fail? Before we answer this question, let us note a re-\nmarkable feature of this algorithm. PCA is completely non-\nparametric: any data set can be plugged in and an answer\ncomes out, requiring no parameters to tweak and no regard for\nhow the data was recorded. From one perspective, the fact that\nPCA is non-parametric (or plug-and-play) can be considered\na positive feature because the answer is unique and indepen-\ndent of the user. From another perspective the fact that PCA\nis agnostic to the source of the data is also a weakness. For\ninstance, consider tracking a person on a ferris wheel in Fig-\nure 6a. The data points can be cleanly described by a single\nvariable, the precession angle of the wheel θ, however PCA\nwould fail to recover this variable.\n",
          "measure the ball’s position in a three-dimensional space (since\nwe live in a three dimensional world). Speciﬁcally, we place\nthree movie cameras around our system of interest. At 120 Hz\neach movie camera records an image indicating a two dimen-\nsional position of the ball (a projection). Unfortunately, be-\ncause of our ignorance, we do not even know what are the real\nx, y and z axes, so we choose three camera positions⃗a,⃗b and⃗c\nat some arbitrary angles with respect to the system. The angles\nbetween our measurements might not even be 90o! Now, we\nrecord with the cameras for several minutes. The big question\nremains: how do we get from this data set to a simple equation\narXiv:1404.1100v1  [cs.LG]  3 Apr 2014\n\n2\ncamera A\ncamera B\ncamera C\nFIG. 1 A toy example. The position of a ball attached to an oscillat-\ning spring is recorded using three cameras A, B and C. The position\nof the ball tracked by each camera is depicted in each panel below.\nof x?\nWe know a-priori that if we were smart experimenters, we\nwould have just measured the position along the x-axis with\none camera. But this is not what happens in the real world.\nWe often do not know which measurements best reﬂect the\ndynamics of our system in question. Furthermore, we some-\ntimes record more dimensions than we actually need.\nAlso, we have to deal with that pesky, real-world problem of\nnoise. In the toy example this means that we need to deal\nwith air, imperfect cameras or even friction in a less-than-ideal\nspring. Noise contaminates our data set only serving to obfus-\ncate the dynamics further. This toy example is the challenge\nexperimenters face everyday. Keep this example in mind as\nwe delve further into abstract concepts. Hopefully, by the end\nof this paper we will have a good understanding of how to\nsystematically extract x using principal component analysis.\nIII. FRAMEWORK: CHANGE OF BASIS\nThe goal of principal component analysis is to identify the\nmost meaningful basis to re-express a data set. The hope is\n",
          "Occasionally, rigorous mathematical proofs are necessary al-\nthough relegated to the Appendix. Although not as vital to the\ntutorial, the proofs are presented for the adventurous reader\nwho desires a more complete understanding of the math. My\nonly assumption is that the reader has a working knowledge\nof linear algebra. My goal is to provide a thorough discussion\nby largely building on ideas from linear algebra and avoiding\nchallenging topics in statistics and optimization theory (but\nsee Discussion). Please feel free to contact me with any sug-\ngestions, corrections or comments.\n∗Electronic address: jonathon.shlens@gmail.com\nII. MOTIVATION: A TOY EXAMPLE\nHere is the perspective: we are an experimenter. We are trying\nto understand some phenomenon by measuring various quan-\ntities (e.g. spectra, voltages, velocities, etc.) in our system.\nUnfortunately, we can not ﬁgure out what is happening be-\ncause the data appears clouded, unclear and even redundant.\nThis is not a trivial problem, but rather a fundamental obstacle\nin empirical science. Examples abound from complex sys-\ntems such as neuroscience, web indexing, meteorology and\noceanography - the number of variables to measure can be\nunwieldy and at times even deceptive, because the underlying\nrelationships can often be quite simple.\nTake for example a simple toy problem from physics dia-\ngrammed in Figure 1. Pretend we are studying the motion\nof the physicist’s ideal spring. This system consists of a ball\nof mass m attached to a massless, frictionless spring. The ball\nis released a small distance away from equilibrium (i.e. the\nspring is stretched). Because the spring is ideal, it oscillates\nindeﬁnitely along the x-axis about its equilibrium at a set fre-\nquency.\nThis is a standard problem in physics in which the motion\nalong the x direction is solved by an explicit function of time.\nIn other words, the underlying dynamics can be expressed as\na function of a single variable x.\nHowever, being ignorant experimenters we do not know any\nof this. We do not know which, let alone how many, axes\nand dimensions are important to measure. Thus, we decide to\n",
          "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\nattention and the parameter-free position representation and became the other person involved in nearly every\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\nour research.\n†Work performed while at Google Brain.\n‡Work performed while at Google Research.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n\n1\nIntroduction\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\ncomputation [32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\nare used in conjunction with a recurrent network.\n",
          "(1)\nwhere α is a function of the coordinates on the 2-sphere. The supertranslation moves each\npoint of I + a distance α to the future along the null geodesic generators of I +. Note\nthat the usual time and space translations form a four parameter sub-group of the inﬁnite\ndimensional supertranslations but they are not an invariant sub-group of the BMS group.\nListening to a lecture by Strominger on the BMS group, [6], at the Mitchell Institute\nfor Fundamental Physics and Astronomy workshop this April, I realized that stationary\nblack hole horizons also have supertranslations. In this case, the advanced time v is shifted\nby α, that is,\nv′ = v + α.\n(2)\nThe null geodesic generators of the horizon need not have a common past end point and\nthere is no canonical cross section of the horizon. The tangent vector l to the horizon is\ntaken to be normalized such that it agrees with the Killing vectors, of time translation\nand rotation, on the horizon.\nClassically, a black hole is independent of its past history. I shall assume this is also\ntrue in the quantum domain. How then can a black hole emit the information about the\nparticles that fell in? The answer I propose, as explained above, is that the information\nis stored in a supertranslation associated with the shift of the horizon that the ingoing\nparticles caused.\nThe supertranslations form a hologram of the ingoing particles. The varying shifts\nalong each generator of the horizon leave an imprint on the outgoing particles in a chaotic\nbut deterministic manner.\nThere is no loss of information.\nNote that although the\ndiscussion in this paper focuses on the asymptotically ﬂat case, this proposal also works\nfor black holes on arbitrary backgrounds, e.g., in the presence of a nonzero cosmological\nconstant.\nPolchinski recently used a shock wave approximation to calculate the shift on a gen-\nerator of the horizon caused by an ingoing wave packet [7]. Even though the calculation\n2\n\nmay require some corrections, this shows in principle that the ingoing particles determine\na supertranslation of the black hole horizon. This in turn, will determine varying delays in\n",
          "are\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\n<pad>\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\nsentence. We give two such examples above, from two different heads from the encoder self-attention\nat layer 5 of 6. The heads clearly learned to perform different tasks.\n15\n\n",
          "this notion to an arbitrary number of dimensions? Before we\napproach this question we need to examine this issue from a\nsecond perspective.\nB. Redundancy\nFigure 2 hints at an additional confounding factor in our data\n- redundancy. This issue is particularly evident in the example\nof the spring. In this case multiple sensors record the same\ndynamic information. Reexamine Figure 2 and ask whether\nit was really necessary to record 2 variables. Figure 3 might\nreﬂect a range of possibile plots between two arbitrary mea-\nsurement types r1 and r2. The left-hand panel depicts two\nlow redundancy\nhigh redundancy\nr1\nr2\nr1\nr2\nr1\nr2\nFIG. 3 A spectrum of possible redundancies in data from the two\nseparate measurements r1 and r2. The two measurements on the\nleft are uncorrelated because one can not predict one from the other.\nConversely, the two measurements on the right are highly correlated\nindicating highly redundant measurements.\nrecordings with no apparent relationship. Because one can not\npredict r1 from r2, one says that r1 and r2 are uncorrelated.\nOn the other extreme, the right-hand panel of Figure 3 de-\npicts highly correlated recordings. This extremity might be\nachieved by several means:\n• A plot of (xA,xB) if cameras A and B are very nearby.\n• A plot of (xA, ˜xA) where xA is in meters and ˜xA is in\ninches.\nClearly in the right panel of Figure 3 it would be more mean-\ningful to just have recorded a single variable, not both. Why?\nBecause one can calculate r1 from r2 (or vice versa) using the\nbest-ﬁt line. Recording solely one response would express the\ndata more concisely and reduce the number of sensor record-\nings (2 →1 variables). Indeed, this is the central idea behind\ndimensional reduction.\nC. Covariance Matrix\nIn a 2 variable case it is simple to identify redundant cases by\nﬁnding the slope of the best-ﬁt line and judging the quality of\nthe ﬁt. How do we quantify and generalize these notions to\n",
          "P is an orthonormal matrix. Why is this assumption easiest?\nEnvision how PCA works. In our simple example in Figure 2,\nP acts as a generalized rotation to align a basis with the axis\nof maximal variance. In multiple dimensions this could be\nperformed by a simple algorithm:\n1. Select a normalized direction in m-dimensional space\nalong which the variance in X is maximized. Save this\nvector as p1.\n2. Find another direction along which variance is maxi-\nmized, however, because of the orthonormality condi-\ntion, restrict the search to all directions orthogonal to\nall previous selected directions. Save this vector as pi\n3. Repeat this procedure until m vectors are selected.\nThe resulting ordered set of p’s are the principal components.\nIn principle this simple algorithm works, however that would\nbely the true reason why the orthonormality assumption is ju-\ndicious. The true beneﬁt to this assumption is that there exists\n\n6\nan efﬁcient, analytical solution to this problem. We will dis-\ncuss two solutions in the following sections.\nNotice what we gained with the stipulation of rank-ordered\nvariance. We have a method for judging the importance of\nthe principal direction. Namely, the variances associated with\neach direction pi quantify how “principal” each direction is\nby rank-ordering each basis vector pi according to the corre-\nsponding variances.We will now pause to review the implica-\ntions of all the assumptions made to arrive at this mathemati-\ncal goal.\nE. Summary of Assumptions\nThis section provides a summary of the assumptions be-\nhind PCA and hint at when these assumptions might perform\npoorly.\nI. Linearity\nLinearity frames the problem as a change of ba-\nsis. Several areas of research have explored how\nextending these notions to nonlinear regimes (see\nDiscussion).\nII. Large variances have important structure.\nThis assumption also encompasses the belief that\nthe data has a high SNR. Hence, principal compo-\nnents with larger associated variances represent\ninteresting structure, while those with lower vari-\nances represent noise. Note that this is a strong,\nand sometimes, incorrect assumption (see Dis-\n",
          "that this new basis will ﬁlter out the noise and reveal hidden\nstructure. In the example of the spring, the explicit goal of\nPCA is to determine: “the dynamics are along the x-axis.” In\nother words, the goal of PCA is to determine that ˆx, i.e. the\nunit basis vector along the x-axis, is the important dimension.\nDetermining this fact allows an experimenter to discern which\ndynamics are important, redundant or noise.\nA. A Naive Basis\nWith a more precise deﬁnition of our goal, we need a more\nprecise deﬁnition of our data as well. We treat every time\nsample (or experimental trial) as an individual sample in our\ndata set. At each time sample we record a set of data consist-\ning of multiple measurements (e.g. voltage, position, etc.). In\nour data set, at one point in time, camera A records a corre-\nsponding ball position (xA,yA). One sample or trial can then\nbe expressed as a 6 dimensional column vector\n⃗X =\n\n\nxA\nyA\nxB\nyB\nxC\nyC\n\n\nwhere each camera contributes a 2-dimensional projection of\nthe ball’s position to the entire vector ⃗X. If we record the ball’s\nposition for 10 minutes at 120 Hz, then we have recorded 10×\n60×120 = 72000 of these vectors.\nWith this concrete example, let us recast this problem in ab-\nstract terms.\nEach sample ⃗X is an m-dimensional vector,\nwhere m is the number of measurement types. Equivalently,\nevery sample is a vector that lies in an m-dimensional vec-\ntor space spanned by some orthonormal basis. From linear\nalgebra we know that all measurement vectors form a linear\ncombination of this set of unit length basis vectors. What is\nthis orthonormal basis?\nThis question is usually a tacit assumption often overlooked.\n",
          "section we compare the stability under subsampling of UMAP, LargeVis and\nt-SNE (the three stochastic dimension reduction techniques considered).\nTo measure the stability of an embedding we make use of the nor-\nmalized Procrustes distance to measure the distance between two poten-\ntially comparable distributions. Given two datasets X = {x1, . . . , xN} and\nY = {y1, . . . , yN} such that xi corresponds to yi, we can deﬁne the Pro-\ncustes distance between the datasets dP (X, Y ) in the following manner.\nDetermine Y ′ = {y1′, . . . , yN ′} the optimal translation, uniform scaling,\nand rotation of Y that minimizes the squared error PN\ni=1(xi −yi′)2, and\ndeﬁne\ndP (X, Y ) =\nv\nu\nu\nt\nN\nX\ni=1\n(xi −yi′)2.\nSince any measure that makes use of distances in the embedding space is\npotentially sensitive to the extent or scale of the embedding, we normal-\nize the data before computing the Procrustes distance by dividing by the\naverage norm of the embedded dataset. In Figure 7 we visualize the re-\nsults of using Procrustes alignment of embedding of sub-samples for both\n33\n\nFigure 6: kNN Classiﬁer accuracy for varying values of k over the embedding\nspaces of Shutle, MNIST and Fashion-MNIST datasets. Accuracy scores are\ngiven for each fold of a 10-fold cross-validation for Shutle, and 20-fold cross-\nvalidation for MNIST and Fashion-MNIST, for each of PCA, Laplacian Eigen-\nmaps, LargeVis, t-SNE and UMAP. UMAP performs beter than the other algo-\nrithms for large k, particularly on the Shutle dataset. For Fashion-MNIST UMAP\nprovides slightly poorer accuracy than t-SNE and LargeVis at small scales, but is\ncompetitive at larger k values.\n",
          "Table 27: Pre-training data – 1.82M examples in total\n• ASR: Existing datasets are used as shown in Table 27. An example prompt is \"Transcribe\nthis audio\".\n36\n\nTechnical Report\nDataset\nTask\nNew\n#Examples\nQA pairs taken from SALMONN used in SFT-v1, SFT-v2, SFT-v3\nLibriSpeech (Panayotov et al., 2015)\nQA (Speech-En)\n✗\n40.0K\nAudioCaps (Kim et al., 2019)\nQA (Audio)\n✗\n30.0K\nQA pairs taken from LTU-AS used in SFT-v1, SFT-v2, SFT-v3\nLibriTTS (Zen et al., 2019)\nQA (Speech-En)\n✗\n21.1K\nIEMOCAP (Busso et al., 2008)\nQA (Speech-En)\n✗\n4.3K\nFSD50K (Fonseca et al., 2021)\nQA (Audio)\n✗\n11.5K\nAudioSet (Gemmeke et al., 2017)\nQA (Audio-Speech)\n✗\n20.0K\nAS20k (Hershey et al., 2021)\nQA (Audio-Speech)\n✗\n12.0K\nASR, Translation, Audio Caption, QA used in SFT-v2, SFT-v3\nLibriSpeech (Panayotov et al., 2015)\nASR (En)\n✗\n32.0K\nCommonVoice-Th (Ardila et al., 2020)\nASR (Th)\n✗\n52.0K\nSelfInstruct-Th\nASR (Th)\n✓\n18.9K\nAudioCaps(Gemini)\nAudio Caption\n✓\n48.3K\nCovost2 (Wang et al., 2021)\nTranslate (X2Th)\n✗\n30.0K\nCommonVoice-Th (Ardila et al., 2020)\nTranslate (Th2X)\n✗\n7.3K\n",
          "focus on finance and general Thai books, we present our systematic Agentics methods to\nimprove and enable tasks such as ChatQA, Document VQA, Data Visualisation QA, and\nImage Captioning within documents. This pipeline is designed to follow a structured and\nsystematic approach:\n1. Data Preparation: Initially, data from the Thai Economic Report-Finance Research\nand the Thai Book are collected and organised in Section 4.3.1.\n28\n\nTechnical Report\nDataset\nTask\n#Examples\nBase Data\nCambrian-737K\nMulti-task\n737,000\n→LLaVA-665K Liu et al. (2023a)\nGeneral vision tasks\n665,000\n−→COCO (Lin et al., 2015)\nImage Captioning\n360,000\n−→Visual Genome (Krishna et al., 2016) Image Captioning\n86,000\n−→GQA (Hudson & Manning, 2019)\nVQA\n72,000\n−→ChartQA (Masry et al., 2022)\nChart Understanding\n28,000\n−→OCR-VQA (Mishra et al., 2019)\nText VQA\n80,000\n→AI2D (Kembhavi et al., 2016)\nDiagram Understanding\n15,501\n→DocVQA (Mathew et al., 2020)\nDocument VQA\n14,999\n→DVQA (Kafle et al., 2018)\nData Visualization QA\n13,000\nTranslated Data (Top 10% COMET-scored)\nCOCO\nImage Captioning\n36,000\nVisual Genome\nDense Captioning\n8,600\nGQA\nVisual Question Answering\n7,200\nDistilled Data (Thai responses)\nOCR-VQA\nText VQA\n8,000\nDocVQA\nDocument VQA\n1,500\nAI2D\nDiagram Understanding\n1,500\nChartQA\nChart Understanding\n2,800\nDVQA\nData Visualization QA\n1,300\nThai OCR Data\nEcon Reports - Fin Research\nMulti-task\n41,888\nThai Book\n",
          "A. Limits and Statistics of Dimensional Reduction\nA deeper appreciation of the limits of PCA requires some con-\nsideration about the underlying assumptions and in tandem,\na more rigorous description of the source of data.\nGener-\nally speaking, the primary motivation behind this method is\nto decorrelate the data set, i.e. remove second-order depen-\ndencies. The manner of approaching this goal is loosely akin\nto how one might explore a town in the Western United States:\ndrive down the longest road running through the town. When\n\n10\none sees another big road, turn left or right and drive down\nthis road, and so forth. In this analogy, PCA requires that each\nnew road explored must be perpendicular to the previous, but\nclearly this requirement is overly stringent and the data (or\ntown) might be arranged along non-orthogonal axes, such as\nFigure 6b. Figure 6 provides two examples of this type of data\nwhere PCA provides unsatisfying results.\nTo address these problems, we must deﬁne what we consider\noptimal results. In the context of dimensional reduction, one\nmeasure of success is the degree to which a reduced repre-\nsentation can predict the original data. In statistical terms,\nwe must deﬁne an error function (or loss function). It can\nbe proved that under a common loss function, mean squared\nerror (i.e. L2 norm), PCA provides the optimal reduced rep-\nresentation of the data. This means that selecting orthogonal\ndirections for principal components is the best solution to pre-\ndicting the original data. Given the examples of Figure 6, how\ncould this statement be true? Our intuitions from Figure 6\nsuggest that this result is somehow misleading.\nThe solution to this paradox lies in the goal we selected for the\nanalysis. The goal of the analysis is to decorrelate the data, or\nsaid in other terms, the goal is to remove second-order depen-\ndencies in the data. In the data sets of Figure 6, higher order\ndependencies exist between the variables. Therefore, remov-\ning second-order dependencies is insufﬁcient at revealing all\nstructure in the data.7\nMultiple solutions exist for removing higher-order dependen-\n",
          "The Information Paradox for Black Holes.\nS. W. Hawking,\nDAMTP,\nCentre for Mathematical Sciences,\nUniversity of Cambridge,\nWilberforce Road,\nCambridge, CB3 0WA\nUK.\nABSTRACT\nI propose that the information loss paradox can be resolved by considering the\nsupertranslation of the horizon caused by the ingoing particles. Information\ncan be recovered in principle, but it is lost for all practical purposes.\nTalk given on 28 August 2015 at “Hawking Radiation”, a conference held at KTH Royal Institute of\nTechnology, Stockholm.\narXiv:1509.01147v1  [hep-th]  3 Sep 2015\n\nForty years ago I wrote a paper, “Breakdown of Predictability in Gravitational Col-\nlapse” [1], in which I claimed there would be loss of predictability of the ﬁnal state if the\nblack hole evaporated completely. This was because one could not measure the quantum\nstate of what fell into the black hole. The loss of information would have meant the\noutgoing radiation is in a mixed state and the S-Matrix was non-unitary.\nSince the publication of that paper, the AdS/CFT correspondence has shown there\nis no information loss. This is the information paradox: How does the information of\nthe quantum state of the infalling particles re-emerge in the outgoing radiation? This\nhas been an outstanding problem in theoretical physics for the last forty years. Despite\na large number of papers (see reference [2, 3] for a list), no satisfactory resolution has\nbeen found. I now propose that the information is stored, not in the interior of the black\nhole (as one might expect), but on its boundary, the event horizon. This is a form of\nholography.\nThe concept of supertranslations was introduced in 1962 by Bondi, Metzner and Sachs\n(BMS) [4, 5], to describe the asymptotic isometries of an asymptotically ﬂat spacetime\nin the presence of gravitational radiation. In other words the BMS group describes the\nsymmetry on I +. For an asymptotically ﬂat spacetime, a supertranslation α shifts the\nretarded time u to\nu′ = u + α,\n",
          "a stronger semantic relationship and a high probability of co-occurring within the given topic’s\ncontext. The overall topic coherence score is computed by averaging these individual topic coherence\nscores. Topic Coherence (TC) is computed for each topic model, varying the number of topics from\n10 to 50 with increments of 10. We averaged the outputs from three separate runs at each interval\nto enhance consistency, resulting in an average score derived from a cumulative total of 15 distinct\nruns using fixed parameters for HDBSCAN and UMAP. Table 1 shows the four evaluation metric\nresults.\n4.4. Model Comparison\nWe compare our model with the existing traditional topic modeling approaches and ChatGPT.\n6\n\nDatasets\nMetrics\n20news\ngroup\nBBC\nNews\nTrump\nC V\n0.735\n0.651\n0.594\nC npmi\n0.211\n0.191\n0.205\nU mass\n9.34\n8.78\n7.94\nC uci\n0.401\n0.376\n0.322\nTable 1: Topic coherence scores obtained using different\nmodel evaluation metrics using our approach.\n20 Newsgroup Dataset\nModels (years)\n(C V)\n(C npmi)\nLDA (2003)\n0.459\n0.056\nCTM (2006)\n0.538\n0.042\nETM (2020)\n0.525\n0.095\nBERTopic (2022)\n0.593\n0.170\nOur Model\n0.735\n0.211\nTable 2: Model comparison with C V and C npmi topic\ncoherence metrics results\n4.4.1. Traditional Models\nWe conduct extensive performance comparisons between our proposed model and well-known,\nestablished models, including (LDA) [8] Latent Dirichlet Allocation, (CTM) Correlated Topic Model\n[13], ETM (Topic Modeling in Embedding Spaces) [12], and BERTopic [11].\nTopic Coherence is computed for each topic model, varying the number of topics from 10 to\n50 with increments of 10. We averaged the outputs from three separate runs at each interval to\nenhance consistency, resulting in an average score derived from a cumulative total of 15 distinct\nruns. Table 2 shows the model comparison results.\n",
          "[1, 3, 62], and only some of these non-English benchmarks such as BHASA [19] include Thai.\nNevertheless, the evaluation datasets in BHASA are still based on multi-lingual datasets or publicly\navailable Thai datasets at a limited scale. To better evaluate the Thai culture and languages of LLMs,\nwe develop ThaiExam, a benchmark comprising Thai multiple-choice examinations as follows:\n• ONET: The Ordinary National Educational Test (ONET) is an examination for students in Thailand.\nWe select the grade-12 ONET exam, which comprises 5 subjects and each question has 5 choices.\nThese subjects are Thai, English, Mathematics, Social Studies, and Science. We extracted these\nquestions from the official 2021 ONET example, amounting to a total of 170 questions and options.\n• IC: The Investment Consultant (IC) examination, a licensing test for investment professionals in\nThailand developed by the Stock Exchange of Thailand (SET), features 4 choices per question. We\nextracted questions for levels 1, 2, and 3 from the official SET website, resulting in a total of 95\nquestions and options.\n• TGAT: The Thai General Aptitude Test (TGAT), a national high school examination in Thailand,\nfocuses on critical and logical thinking skills, as well as proficiency in the English language. We\ncollected a total of 90 questions and answers. The TGAT consists of four choices per question.\n• TPAT-1: The Thai Professional Aptitude Test 1 (TPAT-1) is a national high school examination\nin Thailand that assesses students’ professional skills requirement in medical schools. This subset\ncontains reasoning and medical ethics. We collected a total of 116 questions and answers. The\nTPAT-1 consists of 5 choices per question.\n• A-Level: An academic knowledge assessment examination (Applied Knowledge Level) that covers\ngeneral foundational subjects taught in schools. The content assessed in this examination aligns with\nthe curriculum guidelines and emphasizes the practical application of knowledge in daily life. We\ncollected a total of 175 questions and answers.\nIn addition to ThaiExam, we use existing datasets including XNLI (a cross-lingual textual entail-\nment dataset) [8], XCOPA (a multilingual dataset for causal commonsense reasoning) [43], and\n",
          "We can note the form of each column of Y.\nyi =\n\n\np1 ·xi\n...\npm ·xi\n\n\nWe recognize that each coefﬁcient of yi is a dot-product of\nxi with the corresponding row in P. In other words, the jth\ncoefﬁcient of yi is a projection on to the jth row of P. This is\nin fact the very form of an equation where yi is a projection\non to the basis of {p1,...,pm}. Therefore, the rows of P are a\nnew set of basis vectors for representing of columns of X.\nC. Questions Remaining\nBy assuming linearity the problem reduces to ﬁnding the ap-\npropriate change of basis. The row vectors {p1,...,pm} in\nthis transformation will become the principal components of\nX. Several questions now arise.\n• What is the best way to re-express X?\n• What is a good choice of basis P?\nThese questions must be answered by next asking ourselves\nwhat features we would like Y to exhibit. Evidently, addi-\ntional assumptions beyond linearity are required to arrive at\na reasonable result. The selection of these assumptions is the\nsubject of the next section.\nIV. VARIANCE AND THE GOAL\nNow comes the most important question: what does best ex-\npress the data mean? This section will build up an intuitive\nanswer to this question and along the way tack on additional\nassumptions.\nA. Noise and Rotation\nMeasurement noise in any data set must be low or else, no\nmatter the analysis technique, no information about a signal\ncan be extracted. There exists no absolute scale for noise but\nrather all noise is quantiﬁed relative to the signal strength. A\ncommon measure is the signal-to-noise ratio (SNR), or a ratio\nof variances σ2,\nSNR =\nσ2\nsignal\nσ2\nnoise\n.\nA high SNR (≫1) indicates a high precision measurement,\nwhile a low SNR indicates very noisy data.\n\n4\nσ 2\nsignal\nσ 2\nnoise\n",
          "A Tutorial on Principal Component Analysis\nJonathon Shlens∗\nGoogle\nResearch\nMountain View, CA 94043\n(Dated: April 7, 2014; Version 3.02)\nPrincipal component analysis (PCA) is a mainstay of modern data analysis - a black box that is widely used\nbut (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This\nmanuscript focuses on building a solid intuition for how and why principal component analysis works. This\nmanuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind PCA. This\ntutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The\nhope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of PCA as\nwell as the when, the how and the why of applying this technique.\nI. INTRODUCTION\nPrincipal component analysis (PCA) is a standard tool in mod-\nern data analysis - in diverse ﬁelds from neuroscience to com-\nputer graphics - because it is a simple, non-parametric method\nfor extracting relevant information from confusing data sets.\nWith minimal effort PCA provides a roadmap for how to re-\nduce a complex data set to a lower dimension to reveal the\nsometimes hidden, simpliﬁed structures that often underlie it.\nThe goal of this tutorial is to provide both an intuitive feel for\nPCA, and a thorough discussion of this topic. We will begin\nwith a simple example and provide an intuitive explanation\nof the goal of PCA. We will continue by adding mathemati-\ncal rigor to place it within the framework of linear algebra to\nprovide an explicit solution. We will see how and why PCA\nis intimately related to the mathematical technique of singular\nvalue decomposition (SVD). This understanding will lead us\nto a prescription for how to apply PCA in the real world and an\nappreciation for the underlying assumptions. My hope is that\na thorough understanding of PCA provides a foundation for\napproaching the ﬁelds of machine learning and dimensional\nreduction.\nThe discussion and explanations in this paper are informal in\nthe spirit of a tutorial. The goal of this paper is to educate.\n",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": {
          "bdata": "88AKQUfcDkGlow9BAuIxQR2zMkGbsgxBLFINQfV3DEFuPUNBM3cOQVRQDEFvmA9BPsINQbJlEUEodDBBxGFCQV2TQUHZYwxB2J0SQRa7O0HYD1FBeDkSQc9CC0Fbjh5B",
          "dtype": "f4"
         },
         "y": {
          "bdata": "Q9ZQwB3SVsD/5lTAPV5DwDsDsr5Kfk/AvEhOwDyTUcATg6U/45JGwIFgTsBIOFrAkLlUwEIHSMA5J5C/RyaOQAqAkEB1tlDAuDs7wM+WPEASaDJABIxRwLqfSsCWI86/",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "OpenThaiGPT (Yuenyong et al., 2024), and Pathumma (NECTEC, 2024).\nTo continue our commitment in advancing Thai foundation models, this work introduces a\nnew series of state-of-the-art Thai language and multimodal models, Typhoon2. Follow-\ning our previous releases, these models are optimized for Thai and English, building on\nopen-source models such as Llama 3 and Qwen2.5. The text models, Typhoon2-Text, are\nimproved over Typhoon 1.5 in various aspects, including data filtering techniques for pre-\ntraining, complex instruction data development for improved post-training, long context,\nand function calling capabilities of the models. These text models are also now available in\na range of sizes, consisting of 1B, 3B, 7B, 8B, and 70B parameters. We offer both pre-trained\nand instruction-tuned variants for each size. In addition, we introduce Typhoon2-Safety a\nsafety text classifier designed to detect Thai-sensitive content and enhance the security of\nLM-integrated systems.\nFurthermore, the Typhoon2 series is multimodal. The vision model, Typhoon2-Vision,\nbuilds on the first Typhoon-Vision model by enhancing Thai document understanding\ncapabilities, such as optical character recognition (OCR). The audio model, Typhoon2-Audio,\nextends the first Typhoon-Audio model, evolving into an end-to-end speech processing\nand generation model capable of understanding audio, speech, and text, while generating\ntext and speech outputs in parallel. This report provides details and insights from our\ndevelopment. We make the weights of all models publicly available on Hugging Face Hub\nwhere the summary of our release is shown in Table 1.\n1In this paper, we do not make a distinction between open-source and open-weights. The term\nopen is used for referring to both options.\n4\n\nTechnical Report\n2\nPre-training\nThis section of the report details the pre-training phase of Typhoon 2, which continues to\nbuild on the same motivation as its predecessor: to construct the highest-quality corpus that\nrepresents the Thai culture and language. Typhoon 2 builds upon the foundation laid by\nthe previous iteration of Typhoon. The primary objective of this iteration is to develop a\n",
          "(3)\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\nwarmup_steps = 4000.\n5.4\nRegularization\nWe employ three types of regularization during training:\n7\n\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\nModel\nBLEU\nTraining Cost (FLOPs)\nEN-DE\nEN-FR\nEN-DE\nEN-FR\nByteNet [18]\n23.75\nDeep-Att + PosUnk [39]\n39.2\n1.0 · 1020\nGNMT + RL [38]\n24.6\n39.92\n2.3 · 1019\n1.4 · 1020\nConvS2S [9]\n25.16\n40.46\n9.6 · 1018\n1.5 · 1020\nMoE [32]\n26.03\n40.56\n2.0 · 1019\n1.2 · 1020\nDeep-Att + PosUnk Ensemble [39]\n40.4\n8.0 · 1020\nGNMT + RL Ensemble [38]\n26.30\n41.16\n1.8 · 1020\n1.1 · 1021\nConvS2S Ensemble [9]\n26.36\n41.29\n7.7 · 1019\n1.2 · 1021\nTransformer (base model)\n27.3\n38.1\n3.3 · 1018\nTransformer (big)\n28.4\n41.8\n2.3 · 1019\nResidual Dropout\nWe apply dropout [33] to the output of each sub-layer, before it is added to the\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\nPdrop = 0.1.\nLabel Smoothing\n",
          "more diverse and high-quality dataset in Thai for pre-training. This goal is accomplished by\nimplementing multiple data-gathering pipelines designed to target various domains and\nsubsets within the Thai language.\n2.1\nData Source & Typhoon1-Corpus\nThis section outlines the preparation process for Typhoon 1, which can be summarized in\nfive steps. The first four steps involve preparing the base corpus, which will serve as a\nreference dataset used for filtering additional data in Section 2.2. The fifth step focuses on\nselecting the general Typhoon1-Corpus (Pipatanakul et al., 2023).\n2.1.1\nBase Corpus Preparation\nStep1 - Scaling the Data: We initiate the process by increasing the number of Common\nCrawl (CommonCrawl) packages compared to the previous iteration, where we process a total\nof 40 packs of the CommonCrawl data.\nStep2 - Text Extraction: Although CommonCrawl provides a pre-extracted WET subset, several\nstudies suggest that WET files exhibit lower quality compared to WARC files extracted using\nexternal tools such as Trafilatura (Li et al., 2024a; Penedo et al., 2023). In our study, we begin\nwith a total of 40 packs of Thai CommonCrawl data with a cut-off date of September 2023\nand perform HTML extraction from scratch using Trafilatura2. This process results in a\nsignificantly larger dataset, comprising approximately 3 TB of Thai text, or approximately\n200 billion Llama3 tokens.\nStep3 - Strict Deduplication: To ensure data quality and minimize redundancy, we imple-\nment a fuzzy deduplication pipeline using MinHash and locality-sensitive hashing (LSH)\nalgorithms.3\nStep4 - Heuristic Filtering: To filter out pages containing excessive search engine opti-\nmization (SEO) content, very short documents, and low-quality texts, we evaluate each\nline using signals such as the ratio of numbers to text and the punctuation density. At\nthe document level, document filtering is done based on other metrics, including newline\nratios and overall document length. After deduplication and heuristic filtering, we have\napproximately 44B tokens of Thai text.\n2.1.2\nTyphoon 1 General Corpus\n",
          "OpenThaiGPT\nWangChanGLM\nEfficiency\n262%\n100%\n93%\n89%\n326%\n350%\n305%\nTable 2: Token efficiency with respect to GPT-4. *Based on the newmm tokenizer.\n3.3\nPretraining Details\nInitial Experiments\nIn the initial experiments, we explore various training techniques and base models on a subset of\npretrained data, comprising approximately 500 million tokens. We investigate the following options:\n• Base Model: We compare base models, including Llama2-7B, Llama2-13B [55], CodeLlama-\n34B [48], and Mistral-7B [16] where our criterion is the perplexity. This investigation shows that\nMistral-7B achieves the lowest perplexity. Therefore, Mistral-7B is selected as our base model. Note\nthat we perform training on the embeddings and the language modeling head only.\n• Training Strategy: We compare Low-Rank Adaption (LoRA) [15] and full-weight training on\nMistral-7B. Our experiments demonstrate that LoRA yields a lower final loss. Additionally, we tried a\ntwo-stage training approach where the embeddings are first trained on full-weight followed by LoRA.\nHowever, this setting did not show a significant improvement over using LoRA from the beginning.\n• Batch size: We observed an instability in the training loss when using a batch size of 500k tokens,\nand we empirically found that increasing the batch size to 2 million tokens can stabilize training.\n4\n\nFinal Model\nBased on the initial experiments, we continue pretraining the extended embeddings and the language\nmodelling head of Mistral-7B using LoRA. We use the AdamW optimizer [25] with a cosine\nscheduled learning rate initialized at 4e-4. We apply gradient clipping with a threshold of 1.0.\n3.4\nEvaluation: Thai Knowledge of Pretrained Models\nThe NLP community has developed and released challenging, diverse, and holistic benchmarks such\nas BIG-bench [4] and HELM [21]. However, most of these benchmarks focus only on performance\nin English. Although non-English benchmarks have been proposed, they are still lacking in number\n",
          "Typhoon: Thai Large Language Models\nKunat Pipatanakul, Phatrasek Jirabovonvisut, Potsawee Manakul\nSittipong Sripaisarnmongkol, Ruangsak Patomwong\nPathomporn Chokchainant, Kasima Tharnpipitchai\nSCB 10X\nAbstract\nTyphoon is a series of Thai large language models (LLMs) developed specifically\nfor the Thai language. This technical report presents challenges and insights\nin developing Thai LLMs, including data preparation, pretraining, instruction-\ntuning, and evaluation. As one of the challenges of low-resource languages is the\namount of pretraining data, we apply continual training to transfer existing world\nknowledge from a strong LLM. To evaluate the Thai knowledge encapsulated\nin each model from the pretraining stage, we develop ThaiExam, a benchmark\nbased on examinations for high-school students and investment professionals in\nThailand. In addition, we fine-tune Typhoon to follow Thai instructions, and we\nevaluate instruction-tuned models on Thai instruction datasets as well as translation,\nsummarization, and question-answering tasks. Experimental results on a suite of\nThai benchmarks show that Typhoon outperforms all open-source Thai language\nmodels, and its performance is on par with GPT-3.5 in Thai while having only 7\nbillion parameters and being 2.62 times more efficient in tokenizing Thai text.\nModel Weights: https://huggingface.co/scb10x/typhoon-7b\n1\nIntroduction\nLarge Language Models (LLMs) have demonstrated strong zero-shot or few-shot capabilities on\na wide range of natural language processing (NLP) tasks [6, 55]. These LLMs are auto-regressive\ntransformers, which are pretrained on a large quantity of self-supervised text data. Most of the\nmajor large language models (LLMs) such as GPT-2/3/4 [45, 6, 35], Llama-1/2 [54, 55], Falcon [40],\nMistral [16], are pretrained primarily on English-centric corpora. In addition, LLMs have been\npretrained on specific languages or domains such as Chinese [61], finance [59], or code [48].\n",
          "recurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\nthe approach we take in our model.\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\nand semantic structure of the sentences.\n5\nTraining\nThis section describes the training regime for our models.\n5.1\nTraining Data and Batching\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\ntarget tokens.\n5.2\nHardware and Schedule\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\n(3.5 days).\n5.3\nOptimizer\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\nrate over the course of training, according to the formula:\nlrate = d−0.5\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\n",
          "phase trains only the adapter to align audio and textual representations. We use ASR and\naudio captioning data shown in Table 27 in this phase.\n2) Supervised Fine-Tuning (SFT): This phase trains both the adapter and the LoRA weight (Hu\net al., 2022) of the LLM (r=8, α=32). During SFT, the model is trained on diverse tasks and\ninstruction prompts to enhance its instruction-following capabilities. Table 28 presents the\nfinal SFT data configuration, and Section 5.2.4 presents our findings from SFT data mixture.\n5.2.2\nData\nEach example comprises an {audio, textual_prompt} pair. For pre-training data (Table 27), a\nfew task-specific prompts (e.g., “Transcribe this audio\" for ASR) are predefined, with the\nprompt language matching the response language. Since no Thai audio-captioning data\nexists, AudioCaps and Clotho are translated into Thai. For SFT data (Table 28), 10% of\nprompts and responses in existing QA data are translated into Thai. To enhance prompt\ndiversity, GPT-4o generates prompts for ASR, translation, and audio-captioning tasks. For\nspeech instruction following, where the model listens and responds to spoken instructions,\nthe prompt is null. Newly created datasets, grouped by tasks, are described next:\nDataset\nTask\nLang\n#Examples\nLibriSpeech (Panayotov et al., 2015)\nASR\nEn\n281K\nGigaSpeech-M (Chen et al., 2021a)\nASR\nEn\n900K\nCommonVoice-Th (Ardila et al., 2020)\nASR\nTh\n436K\nFleurs-Th (Conneau et al., 2022)\nASR\nTh\n7.8K\nVulcan+Elderly+Gowajee\nASR\nTh\n65.1K\nAudioCaps (Kim et al., 2019)\nAudio Caption\nEn+Th\n48.3K+48.3K\nClotho (Drossos et al., 2020)\nAudio Caption\nEn+Th\n19.2K+19.2K\n",
          "Technical Report\nTyphoon 2: A Family of Open Text and Multimodal\nThai Large Language Models\nKunat Pipatanakul, Potsawee Manakul, Natapong Nitarach,\nWarit Sirichotedumrong, Surapon Nonesung, Teetouch Jaknamon,\nParinthapat Pengpun, Pittawat Taveekitworachai, Adisai Na-Thalang,\nSittipong Sripaisarnmongkol, Krisanapong Jirayoot, Kasima Tharnpipitchai\nSCB 10X, SCBX\ncontact@opentyphoon.ai\nAbstract\nThis paper introduces Typhoon 2, a series of text and multimodal large\nlanguage models optimized for the Thai language. The series includes\nmodels for text, vision, and audio. Typhoon2-Text builds on state-of-the-art\nopen models, such as Llama 3 and Qwen2, and we perform continual pre-\ntraining on a mixture of English and Thai data. We employ post-training\ntechniques to enhance Thai language performance while preserving the\nbase models’ original capabilities. We release text models across a range of\nsizes, from 1 to 70 billion parameters, available in both base and instruction-\ntuned variants. To guardrail text generation, we release Typhoon2-Safety,\na classifier enhanced for Thai cultures and language. Typhoon2-Vision\nimproves Thai document understanding while retaining general visual\ncapabilities, such as image captioning. Typhoon2-Audio introduces an end-\nto-end speech-to-speech model architecture capable of processing audio,\nspeech, and text inputs and generating both text and speech outputs.\nSummary of the Typhoon2 Models\nModel\nBase Model\nLink to HuggingFace\nText\nTyphoon2-1B-Base\nLlama-3.2-1B\nscb10x/llama3.2-typhoon2-1b\nTyphoon2-1B-Instruct\nscb10x/llama3.2-typhoon2-1b-instruct\nTyphoon2-3B-Base\nllama-3.2-3B\nscb10x/llama3.2-typhoon2-3b\n",
          "(2023); of Thai Medical Schools (2023)\n• CPT-performance depends on the based model: While CPT improves the model’s\nperformance, the based model’s performance has a more significant effect on the\noverall score.\n• Data Mixture Effects in CPT Setup: Qwen2.5 and Llama 3.1 respond differently to\ndata mixtures, requiring distinct configurations to achieve comparable performance\nimprovements. Exploring this phenomenon remains an area for future work.\n• Avoid Optimizing Solely for Knowledge: While knowledge is a crucial aspect\nof LLMs, it is only one of many dimensions. Other objectives, such as instruction-\nfollowing, task specificity, reasoning capabilities, and ease of parameter tuning, are\nequally vital for maximizing the overall utility of LLMs.\n9\n\nTechnical Report\n3\nPost-training\nIn our post-training process, the goal is to improve Typhoon’s usability. We focus on\ninstruction-following abilities, such as multi-turn response capabilities, system prompt\nfollowing, and reasoning. We also focus on enhancing Typhoon 2’s capabilities on tasks\nsuch as function calling and long context for both Thai and English. This section details our\napproaches and findings in the post-training stage of Typhoon 2.\n3.1\nGeneral Supervised Fine Tuning (SFT)\nTo make Typhoon 2 follow human instruction, we employ SFT as the principal strategy\nfor aligning its outputs with human requirements. However, achieving effective human\nalignment is inherently multidimensional, as language models must accommodate a range\nof human values, preferences, and constraints. Recognizing this complexity, we design\na comprehensive dataset encompassing multiple facets and specialized skills, enabling\nTyphoon 2 to meet diverse human needs better.\n3.1.1\nData\nWe develop a dataset and combine it with the open-source dataset to ensure Typhoon 2’s\ninstruction-following performance based on these categories.\n• English Instruction-Dataset: We combine several public datasets based on multiple\niterations of our Typhoon development. In this version, we incorporate SystemChat5,\nCapybara6, OpenChat (Wang et al., 2024a) and a subset of the Tulu 3 (Lambert et al., 2024)\n",
          "dataset as examples to retain the base model’s English language comprehension. These\ndatasets are selected primarily to align with human feedback patterns and various use cases\nin leveraging LLMs. For example, SystemChat supports system role-following features;\nCapybara facilitates multi-turn conversations, and OpenChat and Tulu 3 provide a rich\ndiversity of instructions.\n• Thai General Instruction-Dataset: We utilize the Typhoon self-instruct instruction dataset\nfor training to align it to Thai. Unlike the original Typhoon (Pipatanakul et al., 2023) devel-\nopment, we do not use any translated English instruction data as it introduces hallucination.\n• TyphoonIF Dataset: A new dataset is constructed based on AutoIF (Dong et al., 2024),\navailable in both Thai and English.\nSeed constraints for the English and Thai ver-\nsions are manually crafted to represent typical prompts that humans might use when\ninteracting with LLMs in specific tasks. Additionally, random queries are taken from\nairesearch/WangchanThaiInstruct (Vistec, 2024) and Suraponn/thai_instruction_sft7,\nalong with randomly sampled queries from the English dataset as previously described in\nthis subsection. Rejected samples, identified through an instruction evaluation function,\nare filtered and added to the final dataset. The final instruction set comprises 150,000\nquestion/instruction and response pairs. These pairs are randomly designated as either\nsystem or user turns to enhance generalization. To further improve cross-lingual transfer ca-\npabilities, instruction turns are randomly translated between Thai and English encouraging\nthe models to align both Thai and English spaces to be similar to each other.\n• Typhoon Personality Dataset In addition, we curate an introductory prompt for Typhoon\nto incorporate its personality into the model.\nWe present our SFT data mixture in Table 3. The table shows the composition of the\nfull general SFT dataset, highlighting its structure and the proportion of each component\nincluded.\n5https://huggingface.co/datasets/abacusai/SystemChat-1.1\n6https://huggingface.co/datasets/LDJnr/Capybara\n7https://huggingface.co/datasets/Suraponn/thai_instruction_sft\n",
          "the inclusion of a high-quality English dataset contributes to improving the performance of\nThai language models. This suggests that cross-lingual benefits can be obtained when using\nhigh-quality data from a related or dominant language.\nThai-English Ratio: To enable the model to generate fluent responses in Thai, we initially\nexperimented with a Thai-English ratio of 1:9. Despite the low proportion of Thai data, the\nmodel demonstrated the ability to respond adequately in Thai. However, increasing the\nratio of Thai data leads to a performance improvement. After conducting multiple trials, we\nempirically found that the optimal Thai-to-English ratio is 3:7.\nImportance of Data Quality: The presence of low-quality data from a single source can lead\nto a performance degradation of up to 20% across the entire system.\nQuality over Quantity: We examine combining multiple large datasets, but the performance\nlevels are only comparable to or even worse than those achieved with a smaller curated\ndataset tailored to specific functions and use cases.\n3.2\nDomain-Specific SFT\nThe model’s performance on general domain instruction-following tasks is satisfactory\nacross all datasets. However, a noticeable drop in domain-specific abilities, particularly in\ncoding and mathematics, is observed. To address this issue, we examine incorporating math\nand coding instruction data in the experiment.\n3.2.1\nData\nMath & Code Dataset\nTo improve math and coding performance, we examine domain-specific datasets and select\nthree based on their competitive results as follows,\n• Dart-math (Tong et al., 2024b): An augmented math dataset verified using a rejection\nsampling method, focusing on complex questions. The answers are sampled from\nDeepSeekMath (Shao et al., 2024).\n• ScaleQuest-Math (Ding et al., 2024): A technique to scale diverse math instruction\nusing a small seed math problem. The responses are sampled through a combination\nof DeepSeekMath-RL (Shao et al., 2024) and Qwen2.5-Math (Yang et al., 2024b).\n• OpenCoder-Instruct (Huang et al., 2024): Stage 2 instruction dataset from the\nOpenCoder project contributes to the strong performance of fully open code LLMs.\nThe dataset is created by leverage multiple methods to scale code instruction dataset\n",
          "and (5) generated sentences involving numbers (e.g., phone numbers, dates, years). , with\nTable 33 provides the summary.\n5.3.5\nExperimental Setup\nEvaluation: In speech generation (similar to TTS), we evaluate the quality of generated\nspeech on two aspects: Accuracy and Naturalness as follows:\n• Accuracy: The generated speech was transcribed using Whisper-v3-large-turbo as the ASR\nsystem, and the character error rate (CER) was computed by comparing the transcribed text\nto the original text.\n14It was intended to fine-tune the speech encoder + LLM for more conversational responses, but\nexperiments showed it degraded text generation, so the original speech encoder + LLM was retained.\n15Dataset sourced from https://huggingface.co/datasets/Suraponn/thai_instruction_sft.\n16Thai company names were limited, so this portion was upsampled.\n42\n\nTechnical Report\nDataset\n#Examples\nThai Response\n75,120\nThai Unique Names\n12,787\nAlpaca (English)\n21,816\nLJSpeech\n13,100\nThai-English Mix\n21,000\nNumber\n11,550\nTotal\n155,371\nTable 33: The final data mixture (Mix-3) for speech decoder.\n• Naturalness: The UTokyo-SaruLab MOS (UTMOS) system (Saeki et al., 2022), developed\nfor the VoiceMOS Challenge 2022 (Huang et al., 2022), is a state-of-the-art tool for predicting\nspeech quality using Mean Opinion Scores (MOS) from 1 (poor) to 5 (excellent). It should be\nnoted that while UTMOS performs well across diverse contexts, its accuracy declines with\nnon-English speech, highlighting the need for improvements to better handle language-\nspecific features and support multilingual environments.\nBaselines:\n• When evaluating Typhoon2-Audio-as-TTS, we benchmark it against systems, including,\n(1) Open-source: (1.1) PyThaiTTS (Phatthiyaphaibun, 2022), Thai text-to-speech model based\n",
          "5.3.3\nUnit Vocoder\nA unit vocoder (Polyak et al., 2021), based on the HiFi-GAN architecture (Kong et al.,\n2020), takes a sequence of self-supervised discrete representations (in our case, they are\nk-means of XEUS tokens) to resynthesize speech. By disentangling essential components of\nspeech—such as linguistic content, prosodic features, and speaker identity—into distinct\nlow-bitrate representations, it enables efficient and high-quality speech synthesis. In this\nwork, the unit vocoder is employed to generate speech outputs from discrete units.\n5.3.4\nData\nAs developing a single-speaker speech generation system is simpler than a multi-speaker\none, this work focuses on single-speaker output. However, due to limited single-speaker\nThai TTS data, we use the Google Cloud Platform TTS system (th-TH-Standard-A) to syn-\nthesize speech waveforms from textual data. The synthesized data are derived from:\n• Mix-1: This data mixture includes 28.7K examples derived from Thai self-instruct (8.7K)\nand a translated Alpaca subset (20K). Responses are regenerated using GPT-4o-mini in a\nconversational style, following Llama-Omni’s setup.14\n• Mix-2: This mixture comprises 220K examples derived from: (1) 75K re-written Thai\nSFT data,15 (2) responses generated from re-written instructions, and (3) 70K examples\nof sentences using Thai unique names (e.g., companies, locations).16 Instructions and\nresponses follow the same GPT-4o-mini conversational generation style as Mix-1 but on a\nlarger scale.\n• Mix-3: This mixture focuses on diversity and contains 155K examples. It includes: (1)\nresponses from Mix-2 SFT data (excluding instructions), (2) Thai unique name data (without\nupsampling), (3) 21K English Alpaca examples rewritten conversationally and LJSpeech\nfor English TTS, (4) code-mixed sentences with Thai sentences containing English words,\n",
          "Audio\nText\nResponse\nType2: SpeechIF\nData derived from\nTextual Instruction-\nResponse\nTTS\nText\nInstruction\nFigure 9: Speech Instruction Following Data Creation Pipeline\n• Complex Instruction Following (ComplexIF): We propose ComplexIF to assess models’ ability\nto follow unseen, compound instructions, where each instruction involves two to three\naudio tasks (such as transcribe, then translate). In ComplexIF, models have to respond\nin specific formats (e.g., JSON, XML), with format templates provided in the instruction\nprompt. As it evaluates the general instruction following ability, only English speech data is\nused. ComplexIF is used exclusively for evaluation, without additional training.\n5.2.3\nExperimental Setup\nEvaluation: For existing tasks, we use standard metrics. For SpeechIF and ComplexIF, we\nfollow MT-Bench (Zheng et al., 2023) in using an LLM judge (GPT-4o), and we adapt the\nsingle-turn evaluation prompt from MT-Bench and score responses on a scale from 1.0 to\n10.0. For ComplexIF, we prompt the judge to evaluate the response on two aspects:\n(1) Quality considers helpfulness, relevance, accuracy, depth, creativity, and level of detail of\nthe response.\n(2) Format considers how well the response follows the format required by the user (e.g.,\nJSON, XML, Markdown, etc).\nBaselines: Competitive audio language models include,\n(1) Open-weights: Qwen-Audio (Qwen-7B) (Chu et al., 2023), SALMONN (Vicuna-13B) (Tang\net al., 2024a), and DiVA (Llama3-8B) (Held et al., 2024). For these open models, we use\navailable weights on HuggingFace.\n(2) Proprietary: Gemini-1.5-Pro (Audio) gemini-1.5-pro-001 through Google API with {au-\ndio, text_instruction} as input.\n5.2.4\nResults and Findings\nRemarks: The majority of experiments in Section 5.2.4 were conducted prior to the devel-\nopment of the Typhoon2 Text series. Thus, the best performing 8B Typhoon backbone at\n",
          "To ensure that the pre-trained data accurately represents the Thai language and culture, we\nemploy a filtering process on the base corpus, involving a human-in-the-loop at the domain\nlevel in the same manner as Typhoon (Pipatanakul et al., 2023). This approach ensures that\nthe content is both relevant and appropriate, preserving its authenticity. Consequently, we\nobtain 5 billion high-quality Thai tokens, which serve as the foundation for training the\noriginal Typhoon and Typhoon 1.5 models.\n2.2\nGathering Diverse and High-Quality Thai Documents\nTo enhance our dataset, we observed a growing trend in pre-training large language models\n(LLMs) that emphasizes sourcing high-quality data from general corpora. Following this\napproach, we develop multiple pipelines to collect documents from a range of diverse\ndomains, focusing on high-quality content absent from our existing general corpus.\n2https://trafilatura.readthedocs.io/en/latest/\n3https://github.com/ChenghaoMou/text-dedup\n5\n\nTechnical Report\nOur approach is aimed to address two key questions:\n1. What represents “Thai\"? – We curate data encapsulating Thai cultural knowledge.\n2. What defines a “state-of-the-art\" LLM? – We follow the global trend of filtering the\nweb corpus to gather high quality & high educational text (Penedo et al., 2024; Li\net al., 2024a; Grattafiori et al., 2024).\nAs a result, we augment our dataset with an additional 12B high-quality Thai tokens through\nthis process.\n2.2.1\nCulturally Relevant Thai Text\nA tailored methodology for content collection is developed to address cultural nuances\nin the text data, drawing upon principles of the fine-web educational approach (Penedo\net al., 2024). Specifically, we use an LLM to annotate 50,000 randomly selected entries from\nthe base corpus. Each entry is assessed for its cultural relevancy and educational value\nin understanding Thai culture, using a scale ranging from 1 to 5. Next, we fine-tune the\nclassification head of BGE-M3 (Chen et al., 2024a) using the labeled dataset obtained from\n",
          "Merge vs Non-Merge: Additionally, we examine the difference in performance between\nmerged and non-merged language models. We utilize Llama-based Typhoon2 70B as our\nbase model, which has undergone SFT. Subsequently, we merge this model with Llama\n3.3 70B Instruct. The results of our quantitative analysis in Table 11 show significant\nimprovements across multiple instruction-following benchmarks compared to the baseline.\n21\n\nTechnical Report\n3.7\nFinal Combination Strategy\nTo combine multiple datasets—consisting of General, Domain-Specific, Function Call, and\nLong-Context datasets—we perform a direct concatenation of the datasets. During this\nprocess,\n• Datasets are subsampled when the performance metrics they optimize for have\nalready saturated.\n• Datasets causing model collapse are excluded from the combination.\nThe resulting combined dataset is used to train models with the following total token counts\n(including repeated data),\n• 7-8B parameter models – a total of approximately 1.2B tokens.\n• Smaller models and 70B model – approximately 600-800M tokens.\nTraining: The training process and hyperparameter settings generally follow the method-\nology described in Section 3.1.2 for General-SFT training. However, the batch size is set\nindividually for each model to meet specific training targets. Specifically, for a target of 1.2B\ntokens, the training process is designed to achieve approximately 2,000 steps, while for a\ntarget of 600-800M tokens, the training process aims for approximately 1,000 steps.\n3.8\nPost-Training Configuration Summary\nGiven various configurations of our Typhoon 2 models, in many stages and features, includ-\ning CPT, long-context adaption, and other post-training configurations, we summarize all\nthe configurations we use for post-training in Table 12.\nModel\nSFT\nLongContext FuncCall Distill Merging\nGeneral Specific\nTyphoon2-Llama3.2-1B-Instruct\n✓\n✗\n?\n✓\n✓\n✗\nTyphoon2-Llama3.2-3B-Instruct\n",
          "As our Typhoon adaptation recipe is model-agnostic, we select both models as the base for\nthe 7-8B category. Subsequently, we apply this recipe to other model sizes in the Llama 3\nfamily since we observed a lower hallucination rate and better code-switching performance\nin our investigation.\n2.5\nEvaluation\nWe evaluate the models using the ThaiExam and M3Exam datasets. While this evaluation\nmethod has been widely used for pre-trained language models, the scores obtained using\nthese datasets are highly above the average level of a typical Thai person4. This can\nbe attributed to contamination and saturation due to overfitting (Fourrier et al., 2024).\nNevertheless, we utilize this signal to measure whether the model has acquired knowledge\nof the Thai language and context, as well as a development signal for improvement.\n2.6\nResults and Findings\nThe evaluation results are shown in Table 2. We found the following insights from our\nexperiments and evaluations.\n• Each filtering subset has its own performance gain: We observe a performance\ngain in the “Science\" score on “High-Quality Text Selection,\" while we achieve a\ngain in the “Social\" score on “Culture Related Text in Thai\" and a gain in the “Thai\"\nscore on the “General subset\" during the first-stage data mixture setup on M3Exam.\n4https://www.niets.or.th/th/content/view/11821\n8\n\nTechnical Report\nModel\nThaiExam ONET\nIC\nA-Level TGAT TPAT M3Exam Math Science Social Thai\nLlama3.2-1B\n25.38\n18.51 20.00\n26.77\n32.30 29.31\n25.30\n23.52\n25.36\n27.48 24.82\nTyphoon2-Llama-1B-base\n26.83\n19.75 16.84\n17.32\n49.23 31.03\n26.10\n21.71\n25.60\n32.83 24.27\nLlama3.2-3B\n40.42\n30.86 46.31\n20.47\n63.07 41.37\n36.81\n",
          "10\n\nTechnical Report\nDataset\nSubset\n# Examples\n# Tokens\nEnglish Instruction-Dataset\nSystemChat\n7 K\n4 M\nCapybara\n16 K\n15 M\nOpenChat\n10 K\n19 M\nFlan-fewshot\n50 K\n25 M\nOthers\n160 K\n88 M\nThai General Instruction-Dataset\n-\n10 K\n4 M\nTyphoonIF Dataset\n-\n150 K\n49 M\nTyphoon Personality Dataset\n-\n350\n0.1 K\nTable 3: Detailed data composition of our general instruction-tuning.\n3.1.2\nExperimental Setup\nTraining: We perform full fine-tuning for SFT post-training, using the AdamW optimizer\nwith a learning rate of 2e-5 for all experiments on the 7-8B model. We use a batch size of 16,\nand packing for a 32K context length during SFT. The SFT training is conducted for around\n1,000 steps, resulting in approximately 700M tokens processed in total.\nEvaluation: We evaluate the performance of general SFT using three datasets, focusing on\nassessing general instruction-following performance and the usability of LLMs in Thai and\nEnglish. The three datasets are as follows:\n• IFEval: We employ IFEval (Zhou et al., 2023), a method designed to evaluate\ninstruction-following capabilities using a set of verifiable instructions. These in-\nstructions are assessed against predefined rules implemented through test cases.\nThe evaluation metric for IFEval is accuracy, which measures how well LLMs adhere\nto user-provided instructions. In addition to the standard IFEval (English version),\nwe introduce IFEval-TH, a Thai version of IFEval. The original English instructions\nare translated into Thai, followed by a manual verification and correction process\nto ensure accuracy and content consistency. In this case, we evaluate the average of\nall four metrics from the original work.\n• Code-Switching: We observed that English monolingual and English-Chinese\nbilingual LLMs exhibit a high tendency to produce code-switching responses\nwhen prompted to respond in Thai. To quantify this behavior, we propose a\nsimple code-switching evaluation designed to assess the model’s propensity to\n",
          "Section 3.1.2, which are used for evaluating instruction-following tasks.\n3.5.3\nResults and Findings\nThe results of the distillation experiment are presented in Table 10.\nModel\nIFEval\nMT-Bench\nCode-switch\nTH\nEN\nTH\nEN\n1.0\n0.7\nSFT\n49.53\n53.76\n3.68\n5.37\n85.40\n92.20\nDistillation\n52.46\n53.35\n3.97\n5.40\n88.00\n96.40\nTable 10: Performance comparison between standard SFT and distillation\nWe found the following key insights:\n• Impact of Distillation on Performance: Based on the results, distillation yields a\nperformance improvement in most of the aspects of the small model.\n• Does a larger model’s logits improve performance? In our preliminary exper-\niments, we distil the logits from both Typhoon2-8B and Typhoon2-70B models.\nBased on this setup, we observe a similar results on the 1B and 3B models in our\nsettings.\n3.6\nModel Merging\nModel merging, a method to combine the weights of two models, has recently been shown\nto improve performance in LLMs (Akiba et al., 2024) . We previously performed model\nmerging for our Typhoon 1.5X series12, resulting in significant improvements for Thai and\n12https://blog.opentyphoon.ai/typhoon-1-5x-our-experiment-designed-for-application-use-cases-7b85d9e9845c\n20\n\nTechnical Report\nEnglish instruction-following tasks. Notably, our larger-size models, such as those with\n70B parameters, demonstrated remarkable performance gains. Therefore, we apply model\nmerging techniques to our 70B models in this iteration.\n3.6.1\nExperimental Setup\nIn our experiment involving the Arcee-AI Mergekit (Goddard et al., 2024), we explore\nmerging methods implemented in the Arcee-AI Mergekit, such as linear, slerp, TIES (Yadav\net al., 2023), and DARE (Yu et al., 2024). We manually search for each merge hyperparameter.\n",
          "44\n\nTechnical Report\n5.4\nEnd-to-End Speech-to-Speech Evaluation\nTyphoon2-Audio’s ability to generate text and speech responses from spoken instructions\nis evaluated through speech-to-text (S2TIF) and speech-to-speech (S2SIF) tasks, with a\nfocus on S2SIF here. Two aspects are assessed: content generation and speech quality.\nContent generation is evaluated using the LLM-as-a-judge framework, while speech quality\nis measured by accuracy (e.g., CER, WER) and naturalness (e.g., UTMOS).\nSpoken instructions are taken from SpeechIF (English and Thai splits) (Manakul et al.,\n2024), using the prompt: \"Respond conversationally to the speech provided in the language it is\nspoken in\", similar to Talk Arena (Li et al., 2024b). For content evaluation, automatic speech\nrecognition (ASR) (Gemini-1.5-Flash) transcribes the generated speech. The LLM judge\n(GPT-4o) assesses the transcript on two aspects:\n• Quality: helpfulness, relevance, accuracy, depth, creativity.\n• Style: suitability in a conversational setting.\nThe results in Table 38 show that Typhoon2-Audio outperforms Llama-Omni for English but\nfalls short of GPT-4o-Audio. For Thai, Typhoon2-Audio significantly outperforms Llama-\nOmni, which responds in English to Thai inputs, and performs competitively with GPT-4o-\nAudio. All models show reduced performance on transcribed speech due to imperfections\nin speech generation, with Typhoon2-Audio showing a larger drop in English, as its speech\ngeneration is optimized for Thai. Despite this, transcribed scores suggest the generated\nspeech remains usable.\nModel\nSpeechIF (English)\nSpeechIF (Thai)\nQuality(↑)\nStyle(↑)\nQuality(↑)\nStyle(↑)\nResults using Text Output\nLlama-Omni\n5.58\n6.52\n1.88\n2.53\nGPT-4o-Audio\n7.23\n8.25\n6.96\n8.38\nTyphoon2-Audio\n",
          "42.4\n65.3\n85.7\n48.1\n56.7\nLamaGuard3-1B\n28.4\n62.4\n66.7\n72.9\n29.8\n50.9\n51.8\nTyphoon2-Safety\n71.6\n80.0\n58.8\n76.5\n81.0\n88.5\n76.1\nTable 22: Model performance across benchmarks in Thai as measured by F1 scores.\nIn cross-lingual scenarios, our model exhibited remarkable robustness, consistently outper-\nforming larger and more resource-intensive models. This performance gap was particularly\nevident when compared against established models like LlamaGuard 2 and LlamaGuard 3\n8B, with the largest improvement against LlamaGuard 3 1B. These results suggest that our\napproach can bridge the linguistic gap while maintaining high detection accuracy, proving\nthat effective safety models can be developed without relying solely on model scaling.\nRemarks: These policy differences mean that direct numerical comparisons of F1 scores\nmay not depict the complete story, since: (1) each model may excel in its specifically\ntargeted safety domains, (2) lower scores in certain benchmarks might reflect policy choices\nrather than model limitations, (3) some models may intentionally be more conservative or\npermissive in their classifications based on their intended use case.\n27\n\nTechnical Report\n4\nVision\nWe introduce Typhoon2-Vision, a vision-language model based on Qwen2-VL, and it is\noptimized for Thai document understanding such as Thai OCR, and Chart VQA. This\nsection covers its architecture, training data preparation based on our agentic data curation\nframework and experimental results and findings on our Thai vision-language models.\n4.1\nArchitecture\nThe Typhoon vision model is derived from Qwen2-VL (Wang et al., 2024b), one of the\nmost recent vision-language models in the Qwen series. Qwen2-VL integrates a Vision\nTransformer (ViT) with the Qwen2 language model, offering advanced capabilities for\nmultimodal tasks.\nA key feature of Qwen2-VL is its implementation of Naive Dynamic Resolution, which\nenables the model to handle arbitrary image resolutions by dynamically mapping them\n",
          "47.30\n50.12\nGemini-1.5-Pro\n-\n5.98\n13.56\n22.54\n20.69\n13.52\n90.73\n81.32\nTyphoon-Audio\n8B\n8.72\n14.17\n24.14\n17.52\n10.67\n98.76\n93.74\nTyphoon2-Audio\n8B\n5.83\n14.04\n33.25\n27.15\n15.93\n76.51\n75.65\nTable 31: Audio LM Evaluation in English and Thai on ASR, Translation, Gender Classifica-\ntion. Size refers to the size of the LLM.\nModel\nSize\nSpokenQA (F1↑)\nSpeechIF (Judge↑)\nComplexIF (Judge↑)\nEn\nTh\nEn\nTh\nQual\nFormat\nAvg.\nQwen-Audio\n7B\n25.34\n0.00\n1.07\n1.03\n3.13\n1.68\n2.41\nSALMONN\n13B\n52.92\n2.95\n2.47\n1.18\n4.10\n5.09\n4.60\nDiVA\n8B\n44.52\n15.13\n6.81\n2.68\n6.33\n7.83\n7.08\nGemini-1.5-Pro\n-\n74.09\n62.10\n3.24\n3.93\n7.25\n8.99\n8.12\nTyphoon-Audio\n8B\n48.83\n64.60\n5.62\n6.11\n6.34\n8.73\n7.54\nTyphoon2-Audio\n8B\n69.22\n70.01\n6.00\n6.79\n5.35†\n9.01\n7.18\nTable 32: Audio LM Evaluation in English and Thai on Spoken QA, Speech Instruction\nFollowing, and English Complex Instruction Following. Size refers to the size of the LLM.\n†We observed examples where Typhoon2-Audio did not provide any answer to speech\ninstruction in nested commands; hence, receiving very low scores on these examples.\n40\n\nTechnical Report\n5.3\n",
          "The experimental results in Tables 21 and 22 demonstrate the effectiveness of our Typhoon2-\nSafety model. The model achieves superior performance across all benchmarks, particularly\nexcelling in handling Thai-specific content while maintaining strong capabilities on standard\nsafety evaluation tasks. This performance is especially noteworthy as it demonstrates the\nmodel’s ability to generalize across both languages without compromising effectiveness in\neither domain.\n26\n\nTechnical Report\nModel ( EN )\nWildguard\nHarm\nbench\nSafeRLHF\nBeaver\ntails\nXstest\nThai\nTopic\nAVG\nWildGuard-7B\n75.7\n86.2\n64.1\n84.1\n94.7\n53.9\n76.5\nLlamaGuard2-8B\n66.5\n77.7\n51.5\n71.8\n90.7\n47.9\n67.7\nRandom\n25.3\n47.7\n50.3\n53.4\n22.6\n51.6\n41.8\nLamaGuard3-8B\n70.1\n84.7\n45.0\n68.0\n90.4\n46.7\n67.5\nLamaGuard3-1B\n28.5\n62.4\n66.6\n72.9\n29.8\n50.1\n51.7\nTyphoon2-Safety\n74.0\n81.7\n61.0\n78.2\n81.2\n88.7\n77.5\nTable 21: Model performance across benchmarks in English as measured by F1 scores.\nModel ( TH )\nWildguard\nHarm\nbench\nSafeRLHF\nBeaver\ntails\nXstest\nThai\nTopic\nAVG\nWildGuard-7B\n22.3\n40.8\n18.3\n27.3\n49.5\n42.2\n33.4\nLlamaGuard2-8B\n64.0\n75.5\n46.1\n65.0\n85.1\n45.8\n63.6\nRandom\n24.5\n46.6\n50.4\n53.0\n26.6\n50.9\n42.0\nLamaGuard3-8B\n61.4\n37.5\n",
          "the time, Typhoon1.5 \"llama-3-typhoon-v1.5-8b-instruct\", was selected as the main LLM\nbackbone. In the final experiment (discussed in Finding 4), we provide the performance of\nthe new audio model with Typhoon2 \"typhoon-2-llama-31-8b-instruct-beta-v1\".\n38\n\nTechnical Report\nFinding 1: Performance Disparities of Audio Language Models in English vs. Thai\nThe results in Table 31 and Table 32 demonstrate that: (1) Baselines using multilingual\nbackbones exhibit significant performance degradation in Thai, while Gemini-1.5-Pro main-\ntains strong performance across both Thai and English. (2) Among the baselines, DiVA is\nthe only model that performs well on the SpeechIF task, but it experiences a notable drop\nwhen tested on Thai. Thus, the subsequent experiments aim to develop a model that can\neffectively handle these tasks in both English and a low-resource language such as Thai.\nFinding 2: Pre-training Speech Encoder and LLM Backbones\nThis experiment focuses on selecting backbones, and comparing Whisper with its En-\nglish+Thai fine-tuned variant. Similarly, Typhoon is a Llama-3 model fine-tuned to En-\nglish+Thai. Our results (in Table 29) show that for ASR, models where both backbones are\nmatched with the target language yield the best results. However, for audio captioning, the\nperformance difference between these models is marginal. As a low-resource language such\nas Thai is our goal, Whisper+Th coupled with Typhoon-1.5 are selected.\nBackbone\nASR (WER↓)\nAC (METEOR↑)\nSpeech\nLLM\nEn\nTh*\nEn\nTh\nWhisper-v3-large\nLlama-3\n6.02\n16.66\n30.75\n20.04\nWhisper-v3-large\nTyphoon-1.5\n7.76\n20.01\n29.56\n20.62\nWhisper-v3-large-Th\nLlama-3\n7.35\n15.68\n29.52\n",
          "large portion of crawled Thai texts are search engine optimization (SEO) texts or duplication.\nPublicly Available Data\nIn this work, we consider two primary sources of publicly available Thai data sources as follows.\nFirst, MC4 [60], a multilingual cleaned version of Common Crawl’s web crawl corpus, consists of\ntexts from 108 languages including Thai. For example, mT5 [60] previously used 11 billion Thai\ntokens in this dataset in its pretraining. Our investigation shows that the quality of MC4 data is\nhigher than Oscar. Second, Oscar [37], an open-source multilingual dataset, consists of texts from\n151 languages including Thai. The Oscar dataset is larger than MC4, however, we observe that its\nquality is lower, which necessitates extensive data-cleaning efforts.\nMethodology\nGiven the available resources for pretraining Thai language models, our approach focuses on two key\naspects: quantity and quality. In terms of the quantity of data, as the Oscar dataset extracted a single\npackage of the Common Crawl (CC) data and MC4 only made use of a few packages, it is possible to\nextract more Thai data from the remaining packages of the CC data. In terms of quality, we follow\nthe methodology employed in Falcon RefinedWeb [40] and apply a deduplication pipeline on Thai\ndata in CC datasets.\nOur data preparation can be summarized in four key steps. (1) Scaling the Data: we initiate the\nprocess by increasing the number of Common Crawl packages where we process a total of 40 packs of\n3\n\nthe CC data, resulting in a substantially larger dataset comprising approximately 3 TB of Thai text. (2)\nStrict Deduplication: to ensure data quality and minimize redundancy, we implement a deduplication\nmethod based on MinHash and LSH algorithms. (3) Rule-based and Heuristic Filtering: heuristics\nare applied to filter data to further enhance data quality. This step involves a manual selection\nof high-quality websites at the domain level, supplemented by heuristic criteria such as character\nratio, line length, and document length. (4) Incorporating English Data: to mitigate catastrophic\nforgetting of the base model’s English knowledge [47, 27], we add data randomly selected from\n",
          "Multi-task\n55,509\nTable 23: Summary of data composition for Typhoon2-Vision. Base data, translated data,\nand distilled data are described in Section 4.2 and Thai OCR Data is described in Section 4.3.\n2. Content Extraction: Open-weight models are used to derive structured and un-\nstructured content from this data set.\n3. Agentic Refine Ground Truth and TextVQA Generation: The extracted data un-\ndergo agentic refinement to improve the quality of the label and annotation, while\nAgentic systems simultaneously generate TextVQA data, including tasks like Cap-\ntion, Q&A, and Conversations, as explained in detail in Section 4.3.2.\n4.3.1\nData Sources: Thai Book and Thai Financial\nAs shown in Table 24, our goal is on the intricate process of data filtration, which serves to\nenhance and elevate the caliber of data employed in our comprehensive analysis. Initially,\nthe data set includes a substantial volume of images and text dialogues obtained from the\nThai Economic Report and the Thai Book. Our multi-step filtering methodologies (to be\ndescribed in Section 4.3.2) are designed to filter out data and retain only the entries that are\ndeemed most pertinent and exhibit the highest quality, deemed essential for subsequent\nanalytical processing.\nDataset\nRaw Data\nFiltered Data\nImages\nConversations\nImages\nConversations\nThai Econ Reports - Fin Research\n50K\n35M\n42K\n27M\nThai Book\n108K\n359K\n55K\n224K\nTable 24: Comprehensive Overview of Data Statistics Before and After Filtering\nThe curated data, central to our OCR-related applications in publications, guarantees\ndatasets adhere to the requisite quality standards vital for advanced analysis and modeling,\nparticularly in question answering, summarization, and conversational AI training. These\n29\n\nTechnical Report\nenhanced datasets are supplemented with structured field data, allowing for more precise\nuse in various domains. The field data are categorized as follows:\n• Extract Content: The text retrieved from the document, which includes summarised\neconomic metrics, statistical data, or text descriptions derived from graphs or tables.\n• Caption: A textual explanation of the graph, figure, or visual element, providing\ncontext for the depicted data.\n",
          "-\n-\n-\nTable 3: Performance on the Thai reasoning and understanding tasks. †The results are reported in the\nprevious work [62]. ‡The experiment was conducted on a subset of XNLI as a full evaluation would\ncost more than $1000.\n5\n\nIn Table 3, we compare our pre-trained Typhoon against open-source and proprietary LLMs that\nsupport the Thai language. The results show that Typhoon-7B is the best-performing model among all\nopen-source models across the evaluation datasets. Typhoon-7B also outperforms an average human\ntester on ONET, TGAT and TPAT-1 examinations. When compared to proprietary (and potentially\nmuch larger) models, Typhoon despite having only 7 billion parameters outperforms GPT-3.5 on 4\nout of 8 evaluation datasets.\n4\nInstruction-Tuning\nAlthough pretrained language models are highly capable of predicting the next words, even large\nlanguage models of more than 100 billion parameters may still lack the ability to follow a user’s\nintent well. As a result, instruction-tuning has been applied to align language models with a user’s\nintent [38, 53, 55]. Instruction-tuning or fine-tuning methods could be categorized into supervised\nfine-tuning (SFT) and alignment via reinforcement learning using human feedback (RLHF) [52, 38]\nor AI feedback (RLAIF) [18], and Direct Preference Optimization (DPO) [46]. However, these\ntechniques require significant annotation resources, which do not yet exist in the Thai language.\n4.1\nSupervised Fine-Tuning (SFT)\nTo address the lack of instruction-tuning data, we consider three directions as follows: (1) translating\nEnglish instruction-tuning datasets into Thai, (2) converting Thai NLP datasets using pre-defined\nprompt templates similar to the FLAN collection [57, 7], (3) generating Thai instruction-tuning data\nusing the Self-Instruct technique [56].\nAs a first step, we create SFT data by translating English instruction-following datasets into Thai. The\ntranslation-based approach was also previously used in fine-tuning WangChanGLM where datasets\nsuch as Alpaca [53] and Dolly [9] were translated using Google Translate API. In this work, we\n",
          "checkpoint averaging. We present these results in Table 3.\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\nresults to the base model.\n6.3\nEnglish Constituency Parsing\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\nfor the semi-supervised setting.\nWe performed only a small number of experiments to select the dropout, both attention and residual\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\nremained unchanged from the English-to-German base translation model. During inference, we\n9\n\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\nof WSJ)\nParser\nTraining\nWSJ 23 F1\nVinyals & Kaiser el al. (2014) [37]\n",
          "Training\nBased on our experiments, although current foundation models were already trained on\nsome Thai texts, we do not extend the Thai tokenizer as done in Typhoon (Pipatanakul\net al., 2023). This decision is because recent findings showed that adding more tokens to the\ntokenizer (which requires training their corresponding embeddings) can degrade overall\nperformance (Dou et al., 2024; Zhao et al., 2024) despite yielding high generation efficiency.\nWe use this configuration during the model pre-training.\nFor all models, the AdamW optimizer is used in conjunction with a cosine learning rate\nscheduler. Gradient clipping is applied with a threshold value of 1.0. Our training is\nconducted using a context length of 8192. The DeepSpeed ZeRO optimization framework\nat Stage 2 without offloading is employed, as it provides the highest throughput in our\nexperimental setup. All models are pre-trained on a single node comprising eight H100\nGPUs. The learning rate is optimized individually for each model. We select the Llama 3\nseries (Grattafiori et al., 2024) and Qwen 2.5 series (Yang et al., 2024a) as the base models\ndue to their high performance on global leaderboards at the time of conducting pre-training.\nWe perform full fine-tuning for models with 8B parameters or fewer and we apply LoRA\n(Hu et al., 2022) with a rank of 32 for models with 70B parameters. Due to our resource\nconstraints, we train on sub-sampling instead of the full dataset.\nBase Model\nInitially, we examined the performance of several 7–8B base models, as this is a standard\nsize in academic scaling due to our resource constraints. Ultimately, we identified two\nfamilies of base models that demonstrated significant potential for practical use:\n1. Llama 3 series: A state-of-the-art open-source model developed by Meta. It is primarily\ntrained for English performance. The instruction-tuned version also demonstrates excellent\nperformance and is competitive with proprietary models.\n2. Qwen2.5 series: A state-of-the-art open-source model developed by Alibaba. Its perfor-\nmance on knowledge-driven leaderboards is exceptional, surpassing many open-source\nand proprietary LLMs. It is optimized for English and Chinese as its primary languages.\n",
          "Typhoon2-3B-Instruct\nscb10x/llama3.2-typhoon2-3b-instruct\nTyphoon2-7B-Base\nQwen2.5-7B\nscb10x/typhoon2-qwen2.5-7b\nTyphoon2-7B-Instruct\nscb10x/typhoon2-qwen2.5-7b-instruct\nTyphoon2-8B-Base\nLlama-3.1-8B\nscb10x/llama3.1-typhoon2-8b\nTyphoon2-8B-Instruct\nscb10x/llama3.1-typhoon2-8b-instruct\nTyphoon2-70B-Base\nLlama-3.1-70B\nscb10x/llama3.1-typhoon2-70b\nTyphoon2-70B-Instruct\nscb10x/llama3.1-typhoon2-70b-instruct\nSafety Classifier\nTyphoon2-Safety\nmdeberta-v3-base\nscb10x/typhoon2-safety-preview\nMultimodal\nTyphoon2-Vision\nQwen2-VL-7B-Instruct scb10x/typhoon2-qwen2vl-7b-vision-instruct\nTyphoon2-Audio\nTyphoon2-8B-Instruct scb10x/llama3.1-typhoon2-audio-8b-instruct\nTable 1: Models released in the Typhoon2 series\n1\narXiv:2412.13702v2  [cs.CL]  19 Dec 2024\n\nTechnical Report\nContents\n1\nIntroduction\n4\n2\nPre-training\n5\n2.1\nData Source & Typhoon1-Corpus . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.1.1\nBase Corpus Preparation . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
          "of languages including Thai. GPT-4 is the state-of-the-art in several English benchmarks [20, 63].\nIn addition, given the speculated larger amount of pretraining data than any open-source models,\nChatGPT and GPT-4 can also be exceptional in low-resource languages.\nModel\nMajorLang\n#Params\nVocabSize\nContext\nBaseModel\nTyphoon-7B\nEnglish, Thai\n7B\n35,219\n4096\nMistral\nOpenThaiGPT-beta-7B\nEnglish, Thai\n7B\n56,554\n4096\nLlama2\nWangChanGLM\nMultilingual\n7.5B\n256,008\n2048\nXGLM\nSeaLLM-7B\nMultilingual\n7B\n48,512\n4096\nLlama2\nSEA-LION-7B\nMultilingual\n7B\n256,000\n2048\n✗\nTable 1: Comparison between Typhoon and open-source language models that support Thai.\nOpenThaiGPT is based on Llama2 with an extended vocabulary, continual pretraining, and in-\nstruction fine-tuning. WangChanGLM is a multi-lingual XGLM model fine-tuned to follow Thai\ninstructions without further pretraining. SEA-LION and SeaLLM are multilingual models specialized\nin Southeast Asian languages, including Thai. At the time of writing, SEA-LION is only instruction-\ntuned on Indonesian data, and SeaLLM is only available at 7B size.\n3\nPretraining\nThe development of language models tailored to the Thai language presents several unique challenges.\nUnlike high-resource languages like English, Thai does not have readily available large-scale datasets\nand resources. This section provides an overview of the challenges and considerations specific to\ndeveloping Thai LLMs, including data preparation, tokenization, and the choices of base model.\n3.1\nPretraining Data\nIn the context of the Thai language, a notable observation emerges: the available Thai internet data\nconstitutes only a small fraction, for instance, less than 0.5% in the Common Crawl data [13]. In\naddition to the quantity, our initial investigation reveals that there is an issue with the quality where a\n",
          "20%, on the overall (1k) subset among open TTS models. In terms of naturalness, while\nSeamless attains a higher UTMOS score, its synthesized English speech resembles native\nEnglish speakers speaking Thai. Conversely, Typhoon2-Audio-as-TTS produces English\nspeech that sounds more like native Thai speakers speaking English.\nSystem\nType\nOverall (1k) En+Th Name General-Th Number\nPyThaiTTS\nOpen\n81.74\n92.39\n70.00\n81.53\n63.04\nSeamless\nOpen\n27.90\n33.40\n22.12\n23.90\n41.68\nMMS-TTS\nOpen\n27.50\n38.04\n25.32\n18.44\n48.51\nGCP_TTS\nProprietary\n12.64\n23.76\n12.44\n7.13\n6.61\nAzure_Premwadee\nProprietary\n12.28\n23.50\n11.92\n6.58\n7.26\nTyphoon2-Audio-as-TTS\nOpen\n18.27\n28.19\n17.73\n13.16\n14.65\nTable 36: Character Error Rate (CER) ↓of synthesized speech across different categories.\nSystem\nType\nOverall (1k) En+Th Name General-Th Number\nPyThaiTTS\nOpen\n2.79\n2.95\n2.63\n2.72\n2.87\nSeamless\nOpen\n3.71\n3.82\n3.61\n3.67\n3.71\nMMS-TTS\nOpen\n3.71\n3.74\n3.55\n3.73\n3.66\nGCP_TTS\nProprietary\n3.60\n3.64\n3.62\n3.57\n3.62\nAzure_Premwadee\nProprietary\n4.06\n4.07\n3.99\n4.05\n4.10\nTyphoon2-Audio-as-TTS\nOpen\n3.13\n3.16\n3.12\n3.13\n3.08\nTable 37: Objective Quality Assessment (UTMOS) ↑scores across different categories\n",
          "65.09\n83.98\n83.36\n57.71\n58.00\n78.05\n41.73\n70B\nTyphoon2-Llama-70B-Instruct\n65.78\n90.29\n83.36\n76.63\n33.62\n75.61\n80.35\nLlama-3.3-70B-Instruct\n56.36\n87.10\n86.89\n65.57\n18.25\n97.56\n58.88\nLlama-3.1-70B-Instruct\n53.61\n88.73\n83.68\n61.00\n15.00\n92.68\n57.56\nTable 8: BFCL V3 Benchmark on English Dataset where we report accuracies for overall,\nAST, Exec, Live, Multi-turn as well as relevance and irrelevance scores.\nPerformance Enhancement in English and Thai: Tables 8 and 9 demonstrate that our\nEnglish-Thai data mixing approach leads to substantial performance improvements across\nboth languages. Specifically, the Typhoon2-Qwen2.5-7B model consistently achieves the\nhighest overall accuracy in both English (79.08%) and Thai (75.12%), outperforming other\nbaselines, including OpenThaiGPT-1.5, which is also a Qwen2.5 based model. Notably,\nQwen-based Typhoon models outperform their Llama-based counterparts across all evalua-\ntion metrics, emphasizing the effectiveness of Qwen in this multilingual setting.\n9https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2\n18\n\nTechnical Report\nModel\nOverall\nAST\nExec\nLive\nMultiTurn\nRelv\nIrrelv\n1B\nTyphoon2-Llama-1B-Instruct\n34.96\n45.31\n60.05\n36.12\n18.75\n92.68\n32.26\nQwen2.5-1.5B-Instruct\n29.88\n32.69\n50.98\n30.25\n20.62\n60.98\n25.54\nLlama3.2-1B-Instruct\n13.83\n12.98\n0.18\n26.61\n0.75\n",
          "VISTEC-SER (VISTEC, 2021)\nQA (Emotion & Gender)\n✓\n18.0K\nYodas2-30S (Li et al., 2023b)\nQA (Speech-Th)\n✓\n90.0K\nSpeech Instruction Following used in SFT-v3\nGigaSpeech (Chen et al., 2021a)\nSpeechIF-Type1 (En)\n✓\n20.0K\nCommonVoice-Th (Ardila et al., 2020)\nSpeechIF-Type1 (Th)\n✓\n120.5K\njan-hq-instruction-v1 (Dao et al., 2024)\nSpeechIF-Type2 (En)\n✗\n20.0K\nAiroboros-Th\nSpeechIF-Type2 (Th)\n✓\n5.7K\nAlpaca-Th\nSpeechIF-Type2 (Th)\n✓\n20.0K\nSelfInstruct-Th\nSpeechIF-Type2 (Th)\n✓\n18.9K\nTable 28: SFT data of Typhoon-Audio – 640K examples in total\n• Audio Caption: This task involves generating audio descriptions using the AudioCaps test\nset (Kim et al., 2019), with English references translated into Thai for Thai Audio Captioning.\nThe evaluation metric is METEOR.\n• Speech Translation: Thai-to-English is from CommonVoice (Thai), and target English texts\nare derived from translation. English/X-to-Thai is from Covost2, and target Thai texts are\nderived from translating English texts. X refers to a non-English audio language (Arabic,\nGerman, Spanish, French, Indonesian, Italian, Japanese, Chinese) taken from Covost2. The\ntranslation was performed using our internal system, which matches Google Translate\nAPI performance. An example prompt is \"Translate this audio into language\". Each setup\nincludes 2000 examples. The evaluation metric is BLEU.\n• Gender Classification: Fleurs is used as gender labels are available for both English and\nThai. The metric is accuracy.\n• QA examples in SALMONN/LTU are based on short spoken documents (under 10 sec-\n",
          "investigate translation further by using Typhoon fine-tuned for translation and GPT-4; for example,\nwe translate UltraChat [12] using GPT-4. Additionally, we follow self-instruct [56] in generating a\nThai-instruction dataset. Using translated and self-instruct data, we obtain Typhoon-7B-Instruct by\nperforming supervised fine-tuning.\n4.2\nEvaluation: Instruction-Following Tasks\nIn Section 3.4, we evaluate Thai knowledge using multi-choice question answering and classification\nbenchmarks. However, the previous evaluation may not reflect how well the models understand human\nintents, and the evaluation of instruction-following models typically requires human interactions [20].\nTherefore, we perform instruction-following evaluation using the following datasets:\n• Thai AlpacaEval: We create an instruction-following dataset following AlpacaEval [20]. As\nnative Thai speakers, we manually write prompts in Thai based on the examples randomly selected in\nAlpacaEval. For instance, given an example from AlpacaEval, we write a prompt in Thai as well as\nusing a Thai context instead of a literal translation. This dataset consists of 105 Thai prompts.\n• Thai OASST: We make use of a Thai subset of OpenAssistant (OASST1), 166 human-written\ninstruction-response pairs, which was previously used in evaluating WangChanGLM.\n• Translated MT-Bench: We translate MT-Bench [63] (using Google API) into Thai and we filter\nout poorly translated examples such as coding instructions, resulting in a total of 68 examples. The\ntranslated MT-Bench is used to evaluate the multi-turn ability of the models.\n• Sea-bench (Thai subset) [31]: We make use of a Thai subset of Sea-bench inspired by MT-Bench\nfor SEA languages released with SeaLLM. It utilizes translations of English test sets, real user\nquestions from local sources, math and reasoning questions, and linguist-written instructions. Sea-\nbench encompasses various categories, including task-solving, math-reasoning, general instructions,\nNaturalQA for colloquial language, and safety instructions. This dataset consists of 100 Thai prompts.\nWe use an LLM as a judge to perform pairwise comparison [20, 63, 24] by measuring the fraction\n",
          "Evaluation Benchmarks: To ensure a comprehensive evaluation of our model’s performance,\nwe utilized multiple widely adopted safety benchmarks as follows:\n• WildGuard Test Set (Han et al., 2024) is an evaluation dataset with 1,703 pairs of\nprompts and responses. It includes a diverse range of harmful content categories\nand serves as our primary evaluation dataset.\n• SafeRLHF Test Set (Dai et al., 2023) is an evaluation dataset. It includes safety\nmeta-labels across 19 harm categories with three severity levels (minor to severe).\nWe subsample select 1K dataset.\n• HarmbenchResponse (Mazeika et al., 2024) is an evaluation data set with 602 pairs\nof prompts and responses. This dataset evaluates the robustness of LLMs to conduct\njailbreak attacks.\n• BeaverTails Test Set (Ji et al., 2023) is an evaluation dataset with 3,021 pairs of\nprompts and responses, following wildguard (Han et al., 2024). The prompts are\nbased on the prompts from the HH-RLHF red teaming split, and the responses are\ngenerated by an LLM.\n• Thai Sensitive Topic Test Set is an evaluation test set with 9,587 pairs of prompts\nand responses. It contains various topics as shown in Table 18.\nAll evaluations followed WildGuard’s methodology of using F1 scores for binary classi-\nfication tasks, with Typhoon2-Safety being applied to the full token length. For the Thai\nlanguage evaluations, all benchmark datasets were created by directly translating the En-\nglish benchmarks using an LLM.\nBaseline Models: We compare our model against several SOTA safety classifiers:\n• WildGuard (Han et al., 2024): The current SOTA safety classification model. The\nmodel was shown to be robust across multiple safety benchmarks.\n• LlamaGuard 2 (Inan et al., 2023): An 8B parameter model specifically instruction-\ntuned for safety classification, capable of identifying both harmful prompts and\nharmful model responses.\n• LlamaGuard 3 (Grattafiori et al., 2024): Is a upgrade version of LlamaGuard 2 based\non Llama 3 series available in two size variants (8B and 1B parameters). These\nmodels can be used to classify content in both LLM inputs and response.\n",
          "Falcon RefinedWeb [40] to our Thai data, resulting in a bilingual dataset with a 50/50 split between\nThai and English data. Note that previous work in adapting an LLM to Hungarian shows that mixing\nEnglish data can mitigate catastrophic forgetting on English, and the adaption is not sensitive to the\nexact mixture ratio provided that the original language and target language are included [11].\n3.2\nThai Tokenizer\nA byte-level BPE tokenizer, which is adopted by Mistral as well as other LLMs such as GPT or Llama,\ncan encode most words or characters in all languages by falling back to the byte level. Although\nthis tokenizer can operate on a language that it is not initially trained for (e.g., Thai), it has poor\nefficiency. For instance, previous work shows that the GPT-2 tokenizer with a vocabulary size of\n50k requires 3.8 times more tokens to encode Thai texts compared to a tokenizer with a vocabulary\nsize of 5k trained on Thai data [11]. To adapt an existing LLM, the tokenizer of the original model\nis usually augmented with new tokens where the corresponding embeddings are initialized from\nscratch [36, 11]. This results in the trade-off between an improvement in efficiency and the difficulty\nof model adaption due to new embeddings. Previous work demonstrated that adding beyond 5,000\nnew Thai tokens yields a diminishing return in efficiency [11].\nIn this work, we base our tokenizer on Mistral-7B tokenizer, but we further train an additional Thai\nsubword tokenizer with 5,000 tokens and integrate it with the original tokenizer. This new tokenizer\nis created by training a SentencePiece model [17] on around 8 million samples randomly selected\nfrom the Thai subset of MC4 data [60]. We define efficiency as the number of tokens required to\nrepresent Thai text with respect to the number of GPT-4 tokens on the same text, i.e.,\nEfficiency = #tokenmodel\n#tokenGPT-4\n(1)\nwhere #token is the number of tokens on the same Thai text. Our experimental results in Table 2\nshow that Typhoon’s tokenizer is 2.62 times more efficient than GPT-4.\nTokenizer\nTyphoon\nGPT-4\nMistral\nCharacter\nWord*\n",
          "43\n\nTechnical Report\nTraining Data\nOverall (1k)\nEn+Th\nName\nGeneral-Th\nNumber\nMix-1\n21.29\n38.23\n19.26\n11.73\n22.04\nMix-2\n20.15\n34.15\n19.43\n11.88\n21.43\nMix-3 (base)\n18.76\n28.71\n19.72\n11.93\n23.28\n+ LJSpeech\n19.35\n28.65\n18.62\n11.05\n37.87\n+ LJSpeech + Number\n18.27\n28.19\n17.73\n13.16\n14.65\nTable 34: Character Error Rate (CER) ↓of synthesized speech across different categories.\nTraining Data\nOverall (1k)\nEn+Th\nName\nGeneral-Th\nNumber\nMix-1\n3.05\n2.93\n3.06\n3.13\n3.06\nMix-2\n3.08\n3.02\n3.04\n3.13\n3.07\nMix-3 (base)\n3.10\n3.11\n3.04\n3.13\n3.01\n+ LJSpeech\n3.11\n3.14\n3.07\n3.12\n2.98\n+ LJSpeech + Number\n3.13\n3.16\n3.12\n3.13\n3.08\nTable 35: Objective Quality Assessment (UTMOS) ↑scores across different categories\nFinding 3: Typhoon2-Audio as Text-to-Speech\nAs Typhoon2-Audio can take text as input without audio or text inputs, the model (LLM +\nspeech decoder + unit vocoder) is capable of synthesizing speech from raw text. This means\nthat Typhoon2-Audio can act as a text-to-speech (TTS) system. It should be noted that\nusing Typhoon2-Audio for TTS is entirely non-autoregressive. This experiment investigates\nthe TTS performance and compares it with existing TTS systems.\nAs shown in Table 36 and Table 37, Typhoon2-Audio-as-TTS achieves the lowest CER, below\n",
          "output non-Thai characters when following Thai instructions. The evaluation in-\nvolves scenarios where the input instructions are sampled from the test subset\nof airesearch/WangchanThaiInstruct (Vistec, 2024). The assessment is conducted\nacross two temperature settings, T = 0.7 and T = 1.0, to measure the model’s\nconsistency in producing Thai-majority responses.\n• MT-Bench: We utilize MT-Bench, a variant of the LLM-as-a-judge evaluation frame-\nwork, which employs a strong LLM to assess responses to open-ended questions\nbased on correctness, fluency, and adherence to instructions. For the ThaiLLM\nleaderboard (10X et al., 2024), we use the Thai version of MT-Bench developed by\nVISTEC (VISTEC, 2024), while the English version follows the LMSYS implementa-\ntion (Zheng et al., 2023).\nFor Code-switching (CS) evaluation, the metric is accuracy, defined as:\n1. The response does not contain characters from other languages.\n2. Thai characters constitute the majority of the response content.\nBaseline: We compare the Typhoon 2 model based on Llama 8B fine-tuning on the newly\ndeveloped dataset with Typhoon 1.5 (Llama-based) and Llama 3.1 8B Instruct.\n11\n\nTechnical Report\n3.1.3\nResults and Findings\nWe present our results and findings from the selection process of our SFT dataset in Table 4.\nModel\nIFEval\nMT-Bench\nCode-switch\nTH\nEN\nTH\nEN\n1.0\n0.7\nLlama3.1-8B-Instruct\n58.04\n77.64\n5.11\n8.12\n11.20\n93.00\nTyphoon1.5-8B-Instruct\n58.68\n71.33\n5.18\n7.34\n98.80\n98.60\nTyphoon2-Llama-8B-Instruct\n72.60\n76.43\n5.74\n7.58\n98.00\n98.80\nTable 4: Performance on General instruction following\nWe found the following insights:\nImpact of English Data on Thai Performance: Our preliminary experiments indicate that\n",
          "(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\nconsider three desiderata.\nOne is the total computational complexity per layer. Another is the amount of computation that can\nbe parallelized, as measured by the minimum number of sequential operations required.\nThe third is the path length between long-range dependencies in the network. Learning long-range\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\nability to learn such dependencies is the length of the paths forward and backward signals have to\ntraverse in the network. The shorter these paths between any combination of positions in the input\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\nthe maximum path length between any two input and output positions in networks composed of the\ndifferent layer types.\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\n6\n\nlength n is smaller than the representation dimensionality d, which is most often the case with\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\nthe input sequence centered around the respective output position. This would increase the maximum\npath length to O(n/r). We plan to investigate this approach further in future work.\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\nor O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths\nbetween any two positions in the network. Convolutional layers are generally more expensive than\n",
          "of times the LLM judge (e.g., GPT-4) prefers the responses from the model being assessed over the\nresponses from a reference model. The LLM judge compares each pair twice in a symmetric manner,\n6\n\nand if the outputs of the LLM judge are not the same, it is treated as a draw, i.e., the model being\nevaluated gets a score of 0.5 (tie). Otherwise, the model either gets a score of 0.0 (loss) or 1.0 (win).\nIn this experiment, we use GPT-4 (gpt-4-1106) as the LLM judge, and the reference model is GPT-3.5\n(gpt-3.5-turbo-0613) as the reference model such that it would obtain a score of 0.50. For single-turn\nevaluation sets (e.g., Thai-Alpaca, Thai-OASST, and Sea-bench), we follow the LLM-judge prompt\nadopted by AlpacaEval.1 For multi-turn evaluation sets (e.g., translated MT-Bench), we follow the\nLLM-judge prompt adopted in FastChat.2\nModel\nAlpacaEval\nOASST\nMT-Bench\nSea-bench\nTyphoon-7B-Instruct\n49.05\n35.54\n55.52\n27.25\nSeaLLM-7B-Chat\n31.43\n28.01\n36.03\n25.00\nOpenThaiGPT-beta-7B\n20.24\n13.55\n27.94\n9.00\nWangChanGLM\n7.62\n6.33\n19.49\n2.50\nTable 4: Instruction-following evaluation (Score in %) based on Thai AlpacaEval, Thai OASST,\ntranslated MT-Bench and Sea-bench. Each model is compared against GPT-3.5 using GPT-4 as the\njudge, and the metric is win-rate defined as the number of times that the judge prefers the responses\nfrom the model over the responses from the reference model using symmetric pairwise comparison.\nIn Table 4, we compare Typhoon-7B-Instruct against other instruction-following models. At the time\n",
          "mapping them into the vocabulary space. To perform speech generation, h1:t are passed to\na speech decoder, which can operate in parallel with text generation.\nSince a speech waveform requires a higher number of discrete tokens compared to their\ncorresponding textual form, the hidden representations is upsampled by a factor of λ to\nobtain the input of the speech decoder:\nh′\n1:λ×t = [h1, ..., h1\n|\n{z\n}\nλ\n, h2, ..., h2\n|\n{z\n}\nλ\n, ..., ht, ..., ht\n|\n{z\n}\nλ\n]\n(2)\nwhere upsampling factor, λ, is set to 25. Next, upsampled hidden representations h′ are\npassed to the speech decoder, which is implemented with a stack of causal decoder layers\n(e.g., 4 Llama’s layers in this work) and a feedforward network. This speech decoder is\n41\n\nTechnical Report\ncausal but non-autoregressive in both training and inference. Subsequently, the outputs of\nthe speech decoder o1:λ×t are aligned with the target discrete speech units using CTC.\n5.3.2\nDiscrete Speech Tokens\nThe discrete unit based architecture follows Llama-Omni (Fang et al., 2024) and SpeechGPT\n(Zhang et al., 2023a). However, instead of using HuBERT (Hsu et al., 2021), this work adopts\nXEUS (Chen et al., 2024b) to generate discrete speech tokens. This is because XEUS is a\nmodel designed to support multiple languages, which is crucial for efficient speech synthesis\nand vocoder applications. Essentially, XEUS converts continuous a speech waveform into\ndiscrete speech units. These discrete units correspond to the number of clusters (K) from the\nk-means clustering algorithm applied to XEUS representations. The centroids or k-means\nvectors are trained on 20% of 28.7K audio examples randomly selected from Mix-1 by using\nthe TTS system (described in Section 5.3.4).\n",
          "41.46\n67.01\n3B\nTyphoon2-Llama-3B-Instruct\n71.36\n61.92\n73.48\n56.77\n87.50\n78.05\n74.70\nQwen2.5-3B-Instruct\n53.78\n55.71\n70.55\n48.73\n49.88\n82.93\n54.19\nLlama3.2-3B-Instruct\n35.43\n37.40\n59.89\n33.90\n25.00\n82.93\n34.92\n7-8B\nTyphoon2-Qwen-7B-Instruct\n75.12\n71.00\n76.62\n57.44\n95.38\n87.80\n55.65\nTyphoon2-Llama-8B-Instruct\n74.24\n70.79\n74.05\n64.68\n84.00\n87.80\n78.86\nQwen2.5-7B-Instruct\n66.06\n57.48\n77.79\n54.69\n75.75\n85.37\n61.52\nOpenthaigpt1.5-7B-Instruct\n65.53\n59.77\n75.37\n53.35\n75.62\n80.49\n60.47\nLlama3.1-8B-Instruct\n36.92\n50.94\n76.18\n39.63\n12.88\n82.93\n18.66\n70B\nTyphoon2-Llama-70B-Instruct\n70.89\n78.83\n82.32\n67.88\n64.38\n90.24\n70.21\nLlama-3.3-70B-Instruct\n50.30\n68.21\n80.71\n56.91\n21.75\n97.56\n49.86\nLlama-3.1-70B-Instruct\n48.79\n69.92\n81.95\n47.89\n26.88\n92.68\n33.00\nTable 9: BFCL V3 Benchmark on Thai Dataset where we report accuracies for overall, AST,\n",
          "linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\ni=1 qiki, has mean 0 and variance dk.\n4\n\noutput values. These are concatenated and once again projected, resulting in the final values, as\ndepicted in Figure 2.\nMulti-head attention allows the model to jointly attend to information from different representation\nsubspaces at different positions. With a single attention head, averaging inhibits this.\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\nwhere headi = Attention(QW Q\ni , KW K\ni , V W V\ni )\nWhere the projections are parameter matrices W Q\ni\n∈Rdmodel×dk, W K\ni\n∈Rdmodel×dk, W V\ni\n∈Rdmodel×dv\nand W O ∈Rhdv×dmodel.\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\nis similar to that of single-head attention with full dimensionality.\n3.2.3\nApplications of Attention in our Model\nThe Transformer uses multi-head attention in three different ways:\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\nand the memory keys and values come from the output of the encoder. This allows every\nposition in the decoder to attend over all positions in the input sequence. This mimics the\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n[38, 2, 9].\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\nand queries come from the same place, in this case, the output of the previous layer in the\n",
          "MNIST [32], Fashion-MNIST [63], and GoogleNews [41] datasets. Results\ncan be seen in Table 3. UMAP consistently performs faster than any of\nthe other algorithms aside from on the very small Pendigits dataset, where\nLaplacian Eigenmaps and Isomap have a small edge.\n36\n\nFigure 8: Comparison of average Procustes distance per point for t-SNE, LargeVis\nand UMAP over a variety of sizes of subsamples from the full Flow Cytometry\ndataset. UMAP sub-sample embeddings are very close to the full embedding even\nfor subsamples of 5% of the full dataset, outperforming the results of t-SNE and\nLargeVis even when they use the full Flow Cytometry dataset.\n37\n\nUMAP\nFIt-SNE\nt-SNE\nLargeVis\nEigenmaps\nIsomap\nPen Digits\n9s\n48s\n17s\n20s\n2s\n2s\n(1797x64)\nCOIL20\n12s\n75s\n22s\n82s\n47s\n58s\n(1440x16384)\nCOIL100\n85s\n2681s\n810s\n3197s\n3268s\n3210s\n(7200x49152)\nscRNA\n28s\n131s\n258s\n377s\n470s\n923s\n(21086x1000)\nShuttle\n94s\n108s\n714s\n615s\n133s\n–\n(58000x9)\nMNIST\n87s\n292s\n1450s\n1298s\n40709s\n–\n(70000x784)\nF-MNIST\n65s\n278s\n934s\n1173s\n6356s\n–\n(70000x784)\nFlow\n102s\n164s\n1135s\n1127s\n30654s\n–\n(100000x17)\nGoogle News\n361s\n652s\n16906s\n5392s\n–\n–\n(200000x300)\nTable 3: Runtime of several dimension reduction algorithms on various datasets.\nTo allow a broader range of algorithms to run some of the datasets where sub-\n",
          "as intended.\nBaselines: For evaluation, we compare our model, Typhoon 2, against open-weight models,\nincluding variants of Qwen2.5 and Llama 3.1, to benchmark performance.\n3.4.3\nResults and Findings\nModel\nOverall\nAST\nExec\nLive\nMultiTurn\nRelv\nIrrelv\n1B\nTyphoon2-Llama-1B-Instruct\n45.60\n64.15\n66.20\n49.53\n24.00\n82.93\n52.99\nQwen2.5-1.5B-Instruct\n36.50\n59.40\n57.96\n39.14\n16.62\n73.17\n24.05\nLlama3.2-1B-Instruct\n17.88\n21.62\n19.73\n29.99\n0.12\n46.34\n53.75\n3B\nTyphoon2-Llama-3B-Instruct\n75.90\n77.85\n78.77\n66.50\n81.25\n74.61\n83.20\nQwen2.5-3B-Instruct\n62.55\n80.56\n75.27\n60.06\n51.38\n87.80\n55.08\nLlama3.2-3B-Instruct\n53.87\n81.17\n80.48\n55.44\n27.00\n82.93\n55.43\n7-8B\nTyphoon2-Qwen-7B-Instruct\n79.08\n83.21\n83.05\n68.90\n84.50\n92.68\n77.88\nTyphoon2-Llama-8B-Instruct\n75.44\n81.88\n79.00\n70.15\n74.25\n85.37\n84.19\nQwen2.5-7B-Instruct\n74.81\n83.92\n85.00\n65.30\n75.75\n85.37\n65.23\nOpenthaigpt1.5-7B-Instruct\n73.10\n82.98\n81.64\n64.37\n73.62\n87.80\n64.04\nLlama3.1-8B-Instruct\n",
          "method (Kamradt, 2023). This framework assesses a model’s ability to retrieve specific\n“needle sentences\" hidden within random segments of lengthy documents.\nThe evaluation involves completing sentences such as:\n“The best thing to do in San Francisco is to eat a sandwich and sit in Dolores Park\non a sunny day.\"\nwhere the corresponding input prompt is:\n“What is the best thing to do in San Francisco?\"\nWe evaluate the long context abilities in both English and Thai. To ensure linguistic con-\nsistency, the Thai dataset was created using our in-house machine translation model to\ntranslate the English dataset.\nThis work considers two model architectures:\n• Llama3.1-based Model (Grattafiori et al., 2024): The model underwent continued\npre-training with a context length of 8,192 tokens, using the original RoPE (Su et al.,\n2023) base frequency hyperparameter of 500,000. This was followed by supervised\nfine-tuning to extend the context length to 32,768 tokens.\n• Qwen2.5-based Model (Yang et al., 2024a): A similar training pipeline was applied,\nstarting with pre-training using Qwen2.5’s original RoPE (Su et al., 2023) config-\nuration, which employs a base frequency of 1,000,000. Additionally, this model\nleverages the YARN mechanism (Peng et al., 2024), optimized for long-context\nscenarios.\n8https://huggingface.co/datasets/wenbopan/anti-haystack\n15\n\nTechnical Report\n3.3.3\nResults and Findings\nFindings from Typhoon2-Llama3.1-8B,70B-Instruct Evaluation\nFigure 2: Evaluation of Typhoon2-Llama3.1-8B-Instruct on Needle-in-a-Haystack for both\nEnglish (Left) and Thai (Right).\nFigure 3: Evaluation of Typhoon2-Llama3.1-70B-Instruct on Needle-in-a-Haystack for both\nEnglish (Left) and Thai (Right).\nAs illustrated in Figures 2 and 3, both Typhoon2-Llama-3.1-8B,70B-Instruct models support\n",
          "encoder. Each position in the encoder can attend to all positions in the previous layer of the\nencoder.\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\nall positions in the decoder up to and including that position. We need to prevent leftward\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\nof the softmax which correspond to illegal connections. See Figure 2.\n3.3\nPosition-wise Feed-Forward Networks\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\nconnected feed-forward network, which is applied to each position separately and identically. This\nconsists of two linear transformations with a ReLU activation in between.\nFFN(x) = max(0, xW1 + b1)W2 + b2\n(2)\nWhile the linear transformations are the same across different positions, they use different parameters\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\ndff = 2048.\n3.4\nEmbeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\n5\n\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\nLayer Type\nComplexity per Layer\nSequential\nMaximum Path Length\nOperations\nSelf-Attention\n",
          "of conducting the experiments, SEA-LION is only instruction-tuned in Indonesian. GPT-3.5 is used as\na reference model and GPT-4 is used as a judge, and hence are not shown in Table 4. Our experimental\nresults show that Typhoon-7B-Instruct is comparable to GPT-3.5 on Thai AlpacaEval and translated\nMT-Bench but it is worse on Thai OASST and Sea-bench. When compared to open-source Thai LLMs,\nTyphoon-7B-Instruct achieves state-of-the-art performance on all instruction-following datasets.\n4.3\nEvaluation: Translation, Summarization, Question-Answering\nIn addition to instruction-tuning evaluation with an LLM judge, we evaluate the LLMs on standard\nNatural Language Processing (NLP) tasks, including machine translation, abstractive summarization,\nand question-answering. Here, we investigate the zero-shot abilities of Thai LLMs. First, we\nevaluate the English-to-Thai machine translation performance on FLORES-200 [10]. Second, we\nevaluate the abstractive summarization performance on XLSum (Thai article →Thai summary) [14]\nand CrossSum (English article →Thai summary) [5]. Third, we evaluate the question-answering\nperformance on XQuAD (i.e., reading comprehension task) [2]. Our experimental results in Table 5\nshow that Typhoon-7B-Instruct is the best-performing system on most of the NLP tasks investigated.\nModel\nTranslation\nSummarization\nQuestion-Answering\nFLORES-200\nXLSum(Th→Th)\nCrossSum(En→Th)\nXQuAD (Th)\nTyphoon-7B-Instruct\n31.14/46.62\n21.60/4.24/14.51\n17.32/3.83/11.39\n34.46/54.03\nSeaLLM-7B-Chat\n14.36/37.13\n10.21/1.72/7.96\n15.66/2.33/10.58\n20.89/47.95\nOpenThaiGPT-beta-7B\n",
          "real-world tasks. By enabling LLMs to interact with external tools and third-party services,\nfunction calling facilitates impactful applications such as workflow automation and financial\nanalysis. To equip the Typhoon models with this capability, we utilize existing function-\ncalling datasets described in the following subsection.\n3.4.1\nData\nWe construct the general instruction dataset from Section 3.1 combined with three sources\nto ensure diversity, quality, and multilingual support:\n• APIGen (Liu et al., 2024d): This synthetic dataset emphasizes diversity and quality\nthrough a multi-stage hierarchical verification process. A Flan-style approach is\nused to generate outputs in various formats (e.g., JSON, YAML, XML). An in-house\ntranslation system is employed to translate data from English to Thai, ensuring\nrobust bilingual representation.\n• ToolACE (Liu et al., 2024a): This dataset builds on a prior study, focusing on\nenhancing the function-calling capabilities of LLMs. Synthetic data is translated\ninto Thai using the same in-house machine translation system, enabling bilingual\nsupport and increasing dataset complexity and diversity.\n17\n\nTechnical Report\n• Glaive-v29: The popular Glaive-function-calling-v2 dataset is incorporated into\nthe training data mix, complementing APIGen and ToolACE datasets to provide a\ncomprehensive foundation for training.\nThis data combination ensures high-quality, diverse, and multilingual data to train and\nevaluate models effectively.\n3.4.2\nExperimental Setup\nEvaluation: The trained models are evaluated using the Berkeley Function-Calling Bench-\nmark (BFCL) (Patil et al., 2023), a comprehensive framework for assessing the function-\ncalling capabilities of large language models across diverse domains. The evaluation is\nconducted in both English and Thai, with the Thai dataset generated using our in-house ma-\nchine translation from the English dataset. The assessment consists of two key components:\n• Abstract Syntax Tree (AST) Evaluation: This component measures the syntactic cor-\nrectness of generated function calls by comparing them to predefined specifications,\nfocusing on function names, parameters, and data types.\n• Executable Function (Exec) Evaluation: This component verifies operational cor-\nrectness by executing the generated functions to ensure they compile and perform\n",
          "such as Magicoder (Wei et al., 2024) and Wizardcoder (Luo et al., 2024).\nWe also translate a subset of each dataset into Thai using an early version of our Typhoon2\nmodel. Invalid translations are filtered out by validating the responses against the final\n12\n\nTechnical Report\nanswers of the math solutions, and we use an LLM as a judge to evaluate coding correctness.\nIn total, we translate approximately 12K examples in the dataset.\nData Mixture\nThe dataset consists of approximately 250,000 code samples and 200,000 math problems.\nCode samples are sourced from OpenCoder-Instruct, while math problems are collected\nfrom two sources, ScaleQuest-Math and Dart-Math, in an equal proportion (1:1). Preliminary\nexperiments indicated that combining both math datasets results in better performance\ncompared to using a single source. Additionally, a Thai-translated subset is incorporated,\ncontaining 6,000 samples per domain (code and math).\n3.2.2\nExperimental Setup\nWe evaluate the Typhoon 2 models’ performance under various training scenarios, focus-\ning on the impact of code and math domain-specific subsets. Three key evaluations are\nconducted as follows,\n• Training Data Impact: Models trained on the General-only subset are compared to\nthose using General + Code & Math to assess the benefits of domain-specific data.\n• Math Performance: Typhoon 2, fine-tuned on General + Code & Math, is compared to\nLlama 3.1 8B Instruct and Qwen2.5 7B Instruct to evaluate math task effectiveness.\n• Code Performance: Typhoon 2’s code performance, also fine-tuned on General +\nCode & Math, is compared against the same base models to assess the coding ability.\nTraining: The training process and hyperparameters are identical to those described in Sec-\ntion 3.1.2 for General-SFT training.\nEvaluation Data: We evaluate hard domain-specific tasks for LLMs, such as coding and\nmath, which are also related to reasoning performance. We also incorporate evaluations\nfrom the general domain to ensure the model does not overfit specific domain tasks.\n• GSM8K: The Grade School Math 8K (Cobbe et al., 2021) consists of diverse grade\nschool math word problems which are basic mathematical problems that require\n",
          "Provided proper attribution is provided, Google hereby grants permission to\nreproduce the tables and figures in this paper solely for use in journalistic or\nscholarly works.\nAttention Is All You Need\nAshish Vaswani∗\nGoogle Brain\navaswani@google.com\nNoam Shazeer∗\nGoogle Brain\nnoam@google.com\nNiki Parmar∗\nGoogle Research\nnikip@google.com\nJakob Uszkoreit∗\nGoogle Research\nusz@google.com\nLlion Jones∗\nGoogle Research\nllion@google.com\nAidan N. Gomez∗†\nUniversity of Toronto\naidan@cs.toronto.edu\nŁukasz Kaiser∗\nGoogle Brain\nlukaszkaiser@google.com\nIllia Polosukhin∗‡\nillia.polosukhin@gmail.com\nAbstract\nThe dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks that include an encoder and a decoder. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer,\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to\nbe superior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-German translation task, improving over the existing best results, including\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\nbest models from the literature. We show that the Transformer generalizes well to\nother tasks by applying it successfully to English constituency parsing both with\nlarge and limited training data.\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
          "of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n[10], consuming the previously generated symbols as additional input when generating the next.\n2\n\nFigure 1: The Transformer - model architecture.\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\nrespectively.\n3.1\nEncoder and Decoder Stacks\nEncoder:\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder:\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for position i can depend only on the known outputs at positions less than i.\n3.2\nAttention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
          "on Coqui-TTS trained on TSync-1 and TSync-2 data; (1.2) Seamless (seamless-m4t-v2-large)\n(Communication et al., 2023), a unified multilingual system that can synthesize Thai speech\namong many languages; (1.3) MMS-TTS (facebook/mms-tts) (Pratap et al., 2023), massively\nmultilingual speech project, aiming to provide speech technology across a diverse range\nof languages. (2) Proprierary: (2.1) Google Cloud Platform (GCP) _TTS (th-TH-Standard-A)\nand (2.2) Microsoft Azure TTS (Premwadee) through their APIs.\n• When evaluating Typhoon2-Audio for end-to-end speech-to-speech tasks, we benchmark\nit against existing end-to-end models, including Llama-Omni (open-source) and GPT-4o-\nAudio (proprietary through API).\n5.3.6\nResults and Findings\nFinding 1: Developing a Thai unit vocoder\nWe evaluated several unit vocoder models trained on different data mixtures. One model\nconsistently outperformed the others, providing superior synthesis quality, even when\ntrained on a large dataset. However, models trained on larger datasets did not always\nperform better. In some cases, performance declined, suggesting that too much diverse data\nmight complicate the learning process. Although we could not identify a concrete reason\nfor this, further investigation may be needed.\nModel selection was primarily based on qualitative evaluation. We assessed audio quality\nthrough perceptual listening and coherence checks, selecting the model that produced the\nmost natural, high-fidelity audio. While subjective, this method effectively identified the\nbest model. This evaluation highlights the need to balance data diversity with performance\nand to use flexible criteria for model selection.\nFinding 2: Data Mixture for Speech Decoder\nHere, we investigate different data mixes (described in Section 5.3.4) for speech decoder.\nThe vocoder (trained on data Mix-2) is fixed, and we train only the speech decoder for\naround 8 epochs. The results in Table 34 and Table 35 show that data Mix-3 yields the best\noverall accuracy and naturalness.\n",
          "multiple-step reasoning.\n• MATH: The Mathematics Aptitude Test of Heuristics (Hendrycks et al., 2021) is a\nhard math dataset consisting of problems from mathematics competitions.\n• HumanEval: HumanEval (Chen et al., 2021b) consists of programming problems\nwith a function signature, docstring, body, and several unit tests.\n• MBPP: MBPP (Austin et al., 2021) is a set of Python programming problems de-\nsigned to be solvable by entry-level programmers, covering programming funda-\nmentals, standard library functionality, and related topics.\nEvaluation Implementation: The mathematical evaluation is zero-shot based on the\ndartmath implementation (Tong et al., 2024b). Code evaluation is zero-shot based on the\nevalplus implementation (Liu et al., 2023b) – we report the base subset result. The Thai\nsubset is created by directly translating the original dataset into Thai using GPT-4o, with\nautomatic verification performed using the LLM-as-judge technique.\n3.2.3\nResults and Findings\nModel IFEval(Avg) MT-Bench(Avg) GSM8K Math HumanEval MBPP\nGeneral only\n73.75\n6.581\n39.10\n16.34\n49.70\n54.35\nGeneral + Code & Math\n74.7\n6.715\n81.00\n49.04\n63.70\n61.90\nTable 5: Typhoon2-Llama-8B Performance difference when adding domain-specific dataset\n13\n\nTechnical Report\nModel\nGSM8K-TH\nGSM8K-EN\nMath-TH\nMath-EN\nLlama3.1-8B-Instruct\n45.18\n62.40\n24.42\n48.00\nTyphoon2-Llama3.1-8B-Instruct\n71.72\n81.00\n38.48\n49.04\nQwen2.5-7B-Instruct\n47.53\n81.00\n17.41\n73.40\nTyphoon2-Qwen2.5-7B-Instruct\n79.07\n84.20\n55.42\n66.42\nTable 6: Math only performance compared to SOTA model\n",
          "OCR (TH)\nROUGE-L\n64.41\n56.47\n6.38\n79.51\n64.24\nSapsathien & Jaroenkantasima (2024) Accuracy\n35.58\n55.34\n2.88\n58.65\n63.11\nM3Exam Images-(TH)\nROUGE-L\n-\n-\n-\n-\n-\nZhang et al. (2023c)\nAccuracy\n25.46\n32.17\n29.01\n27.93\n33.67\nGQA (TH)\nROUGE-L\n31.33\n34.55\n10.20\n44.51\n50.25\nHudson & Manning (2019)\nAccuracy\n-\n-\n-\n-\n-\nMTVQ (TH)\nROUGE-L\n11.21\n23.39\n7.63\n15.20\n30.59\nTang et al. (2024b)\nAccuracy\n4.31\n13.79\n1.72\n7.56\n21.55\nAverage (ROUGE-L)\n37.67\n54.26\n25.61\n64.16\n62.77\nAverage (Accuracy)\nx\n53.85\n23.67\n58.75\n59.02\nTable 25: Comprehensive Overview of Benchmark Performance Across Models, including\nthe Typhoon2-Vision model. For each cell, the upper value (top row) represents ROUGE-L,\nwhile the lower value (bottom row) indicates Accuracy (normalized such that ROUGE-L =\n100%). Additionally, cells labeled with ‘x‘ represent outcomes lacking CoT reasoning, thus\ncomplicating verification.\n34\n\nTechnical Report\n5\nAudio & Speech\nWe introduce Typhoon2-Audio, an end-to-end speech processing and generation model. It\nintegrates advanced techniques for encoding audio, speech, and text and generating text\nand speech. This section covers its end-to-end model architecture, followed by audio and\nspeech encoding and speech generation. Each section features model components, data,\nexperiments, and findings. The section concludes with an end-to-end speech-to-speech\n",
          "onds). To enable longer audio understanding, we segmented Yodas2 (Li et al., 2023b) audio\ninto 30-second chunks and used GPT-4o to generate QA pairs, including multiple-choice\nquestions (MCQs) to improve SpokenQA performance (Section 5.2.4). We focused on the\nThai subset of Yodas2 to address the dominance of English in existing QA datasets. Addi-\ntionally, we generated QA pairs from the VISTEC-SER dataset (VISTEC, 2021), leveraging\nmetadata like speaker gender and emotional state to capture voice-specific characteristics.\n• Audio Caption: AudioCaps is used for pre-training, but its short ground-truth captions limit\ndetailed response generation. To address this, we provide Gemini-1.5-Pro with both audio\ninput and the short caption, prompting it to generate detailed responses. This augmented\ndata is called AudioCaps (Gemini).\n• Speech Instruction Following (SpeechIF): This task requires models to listen to spoken\ninstructions and directly respond. Current models like SALMONN lack specific data for this\nability. We propose two methods for generating SpeechIF data (Figure 9). Type1 leverages\nASR datasets to generate text responses from transcripts. However, since ASR data typically\ncontains non-question utterances, LLMs often default to safe responses such as “I’m sorry,\n37\n\nTechnical Report\nas an AI assistant I cannot...\" in up to 30% of cases. While it offers voice diversity, it does\nnot fully reflect real-world interactions. Type2 synthesizes speech from instruction-response\npairs (e.g., Alpaca, Airoboros), providing more practical commands but struggles with\nunsuitable instructions like math or coding. Though lacking voice diversity, it represents\nreal interactions better. For evaluation, we selected instructions from AlpacaEval (English)\nand SelfInstruct (Thai), creating SpeechIF benchmark for both languages. The prompt for\nbaseline models (e.g., SALMONN) is “Listen to the audio and answer the question\".\nASR data\n{Audio, Text}\nAudio\nText\nLLM\nText\nResponse\nType1: SpeechIF\nData derived from\nASR Data\nText Instruction-\nResponse Data\n",
          "6.34\n7.12\n7.43\n8.18\nResults using Transcribed Speech\nLlama-Omni\n5.15\n5.79\n1.71\n2.14\nGPT-4o-Audio\n6.82\n7.86\n6.66\n8.07\nTyphoon2-Audio\n4.92\n5.39\n7.19\n8.04\nTable 38: S2TIF Evaluation of end-to-end systems.\nWe evaluate end-to-end systems on speech generation quality, measuring transcription error\nrates and UTMOS scores, similar to Section 5.3.\nAs shown in Table 39, Typhoon2-Audio performs comparably to GPT-4o-Audio in Thai but\nrequires improvement in English. While Llama-Omni achieves the lowest WER and CER\nfor Thai, it responds exclusively in English, unlike the other models.\nTyphoon2-Audio also shows lower UTMOS scores than GPT-4o and Llama-Omni, indicating\nits speech output is perceived as less natural.\nModel\nSpeechIF (English)\nSpeechIF (Thai)\nWER(↓)\nCER(↓)\nUTMOS(↑)\nWER(↓)\nCER(↓)\nUTMOS(↑)\nLlama-Omni\n4.98\n3.40\n3.932\n8.51†\n6.30†\n3.928†\nGPT-4o-Audio\n4.88\n3.20\n3.652\n11.71\n8.05\n3.464\nTyphoon2-Audio\n33.00\n26.50\n2.285\n10.04\n8.67\n2.348\nTable 39: Speech Quality: End-to-End Evaluation (without ASR or TTS systems). †Llama-\nOmni fails to respond in Thai. As Llama-Omni simply responds in English, its responses\nachieve good results in Thai SpeechIF as measured by WER, CER, UTMOS.\n45\n\nTechnical Report\n6\nConclusions\nThis technical report introduced Typhoon 2, a series of Thai LLMs, comprising text models\n",
          "Exec, Live, Multi-turn as well as relevance and irrelevance scores.\nData Proportion and Balance: Our results indicate that the proportion of token data from\ntool-calling datasets should not exceed or equal that of instruction-following datasets.\nMaintaining an appropriate balance is critical to ensuring practical model training.\nAccuracy vs. Generalization: While the model demonstrates high accuracy on tool-calling\ntasks, it exhibits limited generalization capabilities across other tasks. This highlights the\nneed for a more diverse and balanced training dataset.\nDataset Composition Recommendations:\n• Tool-calling data should comprise 5-10% of the total dataset to balance specializa-\ntion with generalization.\n• Thai-translated tool-calling data should represent approximately 40% of the tool-\ncalling subset to ensure adequate multilingual support.\n• High-quality instruction-following datasets are essential for improving both gen-\neralization and tool-calling performance, suggesting a synergistic relationship be-\ntween these components.\n3.5\nDistillation\nDistillation is a widely recognized method to transfer knowledge from a stronger model to\na smaller model, as seen from the era of BERT to DistilBERT(Sanh et al., 2020), and so on.\nIn the case of LLMs, there have also been successful examples such as Minitron (Sreenivas\net al., 2024) and Llama 3.210. Following this approach, we apply a distillation technique to\nenhance the performance of the smaller Typhoon models.\n3.5.1\nTop-k Logits Distillation\nWe employ top-k logits distillation, drawing inspiration from Arcee-AI’s methodology11.\nThe objective of this approach is to transfer knowledge from a larger teacher model to a\nsmaller student model. Our method involves constructing logit data from a larger teacher\nmodel, where only the top-k predictions for each vocabulary token are retained. The top-k\nlogits are obtained from early versions of the Llama-based Typhoon 2 models, specifically\n10https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/\n",
          "Data Filtering\nUtilizing the Typhoon 1.5X model, we refine the content pattern by excluding question-\nanswer pairs that have no answers from data. This process employs the sentence transform-\ners paraphrase-multilingual-MiniLM-L12-v2 model with a similarity threshold of 0.2337.\n32\n\nTechnical Report\nIn the subsequent phase of this experiment, we compile a comprehensive dataset specifically\ntailored for fine-tuning instruction-based tasks conducted in the Thai language. This dataset\nis instrumental in the automation of issue detection and labeling. These functions are critical\nelements in the methodology aimed at transitioning towards the establishment of a reliable\nand trustworthy model.\n4.4\nExperimental Setup\nEvaluation\nThis evaluation evaluates models’ performance in tasks such as ChartQA, MTVQ (TH),\nOCR (TH), OCRBench and TextVQA against other baselines, including Llama-3.2-Vision,\nQwen2-VL, and Pathumma-Vision. We focus on Thai-specific OCR and visual question-\nanswering tasks. We use standard evaluation metrics for these tasks which are Accuracy\nand ROUGE-L – the measure of the longest n-gram overlap between the generated text and\nits reference.\nTraining\nThe model training process utilizes a multi-GPU setup comprising four NVIDIA A100 GPUs,\neach with 80 GB of memory. Fine-tuning is performed using the Low-Rank Adaptation\n(LoRA) technique (Hu et al., 2022) with a rank parameter r = 8 and an alpha scaling factor\nα = 16, applying to all linear layers of the model. The fine-tuning process follows the SFT\nstage configuration and is conducted over 2 epochs, using a learning rate of 1.0 × 10−4. A\ncosine learning rate scheduler is employed to dynamically adjust the learning rate during\ntraining, ensuring a smooth convergence. This setup balances computational efficiency and\nmodel performance optimization.\n4.5\nResults and Findings\nIn our instruction tuning experiments, we consider two base models, Llama 3.2 and Qwen2,\nand employ the same data set to fine-tune both models.\nWe evaluate the performance in both Thai and English tasks using four evaluation datasets\nper language. The results in Table 25 show the following findings:\n",
          "in multiple sizes (both base and instruction-tuned variants) and multimodal models for\nvision and audio tasks. Our evaluation demonstrates superior performance across a majority\nof evaluated tasks, including math and reasoning. Typhoon2-Text models have an extended\ncontext length of up to 100,000 tokens, compared to 8,192 tokens of Typhoon 1.5. Typhoon2-\nText also features function calling capabilities, achieving state-of-the-art results. Additionally,\nwe include a safety classifier that delivers state-of-the-art performance specifically for Thai.\nTyphoon 2 series also includes multimodal models, focusing on vision and audio. For\nvisual understanding, Typhoon2-Vision achieves significantly improved Thai document\nunderstanding such as Thai OCR performance compared to its predecessor, while Typhoon2-\nAudio has evolved into an end-to-end speech-to-speech model, capable of generating\nsimultaneous text and speech outputs. We have made all research artifacts, including\nmodels’ weights, publicly available. We hope this work will accelerate AI advancements for\nthe Thai language and inspire further innovation in the field.\n7\nAcknowledgments\nWe thank Thanapong Boontaeng for his insightful advice and feedback on this technical\nreport and the overall project. We also thank Mukaya Panich and other members of SCB 10X\nfor their invaluable support and guidance throughout the project. We also extend our\nappreciation to Kaweewut Temphuwapat and the SCBX Innovation Team for their support,\nresources, and valuable insights that have made this project possible. Lastly, we are grateful\nto the global and local AI communities for open-sourcing resources and knowledge.\nReferences\nSCB 10X, VISTEC, and SEACrowd.\nThai LLM Leaderboard, 2024.\nURL https://\nhuggingface.co/spaces/ThaiLLM-Leaderboard/leaderboard.\nMarah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan,\nNguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, et al. Phi-3\ntechnical report: A highly capable language model locally on your phone. arXiv preprint\narXiv:2404.14219, 2024.\n",
          "27.68/44.41\n17.98/1.93/12.69\n17.72/3.06/11.28\n34.58/40.82\nWangChanGLM\n10.63/31.78\n19.10/2.10/13.77\n22.91/3.76/15.61\n17.81/19.94\nTable 5: Zero-shot performance on NLP tasks. Machine translation is evaluated on FLORES-200\nusing BLEU [39] and chrF [44]. Summarization is evaluated on XLSum (Thai-to-Thai) and CrossSum\n(English-to-Thai) using ROUGE-1/2/L [22] with the newmm tokenizer. Question-Answering is\nevaluated on XQuAD using word-overlap F1 metric in 0-shot and 1-shot settings, respectively.\n1https://github.com/tatsu-lab/alpaca_eval/blob/main/src/alpaca_eval/evaluators_\nconfigs/chatgpt/basic_prompt.txt\n2https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/data/judge_\nprompts.jsonl\n7\n\n5\nRisk and Limitations\nSimilar to other language models, Typhoon may (i) hallucinate, e.g., generate responses that are not\nfaithful to the prompt or not factually correct with respect to world knowledge, (ii) generate repetitions,\ne.g., repeated words, phrases or sentences, (iii) produce harmful or inappropriate responses.\n6\nConclusion and Future Work\nOur work on Typhoon, a Thai large language model with 7 billion parameters, demonstrates that we\ncan adapt an existing English-centric LLM to Thai using only a subset of Thai data that we currently\nhave. Typhoon is the state-of-the-art open-source model on Thai benchmarks as well as achieving\nperformance on par with GPT-3.5 in Thai while being 2.62 times more efficient in tokenization.\nFuture work will extend pretraining to utilize a larger amount of Thai data that is available, and use\n",
          "21.71\n36.23\n50.74 38.54\nTyphoon2-Llama-3B-base\n44.53\n40.12 40.00\n26.77\n69.23 46.55\n41.84\n24.43\n41.30\n60.07 41.56\nLlama3.1-8B\n45.80\n38.27 46.31\n34.64\n61.53 48.27\n43.33\n27.14\n40.82\n58.33 47.05\nTyphoon1.5-8B-base\n48.82\n41.35 41.05\n40.94\n70.76 50.00\n43.88\n22.62\n43.47\n62.81 46.63\nTyphoon2-Llama-8B-base\n51.20\n49.38 47.36\n43.30\n67.69 48.27\n47.52\n27.60\n44.20\n68.90 49.38\nQwen2.5-7B\n55.74\n51.23 60.00\n41.73\n72.30 53.44\n55.65\n46.15\n54.10\n66.54 55.82\nTyphoon2-Qwen2.5-7B-base\n58.86\n58.64 65.26\n55.11\n66.15 49.13\n59.90\n42.98\n59.42\n75.62 61.59\nLlama3.1-70B\n60.74\n62.34 67.36\n53.54\n66.15 54.31\n60.35\n38.91\n62.56\n76.99 62.96\nTyphoon2-Llama-70B-base\n63.38\n65.43 69.47\n59.84\n66.15 56.03\n62.33\n42.98\n63.28\n78.60 64.47\nAvg. Human\n-\n31.80\n-\n47.20\n40.60\n-\n31.80\n-\n-\n-\nTable 2: The performance of pre-trained models on Exam in Thai. Human averages are\nestimated from of Educational Testing Service (2021); of University Presidents of Thailand\n",
          "During training, we employed label smoothing of value ϵls = 0.1 [36]. This\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n6\nResults\n6.1\nMachine Translation\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\nthe competitive models.\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\ndropout rate Pdrop = 0.1, instead of 0.3.\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\nwere chosen after experimentation on the development set. We set the maximum output length during\ninference to input length + 50, but terminate early when possible [38].\nTable 2 summarizes our results and compares our translation quality and training costs to other model\narchitectures from the literature. We estimate the number of floating point operations used to train a\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\nsingle-precision floating-point capacity of each GPU 5.\n6.2\nModel Variations\nTo evaluate the importance of different components of the Transformer, we varied our base model\nin different ways, measuring the change in performance on English-to-German translation on the\n",
          "WSJ only, discriminative\n88.3\nPetrov et al. (2006) [29]\nWSJ only, discriminative\n90.4\nZhu et al. (2013) [40]\nWSJ only, discriminative\n90.4\nDyer et al. (2016) [8]\nWSJ only, discriminative\n91.7\nTransformer (4 layers)\nWSJ only, discriminative\n91.3\nZhu et al. (2013) [40]\nsemi-supervised\n91.3\nHuang & Harper (2009) [14]\nsemi-supervised\n91.3\nMcClosky et al. (2006) [26]\nsemi-supervised\n92.1\nVinyals & Kaiser el al. (2014) [37]\nsemi-supervised\n92.1\nTransformer (4 layers)\nsemi-supervised\n92.7\nLuong et al. (2015) [23]\nmulti-task\n93.0\nDyer et al. (2016) [8]\ngenerative\n93.3\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\nfor both WSJ only and the semi-supervised setting.\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\nprisingly well, yielding better results than all previously reported models with the exception of the\nRecurrent Neural Network Grammar [8].\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\nParser [29] even when training only on the WSJ training set of 40K sentences.\n7\nConclusion\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\nmulti-headed self-attention.\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\nmodel outperforms even all previously reported ensembles.\n",
          "Speech Generation\nThe speech encoding components (Section 5.2) and LLM enable processing of audio, speech,\nand text inputs to produce text outputs. For speech output, the generated text can be\npassed to a text-to-speech (TTS) system, but this pipelined approach delays TTS until text\ngeneration finishes, causing high time-to-first-token latency. This section explores extending\nthe output to enable parallel speech and text generation.\nWe extend the output side for speech generation using the Llama-Omni architecture (Fang\net al., 2024), as shown in Figure 10. Hidden states from the LLM are upsampled and fed\ninto a non-autoregressive speech decoder, producing discrete speech units. A unit vocoder\nthen maps these tokens to a waveform.\nSpeech\nDecoder\nLLM\nUnit\nVocoder\nDiscrete\nSpeech Units\nAudio Output\nInput Embeddings (x)\nOutput Embeddings (y)\nUpsampled\nOutput Hidden States\nlatency\nText Generation and \nSpeech Generation can\nbe done simultaneously\nin parallel\nLLM\nInput Embeddings (x)\nOutput Embeddings (y)\nOutput Hidden States\nLanguage Model Head\n+ Softmax\nText Output\nText Generation\nSpeech Generation\nFigure 10: Text Generation (left) and Speech Generation (right)\nThe training process has two stages. First, the speech decoder is trained with Connectionist\nTemporal Classification (CTC) (Graves et al., 2006) to predict discrete speech units. Second,\nthe unit vocoder is trained using multiple losses: (1) reconstruction loss (e.g., L1, L2, or\nspectral) for waveform accuracy, (2) adversarial loss for naturalness, (3) feature matching\nloss to align intermediate features, and (4) duration prediction loss (MSE) to improve\ntemporal alignment of unit segments.\n5.3.1\nSpeech Decoder\nThe LLM encodes output tokens, y1:t, into their hidden representations:\nh1:t = f (y1:t; θLLM)\n(1)\nTo perform text generation, these hidden representations h1:t are passed to a linear layer,\n",
          "insights from developing Thai large language models but also makes Typhoon publicly available\nunder the Apache-2.0 license to promote further development.\n2\nRelated Work\nTraining language models on monolingual data (as well as bilingual data where the target language\nand English data are mixed) has demonstrated gains over multilingual models in both predictive\nand generative modelling tasks [28, 30, 49, 29, 41, 50]. For Thai, WangChangBERTa [26], an\nencoder-only model, was the first transformer-based model to be trained on large-scale Thai data.\nHowever, as an encoder-only model, WangChangBERTa cannot perform text generation.\nTwo open-source Thai generative large language models have also recently been developed.\nFirst, WangChanGLM [42] is based on multilingual XGLM [23] with 7.5 billion parameters.\nWangChanGLM is adapted to Thai by fine-tuning XGLM using LoRA [15] on translated instruction-\nfollowing datasets of around 380k instruction-response pairs. However, WangChanGLM is not\nfurther pretrained on Thai data, so its Thai knowledge is expected to be limited to the pretraining\nstage of XGLM. Second, OpenThaiGPT (openthaigpt-1.0.0-beta-7b) [36] is based on Llama2 [55]\nwith 7 billion parameters. Its tokenizer extends Llama2’s tokenizer to include 24,554 additional\nThai tokens to improve generation efficiency. OpenThaiGPT continues pre-training Llama2 on Thai\ndata and performs instruction fine-tuning on the translated instruction datasets. Although the model\nweights are released to the public, to the best of our knowledge, further details are not publicly\n2\n\navailable. Additionally, the vanilla Llama2 model may not be able to generate Thai responses, but it\ncan understand Thai to a certain extent (which is shown in our results in Table 3) due to cross-lingual\ntransferability and the presence of some Thai data during its pretraining. In Table 1, we summarize\nopen-source generative LLMs that are investigated in this work.\nChatGPT and GPT-4 [35] are proprietary language model based products that support a variety\n",
          "5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\n8\n\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\nper-word perplexities.\nN\ndmodel\ndff\nh\ndk\ndv\nPdrop\nϵls\ntrain\nPPL\nBLEU\nparams\nsteps\n(dev)\n(dev)\n×106\nbase\n6\n512\n2048\n8\n64\n64\n0.1\n0.1\n100K\n4.92\n25.8\n65\n(A)\n1\n512\n512\n5.29\n24.9\n4\n128\n128\n5.00\n25.5\n16\n32\n32\n4.91\n25.8\n32\n16\n16\n5.01\n25.4\n(B)\n16\n5.16\n25.1\n58\n32\n5.01\n25.4\n60\n(C)\n2\n6.11\n23.7\n36\n4\n5.19\n25.3\n50\n8\n4.88\n25.5\n80\n256\n32\n32\n5.75\n24.5\n28\n1024\n128\n128\n4.66\n26.0\n168\n1024\n5.12\n25.4\n53\n4096\n4.75\n26.2\n90\n(D)\n0.0\n5.77\n24.6\n0.2\n4.95\n25.5\n0.0\n4.67\n25.3\n0.2\n5.47\n25.7\n(E)\npositional embedding instead of sinusoids\n4.92\n25.7\nbig\n6\n1024\n4096\n16\n0.3\n300K\n4.33\n26.4\n213\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\n",
          "evaluation, comparing Typhoon2-Audio against other existing end-to-end speech models.\nThe model code and weights are available at https://github.com/scb-10x/typhoon2-audio/\n5.1\nEnd-to-End Model Architecture\nThe architecture of Typhoon2-Audio, illustrated in Figure 8, processes both text and au-\ndio/speech13 modalities, integrating pre-trained components for text and speech handling.\nIt starts with an encoding module comprising a text tokenizer for converting textual input\ninto representations and a speech encoder that embeds speech and audio-event inputs into\na shared representation space. These embeddings are passed to an LLM for reasoning and\ngenerating outputs. The speech generation module then converts LLM outputs into: (1) text\nvia a language model head, and (2) speech via a speech decoder and unit vocoder, producing\nspeech output. Text and speech outputs can be decoded in parallel. The encoding module\nadopts the design of Typhoon-Audio (Manakul et al., 2024) based on SALMONN (Tang\net al., 2024a), while the speech generation module follows Llama-Omni (Fang et al., 2024).\nInput\nTextual Prompt (or Null)\n    Audio \nText Tokenizer\n& Embedding\nAudio\nEncoder\nAdapter\nLLM\nLoRA\n+\nconcat\nSpeech\nDecoder\nUnit\nVocoder\nText Output\nAudio Output\nFigure 8: Typhoon2-Audio End-to-End Model Architecture\nSpecifically, the final configuration of Typhoon2-Audio is based on the following pre-trained\ncomponents with the corresponding number of parameters presented in Table 26.\nComponent\nInitialization\nParameters (Billion)\nWhisper Encoder\nThonburian Whisper\n0.637\nBEATs\nBEATs pre-trained weights\n0.091\nQ-Former\nRandomly Initialized\n0.080\nLinear Layers\nRandomly Initialized\n0.003\nLLM\nTyphoon2-8B (Llama-3.1-based)\n8.030\nSpeech Decoder\nRandomly Initialized\n0.830\nVocoder\nRandomly Initialized\n",
          "TH\nEN\nTH\nEN\n0.7\n1.0\nTH\nEN\nTH\nEN\nTH\nEN\nTH\nEN\nTH\nEN\nTyphoon2-70B-Instruct 81.4 88.7 7.36\n8.85\n98.8 94.8 70.8 65.7 88.7 93.4 59.6 64.9 79.9\n83.5\n86.0 84.9\nLlama-3.1-70B-Instruct 64.9 86.3 6.29\n9.10\n90.2 53.0 47.9 53.2 61.1 60.0 40.6 63.6 73.8\n79.9\n83.6 82.8\nLlama-3.3-70B-Instruct 81.0 91.5 6.79\n8.83\n72.6 39.2 50.3 56.3 61.6 87.7 44.3 73.5 81.7\n84.1\n84.9 87.3\nQwen2.5-72B-Instruct 78.6 86.5 7.46\n9.28\n91.6 48.6 70.8 77.9 71.7 94.6 47.9 83.1 84.1\n87.2\n88.6 90.5\nOpenThaiGPT 1.5 72B 80.3 84.5 7.31\n9.08\n95.6 50.4 67.1 74.6 79.1 89.9 43.6 81.8 81.7\n84.8\n88.9 89.7\nTable 16: 70B Model Performance\n3.10\nSafety\nGiven distinct cultural sensitivities present in Thai society, where certain topics may be\nconsidered sensitive but are not perceived as such in other countries, and the language\ndifferences between Thai and other languages, we develop a guardrail model specifically\nfor the Thai language. This model is referred to as Typhoon2-Safety, which is a lightweight\nbinary classifier designed to address both Thai-specific sensitive topics and universally\nrelevant topics. Additionally, it is designed to guardrail both prompts and responses.\n3.10.1\nData Generation\nWe develop a data generation pipeline to create a Thai culturally aware safety dataset.\nOur methodology emphasizes both Thai-specific cultural sensitivities and universal safety\n",
          "O(n2 · d)\nO(1)\nO(1)\nRecurrent\nO(n · d2)\nO(n)\nO(n)\nConvolutional\nO(k · n · d2)\nO(1)\nO(logk(n))\nSelf-Attention (restricted)\nO(r · n · d)\nO(1)\nO(n/r)\n3.5\nPositional Encoding\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\norder of the sequence, we must inject some information about the relative or absolute position of the\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\nlearned and fixed [9].\nIn this work, we use sine and cosine functions of different frequencies:\nPE(pos,2i) = sin(pos/100002i/dmodel)\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\nchose this function because we hypothesized it would allow the model to easily learn to attend by\nrelative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of\nPEpos.\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\nduring training.\n4\nWhy Self-Attention\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\ntional layers commonly used for mapping one variable-length sequence of symbol representations\n",
          "0.017\nTotal\n-\n9.688\nTable 26: The breakdown of the number of parameters and initialization of each component\nof Typhoon2-Audio. Parameters to be trained in different stages are shown in Figure 8.\n13In this section, the terms “audio\" and “speech\" will be used interchangeably. The input may\nconsist of human speech or general audio events, but the output is speech generated by a single voice.\n35\n\nTechnical Report\n5.2\nSpeech Encoding\nSpeech encoding bridges audio/speech and text modalities, enabling large language models\nto process audio/speech inputs while generating text outputs. This alignment allows the\nmodel to gain audio and speech understanding, enabling it to handle tasks like transcription,\nspoken language comprehension, and multimodal reasoning through speech prompts.\n5.2.1\nSpeech Encoder\nEncoder Architecture: Our model leverages the SALMONN architecture (Tang et al., 2024a),\nemploying Whisper Encoder for speech understanding, BEATs for audio event understand-\ning, and Q-Former with an MLP to align speech and text representations With Thai and\nEnglish as target languages, our model is based on an LLM from the Typhoon series (e.g.,\nTyphoon 1.5, Typhoon 2), Whisper-large-v3 fine-tuned to Thai (Aung et al., 2024) coupled\nwith BEATs (Chen et al., 2023) as the audio encoder, and Q-Former (Li et al., 2023a) trained\nfrom scratch as the adapter. Note that we also examine other variants of LLM and audio\nencoder backbones in Section 5.2.4.\nTraining Strategies: The audio encoder maps the spectrogram into a representation, which\nis then transformed into the audio representation a in the text embedding space via an\nadapter. The model θ is trained to maximize the probability of the next word yt in the textual\nresponse, conditioned on previous words y1:t−1, textual prompt input x and the audio input\na: P(yt|y1:t−1, x, a; θ). Training occurs in two phases:\n1) Pre-training: As the adapter is the only component initialized with random weights, this\n",
          "19.94\nWhisper-v3-large-Th\nTyphoon-1.5\n9.15\n13.52\n30.83\n20.55\nTable 29: Pre-training Results on ASR: LibriSpeech (other), CommonVoice (*subset-1K), AC:\nAudioCaps (En&Th-translated)\nFinding 3: Recipe for Supervised Fine Tuning (SFT) Data Mixture\nThis experiment focuses on data mixture to enhance instruction-following abilities across\ntasks and languages. Training is initialized using the pre-trained model from the previous\nsection. The results in Table 30 show that: First, the pre-trained model does not exhibit task\nability and it simply provides transcriptions of speech regardless of instructions. Second,\nwhen fine-tuned on only English prompt-response pairs (a subset of around 600K pairs\nin total taken from SALMONN and LTU), the model achieves better performance on new\ntasks, but performs poorly on Thai ASR, showing similar characteristics to SALMONN\nin Table 31. Ultimately, our SFT recipe significantly improves the model performance on\nevaluated tasks, while not significantly degrading its ASR abilities. Further information on\nour SFT recipe is provided our the Typhoon-Audio paper (Manakul et al., 2024).\nExperiment\n#Ex\nASR*↓\nTh2En↑\nSpokenQA↑\nSpeechIF↑\nComplexIF†↑\nPre-trained\n-\n13.52\n0.00\n28.33\n1.12\n1.41\n100% English SFT 600K\n80.86\n6.01\n36.88\n1.48\n6.35\nOur SFT recipe\n640K\n16.89\n24.14\n64.60\n6.11\n7.54\nTable 30: SFT Results on Thai Tasks and English ComplexIF. ∗ASR is eval on subset-1K of\nCV17. †Average of Qual and Format. For 100% English SFT, around 600K QA pairs were\ntaken from SALMONN and LTU datasets.\n39\n\nTechnical Report\nFinding 4: Typhoon-Audio & Typhoon2-Audio versus Existing Audio Language Models\n",
          "length to 32,768 tokens on four A100 (80GB) GPUs with Deepspeed ZeRO Stage 3. To\nenhance the long-context capabilities of Typhoon 2, we extend its context length from 8,192\ntokens in Typhoon 1.5 to 32,768 tokens and generalize support for context lengths up to\n128K tokens. We evaluate this capability through experiments on SFT tasks following CPT\nwith an 8,192-token context size.\n3.3.1\nData\nWe construct the dataset based on Section 3.1 combined with three primary sources to ensure\nboth effective exploitation of long contexts and robust multilingual support. These three\nprimary sources are:\n14\n\nTechnical Report\n• LongAlign (Bai et al., 2024): This dataset is derived from the LongAlign framework,\nwhich is specifically designed to enhance LLMs for long-context understanding and\ninstruction-following. While the full framework encompasses data creation, training\nstrategies, and evaluation for long-context alignment, we selectively incorporate\nthe dataset component for our work.\n• Anti-haystack8: This dataset is designed for enhancing the ability of LLMs to locate\nshort and precise facts within long, noisy documents, emulating a “needle in a\nhaystack\" challenge.\n• IApp-Wiki-QA Dataset (Viriyayudhakorn & Polpanumas, 2021): To enhance Thai\nlong-context capabilities, we utilize the Thai Wikipedia Question Answering dataset,\nconsisting of 1,500 unique context records. We extend and reformat the data using\nthe following processes:\n– Irrelevant Content Addition: Random irrelevant contents are sampled from\nthe ThaiSum dataset (Chumpolsathien, 2020), a news summarization dataset\nin the Thai language, to introduce noise and increase the context length.\n– Question and Answer Integration: Questions and answers from the IApp-\nWiki-QA dataset are randomly positioned within the extended context.\n– Token Length Requirement: Each row in the dataset is structured to ensure\nthat the Thai token count exceeds 30,000 tokens.\n3.3.2\nExperimental Setup\nEvaluation: We evaluate the long context abilities using the Needle-in-a-Haystack (NIAH)\n",
          "21.20\n35.43\n53.87\nQwen2.5-3B-Instruct\n58.86\n67.25\n4.626\n7.846\n78.60\n38.00\n53.78\n62.55\nTable 14: 3B Model Performance\nModel\nIFEval\nMTBench\nCS\nFC\nGSM8K\nMath\nHumanEv\nMBPP\nTH\nEN\nTH\nEN\n0.7\n1.0\nTH\nEN\nTH\nEN\nTH\nEN\nTH\nEN\nTH\nEN\nTyphoon2-Q-7B-Instruct 74.3 73.3 6.18\n8.09\n99.2 96.8 74.2 75.4 79.0 84.2 55.4 66.4 73.2\n79.3\n78.3 81.7\nQwen2.5-7B-Instruct 68.4 76.8 6.00\n8.53\n85.8 20.4 66.0 74.8 47.5 81.0 17.4 73.4 77.4\n81.1\n80.4 79.6\nOpenThaiGPT 1.5 7B 67.3 75.4 5.69\n8.10\n93.8 28.0 65.5 73.1 65.7 68.0 24.4 69.6 71.3\n78.7\n77.5 79.1\nTyphoon2-L-8B-Instruct 72.6 76.4 5.74\n7.58\n98.8 98.0 75.1 79.0 71.7 81.0 38.4 49.0 58.5\n68.9\n60.8 63.0\nLlama3.1-8B-instruct 58.0 77.6 5.10\n8.11\n93.0 11.2 36.9 66.0 45.1 62.4 24.4 48.0 51.8\n67.7\n64.6 66.9\nTable 15: Performance of 7-8B Models: Q denotes Qwen2.5, and L denotes Llama 3.1.\nModel\nIFEval\nMTBench\nCS\nFC\nGSM8K\nMath\nHumanEv\nMBPP\n",
          "a maximum context length of approximately 90,000 tokens. This is a reduction compared to\nthe original Llama 3.1 model, which supports up to 128,000 tokens. We hypothesize that\nthis limitation is due to two key factors:\n1. The original Llama 3.1 model was trained incrementally across multiple stages,\nprogressively extending its context length to 128,000 tokens.\n2. Our CPT approach is restricted to a context length of 8,192 tokens, potentially\nlimiting the model’s ability to generalize to longer contexts, despite adjustments to\nthe RoPE scaling (Su et al., 2023).\nAddressing these limitations could pave the way for future enhancements to the Llama-\nbased Typhoon 2 models.\n16\n\nTechnical Report\nFindings from Typhoon2-Qwen2.5-7B-Instruct Evaluation\nFigure 4: Evaluation of Typhoon2-Qwen2.5-7B-Instruct on Needle-in-a-Haystack for both\nEnglish (Left) and Thai (Right).\nAs shown in Figure 4, Typhoon2-Qwen2.5-7B-Instruct successfully supports a maximum con-\ntext length of 128,000 tokens, matching the original performance of Qwen2.5. Remarkably,\ndespite training with shorter context lengths, the Qwen-based Typhoon model demonstrates\neffective extrapolation to significantly longer contexts, surpassing the 32,768-token range.\nDataset Composition and Recommendations: Our analysis highlights the importance of\ndata composition in achieving robust long-context performance, as follows:\n1. Models trained exclusively on English long-context tasks often underperform on Thai\ntasks, but incorporating Thai long-context data into training can mitigate this problem.\n2. Training solely on short-context data leads to substantial degradation in long-context per-\nformance. Conversely, overemphasis on long-context data negatively impacts performance\non other benchmarks.\nBased on our experiments, a good dataset composition consists of 15% long-context data\n(with a 20:80 ratio of Thai to English) and 85% short-context data. This approach yields the\nbest overall performance across both long- and short-context tasks.\n3.4\nFunction Calling\nFunction calling is essential for enhancing the capabilities of LLMs to tackle complex,\n",
          "the previous process. We employ a smaller model to predict the Thai cultural value of\nsamples within our base corpus. Subsequently, we filter only those with a predicted value\nof 4 or higher and use these instances to train Typhoon 2.\n2.2.2\nHigh-Quality Text Selection\nInspired by DCLM (Li et al., 2024a) and the importance of high-quality text filtering in Thai,\nwe develop a fastText (Joulin et al., 2017) classifier tailored for the Thai language. Given the\nlow-resource nature of Thai, we conduct multiple iterations of training to refine our classifier.\nFirst, we compile an instruction-following dataset in Thai, drawing from WangchanThai-\nInstruct (Vistec, 2024) and samples from our Typhoon Instruct dataset (Pipatanakul et al.,\n2023) as positive examples, while incorporating random examples, including toxic content\nand junk websites, as negative examples. Next, we apply the classifier developed in the\ninitial iteration to classify approximately 200,000 samples from a base corpus. After manual\ninspection and filtering, we train another iteration of the fastText classifier. This iterative\napproach results in a high-quality Thai text classifier capable of filtering content with a\npredicted quality ratio exceeding 0.5 as a high-quality sample.\n2.2.3\nSynthetic Textbook\nTo address the lack of textbooks in our general corpus, we employ a method inspired\nby the Phi and Cosmopedia (Ben Allal et al., 2024; Gunasekar et al., 2023) approach. We\nuse LLM to create an augmented dataset of 5,000 text samples with styles that emulate\ntextbooks, blog posts, and academic materials. This augmented dataset is then used to\nfine-tune typhoon-1.5-8b-instruct on a text augmentation task involving raw text and\nstyle information. The fine-tuned model is used to augment 20% of our general corpus to\nresemble textbook-style content.\n2.2.4\nHigh-Educational Content\nTo gather high educational content in Thai, we use a similar approach as in collected culture-\nrelated text in Thai and fine-web edu (Penedo et al., 2024). Specifically, an LLM is used to\n",
          "19\n5\nSum of Thai Sensitive Topics\n9,321\n4,563\nTable 18: Distribution of Thai Sensitive Topics in train Dataset\nCategory\n#English\n#Thai\nOthers\n10,827\n10,827\nSocial Stereotypes & Discrimination\n7,761\n7,763\nDisseminating False Information\n5,031\n5,034\nToxic Language & Hate Speech\n3,836\n3,838\nViolence and Physical Harm\n3,692\n3,693\nSensitive Information Organization\n3,605\n3,607\nDefamation & Unethical Actions\n3,057\n3,060\nPrivate Information Individual\n2,962\n2,962\nFraud Assisting Illegal Activities\n2,828\n2,829\nSexual Content\n2,785\n2,786\nMental Health Over-reliance Crisis\n2,226\n2,226\nCyberattack\n2,045\n2,045\nCopyright Violations\n2,067\n2,067\nCausing Material Harm by Misinformation\n1,835\n1,835\nSum of Wildguard Topics\n51,772\n51,786\nTable 19: Distribution of Wildguard Topics in train Dataset\n3.10.2\nExperimental Setup\nOur objective is to develop a model capable of classifying both Thai culture-specific sensitive\nand universal harmful content. We selected mDeBERTa-v3 (He et al., 2023) as our base\narchitecture, prioritizing computational efficiency while maintaining robust performance.\nThis choice was motivated by the model’s demonstrated effectiveness in multilingual\ntasks and its modest computational requirements compared to larger LMs. We detail our\nhyperparameter settings in Table 20.\n25\n\nTechnical Report\nParameter\nConfiguration\nMaximum Sequence Length\n1,280 tokens\nLearning Rate\n4e-5\nBatch Size (per device)\n32\nNumber of Epochs\n4\nWeight Decay\n0.01\nOptimizer\nAdamW (PyTorch)\nLearning Rate Schedule\nCosine decay\nTraining Precision\nMixed FP16\nTable 20: Typhoon Safety (mDeBERTa-v3 based) Training Configuration\n3.10.3\nResults and Findings\n",
          "• Efficiency: Typhoon2-Qwen2-VL, despite have fewer parameters, can match the\nperformance of Typhoon2-Llama-3.2.\n• Superior Performance: Typhoon2-Qwen2-VL excels in key areas such as ChartQA,\nOCR (TH), MTVQ (TH), and M3Exam Images (TH) compared to other competitive\nmodels.\n• ChartQA Emphasis: ChartQA takes precedence due to inadequate existing solu-\ntions (e.g., Docling, EasyOCR, PyTesseract), which focus primarily on TextVQA and\ndo not adequately address the unique challenges of ChartQA.\nBased on these results, Typhoon2-Qwen2-VL is chosen for this release due to its superior\nperformance and fewer parameter counts.\n33\n\nTechnical Report\nBenchmark\nMetric\nLlama-3.2 Qwen2-VL\nPathumma\nTyphoon2-llama-3.2 Typhoon2-qwen2vl\n11B-Instruct 7B-Instruct Vision-1.0.0-8B 11B-Instruct (Exp)\n7B-vision-instruct\nOCRBench\nROUGE-L\n72.84\n72.31\n32.74\n81.20\n64.38\nLiu et al. (2024c)\nAccuracy\n51.10\n57.90\n25.87\n71.70\n49.60\nMMBench (Dev)\nROUGE-L\n-\n-\n-\n-\n-\nLiu et al. (2024b)\nAccuracy\n76.54\n84.10\n19.51\n83.66\n83.66\nChartQA\nROUGE-L\n13.41\n47.45\n64.20\n74.12\n75.71\nMasry et al. (2022)\nAccuracy\nx\n45.00\n57.83\n67.36\n72.56\nTextVQA\nROUGE-L\n32.82\n91.40\n32.54\n89.44\n91.45\nSingh et al. (2019)\nAccuracy\nx\n88.70\n28.84\n85.74\n88.97\n",
          "Model HumanEval-TH HumanEval-EN MBPP-TH MBPP-EN\nLlama3.1-8B-Instruct\n51.8\n67.7\n64.6\n66.9\nTyphoon2-Llama3.1-8B-Instruct\n58.5\n68.9\n60.8\n63.0\nQwen2.5-7B-Instruct\n58.5\n68.9\n60.8\n63.0\nTyphoon2-Qwen2.5-7B-Instruct\n73.2\n79.3\n78.3\n81.7\nTable 7: Code only performance compare to SOTA model\nEvaluation results for math and code subsets are presented in Table 6 and Table 7, respec-\ntively. We found the following insights:\n• Math & Code also improve general performance: The addition of the Math &\nCode data shows an improvement to the overall performance, as indicated by the\nIFEval/MT-Bench results presented in Table 5.\n• Math performance in English does not automatically transfer to Thai: Results\nin Tables 6 and 7 highlight that state-of-the-art LLMs, while exhibiting strong\nmathematical capabilities in English, show a notable drop in performance when\napplied to Thai. In contrast, performance on coding tasks remains similar between\nEnglish and Thai.\n• Larger Model Requires Fewer Data Points: In our adaptation study with a 70B\nmodel, the model reaches its performance saturation using only 50K coding samples\nand 60K math problems. In comparison, the smaller 7B model requires the entire\ndataset, consisting of 250K coding samples and 200K math problems, to achieve a\nsimilar performance level. Based on these findings, we use 50K coding samples and\n60K math problems for the final evaluation of the 70B model.\n3.3\nLong Context\nThe capability to handle long contexts is essential for LLMs to process and understand\ncomplex and lengthy texts. Numerous real-world applications, such as summarizing\nacademic papers and analyzing legal documents, demand models capable of handling\ninputs that go beyond standard context length limitations. However, training LLMs with\nextended context sizes is computationally demanding, often requiring significant training\ntime and GPU resources. In practice, this limitation typically restricts the maximum context\n",
          "annotate 50K samples and we fine-tune the BGE-M3 classification head. We filter only with\na predicted value of 3 or higher due to the low level of educational content.\n2.2.5\nOther High-Quality Sources\nWe also incorporate highly educational sources, such as Thai Wikipedia, into our final\npre-training dataset.\n6\n\nTechnical Report\n2.3\nData Mixture\nTo ensure good final model performance, it is imperative to determine the proportion of\nvarious data sources within the pre-training dataset. Since our approach involves continual\npre-training (CPT), maintaining an awareness of the original pre-trained distribution is\ncrucial.\nWe conduct a series of experiments to optimize the final model’s performance. In the first\nstage, we independently evaluate each new data source to ensure that individual subsets\ncontribute positively. We examine this by performing CPT on the 1.5B Qwen2.5 (Yang et al.,\n2024a) model using a similar recipe to Blakeney et al. (2024) and verify that each of the\ndata sources improves one of the metrics or scores based on M3Exam (Zhang et al., 2023b)\nand/or ThaiExam (Pipatanakul et al., 2023).\nNext, we explore simple data mixture strategies. Our English dataset ratio, which is\n50%, is inspired by previous studies, including Typhoon (Pipatanakul et al., 2023) and\nSambaLingo (Csaki et al., 2023) to mitigate catastrophic forgetting. For each large corpus, we\nrepeat the data for 1 time, for smaller corpus (such as education documents and Wikipedia)\nwe repeat the data up to three times. Additionally, we experimented with Doremi (Xie\net al., 2023) but did not observe a significant improvement. Ultimately, our best approach\nis based on a simple data mixture strategy where our English subset is sourced from Shen\net al. (2024); Weber et al. (2024), and each of the datasets is repeated 1 time, except for the\neducation content (2 times) and Wikipedia (3 times). The Thai subset of our pretraining data\nmixture is illustrated in Figure 1.\nFigure 1: Thai Pretraining Data Mixture\n7\n\nTechnical Report\n2.4\n",
          "OpenThaiGPT-beta-7B\nWangChanGLM\nChatGPT\nFigure 1: Performance of Typhoon and other open-source Thai large language models on Thai Exam-\ninations (left) and Thai instruction-following (right). Details about ThaiExam and Thai instruction-\nfollowing evaluation are provided in Section 3.4, and Section 4.2, respectively.\nand alignment tuning. In the pretraining data, Thai text accounts for about 5.91%. Due to the limited\namount of Thai data in pretraining these multilingual models, we argue that they may not have rich\nThai knowledge, or understand cultural norms, customs, and stylistic preferences.\nThe Thai language is spoken by more than 70 million people, but it has received less attention\nfrom the NLP community. For instance, the Thai language represents only a small portion of most\nstandard pretraining data. For example, the Thai language constitutes less than 0.5% of the Common\nCrawl data [13], making Thai the 26th rank in terms of size in Common Crawl. The Thai language\nhas its own alphabet, which does not overlap with any other high-resource languages. As a result,\ndespite the success of general and multilingual LLMs, we argue that these LLMs may still lack some\nunderstanding of Thai culture and knowledge. Therefore, this work focuses on developing LLMs\nspecifically for the Thai language. We hypothesize that a strong LLM can be adapted to the Thai\nlanguage by pretraining a strong LLM further on a moderately sized Thai corpus.\nTo this end, this work introduces Typhoon, a 7-billion parameter language model, where its first\nversion is adapted from Mistral-7B [16]. To assess the extent of Thai knowledge encapsulated within\na language model, we develop ThaiExam – an evaluation benchmark based on Thai examinations.\nFurthermore, we study fine-tuning Typhoon to follow Thai instructions. We compare instruction-\ntuned models on both Thai and translated instruction-following datasets, and we also test their\nzero-shot abilities on machine translation, abstractive summarization, and question-answering tasks.\nAs demonstrated in Figure 1, the evaluation on various benchmarks shows that Typhoon is the\nstate-of-the-art open-source Thai large language model. Ultimately, this work not only shares our\n",
          "Model to Merge: Our strategy is to merge the model with the strongest performance in its\nfamily–based on the same pretraining foundation and selected according to its pre-trained\nmodel. In this case, we merge Llama-based Typhoon 2 70B SFT with Llama 3.3 70B Instruct.\nEvaluation: We evaluate the merging technique, as described in Section 3.1.2, which is\nused for instruction-following tasks. In addition to using evaluation sets, we qualitatively\nevaluate the responses, as the merged model tends to exhibit code-switching and output\ngibberish responses.\n3.6.2\nResults and Findings\nThe final configuration of the DARE + linear (Yu et al., 2024) merge method is based on the\nTyphoon model with a density of 1.0 and the original instruction model with a density of\n0.2. In this setup, the original instruction model contributes primarily to the early layers,\nwhile 50% of the later layers are dedicated mostly to Typhoon. The details of merging\nhyperparameters are provided in Listing 1.\nmodels:\n−model: meta−llama/Llama−3.1−70B\n−model: Typhoon2−70b−SFT\nparameters:\ndensity: 1.0\nweight: 0.6\n−model: meta−llama/Llama−3.3−70B−Instruct\nparameters:\ndensity: 0.2\nweight: [0.4, 0.4, 0.0, 0.0]\nmerge_method: dare_linear\nbase_model: meta−llama/Llama−3.1−70B\nparameters:\nnormalize: true\ndtype: bfloat16\nListing 1: Merge configuration for Typhoon 2 70B Instruct\nModel\nIFEval\nMT-Bench\nCode-switch\nTh\nEn\nTh\nEn\n1.0\n0.7\nTyphoon2-Llama-70B-SFT\n78.42\n87.05\n6.70\n8.45\n92.20\n99.00\nMerged model (DARE+linear)\n81.45\n88.72\n7.36\n8.86\n94.80\n98.80\nTable 11: Performance comparison between SFT and Merged Model\n",
          "the two datasets, which are shown in Table 19.\nTo create our final train dataset, we perform a two-step integration process: First, we\ntranslate the entire WildGuard training dataset (Han et al., 2024) into Thai, maintaining a\n1:1 ratio between English and Thai samples. We then merge this translated dataset with our\nThai-specific sensitive topic dataset.\nLabel\nCount\nPercentage (%)\n0 (Unharmful)\n117,442\n49.8\n1 (Harmful)\n118,229\n50.2\nTotal\n235,671\n100.0\nTable 17: Distribution of Harmful and Unharmful Samples in the Dataset\nAs shown in Table 17, the final dataset comprises 235,671 samples with a relatively balanced\ndistribution between harmful (50.2%) and unharmful (49.8%) content. This distribution\nhelps ensure robust model training across both classes while maintaining a sufficient repre-\nsentation of harmful content for effective detection.\nThe test set for Thai sensitive topics is partitioned by allocating 20% of the samples from\neach individual topic category in both Thai and English languages. The test set for Thai\nsensitive topics contains 9,527 samples, ensuring balanced representation across all topic\ncategories in both languages.\n24\n\nTechnical Report\nCategory\n#English\n#Thai\nThe Monarchy\n1,380\n352\nGambling\n1,075\n264\nCannabis\n818\n201\nDrug Policies\n448\n111\nThai-Burmese Border Issues\n442\n119\nMilitary and Coup d’États\n297\n72\nLGBTQ+ Rights\n275\n75\nReligion and Buddhism\n252\n57\nPolitical Corruption\n237\n58\nFreedom of Speech and Censorship\n218\n56\nNational Identity and Immigration\n216\n57\nSouthern Thailand Insurgency\n211\n56\nSex Tourism and Prostitution\n198\n55\nStudent Protests and Activism\n175\n44\nCultural Appropriation\n171\n42\nHuman Trafficking\n158\n39\nPolitical Divide\n156\n43\nForeign Influence\n124\n30\nVaping\n127\n24\nCOVID-19 Management\n105\n27\nMigrant Labor Issues\n79\n23\nRoyal Projects and Policies\n55\n17\nEnvironmental Issues and Land Rights\n",
          "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2\nBackground\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [12]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3\nModel Architecture\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\n",
          "Given a large number of low-resource languages, multilingual language models have been developed\nby pretraining a single model on multiple languages. For example, XGLM [23] is trained on the\nCC100 XL corpus, which consists of 30 diverse languages and includes around 11 billion Thai\ntokens. mT5 [60], a model with an encoder-decoder architecture, is trained on MC4, which covers\n101 languages and includes around 11 billion Thai tokens (or 1.14% of mT5 pretraining data).\nBLOOM [58], the largest open-source multilingual model with 176 billion parameters, is trained on\n46 natural languages (which do not cover Thai) and 13 programming languages. In contrast to high-\ncoverage multilingual LLMs, there exist multilingual LLMs specialized in Southeast Asian (SEA)\nlanguages such as Indonesian, Malay, Thai, Vietnamese, and Filipino. For example, SEA-LION [51]\nis a series of multilingual LLMs of different sizes, focusing on SEA languages. However, SEA\nlanguages only account for 13% of the pretraining data of SEA-LION, of which an even smaller part\nis Thai. Similarly, SeaLLM [31] is another series of LLMs focusing on SEA languages. SeaLLMs are\ndeveloped by continuing pre-training Llama2 with an extended vocabulary and specialized instruction\narXiv:2312.13951v1  [cs.CL]  21 Dec 2023\n\nONET\nIC\nTGAT\nTPAT-1\nA-Level\n0\n10\n20\n30\n40\n50\n60\n70\n80\nAccuracy (%)\nThaiExam (Multiple-choice Exams)\nTyphoon-7B\nSeaLLM-7B-Chat\nOpenThaiGPT-beta-7B\nWangChanGLM\nSEA-LION-7B\nChatGPT\nTH-AlpacaEval\nTH-OASST\nTH-MT-Bench\nTH-Sea-bench\n0\n10\n20\n30\n40\n50\n60\nScore (judged by GPT-4)\nThai Instruction-Following (wrt ChatGPT)\nTyphoon-7B-Instruct\nSeaLLM-7B-Chat\n",
          "✓\n✗\n?\n✓\n✓\n✗\nTyphoon2-Qwen2.5-7B-Instruct\n✓\n✓\n✓\n✓\n✗\n✗\nTyphoon2-Llama3.1-8B-Instruct\n✓\n✓\n✓\n✓\n✗\n✗\nTyphoon2-Llama3.1-70B-Instruct\n✓\n✓\n✓\n✓\n✗\n✓\nTable 12: The Summary of Features of Typhoon2-Text Models\n3.9\nFull Evaluation Results\nFull evaluation results of the Typhoon2-Text models in all sizes are shown in Table 13 (1B),\nTable 14 (3B), Table 15 (7-8B) and Table 16 (70B).\nModel\nIFEval\nMT-Bench\nCS\nFC\nTH\nEN\nTH\nEN\nt=0.7\nt=1.0\nTH\nEN\nTyphoon2-Llama3.2-1B-Instruct\n52.46\n53.35\n3.972\n5.212\n96.40\n88.00\n34.96\n45.60\nLlama-3.2-1B-Instruct\n31.76\n51.15\n2.582\n6.229\n97.80\n22.60\n29.88\n36.50\nQwen2.5-1.5B-Instruct\n44.42\n48.45\n2.939\n6.934\n82.60\n20.60\n13.83\n17.88\nTable 13: 1B Model Performance\n22\n\nTechnical Report\nModel\nIFEval\nMT-Bench\nCS\nFC\nTH\nEN\nTH\nEN\nt=0.7\nt=1.0\nTH\nEN\nTyphoon2-Llama3.2-3B-Instruct\n68.36\n72.18\n5.335\n7.206\n99.20\n96.00\n71.36\n75.90\nLlama3.2-3B-Instruct\n44.84\n71.98\n4.324\n7.725\n93.80\n",
          "11https://blog.arcee.ai/introducing-arcee-supernova-medius-a-14b-model-that-rivals-a-70b-2\n19\n\nTechnical Report\nthe 8B and 70B variants. This method assumes that the teacher and student models share\nidentical vocabularies.\nTo achieve effective knowledge distillation, the loss function includes Kullback-Leibler\n(KL) divergence for logits alignment and a cross-entropy loss for supervised training. The\nformulation of the loss function is as follows:\nLKD = α · T2 · KL\n \nσ\n \nz(k)\nstudent\nT\n!\n∥σ\n \nz(k)\nteacher\nT\n!!\n+ (1 −α) · LCE(ytrue, zstudent),\nwhere LKD denotes the knowledge distillation loss, z(k)\nstudent denotes top-k logits from the\nstudent model, z(k)\nteacher denotes top-k logits from the teacher model, σ denotes the softmax\noperation, T denotes a temperature hyperparameter, α denotes a weight for balancing\nbetween the two loss components, LCE is a cross-entropy loss of the ground-truth labels\n(ytrue), and k denotes the number of top logits retained.\nIn our configuration, the hyperparameters are set as follows: α = 0.5, k = 8 and T = 1. This\ncombination ensures a balanced trade-off between the distillation objective (matching the\ntop-k logits of the teacher) and the supervised training objective (matching true labels).\n3.5.2\nExperimental Setup\nIn this experiment, we compare two approaches: (1) SFT-only and (2) combining SFT\nwith top-k distillation. Both approaches are experimented on three datasets: 1) English\nInstruction, 2) Thai General Instruction, and 3) TyphoonIF. These datasets are the same as\nthose used in Section 3.1.2. The experiments utilize Llama-based Typhoon 1B as the base\nmodel. For all experiments, we apply the same learning rate used for SFT.\nEvaluation: We evaluate the distillation technique following the same approach as in\n",
          "into a variable number of visual tokens. Additionally, the model incorporates Multimodal\nRotary Position Embedding (M-ROPE), which significantly enhances its ability to process\nand interpret complex multimodal data.\nWhile Qwen2-VL is designed to process both image and video inputs, Typhoon2-VL is spe-\ncialized for image-based tasks. The Qwen2-VL series offers three open-weight models with\nparameter counts of 2B, 7B, and 72B. For Typhoon2-VL, we select the 7-billion-parameter\nmodel as the base, providing an optimal balance between dataset requirements and compu-\ntational resource constraints.\n4.2\nGeneral Data\nTo develop Thai capabilities in Typhoon2-Vision, we built on the Cambrian-737K\ndataset (Tong et al., 2024a), which serves as our foundation for vision-language tasks.\nOur approach involves both translation and distillation strategies to create Thai-language\nequivalents while preserving the original English dataset for better bilingual understanding.\nFor translation, we employ a high-quality in-house translation model, followed by quality\nestimation using the COMET model (Unbabel/wmt23-cometkiwi-da-xl). For each source,\nwe only select the top 10% translations based on COMET scores, thus maintaining the\nquality of the translation by semantic preservation.\nFor visual question-answering (VQA) datasets that contain text embedded in images (OCR-\nVQA, DocVQA, AI2D, ChartQA, DVQA), direct translation would alter the original task\nsemantics. Hence, we employ a distillation approach in which a Thai-capable vision-\nlanguage model generates responses in Thai while preserving the original visual contexts.\nThis ensures that text-heavy visual elements maintain their integrity while enabling Thai\nlanguage interaction.\nThe combination of translated and distilled data results in a comprehensive bilingual vision-\nlanguage data set that preserves the strengths of the original Cambrian-737K while adding\nThai language capabilities. The summary of data for our vision-language model training is\nsummarized in Table 23.\n4.3\nThai OCR Enhancement\nIn our efforts to enhance the capabilities of document understanding for Thai Vision, with a\n",
          "Typhoon-Audio: We evaluate our Typhoon-Audio model, based on the Typhoon 1.5 LLM,\nagainst competitive benchmarks (Tables 31 and 32). For ASR, Typhoon-Audio is one\nof two models (along with Gemini) achieving a WER below 15.0 on Thai ASR, despite\nunderperforming in English. In translation, it surpasses SALMONN and Gemini 1.5 Pro\nin Thai-to-English, demonstrating strong Thai comprehension and English generation. For\nvoice characteristics, Typhoon-Audio performs comparably to SALMONN in English-to-\nThai gender recognition. In spoken document QA, it matches Gemini 1.5 Pro, making it the\nonly open-source model for Thai QA. For speech instruction following, Typhoon-Audio\noutperforms Gemini-1.5-Pro in both English and Thai and approaches Gemini 1.5 Pro in\nhandling complex instructions. It also has a lower hallucination rate than prior models (Sun\net al., 2024), though hallucination in speech instruction remains a challenge.\nTyphoon2-Audio: As noted at the beginning, most experiments were conducted before the\ndevelopment of the Typhoon 2 LLM. Once available, we applied the same pre-training\nand SFT methodologies, using the same speech backbones, to create Typhoon2-Audio.\nResults in Tables 31 and 32 show improved performance over Typhoon-Audio in ASR,\nspeech translation, spoken QA, and speech instruction following. However, Typhoon2-\nAudio underperforms in gender classification and occasionally fails to respond to spoken\ninstructions during complex tasks, despite strong question-answering capabilities.\nModel\nSize\nASR (WER↓)\nTranslation (BLEU↑)\nGender (Acc↑)\nEn\nTh\nTh2En\nEn2Th\nX2Th\nEn\nTh\nQwen-Audio\n7B\n6.94\n95.12\n0.00\n2.48\n0.29\n37.09\n67.97\nSALMONN\n13B\n5.79\n98.07\n14.97\n0.07\n0.10\n95.69\n93.26\nDiVA\n8B\n30.28\n65.21\n7.97\n9.82\n5.31\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_as_in_the",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_as_in_the"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "zhxQQUBkMkFMWFVBMZ1EQaJvS0Ft+UNB3pZEQfU6S0HxOU5BjnJPQbq7UkFq+EhBA/FJQdf6SEFEkVJB6Z1GQXAcOkHVE09BtSE9QWPsSkHedkJB4d4qQY8AJUHXSkRB2iFWQXvFVkFAFU9BmzNEQdKDSEEAJSxBAIJKQQRoL0HjOilBokJEQSDWUEFLE01BatFGQQ6OMEGX1jxBstxBQaKsO0HmOkxBcZUoQV5qQEGmRDFBA78oQVd3REEw8kBBvss8QQ7eUkHh2EpBIFJNQXMRQkFqXkpBT4kyQXGSLkHvWkxBcQAxQQPeTEEKwk5B3hxQQRlGO0HeLyhBil9FQQwIPkEudUxBU4xMQfraJ0GKD0xBIWYlQQecQUFxckxBpgtCQS6+UEHTGSZBwVRHQQOEU0HJvzFBhygsQY5gQ0G5E1RB5OhNQVGlPUFvNzNBMPNCQYqxRUFe3ClBqUdLQUmUUEHMi0NBDTxCQQ==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "QOxJQI2pdkDYlg5AtxcAQF+0SkB6leE/lemKQB3yWEDR1xVAUnQZQE5+FEBF9YRAZ+iFQA2Mf0DUiQ9AsLkPQPQ7XEB+SyNA0Q5EQBoYhkDNeyZAQxmMQGj4kUCXpGhAO7EMQBhiA0CkMCxAoxyzP/9D/D9JRoRAciBHQPx6jUCGc4tA9C2JQNlUNEBFYhVAQKC+P4KEjEAtTVtAxXRnP77JXUDCtYZAEZmMQOeqHz98JndAd4iMQHSWPEAfAzc/yvBoQBmwEUDoORRAKi8ZQNmyRz9TLX5AZgR7QLBzi0CeDH5Av0WPQPtIC0DjNxtAcj9KQEQBbEBQCo1AZeHfPyJDR0B8QIZATX9BQNtVj0CyR4JAfwyRQEJFPj9PboFAA6mBQF1SAECNhJBA6HEbQDQ2G0DBAXlAsaSJQNGwI0ClbhFAv0xBQJumRkCn3XBAMXKXP6ljVEBKLolAQC0eQFFDGUCRl3NAl3hHQA==",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "• 𝐿(𝐺) = {𝑏, 𝑎𝑎𝑎}, because we can begin a derivation with 𝑆→𝑎𝐴or with\n𝑆→𝑏, and from 𝑎𝐴we can derive aaa using 𝐴→𝑎𝑎. There are no other\npossible derivations.\n11 / 39\nLanguage Generation\n\nExample: Let 𝐺be the grammar with vocabulary 𝑉= {𝑆, 𝐴, 𝑎, 𝑏}, set of\nterminals 𝑇= {𝑎, 𝑏}, starting symbol 𝑆, and productions\n𝑃= {𝑆→𝑎𝐴, 𝑆→𝑏, 𝐴→𝑎𝑎}. What is 𝐿(𝐺), the language of this grammar?\n12 / 39\nLanguage Generation\n\nExample: Let 𝐺be the grammar with vocabulary 𝑉= {𝑆, 0, 1}, set of terminals\n𝑇= {0, 1}, starting symbol 𝑆, and productions 𝑃= {𝑆→11𝑆, 𝑆→0}. What is\n𝐿(𝐺), the language of this grammar?\n13 / 39\nLanguage Generation\n\nExample: Give a phrase-structure grammar that generates the set\n{0𝑛1𝑛|𝑛= 0, 1, 2, . . .}\n14 / 39\nLanguage Generation\n\nExample: Find a phrase-structure grammar to generate the set\n{0𝑚1𝑛|𝑚and 𝑛are nonnegative integers}\n15 / 39\nLanguage Generation\n\n• We can represent a derivation in the language\ngenerated by a context-free grammar by an\nordered rooted tree, called a derivation, or\nparse tree.\n• The root of the tree represents the start symbol.\n• The internal vertices represent the nonterminal\nsymbols that arise in the derivation.\n• The leaves represent the terminal symbols that\n",
          "For each xi we will deﬁne ρi and σi. Let\nρi = min{d(xi, xij) | 1 ≤j ≤k, d(xi, xij) > 0},\n14\n\nand set σi to be the value such that\nk\nX\nj=1\nexp\n\u0012−max(0, d(xi, xij) −ρi)\nσi\n\u0013\n= log2(k).\nTe selection of ρi derives from the local-connectivity constraint described\nin Section 2.2. In particular it ensures that xi connects to at least one other\ndata point with an edge of weight 1; this is equivalent to the resulting fuzzy\nsimplicial set being locally connected at xi. In practical terms this signif-\nicantly improves the representation on very high dimensional data where\nother algorithms such as t-SNE begin to suﬀer from the curse of dimen-\nsionality.\nTe selection of σi corresponds to (a smoothed) normalisation factor,\ndeﬁning the Riemannian metric local to the point xi as described in Section\n2.1.\nWe can now deﬁne a weighted directed graph ¯G = (V, E, w). Te\nvertices V of ¯G are simply the set X. We can then form the set of directed\nedges E = {(xi, xij) | 1 ≤j ≤k, 1 ≤i ≤N}, and deﬁne the weight\nfunction w by seting\nw((xi, xij)) = exp\n\u0012−max(0, d(xi, xij) −ρi)\nσi\n\u0013\n.\nFor a given point xi there exists an induced graph of xi and outgoing edges\nincident on xi. Tis graph is the 1-skeleton of the fuzzy simplicial set as-\nsociated to the metric space local to xi where the local metric is deﬁned\nin terms of ρi and σi. Te weight associated to the edge is the member-\nship strength of the corresponding 1-simplex within the fuzzy simplicial\nset, and is derived from the adjunction of Teorem 1 using the right adjoint\n",
          "pseudo-metric spaces and non-expansive maps as morphisms. We denote the\nsubcategory of ﬁnite extended-pseudo-metric spaces FinEPMet.\nTe choice of non-expansive maps in Deﬁnition 6 is due to Spivak, but\nwe note that it closely mirrors the work of Carlsson and Memoli in [13] on\ntopological methods for clustering as applied to ﬁnite metric spaces. Tis\nchoice is signiﬁcant since pure isometries are too strict and do not provide\nlarge enough Hom-sets.\nIn [52] Spivak constructs a pair of adjoint functors, Real and Sing be-\ntween the categories sFuzz and EPMet. Tese functors are the natural ex-\ntension of the classical realization and singular set functors from algebraic\ntopology. Te functor Real is deﬁned in terms of standard fuzzy simplices\n∆n\n<a as\nReal(∆n\n<a) ≜\n(\n(t0, . . . , tn) ∈Rn+1 |\nn\nX\ni=0\nti = −log(a), ti ≥0\n)\nsimilarly to the classical realization functor | · |. Te metric on Real(∆n\n<a)\nis simply inherited from Rn+1. A morphism ∆n\n<a →∆m\n<b exists only if\n8\n\na ≤b, and is determined by a ∆morphism σ : [n] →[m]. Te action of\nReal on such a morphism is given by the map\n(x0, x1, . . . , xn) 7→log(b)\nlog(a)\n\n\nX\ni0∈σ−1(0)\nxi0,\nX\ni0∈σ−1(1)\nxi0, . . . ,\nX\ni0∈σ−1(m)\nxi0\n\n.\nSuch a map is clearly non-expansive since 0 ≤a ≤b ≤1 implies that\n",
          "In what follows we are concerned with deﬁning similarities between\ntwo objects i and j in the high dimensional input space X and low di-\nmensional embedded space Y . Tese are normalized and symmetrized in\nvarious ways. In a typical implementation, these pair-wise quantities are\nstored and manipulated as (potentially sparse) matrices. Qantities with\nthe subscript ij are symmetric, i.e. vij = vji. Extending the conditional\nprobability notation used in t-SNE, j | i indicates an asymmetric similarity,\ni.e. vj|i ̸= vi|j.\nt-SNE deﬁnes input probabilities in three stages. First, for each pair of\npoints, i and j, in X, a pair-wise similarity, vij, is calculated, Gaussian with\nrespect to the Euclidean distance between xi and xj:\nvj|i = exp(−∥xi −xj∥2\n2 /2σ2\ni )\n(5)\nwhere σ2\ni is the variance of the Gaussian.\nSecond, the similarities are converted into N conditional probability\ndistributions by normalization:\npj|i =\nvj|i\nP\nk̸=i vk|i\n(6)\nσi is chosen by searching for a value such that the perplexity of the proba-\nbility distribution p·|i matches a user-speciﬁed value.\nTird, these probability distributions are symmetrized and then further\nnormalized over the entire matrix of values to give a joint probability dis-\ntribution:\n54\n\npij = pj|i + pi|j\n2N\n(7)\nWe note that this is a heuristic deﬁnition and not in accordance with stan-\ndard relationship between conditional and joint probabilities that would be\nexpected under probability semantics usually used to describe t-SNE.\nSimilarities between pairs of points in the output space Y are deﬁned\nusing a Student t-distribution with one degree of freedom on the squared\nEuclidean distance:\nwij =\n",
          "Jardine, Brendan Fong, David Spivak and Dmitry Kobak for discussion and\nuseful commentary on various drafs of this paper.\nA\nProof of Lemma 1\nLemma 1. Let (M, g) be a Riemannian manifold in an ambient Rn, and let\np ∈M be a point. If g is locally constant about p in an open neighbourhood\nU such that g is a constant diagonal matrix in ambient coordinates, then in a\nball B ⊆U centered at p with volume\nπn/2\nΓ(n/2+1) with respect to g, the geodesic\n51\n\ndistance from p to any point q ∈B is 1\nrdRn(p, q), where r is the radius of the\nball in the ambient space and dRn is the existing metric on the ambient space.\nProof. Let x1, . . . , xn be the coordinate system for the ambient space. A\nball B in M under Riemannian metric g has volume given by\nZ\nB\np\ndet(g)dx1 ∧· · · ∧dxn.\nIf B is contained in U, then g is constant in B and hence\np\ndet(g) is con-\nstant and can be brought outside the integral. Tus, the volume of B is\np\ndet(g)\nZ\nB\ndx1 ∧... ∧dxn =\np\ndet(g)\nπn/2rn\nΓ(n/2 + 1),\nwhere r is the radius of the ball in the ambient Rn. If we ﬁx the volume of\nthe ball to be\nπn/2\nΓ(n/2+1) we arrive at the requirement that\ndet(g) =\n1\nr2n .\nNow, since g is assumed to be diagonal with constant entries we can solve\nfor g itself as\ngij =\n\n\n\n1\nr2\nif i = j,\n0\notherwise\n.\n(2)\nTe geodesic distance on M under g from p to q (where p, q ∈B) is deﬁned\n",
          "which is a non-expansive map since a ≤b implies da ≥db.\nSince FinReal preserves colimits it admits a right adjoint, the fuzzy sin-\ngular set functor FinSing. We can then deﬁne the (ﬁnite) fuzzy singular set\nfunctor in terms of the action of its image on ∆× I, analogously to Sing.\n9\n\nDeﬁnition 8. Deﬁne the functor FinSing : FinEPMet →Fin-sFuzz by\nFinSing(Y ) : ([n], [0, a)) 7→homFinEPMet(FinReal(∆n\n<a), Y ).\nWe then have the following theorem.\nTeorem 1. Te functors FinReal : Fin-sFuzz →FinEPMet and FinSing :\nFinEPMet →Fin-sFuzz form an adjunction with FinReal the lef adjoint\nand FinSing the right adjoint.\nTe proof of this is by construction. Appendix B provides a full proof\nof the theorem.\nWith the necessary theoretical background in place, the means to han-\ndle the family of incompatible metric spaces described above becomes clear.\nEach metric space in the family can be translated into a fuzzy simplicial\nset via the fuzzy singular set functor, distilling the topological information\nwhile still retaining metric information in the fuzzy structure. Ironing out\nthe incompatibilities of the resulting family of fuzzy simplicial sets can be\ndone by simply taking a (fuzzy) union across the entire family. Te result\nis a single fuzzy simplicial set which captures the relevant topological and\nunderlying metric structure of the manifold M.\nIt should be noted, however, that the fuzzy singular set functor applies\nto extended-pseudo-metric spaces, which are a relaxation of traditional\nmetric spaces. Te results of Lemma 1 only provide accurate approxima-\ntions of geodesic distance local to Xi for distances measured from Xi –\nthe geodesic distances between other pairs of points within the neighbor-\nhood of Xi are not well deﬁned. In deference to this lack of information we\ndeﬁne distances between Xj and Xk in the extended-pseudo metric space\n",
          "\u0010\n1 + ∥yi −yj∥2\n2\n\u0011−1\n(8)\nfollowed by the matrix-wise normalization, to form qij:\nqij =\nwij\nP\nk̸=l wkl\n(9)\nTe t-SNE cost is the Kullback-Leibler divergence between the two proba-\nbility distributions:\nCt−SNE =\nX\ni̸=j\npij log pij\nqij\n(10)\nthis can be expanded into constant and non-constant contributions:\nCt−SNE =\nX\ni̸=j\npij log pij −pij log qij\n(11)\nBecause both pij and qij require calculations over all pairs of points, im-\nproving the eﬃciency of t-SNE algorithms has involved separate strategies\nfor approximating these quantities. Similarities in the high dimensions are\neﬀectively zero outside of the nearest neighbors of each point due to the\ncalibration of the pj|i values to reproduce a desired perplexity. Terefore an\napproximation used in Barnes-Hut t-SNE is to only calculate vj|i for n near-\nest neighbors of i, where n is a multiple of the user-selected perplexity and\nto assume vj|i = 0 for all other j. Because the low dimensional coordinates\nchange with each iteration, a diﬀerent approach is used to approximate\nqij. In Barnes-Hut t-SNE and related methods this usually involves group-\ning together points whose contributions can be approximated as a single\npoint.\nA further heuristic algorithm optimization technique employed by t-\nSNE implementations is the use of early exaggeration where, for some num-\nber of initial iterations, the pij are multiplied by some constant greater than\n55\n\n1.0 (usually 12.0). In theoretical analyses of t-SNE such as [38] results are\nobtained only under an early exaggeration regimen with either large con-\nstant (of order of the number of samples), or in the limit of inﬁnite exagger-\nation. Further papers such as [37], and [28], suggest the option of using ex-\n",
          "aggeration for all iterations rather than just early ones, and demonstrate the\nutility of this. Te eﬀectiveness of these analyses and practical approaches\nsuggests that KL-divergence as a measure between probability distributions\nis not what makes the t-SNE algorithm work, since, under exaggeration, the\npij are manifestly not a probability distribution. Tis is another example\nof the probability semantics used to describe t-SNE are primarily descrip-\ntive rather than foundational. None the less, t-SNE is highly eﬀective and\nclearly produces useful results on a very wide variety of tasks.\nLargeVis uses a similar approach to Barnes-Hut t-SNE when approxi-\nmating pij, but further improves eﬃciency by only requiring approximate\nnearest neighbors for each point. For the low dimensional coordinates,\nit abandons normalization of wij entirely. Rather than use the Kullback-\nLeibler divergence, it optimizes a likelihood function, and hence is maxi-\nmized, not minimized:\nCLV =\nX\ni̸=j\npij log wij + γ\nX\ni̸=j\nlog (1 −wij)\n(12)\npij and wij are deﬁned as in Barnes-Hut t-SNE (apart from the use of\napproximate nearest neighbors for pij, and the fact that, in implementation,\nLargeVis does not normalize the pij by N) and γ is a user-chosen positive\nconstant which weights the strength of the the repulsive contributions (sec-\nond term) relative to the atractive contribution (ﬁrst term). Note also that\nthe ﬁrst term resembles the optimizable part of the Kullback-Leibler diver-\ngence but using wij instead of qij. Abandoning calculation of qij is a crucial\nchange, because the LargeVis cost function is amenable to optimization via\nstochastic gradient descent.\nIgnoring speciﬁc deﬁnitions of vij and wij, the UMAP cost function,\nthe cross entropy, is:\nCUMAP =\nX\ni̸=j\nvij log\n\u0012 vij\nwij\n",
          "Example: Grammar 1\nLet 𝐺= (𝑉,𝑇, 𝑆, 𝑃), where 𝑉= {𝑎, 𝑏, 𝐴, 𝐵, 𝑆}, 𝑇= {𝑎, 𝑏}, 𝑆is the start symbol, and\n𝑃= {𝑆→𝐴𝑏𝑎, 𝐴→𝐵𝐵, 𝐵→𝑎𝑏, 𝐴𝐵→𝑏}.\n9 / 39\nPhrase-Structure Grammars\n\n• Let 𝐺= (𝑉,𝑇, 𝑆, 𝑃) be a phrase-structure grammar. Let 𝑤0 = 𝑙𝑧0𝑟(that is the\nconcatenation of 𝑙, 𝑧0, and 𝑟) and 𝑤1 = 𝑙𝑧1𝑟be strings over 𝑉. If 𝑧0 →𝑧1 is a\nproduction of 𝐺, we say that 𝑤1 is directly derivable from 𝑤0 and write\n𝑤0 ⇒𝑤1.\n• If 𝑤0, 𝑤1, . . . , 𝑤𝑛are strings over 𝑉such that 𝑤0 ⇒𝑤1, 𝑤1 ⇒𝑤2, . . . , 𝑤𝑛−1 ⇒𝑤𝑛,\nthen we say that 𝑤𝑛is derivable from 𝑤0 and write 𝑤0\n∗=⇒𝑤𝑛.\n• The sequence of steps used to obtain 𝑤𝑛from 𝑤0 is called a derivation.\n",
          "local to Xi (where i ̸= j and i ̸= k) to be inﬁnite (local neighborhoods of\nXj and Xk will provide suitable approximations).\nFor real data it is safe to assume that the manifold M is locally con-\nnected. In practice this can be realized by measuring distance in the extended-\npseudo-metric space local to Xi as geodesic distance beyond the nearest\nneighbor of Xi. Since this sets the distance to the nearest neighbor to be\nequal to 0 this is only possible in the more relaxed seting of extended-\npseudo-metric spaces. It ensures, however, that each 0-simplex is the face\nof some 1-simplex with fuzzy membership strength 1, meaning that the\nresulting topological structure derived from the manifold is locally con-\nnected. We note that this has a similar practical eﬀect to the truncated\nsimilarity approach of Lee and Verleysen [33], but derives naturally from\nthe assumption of local connectivity of the manifold.\n10\n\nCombining all of the above we can deﬁne the fuzzy topological repre-\nsentation of a dataset.\nDeﬁnition 9. Let X = {X1, . . . , XN} be a dataset in Rn. Let {(X, di)}i=1...N\nbe a family of extended-pseudo-metric spaces with common carrier set X such\nthat\ndi(Xj, Xk) =\n\n\n\ndM(Xj, Xk) −ρ\nif i = j or i = k,\n∞\notherwise ,\nwhere ρ is the distance to the nearest neighbor of Xi and dM is geodesic\ndistance on the manifold M, either known apriori, or approximated as per\nLemma 1.\nTe fuzzy topological representation of X is\nn[\ni=1\nFinSing((X, di)).\nTe (fuzzy set) union provides the means to merge together the diﬀer-\nent metric spaces. Tis provides a single fuzzy simplicial set as the global\nrepresentation of the manifold formed by patching together the many local\n",
          "finite input alphabet 𝐼, a finite output alphabet 𝑂, a transition function 𝑓that\nassigns to each state and input pair a new state, an output function 𝑔that\nassigns to each state and input pair an output, and an initial state 𝑠0.\n• A state table is used to represent the values of the transition function 𝑓\nand the output function 𝑔for all (state, input).\n• Alternatively, a finite-state machine can be represented by a state\ndiagram, which is a directed graph with labeled edges. Each state is\nrepresented by a circle, and arrows labeled with the input and output pair\nrepresent the transitions.\n• The state table and state diagram both represent the finite state machine\nwith 𝑆= {𝑠0, 𝑠1, 𝑠2, 𝑠3}, 𝐼= {0, 1}, and 𝑂= {0, 1}.\n24 / 39\nFSMs with Outputs\n\nExample: Construct the state diagram for the finite-state machine with the\nstate table.\n𝑓\n𝑔\nState\nInput\nInput\n0\n1\n0\n1\n𝑠0\n𝑠1\n𝑠0\n1\n0\n𝑠1\n𝑠3\n𝑠0\n1\n1\n𝑠2\n𝑠1\n𝑠2\n0\n1\n𝑠3\n𝑠2\n𝑠1\n0\n0\n25 / 39\nFSMs with Outputs\n\nExample: Construct the state table for the finite-state machine with the\nstate diagram.\n𝑓\n𝑔\nState\nInput\nInput\n0\n1\n0\n1\n26 / 39\nFSMs with Outputs\n\nExample: An important element in many electronic devices is a unit-delay\nmachine, which produces as output the input string delayed by a specified\namount of time. How can a finite-state machine be constructed that delays\nan input string by one unit of time, that is, produces as output the bit string\n",
          "(nearest inverse) of the geometric realization of a fuzzy simplicial set. In-\ntuitively one can think of the weight of an edge as akin to the probability\nthat the given edge exists. Section 2 demonstrates why this construction\nfaithfully captures the topology of the data. Given this set of local graphs\n(represented here as a single directed graph) we now require a method to\ncombine them into a uniﬁed topological representation. We note that while\npatching together incompatible ﬁnite metric spaces is challenging, by using\nTeorem 1 to convert to a fuzzy simplicial set representation, the combin-\ning operation becomes natural.\nLet A be the weighted adjacency matrix of ¯G, and consider the sym-\nmetric matrix\nB = A + A⊤−A ◦A⊤,\n15\n\nwhere ◦is the Hadamard (or pointwise) product. Tis formula derives from\nthe use of the probabilistic t-conorm used in unioning the fuzzy simplicial\nsets. If one interprets the value of Aij as the probability that the directed\nedge from xi to xj exists, then Bij is the probability that at least one of\nthe two directed edges (from xi to xj and from xj to xi) exists. Te UMAP\ngraph G is then an undirected weighted graph whose adjacency matrix is\ngiven by B. Section 2 explains this construction in topological terms, pro-\nviding the justiﬁcation for why this construction provides an appropriate\nfuzzy topological representation of the data – that is, this construction cap-\ntures the underlying geometric structure of the data in a faithful way.\n3.2\nGraph Layout\nIn practice UMAP uses a force directed graph layout algorithm in low di-\nmensional space. A force directed graph layout utilizes of a set of atractive\nforces applied along edges and a set of repulsive forces applied among ver-\ntices. Any force directed layout algorithm requires a description of both the\natractive and repulsive forces. Te algorithm proceeds by iteratively ap-\nplying atractive and repulsive forces at each edge or vertex. Tis amounts\nto a non-convex optimization problem. Convergence to a local minima is\n",
          "strings that are recognized by 𝑀. Two finite-state automata are called\nequivalent if they recognize the same language.\n34 / 39\nLanguage Recognition by FSAs\n\nDetermine the languages recognized by the finite-state automata 𝑀1.\n35 / 39\nLanguage Recognition by FSAs\n\nDetermine the languages recognized by the finite-state automata 𝑀2.\n36 / 39\nLanguage Recognition by FSAs\n\nDetermine the languages recognized by the finite-state automata 𝑀3.\n37 / 39\nLanguage Recognition by FSAs\n\nExample: Construct deterministic FSA that recognize the set of bit strings\nthat begin with two 0s.\n38 / 39\nLanguage Recognition by FSAs\n\nExample: Construct deterministic FSA that recognize the set of bit strings\nthat contain two consecutive 0s.\n39 / 39\nLanguage Recognition by FSAs\n\n",
          "Definition\nA finite-state automaton 𝑀= (𝑆, 𝐼, 𝑓, 𝑠0, 𝐹) consists of a finite set 𝑆of states, a\nfinite input alphabet 𝐼, a transition function 𝑓that assigns a next state to\nevery pair of state and input (so that 𝑓: 𝑆× 𝐼→𝑆), an initial or start state 𝑠0,\nand a subset 𝐹of 𝑆consisting of final (or accepting) states.\nFSAs can be represented using either state tables or state diagrams, in which\nfinal states are indicated with a double circle.\n32 / 39\nFinite-State Automata (FSA)\n\nExample: Construct the state diagram for the finite-state automaton\n𝑀= (𝑆, 𝐼, 𝑓, 𝑠0, 𝐹), where 𝑆= {𝑠0, 𝑠1, 𝑠2, 𝑠3}, 𝐼= {0, 1}, 𝐹= {𝑠0, 𝑠3}, and the transition\nfunction 𝑓is given in table.\n𝑓\nState\nInput\n0\n1\n𝑠0\n𝑠0\n𝑠1\n𝑠1\n𝑠0\n𝑠2\n𝑠2\n𝑠0\n𝑠0\n𝑠3\n𝑠2\n𝑠1\n33 / 39\nFinite-State Automata (FSA)\n\nDefinition\nA string 𝑥is said to be recognized (or accepted) by the machine\n𝑀= (𝑆, 𝐼, 𝑓, 𝑠0, 𝐹) if it takes the initial state 𝑠0 to a final state, that is, 𝑓(𝑠0, 𝑥). The\nlanguage recognized (or accepted) by 𝑀, denoted by 𝐿(𝑀), is the set of all\n",
          "Deﬁnition 2. A simplicial set is a functor from ∆op to Sets, the category of\nsets; that is, a contravariant functor from ∆to Sets.\nGiven a simplicial set X : ∆op →Sets, it is common to denote the set\nX([n]) as Xn and refer to the elements of the set as the n-simplices of X.\nTe simplest possible examples of simplicial sets are the standard simplices\n∆n, deﬁned as the representable functors hom∆(·, [n]). It follows from the\nYoneda lemma that there is a natural correspondence between n-simplices\nof X and morphisms ∆n →X in the category of simplicial sets, and it\nis ofen helpful to think in these terms. Tus for each x ∈Xn we have\na corresponding morphism x : ∆n →X. By the density theorem and\nemploying a minor abuse of notation we then have\ncolim\nx∈Xn ∆n ∼= X\nTere is a standard covariant functor | · | : ∆→Top mapping from\nthe category ∆to the category of topological spaces that sends [n] to the\nstandard n-simplex |∆n| ⊂Rn+1 deﬁned as\n|∆n| ≜\n(\n(t0, . . . , tn) ∈Rn+1 |\nn\nX\ni=0\nti = 1, ti ≥0\n)\nwith the standard subspace topology. If X : ∆op →Sets is a simplicial\nset then we can construct the realization of X (denoted |X|) as the colimit\n|X| = colim\nx∈Xn |∆n|\n6\n\nand thus associate a topological space with a given simplicial set. Con-\nversely given a topological space Y we can construct an associated simpli-\ncial set S(Y ), called the singular set of Y , by deﬁning\nS(Y ) : [n] 7→homTop(|∆n|, Y ).\nIt is a standard result of classical homotopy theory that the realization func-\n",
          "• the large noun verb adverb\n• the large rabbit verb adverb\n• the large rabbit hops adverb\n• the large rabbit hops quickly\nSome additional valid\nsentences are:\n• a hungry mathematician\neats wildly,\n• a large mathematician\nhops,\n• the rabbit eats quickly, etc.\nBut note that the following is\nnot valid:\n• the quickly eats\nmathematician\n7 / 39\nAn Example Grammar\n\n• A vocabulary (or alphabet) 𝑉is a finite, nonempty set of elements called\nsymbols.\n• A word (or sentence) over 𝑉is a string of finite length of elements of 𝑉.\n• The empty string or null string, denoted by 𝜆, is the string containing no\nsymbols.\n• The set of all words over 𝑉is denoted by 𝑉∗. A language over 𝑉is a subset\nof 𝑉∗.\n• The elements of 𝑉that can not be replaced by other symbols are called\nterminals, e.g., a, the, and rabbit in the example grammar.\n• Those that can be replaced by other symbols are called nonterminals, e.g.,\nsentence, noun phrase, etc.\n• The rules that specify when we can replace a string 𝑉∗with another string\nare called productions of the grammar. We denote by 𝑧0 →𝑧1 the\nproduction that specifies that 𝑧0 can be replaced by 𝑧1 within a string.\n8 / 39\nPhrase-Structure Grammars\n\n• A phrase-structure grammar 𝐺= (𝑉,𝑇, 𝑆, 𝑃) consists of\n• a vocabulary 𝑉,\n• a subset 𝑇of 𝑉consisting of terminal symbols,\n• a start symbol 𝑆from 𝑉, and\n• a finite set of productions 𝑃.\n• The set 𝑁= 𝑉−𝑇is the set of nonterminal symbols.\n• Every production in 𝑃must contain at least one nonterminal on its left side.\n",
          "tor and singular set functors form an adjunction, and provide the standard\nmeans of translating between topological spaces and simplicial sets. Our\ngoal will be to adapt these powerful classical results to the case of ﬁnite\nmetric spaces.\nWe draw signiﬁcant inspiration from Spivak, speciﬁcally [52], where\nhe extends the classical theory of singular sets and topological realization\nto fuzzy singular sets and metric realization. To develop this theory here\nwe will ﬁrst outline a categorical presentation of fuzzy sets, due to [3], that\nwill make extending classical simplicial sets to fuzzy simplicial sets most\nnatural.\nClassically a fuzzy set [65] is deﬁned in terms of a carrier set A and a\nmap µ : A →[0, 1] called the membership function. One is to interpret the\nvalue µ(x) for x ∈A to be the membership strength of x to the set A. Tus\nmembership of a set is no longer a bi-valent true or false property as in\nclassical set theory, but a fuzzy property taking values in the unit interval.\nWe wish to formalize this in terms of category theory.\nLet I be the unit interval (0, 1] ⊆R with topology given by intervals\nof the form [0, a) for a ∈(0, 1]. Te category of open sets (with morphisms\ngiven by inclusions) can be imbued with a Grothendieck topology in the\nnatural way for any poset category.\nDeﬁnition 3. A presheaf P on I is a functor from Iop to Sets. A fuzzy set\nis a presheaf on I such that all maps P(a ≤b) are injections.\nPresheaves on I form a category with morphisms given by natural\ntransformations. We can thus form a category of fuzzy sets by simply re-\nstricting to the sub-category of presheaves that are fuzzy sets. We note that\nsuch presheaves are trivially sheaves under the Grothendieck topology on\nI. As one might expect, limits (including products) of such sheaves are\n",
          "overall topology of the data.\n4\nImplementation and Hyper-parameters\nHaving completed a theoretical description of the approach, we now turn\nour atention to the practical realization of this theory. We begin by pro-\nviding a more detailed description of the algorithm as implemented, and\nthen discuss a few implementation speciﬁc details. We conclude this sec-\ntion with a discussion of the hyper-parameters for the algorithm and their\npractical eﬀects.\n4.1\nAlgorithm description\nIn overview the UMAP algorithm is relatively straightforward (see Algo-\nrithm 1). When performing a fuzzy union over local fuzzy simplicial sets\nwe have found it most eﬀective to work with the probabilistic t-conorm (as\none would expect if treating membership strengths as a probability that the\nsimplex exists). Te individual functions for constructing the local fuzzy\nsimplicial sets, determining the spectral embedding, and optimizing the\nembedding with regard to fuzzy set cross entropy, are described in more\ndetail below.\nTe inputs to Algorithm 1 are: X, the dataset to have its dimension\nreduced; n, the neighborhood size to use for local metric approximation;\nd, the dimension of the target reduced space; min-dist, an algorithmic pa-\n17\n\nAlgorithm 1 UMAP algorithm\nfunction UMAP(X, n, d, min-dist, n-epochs)\n# Construct the relevant weighted graph\nfor all x ∈X do\nfs-set[x] ←LocalFuzzySimplicialSet(X, x, n)\ntop-rep ←S\nx∈X fs-set[x]\n# We recommend the probabilistic t-conorm\n# Perform optimization of the graph layout\nY ←SpectralEmbedding(top-rep, d)\nY ←OptimizeEmbedding(top-rep, Y , min-dist, n-epochs)\nreturn Y\nrameter controlling the layout; and n-epochs, controlling the amount of\noptimization work to perform.\nAlgorithm 2 describes the construction of local fuzzy simplicial sets.\nTo represent fuzzy simplicial sets we work with the fuzzy set images of [0]\n",
          "0𝑥1𝑥2 . . . 𝑥𝑘−1 given the input bit string 𝑥1𝑥2 . . . 𝑥𝑘?\n𝑓\n𝑔\nState\nInput\nInput\n0\n1\n0\n1\n27 / 39\nUnit-Delay Machine\n\nExample: Produce a finite-state machine that adds two positive integers\nusing their binary expansions.\n𝑓\n𝑔\nState\nInput\nInput\n00\n01\n10\n11\n00\n01\n10\n11\n28 / 39\nAddition Machine\n\nFinite-State Machines with No\nOutput\n\nFSMs with no output, but with some states designated as accepting states,\nare specifically designed for recognizing languages.\nConcatenation\nThe concatenation of 𝐴and 𝐵, where 𝐴and 𝐵are subsets of 𝑉∗, denoted by 𝐴𝐵,\nis the set of all strings of the form 𝑥𝑦, where 𝑥is a string in 𝐴and 𝑦is a string in\n𝐵.\nExample: Let 𝐴= {0, 11} and 𝐵= {1, 10, 110}. Find 𝐴𝐵and 𝐵𝐴.\n30 / 39\nSet of Strings\n\nDefinition\nIf 𝐴is a subset of 𝑉∗, the Kleene closure of 𝐴, denoted by 𝐴∗, is the set\nconsisting of arbitrarily long strings of elements of 𝐴. That is, 𝐴∗= Ð∞\n𝑘=0 𝐴𝑘.\nExample: What are the Kleene closures of the sets\n𝐴= {0}, 𝐵= {0, 1}, 𝑎𝑛𝑑𝐶= {11}?\n31 / 39\nKleene Closure\n\n",
          "for e ←1, . . . , n-epochs do\nfor all ([a, b], p) ∈top-rep1 do\nif Random( ) ≤p then\n# Sample simplex with probability p\nya ←ya + α · ∇(log(Φ))(ya, yb)\nfor i ←1, . . . , n-neg-samples do\nc ←random sample from Y\nya ←ya + α · ∇(log(1 −Φ))(ya, yc)\nα ←1.0 −e/n-epochs\nreturn Y\nTis completes the UMAP algorithm.\n4.2\nImplementation\nPractical implementation of this algorithm requires (approximate) k-nearest-\nneighbor calculation and eﬃcient optimization via stochastic gradient de-\nscent.\nEﬃcient approximate k-nearest-neighbor computation can be achieved\nvia the Nearest-Neighbor-Descent algorithm of [18]. Te error intrinsic in\na dimension reduction technique means that such approximation is more\nthan adequate for these purposes. While no theoretical complexity bounds\n21\n\nhave been established for Nearest-Neighbor-Descent the authors of the\noriginal paper report an empirical complexity of O(N1.14). A further ben-\neﬁt of Nearest-Neighbor-Descent is its generality; it works with any valid\ndissimilarity measure, and is eﬃcient even for high dimensional data.\nIn optimizing the embedding under the provided objective function, we\nfollow work of [54]; making use of probabilistic edge sampling and nega-\ntive sampling [41]. Tis provides a very eﬃcient approximate stochastic\ngradient descent algorithm since there is no normalization requirement.\nFurthermore, since the normalized Laplacian of the fuzzy graph represen-\ntation of the input data is a discrete approximation of the Laplace-Betrami\noperator of the manifold [?, see]]belkin2002laplacian, belkin2003laplacian,\nwe can provide a suitable initialization for stochastic gradient descent by\nusing the eigenvectors of the normalized Laplacian. Te amount of opti-\n",
          "representations.\nGiven the ability to construct such topological structures, either from\na known manifold, or by learning the metric structure of the manifold, we\ncan perform dimension reduction by simply ﬁnding low dimensional rep-\nresentations that closely match the topological structure of the source data.\nWe now consider the task of ﬁnding such a low dimensional representation.\n2.3\nOptimizing a low dimensional representation\nLet Y = {Y1, . . . , YN} ⊆Rd be a low dimensional (d ≪n) representation\nof X such that Yi represents the source data point Xi. In contrast to the\nsource data where we want to estimate a manifold on which the data is\nuniformly distributed, a target manifold for Y is chosen apriori (usually this\nwill simply be Rd itself, but other choices such as d-spheres or d-tori are\ncertainly possible) . Terefore we know the manifold and manifold metric\napriori, and can compute the fuzzy topological representation directly. Of\nnote, we still want to incorporate the distance to the nearest neighbor as per\nthe local connectedness requirement. Tis can be achieved by supplying a\nparameter that deﬁnes the expected distance between nearest neighbors in\nthe embedded space.\n11\n\nGiven fuzzy simplicial set representations of X and Y , a means of com-\nparison is required. If we consider only the 1-skeleton of the fuzzy sim-\nplicial sets we can describe each as a fuzzy graph, or, more speciﬁcally, a\nfuzzy set of edges. To compare two fuzzy sets we will make use of fuzzy set\ncross entropy. For these purposes we will revert to classical fuzzy set no-\ntation. Tat is, a fuzzy set is given by a reference set A and a membership\nstrength function µ : A →[0, 1]. Comparable fuzzy sets have the same\nreference set. Given a sheaf representation P we can translate to classical\nfuzzy sets by seting A = S\na∈(0,1] P([0, a)) and µ(x) = sup{a ∈(0, 1] |\n",
          "lationships between UMAP, t-SNE and Largeviz located in Appendix C en-\nlightening. Unfortunately, this purely computational view fails to shed any\nlight upon the reasoning that underlies the algorithmic decisions made in\nUMAP. Without strong theoretical foundations the only arguments which\ncan be made about algorithms amount to empirical measures, for which\nthere are no clear universal choices for unsupervised problems.\nAt a high level, UMAP uses local manifold approximations and patches\ntogether their local fuzzy simplicial set representations to construct a topo-\nlogical representation of the high dimensional data. Given some low dimen-\nsional representation of the data, a similar process can be used to construct\nan equivalent topological representation. UMAP then optimizes the layout\nof the data representation in the low dimensional space, to minimize the\ncross-entropy between the two topological representations.\nTe construction of fuzzy topological representations can be broken\ndown into two problems: approximating a manifold on which the data is\nassumed to lie; and constructing a fuzzy simplicial set representation of\nthe approximated manifold. In explaining the algorithm we will ﬁrst dis-\ncuss the method of approximating the manifold for the source data. Next\nwe will discuss how to construct a fuzzy simplicial set structure from the\nmanifold approximation. Finally, we will discuss the construction of the\nfuzzy simplicial set associated to a low dimensional representation (where\nthe manifold is simply Rd), and how to optimize the representation with\nrespect to our objective function.\n2.1\nUniform distribution of data on a manifold and\ngeodesic approximation\nTe ﬁrst step of our algorithm is to approximate the manifold we assume\nthe data (approximately) lies on. Te manifold may be known apriori (as\nsimply Rn) or may need to be inferred from the data. Suppose the manifold\nis not known in advance and we wish to approximate geodesic distance on\nit. Let the input data be X = {X1, . . . , XN}. As in the work of Belkin and\nNiyogi on Laplacian eigenmaps [6, 7], for theoretical reasons it is beneﬁcial\nto assume the data is uniformly distributed on the manifold, and even if that\n",
          "Initial\ncontent\n| **Company**                                  | **Currency** | **Current Price** | **P/B FY23F** | **Div Yield FY23F** | **Net D/E** |                 |                    |\n|:----------------------------------------------|:----------------:|------------------------:|--------------------:|:--------------------------:|----------------:|--------------:|----------------:|\n| Tesla Inc                                          | USD           | 246.4                    | 10.0                 | 0.0                            | -0.3             | 189.1       | 283.9          |\n| Meta Platforms Inc                          | USD           | 488.7                    | 5.1                   | 0.5                            | 0.2              | 464.0       | 545.0          |\n| NVIDIA Corp                                   | USD           | 122.6                    | 19.5                 | 0.1                            | -0.3             | 117.4       | 133.6          |\n|                                                        | USD           | 264.8                    | 11.5                  | 0.1                            | -0.1             | 260.6       | 274.1          |\n| United Parcel Service Inc               | USD           | 127.7                    | 5.6                   | 4.0                            | 1.2              | 124.8       | 149.2          |\n| LVMH Moet Hennessy Louis Vuitt  | EUR           | 691.6                    | 4.3                   | 2.5                            | 0.4              | 677.3       | 731.3          |\n| Kering SA                                       | EUR           | 315.0                    | 2.3                   | 420%                        | 0.9              | 308.2       | 331.3         |\n",
          "Example: Grammar 1\n• 𝐴𝑎𝑏𝑎is directly derivable from 𝐴𝐵𝑎because 𝐵→𝑎𝑏is a production.\n• 𝑎𝑏𝑎𝑏𝑎𝑏𝑎is derivable from 𝐴𝐵𝑎because\n𝐴𝐵𝑎⇒𝐴𝑎𝑏𝑎⇒𝐵𝐵𝑎𝑏𝑎⇒𝐵𝑎𝑏𝑎𝑏𝑎⇒𝑎𝑏𝑎𝑏𝑎𝑏𝑎using the productions\n𝐵→𝑎𝑏, 𝐴→𝐵𝐵, and 𝐵→𝑎𝑏in both of the last two steps of the derivation.\n10 / 39\nDerivations\n\n• Let 𝐺= (𝑉,𝑇, 𝑆, 𝑃) be a phrase-structure grammar. The language\ngenerated by 𝐺, denoted by 𝐿(𝐺), is the set of all strings or terminals that\nare derivable from the starting state 𝑆.\n• In other words, 𝐿(𝐺) = {𝑤∈𝑇∗|𝑆\n∗=⇒𝑤}.\n• Let 𝐺be the grammar with the vocabulary 𝑉= {𝑆, 𝐴, 𝑎, 𝑏}, a set of terminals\n𝑇= {𝑎, 𝑏}, starting symbol 𝑆, and productions 𝑃= {𝑆→𝑎𝐴, 𝑆→𝑏, 𝐴→𝑎𝑎}.\n",
          "well deﬁned, but care must be taken to deﬁne colimits (and coproducts) of\nsheaves. To link to the classical approach to fuzzy sets one can think of a\nsection P([0, a)) as the set of all elements with membership strength at\nleast a. We can now deﬁne the category of fuzzy sets.\nDeﬁnition 4. Te category Fuzz of fuzzy sets is the full subcategory of\nsheaves on I spanned by fuzzy sets.\n7\n\nWith this categorical presentation in hand, deﬁning fuzzy simplicial\nsets is simply a mater of considering presheaves of ∆valued in the cate-\ngory of fuzzy sets rather than the category of sets.\nDeﬁnition 5. Te category of fuzzy simplicial sets sFuzz is the category\nwith objects given by functors from ∆op to Fuzz, and morphisms given by\nnatural transformations.\nAlternatively, a fuzzy simplicial set can be viewed as a sheaf over ∆×I,\nwhere ∆is given the trivial topology and ∆× I has the product topology.\nWe will use ∆n\n<a to denote the sheaf given by the representable functor of\nthe object ([n], [0, a)). Te importance of this fuzzy (sheaﬁﬁed) version of\nsimplicial sets is their relationship to metric spaces. We begin by consider-\ning the larger category of extended-pseudo-metric spaces.\nDeﬁnition 6. An extended-pseudo-metric space (X, d) is a set X and a\nmap d : X × X →R≥0 ∪{∞} such that\n1. d(x, y) ⩾0, and x = y implies d(x, y) = 0;\n2. d(x, y) = d(y, x); and\n3. d(x, z) ⩽d(x, y) + d(y, z) or d(x, z) = ∞.\nTe category of extended-pseudo-metric spaces EPMet has as objects extended-\n",
          "log(b)/ log(a) ≤1.\nWe then extend this to a general simplicial set X via colimits, deﬁning\nReal(X) ≜colim\n∆n\n<a→X Real(∆n\n<a).\nSince the functor Real preserves colimits, it follows that there exists a\nright adjoint functor. Again, analogously to the classical case, we ﬁnd the\nright adjoint, denoted Sing, is deﬁned for an extended pseudo metric space\nY in terms of its action on the category ∆× I:\nSing(Y ) : ([n], [0, a)) 7→homEPMet(Real(∆n\n<a), Y ).\nFor our case we are only interested in ﬁnite metric spaces. To corre-\nspond with this we consider the subcategory of bounded fuzzy simplicial\nsets Fin-sFuzz. We therefore use the analogous adjoint pair FinReal and\nFinSing. Formally we deﬁne the ﬁnite fuzzy realization functor as follows:\nDeﬁnition 7. Deﬁne the functor FinReal : Fin-sFuzz →FinEPMet by\nseting\nFinReal(∆n\n<a) ≜({x1, x2, . . . , xn}, da),\nwhere\nda(xi, xj) =\n\n\n\n−log(a)\nif i ̸= j,\n0\notherwise\n.\nand then deﬁning\nFinReal(X) ≜colim\n∆n\n<a→X FinReal(∆n\n<a).\nSimilar to Spivak’s construction, the action of FinReal on a map ∆n\n<a →\n∆m\n<b, where a ≤b deﬁned by σ : ∆n →∆m, is given by\n({x1, x2, . . . , xn}, da) 7→({xσ(1), xσ(2), . . . , xσ(n)}, db),\n",
          "x ∈P([0, a))}.\nDeﬁnition 10. Te cross entropy C of two fuzzy sets (A, µ) and (A, ν) is\ndeﬁned as\nC((A, µ), (A, ν)) ≜\nX\na∈A\n\u0012\nµ(a) log\n\u0012µ(a)\nν(a)\n\u0013\n+ (1 −µ(a)) log\n\u00121 −µ(a)\n1 −ν(a)\n\u0013\u0013\n.\nSimilar to t-SNE we can optimize the embedding Y with respect to fuzzy\nset cross entropy C by using stochastic gradient descent. However, this re-\nquires a diﬀerentiable fuzzy singular set functor. If the expected minimum\ndistance between points is zero the fuzzy singular set functor is diﬀeren-\ntiable for these purposes, however for any non-zero value we need to make\na diﬀerentiable approximation (chosen from a suitable family of diﬀeren-\ntiable functions).\nTis completes the algorithm: by using manifold approximation and\npatching together local fuzzy simplicial set representations we construct a\ntopological representation of the high dimensional data. We then optimize\nthe layout of data in a low dimensional space to minimize the error between\nthe two topological representations.\nWe note that in this case we restricted atention to comparisons of the\n1-skeleton of the fuzzy simplicial sets. One can extend this to ℓ-skeleta by\ndeﬁning a cost function Cℓas\nCℓ(X, Y ) =\nℓ\nX\ni=1\nλiC(Xi, Yi),\nwhere Xi denotes the fuzzy set of i-simplices of X and the λi are suit-\nably chosen real valued weights. While such an approach will capture the\noverall topological structure more accurately, it comes at non-negligible\ncomputational cost due to the increasingly large numbers of higher dimen-\nsional simplices. For this reason current implementations restrict to the\n1-skeleton at this time.\n12\n\n3\nA Computational View of UMAP\nTo understand what computations the UMAP algorithm is actually making\n",
          "|:----------------------------------------------|:----------------:|------------------------:|--------------------:|:--------------------------:|----------------:|--------------:|----------------:|\n| Tesla Inc                                          | USD           | 246.4                    | 10.0                 | 0.0                            | -0.3             | 189.1       | 283.9          |\n| Meta Platforms Inc                          | USD           | 488.7                    | 5.1                   | 0.5                            | 0.2              | 464.0       | 545.0          |\n| NVIDIA Corp                                   | USD           | 122.6                    | 19.5                 | 0.1                            | -0.3             | 117.4       | 133.6          |\n| Visa Inc                                           | USD           | 264.8                    | 11.5                 | 1.0                            | -0.1             | 260.6       | 274.1          |\n| United Parcel Service Inc               | USD           | 127.7                    | 5.6                   | 5.4                            | 1.2              | 128.4       | 149.2          |\n| LVMH Moet Hennessy Louis Vuitt  | EUR           | 691.6                    | 4.3                   | 2.5                            | 0.4              | 677.3       | 731.3          |\n| Kering SA                                       | EUR           | 315.0                    | 2.3                   | 420%                        | 0.9              | 308.2       | 344.8          |\n| Chow Tai Fook Jewellery Group    | HKD           | 7.4                        | 2.4                   | 9.6                             | 0.8             | 7.8            | 8.7             |\n",
          "assumption is not made (e.g [26]) results are only valid in the limit of inﬁnite\ndata. In practice, ﬁnite real world data is rarely so nicely behaved. However,\nif we assume that the manifold has a Riemannian metric not inherited from\nthe ambient space, we can ﬁnd a metric such that the data is approximately\nuniformly distributed with regard to that metric.\n4\n\nFormally, let M be the manifold we assume the data to lie on, and let g\nbe the Riemannian metric on M. Tus, for each point p ∈M we have gp,\nan inner product on the tangent space TpM.\nLemma 1. Let (M, g) be a Riemannian manifold in an ambient Rn, and let\np ∈M be a point. If g is locally constant about p in an open neighbourhood\nU such that g is a constant diagonal matrix in ambient coordinates, then in a\nball B ⊆U centered at p with volume\nπn/2\nΓ(n/2+1) with respect to g, the geodesic\ndistance from p to any point q ∈B is 1\nrdRn(p, q), where r is the radius of the\nball in the ambient space and dRn is the existing metric on the ambient space.\nSee Appendix A of the supplementary materials for a proof of Lemma\n1.\nIf we assume the data to be uniformly distributed on M (with respect to\ng) then, away from any boundaries, any ball of ﬁxed volume should contain\napproximately the same number of points of X regardless of where on the\nmanifold it is centered. Given ﬁnite data and small enough local neighbor-\nhoods this crude approximation should be accurate enough even for data\nsamples near manifold boundaries. Now, conversely, a ball centered at Xi\nthat contains exactly the k-nearest-neighbors of Xi should have approxi-\nmately ﬁxed volume regardless of the choice of Xi ∈X. Under Lemma 1\nit follows that we can approximate geodesic distance from Xi to its neigh-\nbors by normalising distances with respect to the distance to the kth nearest\n",
          "1 / 39\nCPE 111 Discrete Mathematics for Computer Engineer\nModeling\nComputation\nDr. Taweechai Nuntawisuttiwong\n\n1\nLanguages and Grammars\n2\nFinite-State Machines with Output\n3\nFinite-State Machines with No Output\n2 / 39\nContents\n\nLanguages and Grammars\n\n• Syntax (form of a sentence) vs. semantics (meaning of a sentence)\n• The sentence “the frog writes neatly” is a valid sentence according to the\nrules of English grammar. That is, it is syntactically correct, even though\nit’s nonsensical (unless we are talking about a fantasy world).\n• The sequence of words “swims quickly mathematics” is not a valid\nsentence according to the rules of English grammar.\n4 / 39\nIntroduction\n\n• The rules that specify the syntactically correct sentences of a natural\nlanguage such as English are complex.\n• Instead of studying natural languages, we can define formal languages\nthat have well-defined rules of syntax.\n• These rules of syntax are important both in linguistics (the study of natural\nlanguages) and in the study of programming languages.\n5 / 39\nGrammars\n\n1 a sentence is made up of a noun phrase followed by a verb phrase;\n2 a noun phrase is made up of an article followed by an adjective followed\nby a noun, or\n3 a noun phrase is made up of an article followed by a noun;\n4 a verb phrase is made up of a verb followed by an adverb, or\n5 a verb phrase is made up of a verb;\n6 an article is a, or\n7 an article is the;\n8 an adjective is large, or\n9 an adjective is hungry;\n10 a noun is rabbit, or\n11 a noun is mathematician;\n12 a verb is eats, or\n13 a verb is hops;\n14 an adverb is quickly, or\n15 an adverb is wildly.\n6 / 39\nAn Example Grammar\n\nWe use these rules to form valid sentences by making a series of replacements\nuntil no more rules can be used.\nAn example sequence of replacements:\n• noun phrase verb phrase\n• article adjective noun verb phrase\n• article adjective noun verb adverb\n• the adjective noun verb adverb\n",
          "We now construct FinReal as the lef Kan extension of F along the\nYoneda embedding:\nFin-sFuzz\nFinReal\n(\n∆× I\n+\u000b\ny\n8\nF\n/ FinEPMet\nExplicitly this results in a deﬁnition of FinReal at a fuzzy simplicial set X\nas a colimit:\nFinReal(X) =\ncolim\ny([n],[0,a))→X F([n]).\nFurther, it follows from the Yoneda lemma that FinReal(∆n\n<a) ∼= F([n], [0, a)),\nand hence this deﬁnition as a lef Kan extension agrees with Deﬁnition 7,\nand the deﬁnition of FinSing above agrees with that of Deﬁnition 8. To see\nthat FinReal and FinSing are adjoint we note that\nhomFin-sFuzz(∆n\n<a, FinSing(Y )) ∼= FinSing(Y )n\n<a\n= homFinEPMet(F([n], [0, a)), Y )\n∼= homFinEPMet(FinReal(∆n\n<a), Y )).\n(4)\n53\n\nTe ﬁrst isomorphism follows from the Yoneda lemma, the equality is by\nconstruction, and the ﬁnal isomorphism follows by another application of\nthe Yoneda lemma. Since every simplicial set can be canonically expressed\nas a colimit of standard simplices and FinReal commutes with colimits (as\nit was deﬁned via a colimit formula), it follows that FinReal is completely\ndetermined by its image on standard simplices. As a result the isomor-\nphism of equation (4) extends to the required isomorphism demonstrating\nthe adjunction.\nC\nFrom t-SNE to UMAP\nAs an aid to implementation of UMAP and to illuminate the algorithmic\nsimilarities with t-SNE and LargeVis, here we review the main equations\nused in those methods, and then present the equivalent UMAP expressions\nin a notation which may be more familiar to users of those other methods.\n",
          "guaranteed by slowly decreasing the atractive and repulsive forces in a\nsimilar fashion to that used in simulated annealing.\nIn UMAP the atractive force between two vertices i and j at coordi-\nnates yi and yj respectively, is determined by:\n−2ab∥yi −yj∥2(b−1)\n2\n1 + ∥yi −yj∥2\n2\nw((xi, xj)) (yi −yj)\nwhere a and b are hyper-parameters.\nRepulsive forces are computed via sampling due to computational con-\nstraints. Tus, whenever an atractive force is applied to an edge, one of\nthat edge’s vertices is repulsed by a sampling of other vertices. Te repul-\nsive force is given by\n2b\n�ϵ + ∥yi −yj∥2\n2\n\u0001 �1 + a∥yi −yj∥2b\n2\n\u0001 (1 −w((xi, xj))) (yi −yj) .\nϵ is a small number to prevent division by zero (0.001 in the current\nimplementation).\n16\n\nTe algorithm can be initialized randomly but in practice, since the sym-\nmetric Laplacian of the graph G is a discrete approximation of the Laplace-\nBeltrami operator of the manifold, we can use a spectral layout to initialize\nthe embedding. Tis provides both faster convergence and greater stability\nwithin the algorithm.\nTe forces described above are derived from gradients optimising the\nedge-wise cross-entropy between the weighted graph G, and an equiva-\nlent weighted graph H constructed from the points {yi}i=1..N. Tat is, we\nare seeking to position points yi such that the weighted graph induced by\nthose points most closely approximates the graph G, where we measure\nthe diﬀerence between weighted graphs by the total cross entropy over all\nthe edge existence probabilities. Since the weighted graph G captures the\ntopology of the source data, the equivalent weighted graph H constructed\nfrom the points {yi}i=1..N matches the topology as closely as the optimiza-\ntion allows, and thus provides a good low dimensional representation of the\n",
          "return fs-set\nAlgorithm 3 Compute the normalizing factor for distances σ\nfunction SmoothKNNDist(knn-dists, n, ρ)\nBinary search for σ such that Pn\ni=1 exp(−(knn-distsi −ρ)/σ) = log2(n)\nreturn σ\nAlgorithm 4 Spectral embedding for initialization\nfunction SpectralEmbedding(top-rep, d)\nA ←1-skeleton of top-rep expressed as a weighted adjacency matrix\nD ←degree matrix for the graph A\nL ←D1/2(D −A)D1/2\nevec ←Eigenvectors of L (sorted)\nY ←evec[1..d + 1]\n# 0-base indexing assumed\nreturn Y\n19\n\nfuzzy set cross entropy, with respect given membership functions µ and ν,\nis given by\nC((A, µ), (A, ν)) =\nX\na∈A\nµ(a) log\n\u0012µ(a)\nν(a)\n\u0013\n+ (1 −µ(a)) log\n\u00121 −µ(a)\n1 −ν(a)\n\u0013\n=\nX\na∈A\n(µ(a) log(µ(a)) + (1 −µ(a)) log(1 −µ(a)))\n−\nX\na∈A\n(µ(a) log(ν(a)) + (1 −µ(a)) log(1 −ν(a))) .\n(1)\nTe ﬁrst sum depends only on µ which takes ﬁxed values during the op-\ntimization, thus the minimization of cross entropy depends only on the\nsecond sum, so we seek to minimize\n−\nX\na∈A\n(µ(a) log(ν(a)) + (1 −µ(a)) log(1 −ν(a))) .\nFollowing both [54] and [41], we take a sampling based approach to the\noptimization. We sample 1-simplices with probability µ(a) and update ac-\n",
          "neighbor of Xi.\nIn essence, by creating a custom distance for each Xi, we can ensure\nthe validity of the assumption of uniform distribution on the manifold. Te\ncost is that we now have an independent notion of distance for each and\nevery Xi, and these notions of distance may not be compatible. We have\na family of discrete metric spaces (one for each Xi) that we wish to merge\ninto a consistent global structure. Tis can be done in a natural way by\nconverting the metric spaces into fuzzy simplicial sets.\n2.2\nFuzzy topological representation\nWe will use functors between the relevant categories to convert from metric\nspaces to fuzzy topological representations. Tis will provide a means to\nmerge the incompatible local views of the data. Te topological structure\nof choice is that of simplicial sets. For more details on simplicial sets we\nrefer the reader to [25], [40], [48], or [22]. Our approach draws heavily\nupon the work of Michael Barr [3] and David Spivak in [52], and many\nof the deﬁnitions and theorems below are drawn or adapted from those\n5\n\nsources. We assume familiarity with the basics of category theory. For an\nintroduction to category theory readers may consult [39] or [49].\nTo start we will review the deﬁnitions for simplicial sets. Simplicial sets\nprovide a combinatorial approach to the study of topological spaces. Tey\nare related to the simpler notion of simplicial complexes – which construct\ntopological spaces by gluing together simple building blocks called sim-\nplices – but are more general. Simplicial sets are most easily deﬁned purely\nabstractly in the language of category theory.\nDeﬁnition 1. Te category ∆has as objects the ﬁnite order sets [n] =\n{1, . . . , n}, with morphims given by (non-strictly) order-preserving maps.\nFollowing standard category theoretic notation, ∆op denotes the cate-\ngory with the same objects as ∆and morphisms given by the morphisms\nof ∆with the direction (domain and codomain) reversed.\n",
          "as\ninf\nc∈C\nZ b\na\np\ng(˙c(t), ˙c(t))dt,\nwhere C is the class of smooth curves c on M such that c(a) = p and\nc(b) = q, and ˙c denotes the ﬁrst derivative of c on M. Given that g is as\ndeﬁned in (2) we see that this can be simpliﬁed to\n1\nr inf\nc∈C\nZ b\na\n⟨\np\n˙c(t), ˙c(t)⟩dt\n=1\nr inf\nc∈C\nZ b\na\n⟨∥˙c(t), ˙c(t)∥dt\n=1\nrdRn(p, q).\n(3)\n52\n\nB\nProof that FinReal and FinSing are adjoint\nTeorem 2. Te functors FinReal : Fin-sFuzz →FinEPMet and FinSing :\nFinEPMet →Fin-sFuzz form an adjunction with FinReal the lef adjoint\nand FinSing the right adjoint.\nProof. Te adjunction is evident by construction, but can be made more\nexplicit as follows. Deﬁne a functor F : ∆× I →FinEPMet by\nF([n], [0, a)) = ({x1, x2, . . . , xn}, da),\nwhere\nda(xi, xj) =\n\n\n\n−log(a)\nif i ̸= j,\n0\notherwise\n.\nNow FinSing can be deﬁned in terms of F as\nFinSing(Y ) : ([n], [0, a)) 7→homFinEPMet(F([n], [0, a)), Y ).\nwhere the face maps di are given by pre-composition with Fdi, and sim-\nilarly for degeneracy maps, at any given value of a. Furthermore post-\ncomposition with F level-wise for each a deﬁnes maps of fuzzy simplicial\nsets making FinSing a functor.\n",
          "arise.\n• If the production A →w, where w is a word, arises\nin the derivation, the vertex that represents A\nhas as children vertices that represent each\nsymbol in w, in order from left to right.\n• A derivation tree for the derivation of the\nhungry rabbit eats quickly, given the grammar\ndescribed earlier.\n16 / 39\nDerivation Trees\n\n• Backus-Naur form (BNF) is sometimes used to specify a type 2 grammar\n(context-free grammar). It is often used to specify the syntactic rules of\ncomputer languages.\n• The productions of a type 2 grammar have a single nonterminal symbol on\ntheir left-hand side. All the productions with the same nonterminal\nsymbol on the left-hand side are combined into one statement using the\nsymbol ::= instead of →. Additionally, all nonterminal symbols are enclosed\nin brackets (<>), and the right-hand side of productions are spearated by\nbars.\nExample:\nThe productions 𝐴→𝐴𝑎, 𝐴→𝑎, and , 𝐴→𝐴𝐵are written as\n< 𝐴>::=< 𝐴> 𝑎|𝑎| < 𝐴>< 𝐵> .\n17 / 39\nBackus-Naur Form\n\nFinite-State Machines with\nOutput\n\n• Many kinds of machines, including computers, can be modeled using a\nstructure called a finite-state machine (or finite automaton).\n• A finite-state machine consists of a finite set of states, a designated start\nstate, an input alphabet, and a transition function that assigns a next state\nto every (state, input) pair\n• Some types of finite-state machines produce output, while for other types\nof finite-state machines that do not produce output some states are\ndesignated as accepting states.\n• Finite-state machines are used in many diverse applications, including\nspell-checking programs, grammar checking, indexing, searching large\nbodies of text, speech recognition, XML, HTML, and network protocols\n19 / 39\nIntroduction\n\n• A vending machine accepts nickels (5 cents) , dimes (10 cents) , and\n",
          "cording to the value of ν(a), which handles the term µ(a) log(ν(a)). Te\nterm (1 −µ(a)) log(1 −ν(a)) requires negative sampling – rather than\ncomputing this over all potential simplices we randomly sample potential\n1-simplices and assume them to be a negative example (i.e. with member-\nship strength 0) and update according to the value of 1 −ν(a). In contrast\nto [54] the above formulation provides a vertex sampling distribution of\nP(xi) =\nP\n{a∈A|d0(a)=xi} 1 −µ(a)\nP\n{b∈A|d0(b)̸=xi} 1 −µ(b)\nfor negative samples, which can be reasonably approximated by a uniform\ndistribution for suﬃciently large data sets.\nIt therefore only remains to ﬁnd a diﬀerentiable approximation to ν(a)\nfor a given 1-simplex a so that gradient descent can be applied for opti-\nmization. Tis is done as follows:\nDeﬁnition 11. Deﬁne Φ : Rd ×Rd →[0, 1], a smooth approximation of the\nmembership strength of a 1-simplex between two points in Rd, as\nΦ(x, y) =\n\u0010\n1 + a(∥x −y∥2\n2)b\u0011−1\n,\n20\n\nwhere a and b are chosen by non-linear least squares ﬁting against the curve\nΨ : Rd × Rd →[0, 1] where\nΨ(x, y) =\n(\n1\nif ∥x −y∥2 ≤min-dist\nexp(−(∥x −y∥2 −min-dist))\notherwise\n.\nTe optimization process is now executed by stochastic gradient de-\nscent as given by Algorithm 5.\nAlgorithm 5 Optimizing the embedding\nfunction OptimizeEmbedding(top-rep, Y , min-dist, n-epochs)\nα ←1.0\nFit Φ from Ψ deﬁned by min-dist\n",
          "and [1] (i.e. the 1-skeleton), which we denote as fs-set0 and fs-set1. One can\nwork with higher order simplices as well, but the current implementation\ndoes not. We can construct the fuzzy simplicial set local to a given point x\nby ﬁnding the n nearest neighbors, generating the appropriate normalised\ndistance on the manifold, and then converting the ﬁnite metric space to a\nsimplicial set via the functor FinSing, which translates into exponential of\nthe negative distance in this case.\nRather than directly using the distance to the nth nearest neighbor as\nthe normalization, we use a smoothed version of knn-distance that ﬁxes\nthe cardinality of the fuzzy set of 1-simplices to a ﬁxed value. We selected\nlog2(n) for this purpose based on empirical experiments. Tis is described\nbrieﬂy in Algorithm 3.\nSpectral embedding is performed by considering the 1-skeleton of the\nglobal fuzzy topological representation as a weighted graph and using stan-\ndard spectral methods on the symmetric normalized Laplacian. Tis pro-\ncess is described in Algorithm 4.\nTe ﬁnal major component of UMAP is the optimization of the em-\nbedding through minimization of the fuzzy set cross entropy. Recall that\n18\n\nAlgorithm 2 Constructing a local fuzzy simplicial set\nfunction LocalFuzzySimplicialSet(X, x, n)\nknn, knn-dists ←ApproxNearestNeighbors(X, x, n)\nρ ←knn-dists[1]\n# Distance to nearest neighbor\nσ ←SmoothKNNDist(knn-dists, n, ρ)\n# Smooth approximator to\nknn-distance\nfs-set0 ←X\nfs-set1 ←{([x, y], 0) | y ∈X}\nfor all y ∈knn do\ndx,y ←max{0, dist(x, y) −ρ}/σ\nfs-set1 ←fs-set1 ∪([x, y], exp(−dx,y))\n",
          "quarters (25 cents).\n• When 30 cents or more has been deposited, the machine returns the\namount over 30 cents.\n• The customer can then press an orange button to receive a container of\norange juice or a red button to receive a container of apple juice.\n• The machine can be in any of the states 𝑠𝑖, 𝑖= 0, . . . , 6, where 𝑠𝑖is the state\nwhere the machine has received 5𝑖cents.\n• The machine starts in state 𝑠0, with 0 cents received.\n• The possible inputs are 5 cents, 10 cents, 25 cents, the orange button (𝑂),\nand the red button (𝑅).\n• The possible outputs are nothing (𝑛), 5 cents, 15 cents, 20 cents, 25 cents,\nan orange juice, and an apple juice.\n20 / 39\nAn Example of a Finite-State Machine with Output\n\n21 / 39\nAn Example of a State Table\n\nWe represent this vending machine using a directed graph with labeled\nedges, where each state is represented by a circle, edges represent transitions,\nand edges are labeled with the input and output for that transition.\n22 / 39\nAn Example of a State Diagram\n\n• We will trace the transitions and outputs of the vending machine when a\nstudent puts in a dime followed by a quarter, receives 5 cents back, and\nthen pushes the orange button and receives an orange juice.\n• The machine starts in state 𝑠0.\n• The first input is 10 cents, which changes the state to 𝑠2 and gives no\noutput.\n• After the second input of 25 cents, the state changes to 𝑠6 and gives 5\ncents as output.\n• The last input is the orange button, which changes the state back to 𝑠0 and\ngives an orange juice as output.\n23 / 39\nAn Example of a State Diagram\n\nDefinition\nA finite-state machine 𝑀= (𝑆, 𝐼, 𝑂, 𝑓, 𝑔, 𝑠0) consists of a finite set 𝑆of states, a\n",
          "\u0013\n+ (1 −vij) log\n\u0012 1 −vij\n1 −wij\n\u0013\n(13)\nLike the Kullback-Leibler divergence, this can be arranged into two con-\nstant contributions (those containing vij only) and two optimizable contri-\nbutions (containing wij):\n56\n\nCUMAP =\nX\ni̸=j\nvij log vij + (1 −vij) log (1 −vij)\n−vij log wij −(1 −vij) log (1 −wij)\n(14)\nIgnoring the two constant terms, the UMAP cost function has a very\nsimilar form to that of LargeVis, but without a γ term to weight the re-\npulsive component of the cost function, and without requiring matrix-wise\nnormalization in the high dimensional space. Te cost function for UMAP\ncan therefore be optimized (in this case, minimized) with stochastic gradi-\nent descent in the same way as LargeVis.\nAlthough the above discussion places UMAP in the same family of meth-\nods as t-SNE and LargeVis, it does not use the same deﬁnitions for vij and\nwij. Using the notation established above, we now provide the equivalent\nexpressions for the UMAP similarities. In the high dimensional space, the\nsimilarities vj|i are the local fuzzy simplicial set memberships, based on the\nsmooth nearest neighbors distances:\nvj|i = exp[(−d (xi, xj) −ρi)/σi]\n(15)\nAs with LargeVis, vj|i is calculated only for n approximate nearest neigh-\nbors and vj|i = 0 for all other j. d (xi, xj) is the distance between xi and\nxj, which UMAP does not require to be Euclidean. ρi is the distance to the\nnearest neighbor of i. σi is the normalizing factor, which is chosen by Al-\ngorithm 3 and plays a similar role to the perplexity-based calibration of σi\nin t-SNE. Calculation of vj|i with Equation 15 corresponds to Algorithm 2.\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_of_as_is",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_of_as_is"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "aK8zQcAFL0Hy5TBBkrQyQXPsJEEQQC1BnoIzQdTXMkHloTNBsMEqQTBRNUHvOCtB+4c1QeNUNUGhYDFB/CIzQVyPK0EvBS1BiLkzQR1VM0HNHCtBELcqQczVNEGSxTNBINAtQR/yLkGAYC5BGM00QRfeJkE/xzNBPUYuQRQeMEH6yzFBxj0qQVGnLkFV0zRBgcwyQccGL0HFDzdBRiszQeJkMEE=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "hWtpwHkwJcBGpVjAYAMRwMk5MsBozyDAEJ0OwMGUDMA4cmfASx0cwPTOf8ALR/6/XMOBwPA0f8CgpFHAMCp7wC20F8DBtwTA0MZpwK3nB8CpnQ/AmhcDwPIKXMB+xmbAeOsswMCqS8CO7RLAfQlZwH6IGcDzEHvAmTk+wIC6EMDWNkXAB/gLwPHTQcBocYHAfrFMwCGlKcAtAIPABJoXwConPcA=",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "46\n\nTechnical Report\nYushi Bai, Xin Lv, Jiajie Zhang, Yuze He, Ji Qi, Lei Hou, Jie Tang, Yuxiao Dong, and Juanzi\nLi. LongAlign: A Recipe for Long Context Alignment of Large Language Models. In\nYaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Findings of the Association for\nComputational Linguistics: EMNLP 2024, pp. 1376–1395, Miami, Florida, USA, November\n2024. Association for Computational Linguistics. URL https://aclanthology.org/2024.\nfindings-emnlp.74.\nLoubna Ben Allal, Anton Lozhkov, Guilherme Penedo, Thomas Wolf, and Leandro\nvon Werra.\nCosmopedia, February 2024.\nURL https://huggingface.co/datasets/\nHuggingFaceTB/cosmopedia.\nCody Blakeney, Mansheej Paul, Brett W. Larsen, Sean Owen, and Jonathan Frankle. Does\nyour data spark joy? Performance gains from domain upsampling at the end of training.\nIn First Conference on Language Modeling, 2024. URL https://openreview.net/forum?id=\nvwIIAot0ff.\nCarlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim,\nJeannette N Chang, Sungbok Lee, and Shrikanth S Narayanan. IEMOCAP: Interactive\nemotional dyadic motion capture database. Language resources and evaluation, 2008.\nGuoguo Chen, Shuzhou Chai, Guanbo Wang, Jiayu Du, Wei-Qiang Zhang, Chao Weng,\nDan Su, Daniel Povey, Jan Trmal, Junbo Zhang, Mingjie Jin, Sanjeev Khudanpur, Shinji\nWatanabe, Shuaijiang Zhao, Wei Zou, Xiangang Li, Xuchen Yao, Yongqing Wang, Yujun\nWang, Zhao You, and Zhiyong Yan. GigaSpeech: An Evolving, Multi-domain ASR Corpus\n",
          "Wenda Xu, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, and William Yang\nWang. Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement, 2024. URL\nhttps://arxiv.org/abs/2402.11436.\nPrateek Yadav, Derek Tam, Leshem Choshen, Colin Raffel, and Mohit Bansal. TIES-Merging:\nResolving Interference When Merging Models. In Thirty-seventh Conference on Neural In-\nformation Processing Systems, 2023. URL https://openreview.net/forum?id=xtaX3WyCj1.\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,\nChengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong\nTang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin\nXu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, et al. Qwen2 Technical\nReport, 2024a. URL https://arxiv.org/abs/2407.10671.\nAn Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu,\nJianhong Tu, Jingren Zhou, Junyang Lin, Keming Lu, Mingfeng Xue, Runji Lin, Tianyu\nLiu, Xingzhang Ren, and Zhenru Zhang. Qwen2.5-Math Technical Report: Toward\nMathematical Expert Model via Self-Improvement, 2024b. URL https://arxiv.org/abs/\n2409.12122.\nLing Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E.\nGonzalez, and Bin Cui. Buffer of Thoughts: Thought-Augmented Reasoning with Large\nLanguage Models, 2024c. URL https://arxiv.org/abs/2406.04271.\n",
          "54\n\nTechnical Report\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and\nKarthik Narasimhan. Tree of Thoughts: Deliberate Problem Solving with Large Language\nModels, 2023. URL https://arxiv.org/abs/2305.10601.\nLe Yu, Bowen Yu, Haiyang Yu, Fei Huang, and Yongbin Li. Language Models are Super\nMario: Absorbing Abilities from Homologous Models as a Free Lunch, 2024. URL\nhttps://arxiv.org/abs/2311.03099.\nSumeth Yuenyong, Kobkrit Viriyayudhakorn, Apivadee Piyatumrong, and Jillaphat\nJaroenkantasima. OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model.\narXiv preprint arXiv:2411.07238, 2024.\nHeiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J Weiss, Ye Jia, Zhifeng Chen, and Yonghui\nWu. LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech. In Proc. Interspeech\n2019, 2019.\nDong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, and Xipeng Qiu.\nSpeechgpt: Empowering large language models with intrinsic cross-modal conversational\nabilities. arXiv preprint arXiv:2305.11000, 2023a.\nWenxuan Zhang, Mahani Aljunied, Chang Gao, Yew Ken Chia, and Lidong Bing. M3Exam:\nA Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Mod-\nels. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and\nBenchmarks Track, 2023b. URL https://openreview.net/forum?id=hJPATsBb3l.\nWenxuan Zhang, Sharifah Mahani Aljunied, Chang Gao, Yew Ken Chia, and Lidong Bing.\n",
          "models. https://github.com/tatsu-lab/alpaca_eval, 2023.\n[21] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga,\nYian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang\nYuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré,\nDiana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda\nRong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng,\nMert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab,\nPeter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli,\nTatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen\nLi, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. Holistic evaluation of language models, 2023.\n9\n\n[22] Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain, July 2004. Association for Computational\nLinguistics.\n[23] Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig,\nMyle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer,\nPunit Singh Koura, Vishrav Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa\nKozareva, Mona Diab, Veselin Stoyanov, and Xian Li. Few-shot learning with multilingual\ngenerative language models. In Proceedings of the 2022 Conference on Empirical Methods in\n",
          "M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Lan-\nguage Models, 2023c. URL https://arxiv.org/abs/2306.05179.\nWenxuan Zhang, Hou Pong Chan, Yiran Zhao*, Mahani Aljunied*, Jianyu Wang*, Chao-\nqun Liu, Yue Deng, Zhiqiang Hu, Weiwen Xu, Yew Ken Chia, Xin Li, and Lidong Bing.\nSeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for South-\neast Asian Languages, 2024. URL https://arxiv.org/abs/2407.19672.\nJun Zhao, Zhihao Zhang, Luhui Gao, Qi Zhang, Tao Gui, and Xuanjing Huang. LLaMA\nBeyond English: An Empirical Study on Language Capability Transfer, 2024. URL\nhttps://arxiv.org/abs/2401.01055.\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E. Gonzalez, and\nIon Stoica. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. In Thirty-seventh\nConference on Neural Information Processing Systems Datasets and Benchmarks Track, 2023.\nURL https://openreview.net/forum?id=uccHPGDlao.\nJeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny\nZhou, and Le Hou. Instruction-Following Evaluation for Large Language Models, 2023.\nURL https://arxiv.org/abs/2311.07911.\nContributions\nTyphoon Text: Kunat Pipatanakul, Surapon Nonesung, Teetouch Jaknamon\nTyphoon Vision: Natapong Nitarach, Surapon Nonesung, Parinthapat Pengpun, Kunat\n",
          "Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. ChartQA: A\nBenchmark for Question Answering about Charts with Visual and Logical Reasoning,\n2022. URL https://arxiv.org/abs/2203.10244.\nMinesh Mathew, Dimosthenis Karatzas, R Manmatha, and CV Jawahar.\nDocVQA: A\nDataset for VQA on Document Images. CoRR abs/2007.00398 (2020). arXiv preprint\narXiv:2007.00398, 2020.\nMantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham\nSakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, and Dan Hendrycks. Harm-\nBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust\nRefusal, 2024. URL https://arxiv.org/abs/2402.04249.\n51\n\nTechnical Report\nAnand Mishra, Shashank Shekhar, Ajeet Kumar Singh, and Anirban Chakraborty. OCR-\nVQA: Visual Question Answering by Reading Text in Images. In ICDAR, 2019.\nNECTEC.\nPathummaLLM\nV\n1.0.0\nRelease.\nhttps://medium.com/nectec/\npathummallm-v-1-0-0-release-6a098ddfe276, 2024.\nThe National Institute of Educational Testing Service. Basic Statistical Values of O-NET Test\nResults. https://www.niets.or.th/th/content/view/11821, 2021.\nConsortium of Thai Medical Schools. Scores report of the TPAT1 exam for thai medical\nschools admission. https://www9.si.mahidol.ac.th/cotmes_stat.html, 2023.\nCouncil of University Presidents of Thailand. Basic Statistical Report TGAT/TPAT Exami-\nnation. https://www.mytcas.com/stat/, 2023.\n",
          "mongkol, Ruangsak Patomwong, Pathomporn Chokchainant, and Kasima Tharnpipitchai.\nTyphoon: Thai large language models. arXiv preprint arXiv:2312.13951, 2023.\nCharin Polpanumas, Wannaphong Phatthiyaphaibun, Patomporn Payoungkhamdee, Peerat\nLimkonchotiwat, Lalita Lowphansirikul, Can Udomcharoenchaikit, Titipat Achakul-\nwisut, Ekapol Chuangsuwanich, and Sarana Nutanong. WangChanGLM — The Multilin-\ngual Instruction- Following Model, April 2023. URL https://doi.org/10.5281/zenodo.\n7878101.\nAdam Polyak, Yossi Adi, Jade Copet, Eugene Kharitonov, Kushal Lakhotia, Wei-Ning Hsu,\nAbdelrahman Mohamed, and Emmanuel Dupoux. Speech Resynthesis from Discrete\nDisentangled Self-Supervised Representations. In Proc. Interspeech 2021, 2021.\nVineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu,\nAli Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi\nAdi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, and Michael Auli. Scaling Speech\nTechnology to 1,000+ Languages, 2023. URL https://arxiv.org/abs/2305.13516.\nTakaaki Saeki, Detai Xin, Wataru Nakata, Tomoki Koriyama, Shinnosuke Takamichi, and\nHiroshi Saruwatari. UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022.\nProc. Interspeech 2022, 2022.\n52\n\nTechnical Report\nVictor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled\n",
          "and Yun-Nung Chen (eds.), Proceedings of the 2024 Conference on Empirical Methods in\nNatural Language Processing, pp. 10205–10224, Miami, Florida, USA, November 2024b.\nAssociation for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.570. URL\nhttps://aclanthology.org/2024.emnlp-main.570.\nYunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou,\nand Jingren Zhou. Qwen-audio: Advancing universal audio understanding via unified\nlarge-scale audio-language models. arXiv preprint arXiv:2311.07919, 2023.\nNakhun Chumpolsathien. Using Knowledge Distillation from Keyword Extraction to\nImprove the Informativeness of Neural Cross-lingual Summarization. Master’s thesis,\nBeijing Institute of Technology, 2020.\n47\n\nTechnical Report\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz\nKaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher\nHesse, and John Schulman. Training Verifiers to Solve Math Word Problems, 2021. URL\nhttps://arxiv.org/abs/2110.14168.\nSeamless Communication, Loïc Barrault, Yu-An Chung, Mariano Coria Meglioli, David Dale,\nNing Dong, Mark Duppenthaler, Paul-Ambroise Duquenne, Brian Ellis, Hady Elsahar,\nJustin Haaheim, John Hoffman, Min-Jae Hwang, Hirofumi Inaguma, Christopher Klaiber,\nIlia Kulikov, Pengwei Li, Daniel Licht, Jean Maillard, Ruslan Mavlyutov, Alice Rakotoari-\nson, Kaushik Ram Sadagopan, Abinesh Ramakrishnan, Tuan Tran, Guillaume Wenzek,\nYilin Yang, Ethan Ye, Ivan Evtimov, Pierre Fernandez, Cynthia Gao, et al. Seamless:\n",
          "Takuya Akiba, Makoto Shing, Yujin Tang, Qi Sun, and David Ha. Evolutionary Optimization\nof Model Merging Recipes, 2024. URL https://arxiv.org/abs/2403.13187.\nR. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler, J. Meyer, R. Morais, L. Saunders,\nF. M. Tyers, and G. Weber. Common Voice: A Massively-Multilingual Speech Corpus. In\nProceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020), 2020.\nChristoph Auer, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Nikolaos Livathinos, Panos\nVagenas, Cesar Berrospi Ramis, Matteo Omenetti, Fabian Lindlbauer, Kasper Dinkla,\nLokesh Mishra, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas\nMorin, Ingmar Meijer, Viktor Kuropiatnyk, and Peter W. J. Staar. Docling Technical Report,\n2024. URL https://arxiv.org/abs/2408.09869.\nZaw Htet Aung, Thanachot Thavornmongkol, Atirut Boribalburephan, Vittavas Tangsri-\nworakan, Knot Pipatsrisawat, and Titipat Achakulvisut. Thonburian Whisper: Robust\nFine-tuned and Distilled Whisper for Thai. In Mourad Abbas and Abed Alhakim Freihat\n(eds.), Proceedings of the 7th ICNLSP 2024, pp. 149–156, Trento, October 2024. Association\nfor Computational Linguistics. URL https://aclanthology.org/2024.icnlsp-1.17.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David\nDohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program\nSynthesis with Large Language Models, 2021. URL https://arxiv.org/abs/2108.07732.\n",
          "Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\nhttps://github.com/tatsu-lab/stanford_alpaca, 2023.\n[54] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-\nthée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open\nand efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.\n[55] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,\nNikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open\nfoundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\n[56] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi,\nand Hannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated instruc-\ntions. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the\n61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npages 13484–13508, Toronto, Canada, July 2023. Association for Computational Linguistics.\n[57] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan\nDu, Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In\nInternational Conference on Learning Representations, 2022.\n11\n\n[58] BigScience Workshop, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana\nIli´c, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, et al. Bloom:\n",
          "Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an\nasr corpus based on public domain audio books. In 2015 IEEE international conference on\nacoustics, speech and signal processing (ICASSP), pp. 5206–5210. IEEE, 2015.\nShishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. Gorilla: Large Language\nModel Connected with Massive APIs. arXiv preprint arXiv:2305.15334, 2023.\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Hamza Alobei-\ndli, Alessandro Cappelli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The\nRefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data\nOnly. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and\nBenchmarks Track, 2023. URL https://openreview.net/forum?id=kM5eGcdCzq.\nGuilherme Penedo, Hynek Kydlíˇcek, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell,\nColin Raffel, Leandro Von Werra, and Thomas Wolf. The FineWeb Datasets: Decanting\nthe Web for the Finest Text Data at Scale, 2024. URL https://arxiv.org/abs/2406.17557.\nBowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. YaRN: Efficient Context\nWindow Extension of Large Language Models. In The Twelfth International Conference on\nLearning Representations, 2024. URL https://openreview.net/forum?id=wHBfxhZu1u.\nWannaphong Phatthiyaphaibun.\nPyThaiTTS, 2022.\nURL https://pythainlp.org/\nPyThaiTTS/.\nKunat Pipatanakul, Phatrasek Jirabovonvisut, Potsawee Manakul, Sittipong Sripaisarn-\n",
          "of the 40th International Conference on Machine Learning, ICML’23. JMLR.org, 2023a.\nMinzhi Li, Will Held, Michael J. Ryan, Kunat Pipatanakul, Potsawee Manakul, Hao Zhu,\nand Diyi Yang. Talk Arena: Interactive Evaluation of Large Audio Models, 2024b.\nXinjian Li, Shinnosuke Takamichi, Takaaki Saeki, William Chen, Sayaka Shiota, and Shinji\nWatanabe.\nYodas: Youtube-Oriented Dataset for Audio and Speech.\nIn 2023 IEEE\nAutomatic Speech Recognition and Understanding Workshop (ASRU), pp. 1–8. IEEE, 2023b.\nTsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays,\nPietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Dollár. Microsoft COCO:\nCommon Objects in Context, 2015. URL https://arxiv.org/abs/1405.0312.\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual Instruction Tuning,\n2023a. URL https://arxiv.org/abs/2304.08485.\nJiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and LINGMING ZHANG. Is Your Code\nGenerated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models\nfor Code Generation. In Thirty-seventh Conference on Neural Information Processing Systems,\n2023b. URL https://openreview.net/forum?id=1qvx610Cu7.\nWeiwen Liu, Xu Huang, Xingshan Zeng, Xinlong Hao, Shuai Yu, Dexun Li, Shuai Wang,\nWeinan Gan, Zhengying Liu, Yuanqing Yu, Zezhong Wang, Yuxian Wang, Wu Ning,\nYutai Hou, Bin Wang, Chuhan Wu, Xinzhi Wang, Yong Liu, Yasheng Wang, Duyu Tang,\nDandan Tu, Lifeng Shang, Xin Jiang, Ruiming Tang, Defu Lian, Qun Liu, and Enhong\n",
          "03608.\nKonstantinos Drossos, Samuel Lipping, and Tuomas Virtanen. Clotho: an Audio Captioning\nDataset. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),\npp. 736–740, 2020. doi: 10.1109/ICASSP40776.2020.9052990.\nQingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, and Yang Feng.\nLlama-omni: Seamless speech interaction with large language models. arXiv preprint\narXiv:2409.06666, 2024.\nEduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, and Xavier Serra. Fsd50k: an\nopen dataset of human-labeled sound events. IEEE/ACM Transactions on Audio, Speech,\nand Language Processing, 30:829–852, 2021.\nClémentine Fourrier, Nathan Habib, Alina Lozovskaya, Konrad Szafer, and Thomas Wolf.\nOpen LLM Leaderboard v2. https://huggingface.co/spaces/open-llm-leaderboard/\nopen_llm_leaderboard, 2024.\nJort F. Gemmeke, Daniel P. W. Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R. Chan-\nning Moore, Manoj Plakal, and Marvin Ritter. Audio Set: An ontology and human-labeled\ndataset for audio events. In 2017 IEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP), pp. 776–780, 2017. doi: 10.1109/ICASSP.2017.7952261.\n48\n\nTechnical Report\nCharles Goddard, Shamane Siriwardhana, Malikeh Ehghaghi, Luke Meyers, Vladimir\nKarpukhin, Brian Benedict, Mark McQuade, and Jacob Solawetz. Arcee’s MergeKit: A\nToolkit for Merging Large Language Models. In Franck Dernoncourt, Daniel Preo¸tiuc-\nPietro, and Anastasia Shimorina (eds.), Proceedings of the 2024 Conference on Empirical\n",
          "A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100,\n2022.\n[59] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann,\nPrabhanjan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language\nmodel for finance. arXiv preprint arXiv:2303.17564, 2023.\n[60] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant,\nAditya Barua, and Colin Raffel.\nmT5: A massively multilingual pre-trained text-to-text\ntransformer. In Proceedings of the 2021 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, pages 483–498,\nOnline, June 2021. Association for Computational Linguistics.\n[61] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan\nXu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang\nChen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie Tang. GLM-130b: An open bilingual\npre-trained model. In The Eleventh International Conference on Learning Representations,\n2023.\n[62] Wenxuan Zhang, Sharifah Mahani Aljunied, Chang Gao, Yew Ken Chia, and Lidong Bing.\nM3exam: A multilingual, multimodal, multilevel benchmark for examining large language\nmodels. arXiv preprint arXiv:2306.05179, 2023.\n[63] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\n",
          "Aithal, Oleksii Kuchaiev, Daniel Korzekwa, Pavlo Molchanov, Mostofa Patwary, Moham-\nmad Shoeybi, Jan Kautz, and Bryan Catanzaro. LLM Pruning and Distillation in Practice:\nThe Minitron Approach, 2024. URL https://arxiv.org/abs/2408.11796.\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. RoFormer:\nEnhanced Transformer with Rotary Position Embedding, 2023. URL https://arxiv.org/\nabs/2104.09864.\nGuangzhi Sun, Potsawee Manakul, Adian Liusie, Kunat Pipatanakul, Chao Zhang, Phil\nWoodland, and Mark Gales.\nCrossCheckGPT: Universal Hallucination Ranking for\nMultimodal Foundation Models. arXiv preprint arXiv:2405.13684, 2024.\nChangli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Lu Lu, Zejun MA,\nand Chao Zhang. SALMONN: Towards Generic Hearing Abilities for Large Language\nModels. In The Twelfth International Conference on Learning Representations, 2024a. URL\nhttps://openreview.net/forum?id=14rn7HpKVk.\nJingqun Tang, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, Chunhui Lin, Wanqing Li, Mohamad\nFitri Faiz Bin Mahmood, Hao Feng, Zhen Zhao, Yanjie Wang, Yuliang Liu, Hao Liu, Xiang\nBai, and Can Huang. MTVQA: Benchmarking Multilingual Text-Centric Visual Question\nAnswering, 2024b. URL https://arxiv.org/abs/2405.11985.\nShengbang Tong, Ellis Brown, Penghao Wu, Sanghyun Woo, Manoj Middepogu,\nSai Charitha Akula, Jihan Yang, Shusheng Yang, Adithya Iyer, Xichen Pan, Austin Wang,\n",
          "Pipatanakul\nTyphoon Audio: Potsawee Manakul, Warit Sirichotedumrong, Kunat Pipatanakul\nEngineering & Infrastructure & Applications: Sittipong Sripaisarnmongkol, Pittawat\nTaveekitworachai\nData Annotation: Adisai Na-Thalang\nBusiness & Leadership: Krisanapong Jirayoot, Kasima Tharnpipitchai\n55\n\n",
          "Chelsea Finn. Direct preference optimization: Your language model is secretly a reward model.\narXiv preprint arXiv:2305.18290, 2023.\n[47] Vinay Venkatesh Ramasesh, Aitor Lewkowycz, and Ethan Dyer. Effect of scale on catastrophic\nforgetting in neural networks. In International Conference on Learning Representations, 2022.\n[48] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan,\nYossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. Code llama: Open foundation models\nfor code. arXiv preprint arXiv:2308.12950, 2023.\n[49] Gabriele Sarti and Malvina Nissim. It5: Large-scale text-to-text pretraining for italian language\nunderstanding and generation. arXiv preprint arXiv:2203.03759, 2022.\n[50] Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto,\nOsama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, et al. Jais and jais-chat:\nArabic-centric foundation and instruction-tuned open generative large language models. arXiv\npreprint arXiv:2308.16149, 2023.\n[51] AI Singapore. Sea-lion (southeast asian languages in one network): A family of large language\nmodels for southeast asia. https://github.com/aisingapore/sealion, 2023.\n[52] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec\nRadford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback.\nAdvances in Neural Information Processing Systems, 33:3008–3021, 2020.\n[53] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
          "and Rifat Shahriyar. CrossSum: Beyond English-centric cross-lingual summarization for\n1,500+ language pairs. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors,\nProceedings of the 61st Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 2541–2564, Toronto, Canada, July 2023. Association for\nComputational Linguistics.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\nHerbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott\nGray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle,\nM. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information\nProcessing Systems, volume 33, pages 1877–1901. Curran Associates, Inc., 2020.\n[7] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan\nLi, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned\nlanguage models. arXiv preprint arXiv:2210.11416, 2022.\n8\n\n[8] Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman, Holger\nSchwenk, and Veselin Stoyanov. XNLI: Evaluating cross-lingual sentence representations. In\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,\n",
          "version of bert: smaller, faster, cheaper and lighter, 2020. URL https://arxiv.org/abs/\n1910.01108.\nSuchut Sapsathien and Jillaphat Jaroenkantasima. openthaigpt/thai-ocr-evaluation. https:\n//huggingface.co/datasets/openthaigpt/thai-ocr-evaluation, 2024. Available online\nat Hugging Face.\nZhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y.K.\nLi, Y. Wu, and Daya Guo. DeepSeekMath: Pushing the Limits of Mathematical Reasoning\nin Open Language Models, 2024. URL https://arxiv.org/abs/2402.03300.\nZhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Zhengzhong Liu, Hongyi\nWang, Bowen Tan, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing.\nSlimPajama-DC: Understanding Data Combinations for LLM Training, 2024. URL https:\n//arxiv.org/abs/2309.10818.\nAI Singapore. SEA-LION (Southeast Asian Languages In One Network): A Family of Large\nLanguage Models for Southeast Asia. https://github.com/aisingapore/sealion, 2024.\nAmanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi\nParikh, and Marcus Rohrbach. Towards VQA Models That Can Read, 2019. URL https:\n//arxiv.org/abs/1904.08920.\nSharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski,\nAmeya Sunil Mahabaleshwarkar, Gerald Shen, Jiaqi Zeng, Zijia Chen, Yoshi Suhara,\nShizhe Diao, Chenhan Yu, Wei-Chun Chen, Hayley Ross, Oluwatobi Olabiyi, Ashwath\n",
          "Rob Fergus, Yann LeCun, and Saining Xie. Cambrian-1: A Fully Open, Vision-Centric\nExploration of Multimodal LLMs. arXiv preprint arXiv:2406.16860, 2024a.\nYuxuan Tong, Xiwen Zhang, Rui Wang, Ruidong Wu, and Junxian He.\nDART-Math:\nDifficulty-Aware Rejection Tuning for Mathematical Problem-Solving. In The Thirty-\neighth Annual Conference on Neural Information Processing Systems, 2024b. URL https:\n//openreview.net/forum?id=zLU21oQjD5.\nKobkrit Viriyayudhakorn and Charin Polpanumas. iapp_wiki_qa_squad, February 2021.\nURL https://doi.org/10.5281/zenodo.4539916.\nVISTEC. Thai Speech Emotion Dataset, 2021.\n53\n\nTechnical Report\nVISTEC.\nMT-Bench\nThai,\n2024.\nURL\nhttps://huggingface.co/datasets/\nThaiLLM-Leaderboard/mt-bench-thai.\nVistec. airesearch/WangchanThaiInstruct, 2024. URL https://huggingface.co/datasets/\nairesearch/WangchanThaiInstruct.\nChanghan Wang, Anne Wu, Jiatao Gu, and Juan Pino. CoVoST 2 and Massively Mul-\ntilingual Speech Translation.\nIn Proc. Interspeech 2021, pp. 2247–2251, 2021.\ndoi:\n10.21437/Interspeech.2021-2027.\nGuan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, and Yang Liu. OpenChat:\nAdvancing Open-source Language Models with Mixed-Quality Data. In The Twelfth\nInternational Conference on Learning Representations, 2024a. URL https://openreview.net/\nforum?id=AOJyfhWYHf.\nPeng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing\n",
          "Guanzheng Chen, Yue Deng, Sen Yang, Chaoqun Liu, et al. Seallms–large language models for\nsoutheast asia. arXiv preprint arXiv:2312.00738, 2023.\n[32] The National Institute of Educational Testing Service. Basic statistical values of o-net test\nresults. https://www.niets.or.th/th/content/view/11821, 2021.\n[33] Consortium of Thai Medical Schools. Scores report of the tpat1 exam for thai medical schools\nadmission. https://www9.si.mahidol.ac.th/cotmes_stat.html, 2023.\n[34] Council of University Presidents of Thailand. Basic statistical report tgat/tpat examination.\nhttps://www.mytcas.com/stat/, 2023.\n[35] OpenAI. GPT-4 technical report, 2023.\n[36] OpenThaiGPT. Released openthaigpt 7b 1.0.0-beta. https://openthaigpt.aieat.or.th/,\n2023.\n[37] Pedro Javier Ortiz Suárez, Laurent Romary, and Benoît Sagot. A monolingual approach to\ncontextualized word embeddings for mid-resource languages. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics, pages 1703–1714, Online, July 2020.\nAssociation for Computational Linguistics.\n[38] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,\nChong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to\nfollow instructions with human feedback. Advances in Neural Information Processing Systems,\n35:27730–27744, 2022.\n[39] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic\nevaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association\nfor Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA, July 2002.\nAssociation for Computational Linguistics.\n",
          "larger base models such as 34B, 70B, or mixture-of-experts to exploit the emergent ability. Also,\nfuture work will investigate instruction tuning further for an improved alignment.\nAcknowledgements\nWe would like to thank Mukaya Panich, Tanwa Arpornthip, Unnawut Leepaisalsuwanna, and Panuwat\nChayabunjonglerd for their advice on this project. We would like to thank the SCBX R&D team for\ntheir support with the evaluation. We would also like to thank Sarana Nutanong and the NLP team at\nVISTEC for their feedback on the experiments and this technical report.\nReferences\n[1] Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee, Samuel Maina,\nTanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, et al. Mega: Multilingual evaluation\nof generative ai. arXiv preprint arXiv:2303.12528, 2023.\n[2] Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. On the cross-lingual transferability of\nmonolingual representations. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 4623–4637, Online, July 2020. Association for Computational\nLinguistics.\n[3] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy\nLovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. A\nmultitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and\ninteractivity. arXiv preprint arXiv:2302.04023, 2023.\n[4] BIG bench authors. Beyond the imitation game: Quantifying and extrapolating the capabilities\nof language models. Transactions on Machine Learning Research, 2023.\n[5] Abhik Bhattacharjee, Tahmid Hasan, Wasi Uddin Ahmad, Yuan-Fang Li, Yong-Bin Kang,\n",
          "Jiaming Ji, Mickel Liu, Juntao Dai, Xuehai Pan, Chi Zhang, Ce Bian, Chi Zhang, Ruiyang\nSun, Yizhou Wang, and Yaodong Yang. BeaverTails: Towards Improved Safety Alignment\nof LLM via a Human-Preference Dataset, 2023. URL https://arxiv.org/abs/2307.04657.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of Tricks for\nEfficient Text Classification. In Mirella Lapata, Phil Blunsom, and Alexander Koller (eds.),\nProceedings of the 15th Conference of the European Chapter of the Association for Computational\nLinguistics: Volume 2, Short Papers, pp. 427–431, Valencia, Spain, April 2017. Association\nfor Computational Linguistics. URL https://aclanthology.org/E17-2068.\nKushal Kafle, Scott Cohen, Brian Price, and Christopher Kanan. DVQA: Understanding\nData Visualizations via Question Answering. In CVPR, 2018.\nGregory Kamradt. LLMTest - Needle In A Haystack, 2023. URL https://github.com/\ngkamradt/LLMTest_NeedleInAHaystack/blob/main/README.md. GitHub repository.\nAniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, and\nAli Farhadi. A Diagram Is Worth A Dozen Images, 2016.\nChris Dongjoo Kim, Byeongchang Kim, Hyunmin Lee, and Gunhee Kim. AudioCaps:\nGenerating Captions for Audios in The Wild. In NAACL-HLT, 2019.\nJungil Kong, Jaehyeon Kim, and Jaekyoung Bae. Hifi-gan: Generative adversarial networks\nfor efficient and high fidelity speech synthesis. Advances in neural information processing\nsystems, 33:17022–17033, 2020.\nRanjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz,\n",
          "Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui\nMen, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin. Qwen2-VL: Enhancing\nVision-Language Model’s Perception of the World at Any Resolution. arXiv preprint\narXiv:2409.12191, 2024b.\nMaurice Weber, Daniel Y Fu, Quentin Gregory Anthony, Yonatan Oren, Shane Adams,\nAnton Alexandrov, Xiaozhong Lyu, Huu Nguyen, Xiaozhe Yao, Virginia Adams, Ben\nAthiwaratkun, Rahul Chalamala, Kezhen Chen, Max Ryabinin, Tri Dao, Percy Liang,\nChristopher Re, Irina Rish, and Ce Zhang. RedPajama: an Open Dataset for Training Large\nLanguage Models. In The Thirty-eight Conference on Neural Information Processing Systems\nDatasets and Benchmarks Track, 2024. URL https://openreview.net/forum?id=lnuXaRpwvw.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi,\nQuoc Le, and Denny Zhou. Chain-of-Thought Prompting Elicits Reasoning in Large\nLanguage Models, 2023. URL https://arxiv.org/abs/2201.11903.\nYuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. Magicoder: Em-\npowering Code Generation with OSS-Instruct, 2024. URL https://arxiv.org/abs/2312.\n02120.\nSang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy\nLiang, Quoc V Le, Tengyu Ma, and Adams Wei Yu. DoReMi: Optimizing Data Mixtures\nSpeeds Up Language Model Pretraining. In Thirty-seventh Conference on Neural Information\nProcessing Systems, 2023. URL https://openreview.net/forum?id=lXuByUeHhd.\n",
          "and language processing, 29:3451–3460, 2021.\nEdward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,\nLu Wang, and Weizhu Chen. LoRA: Low-Rank Adaptation of Large Language Models.\nIn ICLR, 2022. URL https://openreview.net/forum?id=nZeVKeeFYf9.\nShengran Hu, Cong Lu, and Jeff Clune. Automated Design of Agentic Systems, 2024. URL\nhttps://arxiv.org/abs/2408.08435.\nSiming Huang, Tianhao Cheng, J. K. Liu, Jiaran Hao, Liuyihan Song, Yang Xu, J. Yang, J. H.\nLiu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Zhaoxiang Zhang, Jie Fu, Qian\n49\n\nTechnical Report\nLiu, Ge Zhang, Zili Wang, Yuan Qi, Yinghui Xu, and Wei Chu. OpenCoder: The Open\nCookbook for Top-Tier Code Large Language Models, 2024. URL https://arxiv.org/\nabs/2411.04905.\nWen-Chin Huang, Erica Cooper, Yu Tsao, Hsin-Min Wang, Tomoki Toda, and Junichi\nYamagishi. The VoiceMOS Challenge 2022. Proc. Interspeech 2022, 2022.\nDrew A. Hudson and Christopher D. Manning. GQA: A New Dataset for Real-World Visual\nReasoning and Compositional Question Answering, 2019. URL https://arxiv.org/abs/\n1902.09506.\nHakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao,\nMichael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, and Madian Khabsa. Llama\nGuard: LLM-based Input-Output Safeguard for Human-AI Conversations, 2023. URL\nhttps://arxiv.org/abs/2312.06674.\n",
          "Methods in Natural Language Processing: Industry Track, pp. 477–485, Miami, Florida, US,\nNovember 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.\nemnlp-industry.36. URL https://aclanthology.org/2024.emnlp-industry.36.\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian,\nAhmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy\nYang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie\nSravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien\nRodriguez, Austen Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang,\nBobbie Chern, Charlotte Caucheteux, Chaya Nayak, et al. The Llama 3 Herd of Models,\n2024. URL https://arxiv.org/abs/2407.21783.\nAlex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber. Connectionist\ntemporal classification: labelling unsegmented sequence data with recurrent neural\nnetworks. In Proceedings of the 23rd ICML, pp. 369–376, 2006.\nSuriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno,\nSivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi,\nAdil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan,\nAdam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks Are All You Need, 2023.\nURL https://arxiv.org/abs/2306.11644.\n",
          "Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and\nchatbot arena. arXiv preprint arXiv:2306.05685, 2023.\n12\n\n",
          "Multilingual Expressive and Streaming Speech Translation, 2023.\nAlexis Conneau, Min Ma, Simran Khanuja, Yu Zhang, Vera Axelrod, Siddharth Dalmia,\nJason Riesa, Clara Rivera, and Ankur Bapna. FLEURS: Few-shot Learning Evaluation\nof Universal Representations of Speech. arXiv preprint arXiv:2205.12446, 2022. URL\nhttps://arxiv.org/abs/2205.12446.\nZoltan Csaki, Pian Pawakapan, Urmish Thakker, and Qiantong Xu. Efficiently Adapting\nPretrained Language Models To New Languages, 2023. URL https://arxiv.org/abs/\n2311.05741.\nJosef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu, Mickel Liu, Yizhou Wang, and\nYaodong Yang. Safe RLHF: Safe Reinforcement Learning from Human Feedback, 2023.\nURL https://arxiv.org/abs/2310.12773.\nAlan Dao, Dinh Bach Vu, and Huy Hoang Ha. Ichigo: Mixed-Modal Early-Fusion Realtime\nVoice Assistant. arXiv preprint arXiv:2410.15316, 2024.\nYuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Qiaoming Zhu, and Min Zhang. Unleash-\ning Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch, 2024.\nURL https://arxiv.org/abs/2410.18693.\nGuanting Dong, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, and\nJingren Zhou. Self-play with Execution Feedback: Improving Instruction-following\nCapabilities of Large Language Models, 2024. URL https://arxiv.org/abs/2406.13542.\nLongxu Dou, Qian Liu, Guangtao Zeng, Jia Guo, Jiahui Zhou, Wei Lu, and Min Lin. Sailor:\nOpen Language Models for South-East Asia, 2024. URL https://arxiv.org/abs/2404.\n",
          "Seungju Han, Kavel Rao, Allyson Ettinger, Liwei Jiang, Bill Yuchen Lin, Nathan Lambert,\nYejin Choi, and Nouha Dziri. WildGuard: Open One-Stop Moderation Tools for Safety\nRisks, Jailbreaks, and Refusals of LLMs, 2024. URL https://arxiv.org/abs/2406.18495.\nPengcheng He, Jianfeng Gao, and Weizhu Chen. DeBERTaV3: Improving DeBERTa using\nELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing, 2023. URL\nhttps://arxiv.org/abs/2111.09543.\nWilliam Held, Ella Li, Michael Ryan, Weiyan Shi, Yanzhe Zhang, and Diyi Yang. Dis-\ntilling an end-to-end voice assistant without instruction training data. arXiv preprint\narXiv:2410.02678, 2024.\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn\nSong, and Jacob Steinhardt. Measuring Mathematical Problem Solving With the MATH\nDataset. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and\nBenchmarks Track (Round 2), 2021. URL https://openreview.net/forum?id=7Bywt2mQsCe.\nShawn Hershey, Daniel P W Ellis, Eduardo Fonseca, Aren Jansen, Caroline Liu, R Chan-\nning Moore, and Manoj Plakal. The Benefit of Temporally-Strong Labels in Audio Event\nClassification. In ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP), pp. 366–370, 2021. doi: 10.1109/ICASSP39728.2021.9414579.\nWei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhut-\ndinov, and Abdelrahman Mohamed. Hubert: Self-supervised speech representation\nlearning by masked prediction of hidden units. IEEE/ACM transactions on audio, speech,\n",
          "ACL-IJCNLP 2021, pages 4693–4703, Online, August 2021. Association for Computational\nLinguistics.\n[15] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,\nLu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In\nInternational Conference on Learning Representations, 2022.\n[16] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh\nChaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile\nSaulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.\n[17] Taku Kudo and John Richardson. SentencePiece: A simple and language independent subword\ntokenizer and detokenizer for neural text processing. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language Processing: System Demonstrations, pages 66–71,\nBrussels, Belgium, November 2018. Association for Computational Linguistics.\n[18] Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop,\nVictor Carbune, and Abhinav Rastogi. Rlaif: Scaling reinforcement learning from human\nfeedback with ai feedback. arXiv preprint arXiv:2309.00267, 2023.\n[19] Wei Qi Leong, Jian Gang Ngui, Yosephine Susanto, Hamsawardhini Rengarajan, Kengatharaiyer\nSarveswaran, and William Chandra Tjhi. Bhasa: A holistic southeast asian linguistic and cultural\nevaluation suite for large language models. arXiv preprint arXiv:2309.06085, 2023.\n[20] Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy\nLiang, and Tatsunori B. Hashimoto. Alpacaeval: An automatic evaluator of instruction-following\n",
          "Chen.\nToolACE: Winning the Points of LLM Function Calling, 2024a.\nURL https:\n//arxiv.org/abs/2409.00920.\nYuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike\nYuan, Jiaqi Wang, Conghui He, Ziwei Liu, Kai Chen, and Dahua Lin. MMBench: Is Your\nMulti-modal Model an All-around Player?, 2024b. URL https://arxiv.org/abs/2307.\n06281.\nYuliang Liu, Zhang Li, Mingxin Huang, Biao Yang, Wenwen Yu, Chunyuan Li, Xucheng\nYin, Cheng lin Liu, Lianwen Jin, and Xiang Bai. OCRBench: On the Hidden Mystery of\nOCR in Large Multimodal Models, 2024c. URL https://arxiv.org/abs/2305.07895.\nZuxin Liu, Thai Hoang, Jianguo Zhang, Ming Zhu, Tian Lan, Shirley Kokane, Juntao Tan,\nWeiran Yao, Zhiwei Liu, Yihao Feng, et al. APIGen: Automated Pipeline for Generating\nVerifiable and Diverse Function-Calling Datasets. arXiv preprint arXiv:2406.18518, 2024d.\nZiyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang\nTao, Jing Ma, Qingwei Lin, and Daxin Jiang. WizardCoder: Empowering Code Large\nLanguage Models with Evol-Instruct. In The Twelfth International Conference on Learning\nRepresentations, 2024. URL https://openreview.net/forum?id=UnUwSIgK5W.\nPotsawee Manakul, Guangzhi Sun, Warit Sirichotedumrong, Kasima Tharnpipitchai, and\nKunat Pipatanakul. Enhancing low-resource language and instruction following capabili-\nties of audio language models. arXiv preprint arXiv:2409.10999, 2024.\n",
          "10\n\n[40] Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli,\nHamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb\ndataset for falcon llm: Outperforming curated corpora with web data, and web data only, 2023.\n[41] Ramon Pires, Hugo Abonizio, Thales Rogério, and Rodrigo Nogueira. Sabi\\’a: Portuguese\nlarge language models. arXiv preprint arXiv:2304.07880, 2023.\n[42] Charin Polpanumas, Wannaphong Phatthiyaphaibun, Patomporn Payoungkhamdee, Peerat\nLimkonchotiwat, Lalita Lowphansirikul, Can Udomcharoenchaikit, Titipat Achakulwisut,\nEkapol Chuangsuwanich, and Sarana Nutanong.\nWangChanGLM — The Multilingual\nInstruction-Following Model, April 2023.\n[43] Edoardo Maria Ponti, Goran Glavaš, Olga Majewska, Qianchu Liu, Ivan Vuli´c, and Anna\nKorhonen. XCOPA: A multilingual dataset for causal commonsense reasoning. In Proceedings\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),\npages 2362–2376, Online, November 2020. Association for Computational Linguistics.\n[44] Maja Popovi´c. chrF: character n-gram F-score for automatic MT evaluation. In Proceedings\nof the Tenth Workshop on Statistical Machine Translation, pages 392–395, Lisbon, Portugal,\nSeptember 2015. Association for Computational Linguistics.\n[45] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.\nLanguage models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n[46] Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and\n",
          "Natural Language Processing, pages 9019–9052, Abu Dhabi, United Arab Emirates, December\n2022. Association for Computational Linguistics.\n[24] Adian Liusie, Potsawee Manakul, and Mark J. F. Gales. LLM Comparative Assessment:\nZero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models, 2023.\n[25] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International\nConference on Learning Representations, 2019.\n[26] Lalita Lowphansirikul, Charin Polpanumas, Nawat Jantrakulchai, and Sarana Nutanong.\nWangchanberta:\nPretraining transformer-based thai language models.\narXiv preprint\narXiv:2101.09635, 2021.\n[27] Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, and Yue Zhang. An empirical study of\ncatastrophic forgetting in large language models during continual fine-tuning. arXiv preprint\narXiv:2308.08747, 2023.\n[28] Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary,\nÉric de la Clergerie, Djamé Seddah, and Benoît Sagot. CamemBERT: a tasty French language\nmodel. In Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, pages 7203–7219, Online, July 2020. Association for Computational Linguistics.\n[29] Martin Müller and Florian Laurent. Cedille: A large autoregressive french language model.\narXiv preprint arXiv:2202.03371, 2022.\n[30] Dat Quoc Nguyen and Anh Tuan Nguyen. PhoBERT: Pre-trained language models for Viet-\nnamese. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages\n1037–1042, Online, November 2020. Association for Computational Linguistics.\n[31] Xuan-Phi Nguyen, Wenxuan Zhang, Xin Li, Mahani Aljunied, Qingyu Tan, Liying Cheng,\n",
          "pages 2475–2485, Brussels, Belgium, October-November 2018. Association for Computational\nLinguistics.\n[9] Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick\nWendell, Matei Zaharia, and Reynold Xin. Free dolly: Introducing the world’s first truly open\ninstruction-tuned llm, 2023.\n[10] Marta R Costa-jussa, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin\nHeffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al. No language left\nbehind: Scaling human-centered machine translation. arXiv preprint arXiv:2207.04672, 2022.\n[11] Zoltan Csaki, Pian Pawakapan, Urmish Thakker, and Qiantong Xu.\nEfficiently adapting\npretrained language models to new languages. arXiv preprint arXiv:2311.05741, 2023.\n[12] Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun,\nand Bowen Zhou. Enhancing chat language models by scaling high-quality instructional\nconversations. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the\n2023 Conference on Empirical Methods in Natural Language Processing, pages 3029–3051,\nSingapore, December 2023. Association for Computational Linguistics.\n[13] Common Crawl Foundation. Statistics of common crawl monthly archives by commoncrawl.\nhttps://commoncrawl.github.io/cc-crawl-statistics/plots/languages, 2023.\n[14] Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-\nBin Kang, M. Sohel Rahman, and Rifat Shahriyar. XL-sum: Large-scale multilingual abstractive\nsummarization for 44 languages. In Findings of the Association for Computational Linguistics:\n",
          "Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A. Shamma, Michael S. Bernstein, and\nFei-Fei Li. Visual Genome: Connecting Language and Vision Using Crowdsourced Dense\nImage Annotations, 2016. URL https://arxiv.org/abs/1602.07332.\nNathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze\nBrahman, Lester James V. Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, Yuling Gu, Saumya\nMalik, Victoria Graf, Jena D. Hwang, Jiangjiang Yang, Ronan Le Bras, Oyvind Tafjord,\nChris Wilhelm, Luca Soldaini, Noah A. Smith, Yizhong Wang, Pradeep Dasigi, and\nHannaneh Hajishirzi. Tulu 3: Pushing Frontiers in Open Language Model Post-Training,\n2024. URL https://arxiv.org/abs/2411.15124.\nJeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Yitzhak Gadre, Hritik\nBansal, Etash Kumar Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas\nMuennighoff, Reinhard Heckel, Jean Mercat, Mayee F Chen, Suchin Gururangan, Mitchell\nWortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Kamal Mohamed\nAbbas, et al. DataComp-LM: In search of the next generation of training sets for language\nmodels. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and\nBenchmarks Track, 2024a. URL https://openreview.net/forum?id=CNWdWn47IE.\n50\n\nTechnical Report\nJunnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. BLIP-2: bootstrapping language-\nimage pre-training with frozen image encoders and large language models. In Proceedings\n",
          "with 10,000 Hours of Transcribed Audio. In Proc. Interspeech 2021, 2021a.\nJianlyu Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu.\nM3-\nEmbedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings\nThrough Self-Knowledge Distillation. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar\n(eds.), Findings of the Association for Computational Linguistics: ACL 2024, pp. 2318–2335,\nBangkok, Thailand, August 2024a. Association for Computational Linguistics. URL\nhttps://aclanthology.org/2024.findings-acl.137.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,\nJared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray,\nRaul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin,\nBrooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser,\nMohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, et al. Evaluating Large Language Models\nTrained on Code, 2021b. URL https://arxiv.org/abs/2107.03374.\nSanyuan Chen, Yu Wu, Chengyi Wang, Shujie Liu, Daniel Tompkins, Zhuo Chen, Wanxiang\nChe, Xiangzhan Yu, and Furu Wei. BEATs: audio pre-training with acoustic tokenizers. In\nProceedings of the 40th International Conference on Machine Learning, 2023.\nWilliam Chen, Wangyou Zhang, Yifan Peng, Xinjian Li, Jinchuan Tian, Jiatong Shi, Xuankai\nChang, Soumi Maiti, Karen Livescu, and Shinji Watanabe. Towards Robust Speech\nRepresentation Learning for Thousands of Languages. In Yaser Al-Onaizan, Mohit Bansal,\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_huang_zhao_zhu",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_huang_zhao_zhu"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "M5+jQGJZnUAsIqJA8UykQH/mm0BxLrhAeh2sQNAAsEC3h7NArU69QKgysUC4LaFAbe20QHMmnUDWn51A/LuqQBbzxkBF17lAWqSmQIiJo0CH48BAmnvAQAWps0Cd3pxAjX+cQIuytEDAg5tAk1OaQMjSskBM0sFAjNieQCvcvUCWa8JAUfy/QJXTs0Dr0qVAD4StQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "/khmQXGcaUEKgGZB4jNmQev8aUHUnltB9sRgQQwZYEEpKF5Bn4pWQZmlXkFAN2dBC8RaQbJXaUFunGhBc09hQWsDUkHMVlhBjl1kQWglZUEsAFVB1p1VQSOSYUGGAGpB/OpoQWcLX0G5N2pBDGVoQfHgXEGYmFRBSSpoQeaGVkEuxVVBda5VQaZ5XkFknmVB03FgQQ==",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Fashion-MNIST), while also preserving the local ﬁne structure similar to t-SNE\nand LargeVis.\n29\n\nIt can be argued that UMAP has captured more of the global and topo-\nlogical structure of the datasets than t-SNE [4, 62]. More of the loops in the\nCOIL20 dataset are kept intact, including the intertwined loops. Similarly\nthe global relationships among diﬀerent digits in the MNIST digits dataset\nare more clearly captured with 1 (red) and 0 (dark red) at far corners of\nthe embedding space, and 4,7,9 (yellow, sea-green, and violet) and 3,5,8 (or-\nange, chartreuse, and blue) separated as distinct clumps of similar digits.\nIn the Fashion MNIST dataset the distinction between clothing (dark red,\nyellow, orange, vermilion) and footwear (chartreuse, sea-green, and violet)\nis made more clear. Finally, while both t-SNE and UMAP capture groups of\nsimilar word vectors, the UMAP embedding arguably evidences a clearer\nglobal structure among the various word clusters.\n5.2\nQantitative Comparison of Multiple Algorithms\nWe compare UMAP, t-SNE, LargeVis, Laplacian Eigenmaps and PCA em-\nbeddings with respect to the performance of a k-nearest neighbor clas-\nsiﬁer trained on the embedding space for a variety of datasets. Te k-\nnearest neighbor classiﬁer accuracy provides a clear quantitative measure\nof how well the embedding has preserved the important local structure of\nthe dataset. By varying the hyper-parameter k used in the training we\ncan also consider how structure preservation varies under transition from\npurely local to non-local, to more global structure. Te embeddings used\nfor training the kNN classiﬁer are for those datasets that come with deﬁned\ntraining labels: PenDigits, COIL-20, Shutle, MNIST, and Fashion-MNIST.\nWe divide the datasets into two classes: smaller datasets (PenDigits and\nCOIL-20), for which a smaller range of k values makes sense, and larger\n",
          "For all the datasets except GoogleNews we use Euclidean distance be-\ntween vectors. For GoogleNews, as per [41], we use cosine distance (or\nangular distance in t-SNE which does support non-metric distances, in con-\ntrast to UMAP).\n5.1\nQalitative Comparison of Multiple Algorithms\nWe compare a number of algorithms–UMAP, t-SNE [60, 58], LargeVis [54],\nLaplacian Eigenmaps [7], and Principal Component Analysis [27]–on the\nCOIL20 [43], MNIST [32], Fashion-MNIST [63], and GoogleNews [41] datasets.\nTe Isomap algorithm was also tested, but failed to complete in any reason-\nable time for any of the datasets larger than COIL20.\nTe Multicore t-SNE package [57] was used for t-SNE. Te reference\nimplementation [53] was used for LargeVis. Te scikit-learn [10] imple-\nmentations were used for Laplacian Eigenmaps and PCA. Where possible\nwe atempted to tune parameters for each algorithm to give good embed-\ndings.\nHistorically t-SNE and LargeVis have oﬀered a dramatic improvement\nin ﬁnding and preserving local structure in the data. Tis can be seen qual-\nitatively by comparing their embeddings to those generated by Laplacian\nEigenmaps and PCA in Figure 4. We claim that the quality of embeddings\nproduced by UMAP is comparable to t-SNE when reducing to two or three\ndimensions. For example, Figure 4 shows both UMAP and t-SNE embed-\ndings of the COIL20, MNIST, Fashion MNIST, and Google News datasets.\nWhile the precise embeddings are diﬀerent, UMAP distinguishes the same\nstructures as t-SNE and LargeVis.\n28\n\nFigure 4: A comparison of several dimension reduction algorithms. We note\nthat UMAP successfully reﬂects much of the large scale global structure that is\nwell represented by Laplacian Eigenmaps and PCA (particularly for MNIST and\n",
          "34\n\n(a) UMAP\n(b) t-SNE\nFigure 7: Procrustes based alignment of a 10% subsample (red) against the full\ndataset (blue) for the ﬂow cytometry dataset for both UMAP and t-SNE.\nUMAP and t-SNE, demonstrating how Procrustes distance can measure the\nstability of the overall structure of the embedding.\nGiven a measure of distance between diﬀerent embeddings we can ex-\namine stability under sub-sampling by considering the normalized Pro-\ncrustes distance between the embedding of a sub-sample, and the corre-\nsponding sub-sample of an embedding of the full dataset. As the size of\nthe sub-sample increases the average distance per point between the sub-\nsampled embeddings should decrease, potentially toward some asymptote\nof maximal agreement under repeated runs. Ideally this asymptotic value\nwould be zero error, but for stochastic embeddings such as UMAP and t-\nSNE this is not achievable.\nWe performed an empirical comparison of algorithms with respect to\nstability using the Flow Cytometry dataset due its large size, interesting\nstructure, and low ambient dimensionality (aiding runtime performance\nfor t-SNE). We note that for a dataset this large we found it necessary to\nincrease the default n_iter value for t-SNE from 1000 to 1500 to ensure bet-\nter convergence. While this had an impact on the runtime, it signiﬁcantly\nimproved the Procrustes distance results by providing more stable and con-\nsistent embeddings. Figure 8 provides a comparison between UMAP and\nt-SNE, demonstrating that UMAP has signifcantly more stable results than\n35\n\nt-SNE. In particular, afer sub-sampling on 5% of the million data points, the\nper point error for UMAP was already below any value achieved by t-SNE.\n5.4\nComputational Performance Comparisons\nBenchmarks against the real world datasets were performed on a Macbook\nPro with a 3.1 GHz Intel Core i7 and 8GB of RAM for Table 3, and on a\n",
          "gorithms must share certain fundamental components we believe it to be\nadvantageous for these components to be selected through well grounded\ntheoretical decisions. One of the primary contributions of this paper is to\nreframe the problem of manifold learning and dimension reduction in a dif-\nferent mathematical language allowing pracitioners to apply a new ﬁeld of\nmathemtaics to the problems.\nIn Section 3 we provide a more computational description of UMAP.\nSection 3 should provide readers less familiar with topological data analysis\nwith a beter foundation for understanding the theory described in Section\n2. Appendix C contrasts UMAP against the more familiar algorithms t-SNE\nand LargeVis, describing all these algorithms in similar language. Tis sec-\ntion should assist readers already familiar with those techniques to quickly\ngain an understanding of the UMAP algorithm though they will grant litle\ninsite into its theoretical underpinnings.\nIn Section 4 we discuss implementation details of the UMAP algorithm.\nTis includes a more detailed algorithmic description, and discussion of the\nhyper-parameters involved and their practical eﬀects.\nIn Section 5 we provide practical results on real world datasets as well\nas scaling experiments to demonstrate the algorithm’s performance in real\nworld scenarios as compared with other dimension reduction algorithms.\nIn Section 6 we discuss relative weakenesses of the algorithm, and ap-\nplications for which UMAP may not be the best choice.\nFinally, in Section 7 we detail a number of potential extensions of UMAP\nthat are made possible by its construction upon solid mathematical foun-\ndations. Tese avenues for further development include semi-supervised\nlearning, metric learning and heterogeneous data embedding.\n2\nTeoretical Foundations for UMAP\nTe theoretical foundations for UMAP are largely based in manifold theory\nand topological data analysis. Much of the theory is most easily explained\nin the language of topology and category theory. Readers may consult\n[39], [49] and [40] for background. Readers more interested in practical\ncomputational aspects of the algorithm, and not necessarily the theoretical\nmotivation for the computations involved, may wish to skip this section.\n3\n\nReaders more familiar with traditional machine learning may ﬁnd the re-\n",
          "mization work required will scale with the number of edges in the fuzzy\ngraph (assuming a ﬁxed negative sampling rate), resulting in a complexity\nof O(kN).\nCombining these techniques results in highly eﬃcient embeddings, which\nwe will discuss in Section 5. Te overall complexity is bounded by the ap-\nproximate nearest neighbor search complexity and, as mentioned above, is\nempirically approximately O(N1.14). A reference implementation can be\nfound at https://github.com/lmcinnes/umap, and an R implementa-\ntion can be found at https://github.com/jlmelville/uwot.\nFor simplicity these experiments were carried out on a single core ver-\nsion of our algorithm. It should be noted that at the time of this publication\nthat both Nearest-Neighbour-Descent and SGD have been parallelized and\nthus the python reference implementation can be signiﬁcantly accelerated.\nOur intention in this paper was to introduce the underlying theory behind\nour UMAP algorithm and we felt that parallel vs single core discussions\nwould distract from our intent.\n4.3\nHyper-parameters\nAs described in Algorithm 1, the UMAP algorithm takes four hyper-parameters:\n1. n, the number of neighbors to consider when approximating the local\nmetric;\n2. d, the target embedding dimension;\n3. min-dist, the desired separation between close points in the embed-\nding space; and\n22\n\n4. n-epochs, the number of training epochs to use when optimizing the\nlow dimensional representation.\nTe eﬀects of the parameters d and n-epochs are largely self-evident, and\nwill not be discussed in further detail here. In contrast the eﬀects of the\nnumber of neighbors n and of min-dist are less clear.\nOne can interpret the number of neighbors n as the local scale at which\nto approximate the manifold as roughly ﬂat, with the manifold estimation\naveraging over the n neighbors. Manifold features that occur at a smaller\nscale than within the n nearest-neighbors of points will be lost, while large\nscale manifold features that cannot be seen by patching together locally ﬂat\n",
          "UMAP: Uniform Manifold\nApproximation and Projection for\nDimension Reduction\nLeland McInnes\nTute Institute for Mathematics and Computing\nleland.mcinnes@gmail.com\nJohn Healy\nTute Institute for Mathematics and Computing\njchealy@gmail.com\nJames Melville\njlmelville@gmail.com\nSeptember 21, 2020\nAbstract\nUMAP (Uniform Manifold Approximation and Projection) is a novel\nmanifold learning technique for dimension reduction. UMAP is constructed\nfrom a theoretical framework based in Riemannian geometry and algebraic\ntopology. Te result is a practical scalable algorithm that is applicable to\nreal world data. Te UMAP algorithm is competitive with t-SNE for visu-\nalization quality, and arguably preserves more of the global structure with\nsuperior run time performance. Furthermore, UMAP has no computational\nrestrictions on embedding dimension, making it viable as a general purpose\ndimension reduction technique for machine learning.\n1\nIntroduction\nDimension reduction plays an important role in data science, being a funda-\nmental technique in both visualisation and as pre-processing for machine\n1\narXiv:1802.03426v3  [stat.ML]  18 Sep 2020\n\nlearning. Dimension reduction techniques are being applied in a broaden-\ning range of ﬁelds and on ever increasing sizes of datasets. It is thus desir-\nable to have an algorithm that is both scalable to massive data and able to\ncope with the diversity of data available. Dimension reduction algorithms\ntend to fall into two categories; those that seek to preserve the pairwise\ndistance structure amongst all the data samples and those that favor the\npreservation of local distances over global distance. Algorithms such as\nPCA [27], MDS [30], and Sammon mapping [50] fall into the former cate-\ngory while t-SNE [59, 58], Isomap [56], LargeVis [54], Laplacian eigenmaps\n[6, 7] and diﬀusion maps [16] all fall into the later category.\nIn this paper we introduce a novel manifold learning technique for di-\nmension reduction. We provide a sound mathematical theory grounding\nthe technique and a practical scalable algorithm that applies to real world\n",
          "sampled or had their dimension reduced by PCA. Te Flow Cytometry dataset\nwas benchmarked on a 10% sample and the GoogleNews was subsampled down\nto 200,000 data points. Finally, the Mouse scRNA dataset was reduced to 1,000\ndimensions via PCA. Te fastest runtime for each dataset has been bolded.\n38\n\n5.4.1\nScaling with Embedding Dimension\nUMAP is signiﬁcantly more performant than t-SNE4 when embedding into\ndimensions larger than 2. Tis is particularly important when the intention\nis to use the low dimensional representation for further machine learning\ntasks such as clustering or anomaly detection rather than merely for visu-\nalization. Te computation performance of UMAP is far more eﬃcient than\nt-SNE, even for very small embedding dimensions of 6 or 8 (see Figure 9).\nTis is largely due to the fact that UMAP does not require global normali-\nsation (since it represents data as a fuzzy topological structure rather than\nas a probability distribution). Tis allows the algorithm to work without\nthe need for space trees —such as the quad-trees and oct-trees that t-SNE\nuses [58]—. Such space trees scale exponentially in dimension, resulting\nin t-SNE’s relatively poor scaling with respect to embedding dimension.\nBy contrast, we see that UMAP consistently scales well in embedding di-\nmension, making the algorithm practical for a wider range of applications\nbeyond visualization.\n5.4.2\nScaling with Ambient Dimension\nTrough a combination of the local-connectivity constraint and the approx-\nimate nearest neighbor search, UMAP can perform eﬀective dimension re-\nduction even for very high dimensional data (see Figure 13 for an example\nof UMAP operating directly on 1.8 million dimensional data). Tis stands in\ncontrast to many other manifold learning techniques, including t-SNE and\nLargeVis, for which it is generally recommended to reduce the dimension\nwith PCA before applying these techniques (see [59] for example).\nTo compare runtime performance scaling with respect to the ambient\ndimension of the data we chose to use the Mouse scRNA dataset, which\n",
          "should be noted that these techniques are more computationally intensive\nand thus rely on landmarking approaches for scalability.\nIt should also be noted that a signiﬁcant contributor to UMAP’s relative\nglobal structure preservation is derived from the Laplacian Eigenmaps ini-\ntialization (which, in turn, followed from the theoretical foundations). Tis\nwas noted in, for example, [29]. Te authors of that paper demonstrate\nthat t-SNE, with similar initialization, can perform equivalently to UMAP\nin a particular measure of global structure preservation. However, the ob-\njective function derived for UMAP (cross-entropy) is signiﬁcantly diﬀerent\nfrom that of t-SNE (KL-divergence), in how it penalizes failures to preserve\nnon-local and global structure, and is also a signiﬁcant contributor6.\nIt is worth noting that, in combining the local simplicial set structures,\npure nearest neighbor structure in the high dimensional space is not ex-\nplicitly preserved. In particular it introduces so called ”reverse-nearest-\nneighbors” into the classical knn-graph. Tis, combined with the fact that\nUMAP is preserving topology rather than pure metric structures, mean that\nUMAP will not perform as well as some methods on quality measures based\non metric structure preservation – particularly methods, such as MDS –\nwhich are explicitly designed to optimize metric structure preservation.\nUMAP atempts to discover a manifold on which your data is uniformly\ndistributed. If you have strong conﬁdence in the ambient distances of your\ndata you should make use of a technique that explicitly atempts to preserve\nthese distances. For example if your data consisted of a very loose structure\nin one area of your ambient space and a very dense structure in another\nregion region UMAP would atempt to put these local areas on an even\nfooting.\nFinally, to improve the computational eﬃciency of the algorithm a num-\nber of approximations are made. Tis can have an impact on the results\nof UMAP for small (less than 500 samples) dataset sizes. In particular the\nuse of approximate nearest neighbor algorithms, and the negative sampling\n",
          "datasets, for which much larger values of k are reasonable. For each of\nthe small datasets a stratiﬁed 10-fold cross-validation was used to derive\na set of 10 accuracy scores for each embedding. For the Shutle dataset a\n10-fold cross-validation was used due to constraints imposed by class sizes\nand the stratiﬁed sampling. For MNIST and Fashion-MNIST a 20-fold cross\nvalidation was used, producing 20 accuracy scores.\nIn Table 1 we present the average accuracy across the 10-folds for the\nPenDigits and COIL-20 datasets. UMAP performs at least as well as t-SNE\nand LargeVis (given the conﬁdence bounds on the accuracy) for k in the\nrange 10 to 40, but for larger k values of 80 and 160 UMAP has signiﬁcantly\nhigher accuracy on COIL-20, and shows evidence of higher accuracy on\nPenDigits. Figure 5 provides swarm plots of the accuracy results across the\nCOIL-20 and PenDigits datasets.\n30\n\nIn Table 2 we present the average cross validation accuracy for the Shut-\ntle, MNIST and Fashion-MNIST datasets. UMAP performs at least as well\nas t-SNE and LargeVis (given the conﬁdence bounds on the accuracy) for k\nin the range 100 to 400 on the Shutle and MNIST datasets (but notably un-\nderperforms on the Fashion-MNIST dataset), but for larger k values of 800\nand 3200 UMAP has signiﬁcantly higher accuracy on the Shutle dataset,\nand shows evidence of higher accuracy on MNIST. For k values of 1600 and\n3200 UMAP establishes comparable performance on Fashion-MNIST. Fig-\nure 6 provides swarm plots of the accuracy results across the Shutle and\nMNIST and Fashion-MNIST datasets.\nk\nt-SNE\nUMAP\nLargeVis\nEigenmaps\nPCA\nCOIL-20\n10\n0.934 (± 0.115)\n0.921 (± 0.075)\n0.888 (± 0.092)\n0.629 (± 0.153)\n0.667 (± 0.179)\n",
          "server with Intel Xeon E5-2697v4 processors and 512GB of RAM for the\nlarge scale benchmarking in Subsections 5.4.1, 5.4.2, and 5.4.3.\nFor t-SNE we chose MulticoreTSNE [57], which we believe to be the\nfastest extant implementation of Barnes-Hut t-SNE at this time, even when\nrun in single core mode. It should be noted that MulticoreTSNE is a heav-\nily optimized implementation writen in C++ based on Van der Maaten’s\nbhtsne [58] code.\nAs a fast alternative approach to t-SNE we also consider the FIt-SNE\nalgorithm [37]. We used the reference implementation [36], which, like\nMulticoreTNSE is an optimized C++ implementation. We also note that\nFIt-SNE makes use of multiple cores.\nLargeVis [54] was benchmarked using the reference implementation\n[53]. It was run with default parameters including use of 8 threads on the 4-\ncore machine. Te only exceptions were small datasets where we explicitly\nset the -samples parameter to n_samples/100 as per the recommended\nvalues in the documentation of the reference implementation.\nTe Isomap [55] and Laplacian Eigenmaps [7] implementations in scikit-\nlearn [10] were used. We suspect the Laplacian eigenmaps implementation\nmay not be well optimized for large datasets but did not ﬁnd a beter per-\nforming implementation that provided comparable quality results. Isomap\nfailed to complete for the Shutle, Fashion-MNIST, MNIST and Google-\nNews datasets, while Laplacian Eigenmaps failed to run for the Google-\nNews dataset.\nTo allow a broader range of algorithms to run some of the datasets\nwhere subsampled or had their dimension reduced by PCA. Te Flow Cy-\ntometry dataset was benchmarked on a 10% sample and the GoogleNews\nwas subsampled down to 200,000 data points. Finally, the Mouse scRNA\ndataset was reduced to 1,000 dimensions via PCA.\nTiming were performed for the COIL20 [43], COIL100 [44], Shutle [35],\n",
          "data. UMAP (Uniform Manifold Approximation and Projection) builds upon\nmathematical foundations related to the work of Belkin and Niyogi on\nLaplacian eigenmaps. We seek to address the issue of uniform data distri-\nbutions on manifolds through a combination of Riemannian geometry and\nthe work of David Spivak [52] in category theoretic approaches to geomet-\nric realization of fuzzy simplicial sets. t-SNE is the current state-of-the-art\nfor dimension reduction for visualization. Our algorithm is competitive\nwith t-SNE for visualization quality and arguably preserves more of the\nglobal structure with superior run time performance. Furthermore the al-\ngorithm is able to scale to signiﬁcantly larger data set sizes than are feasible\nfor t-SNE. Finally, UMAP has no computational restrictions on embedding\ndimension, making it viable as a general purpose dimension reduction tech-\nnique for machine learning.\nBased upon preliminary releases of a sofware implementation, UMAP\nhas already found widespread use in the ﬁelds of bioinformatics [5, 12, 17,\n46, 2, 45, 15], materials science [34, 23], and machine learning [14, 20, 21,\n24, 19, 47] among others.\nTis paper is laid out as follows. In Section 2 we describe the theory un-\nderlying the algorithm. Section 2 is necessary to understand both the the-\nory underlying why UMAP works and the motivation for the choices that\nwhere made in developing the algorithm. A reader without a background\n(or interest) in topological data analysis, category theory or the theoretical\nunderpinnings of UMAP should skip over this section and proceed directly\nto Section 3.\nTat being said, we feel that strong theory and mathematically justiﬁed\nalgorithmic decisions are of particular importance in the ﬁeld of unsuper-\nvised learning. Tis is, at least partially, due to plethora of proposed objec-\n2\n\ntive functions within the area. We atempt to highlight in this paper that\nUMAPs design decisions were all grounded in a solid theoretic foundation\nand not derived through experimentation with any particular task focused\nobjective function. Tough all neighbourhood based manifold learning al-\n",
          "the pre-processing, is a signiﬁcant advantage. Tis advantage comes from\nthe local connectivity assumption which ensures good topological repre-\nsentation of high dimensional data, particularly with smaller numbers of\nnear neighbors, and the eﬃciency of the NN-Descent algorithm for approx-\nimate nearest neighbor search even in high dimensions.\nSince UMAP scales well with ambient dimension the python implemen-\ntation also supports input in sparse matrix format, allowing scaling to ex-\ntremely high dimensional data, such as the integer data shown in Figures\n13 and 14.\n5.4.3\nScaling with the Number of Samples\nFor dataset size performance comparisons we chose to compare UMAP with\nFIt-SNE [37], a version of t-SNE that uses approximate nearest neighbor\nsearch and a Fourier interpolation optimisation approach; MulticoreTSNE\n[57], which we believe to be the fastest extant implementation of Barnes-\nHut t-SNE; and LargeVis [54]. It should be noted that FIt-SNE, MulticoreT-\nSNE, and LargeVis are all heavily optimized implementations writen in\nC++. In contrast our UMAP implementation was writen in Python — mak-\ning use of the numba [31] library for performance. MulticoreTSNE and\nLargeVis were run in single threaded mode to make fair comparisons to\nour single threaded UMAP implementation.\nWe benchmarked all four implementations using subsamples of the Google-\nNews dataset. Te results can be seen in Figure 11. Tis demonstrates that\nUMAP has superior scaling performance in comparison to Barnes-Hut t-\nSNE, even when Barnes-Hut t-SNE is given multiple cores. Asymptotic\nscaling of UMAP is comparable to that of FIt-SNE (and LargeVis). On this\ndataset UMAP demonstrated somewhat faster absolute performance com-\npared to FIt-SNE, and was dramatically faster than LargeVis.\nTe UMAP embedding of the full GoogleNews dataset of 3 million word\nvectors, as seen in Figure 12, was completed in around 200 minutes, as com-\npared with several days required for MulticoreTSNE, even using multiple\n",
          "used in optimization, can result in suboptimal embeddings. For this reason\n6Te authors would like to thank Nikolay Oskolkov for his article (tSNE vs. UMAP: Global\nStructure) which does an excellent job of highlighting these aspects from an empirical and the-\noretical basis.\n49\n\nwe encourage users to take care with particularly small datasets. A slower\nbut exact implementation of UMAP for small datasets is a future project.\n7\nFuture Work\nHaving established both relevant mathematical theory and a concrete im-\nplementation, there still remains signiﬁcant scope for future developments\nof UMAP.\nA comprehensive empirical study which examines the impact of the\nvarious algorithmic components, choices, and hyper-parameters of the al-\ngorithm would be beneﬁcial. While the structure and choices of the algo-\nrithm presented were derived from our foundational mathematical frame-\nwork, examining the impacts that these choices have on practical results\nwould be enlightening and a signiﬁcant contribution to the literature.\nAs noted in the weaknesses section there is a great deal of uncertainty\nsurrounding the preservation of global structure among the ﬁeld of man-\nifold learning algorithms. In particular this is hampered by the lack clear\nobjective measures, or even deﬁnitions, of global structure preservation.\nWhile some metrics exist, they are not comprehensive, and are ofen spe-\nciﬁc to various downstream tasks. A systematic study of both metrics of\nnon-local and global structure preservation, and performance of various\nmanifold learning algorithms with respect to them, would be of great ben-\neﬁt. We believe this would aid in beter understanding UMAP’s success in\nvarious downstream tasks.\nMaking use of the fuzzy simplicial set representation of data UMAP can\npotentially be extended to support (semi-)supervised dimension reduction,\nand dimension reduction for datasets with heterogeneous data types. Each\ndata type (or prediction variables in the supervised case) can be seen as an\nalternative view of the underlying structure, each with a diﬀerent associ-\nated metric – for example categorical data may use Jaccard or Dice distance,\nwhile ordinal data might use Manhatan distance. Each view and metric can\n",
          "of factor loadings that linear techniques such as PCA, or Factor Analysis\ncan provide. If strong interpretability is critical we therefore recommend\nlinear techniques such as PCA, NMF or pLSA.\nOne of the core assumptions of UMAP is that there exists manifold\nstructure in the data. Because of this UMAP can tend to ﬁnd manifold\nstructure within the noise of a dataset – similar to the way the human mind\nﬁnds structured constellations among the stars. As more data is sampled\nthe amount of structure evident from noise will tend to decrease and UMAP\nbecomes more robust, however care must be taken with small sample sizes\nof noisy data, or data with only large scale manifold structure. Detecting\nwhen a spurious embedding has occurred is a topic of further research.\nUMAP is derived from the axiom that local distance is of more im-\nportance than long range distances (similar to techniques like t-SNE and\nLargeVis). UMAP therefore concerns itself primarily with accurately rep-\nresenting local structure. While we believe that UMAP can capture more\nglobal structure than these other techniques, it remains true that if global\n45\n\nFigure 13: Visualization of 30,000,000 integers as represented by binary vectors\nof prime divisibility, colored by density of points.\n46\n\nFigure 14: Visualization of 30,000,000 integers as represented by binary vectors\nof prime divisibility, colored by integer value of the point (larger values are green\nor yellow, smaller values are blue or purple).\n47\n\n(a) Upper right spiral\n(b) Lower right spiral and starbursts\n(c) Central cloud\nFigure 15: Zooming in on various regions of the integer embedding reveals fur-\nther layers of ﬁne structure have been preserved.\n48\n\nstructure is of primary interest then UMAP may not be the best choice for\ndimension reduction. Multi-dimensional scaling speciﬁcally seeks to pre-\nserve the full distance matrix of the data, and as such is a good candidate\nwhen all scales of structure are of equal importance. PHATE [42] is a good\nexample of a hybrid approach that begins with local structure information\nand makes use of MDS to atempt to preserve long scale distances as well. It\n",
          "theory, of representing a manifold as a k-neighbour graph.\n13\n\nAs highlighted in Appendix C any algorithm that atempts to use a\nmathematical structure akin to a k-neighbour graph to approximate a man-\nifold must follow a similar basic structure.\n• Graph Construction\n1. Construct a weighted k-neighbour graph\n2. Apply some transform on the edges to ambient local distance.\n3. Deal with the inherent asymmetry of the k-neighbour graph.\n• Graph Layout\n1. Deﬁne an objective function that preserves desired characteris-\ntics of this k-neighbour graph.\n2. Find a low dimensional representation which optimizes this ob-\njective function.\nMany dimension reduction algorithms can be broken down into these\nsteps because they are fundamental to a particular class of solutions. Choices\nfor each step must be either chosen through task oriented experimentation\nor by selecting a set of believable axioms and building strong theoretical\narguments from these. Our belief is that basing our decisions on a strong\nfoundational theory will allow for a more extensible and generalizable al-\ngorithm in the long run.\nWe theoretically justify using the choice of using a k-neighbour graph\nto represent a manifold in Section 2.1. Te choices for our kernel transform\nan symmetrization function can be found in Section 2.2. Finally, the justiﬁ-\ncations underlying our choices for our graph layout are outlined in Section\n2.3.\n3.1\nGraph Construction\nTe ﬁrst phase of UMAP can be thought of as the construction of a weighted\nk-neighbour graph. Let X = {x1, . . . , xN} be the input dataset, with a\nmetric (or dissimilarity measure) d : X ×X →R≥0. Given an input hyper-\nparameter k, for each xi we compute the set {xi1, . . . , xik} of the k nearest\nneighbors of xi under the metric d. Tis computation can be performed via\nany nearest neighbour or approximate nearest neighbour search algorithm.\nFor the purposes of our UMAP implemenation we prefer to use the nearest\nneighbor descent algorithm of [18].\n",
          "charts at the scale of n nearest-neighbors may not be well detected. Tus\nn represents some degree of trade-oﬀbetween ﬁne grained and large scale\nmanifold features — smaller values will ensure detailed manifold structure\nis accurately captured (at a loss of the “big picture” view of the manifold),\nwhile larger values will capture large scale manifold structures, but at a loss\nof ﬁne detail structure which will get averaged out in the local approxima-\ntions. With smaller n values the manifold tends to be broken into many\nsmall connected components (care needs to be taken with the spectral em-\nbedding for initialization in such cases).\nIn contrast min-dist is a hyperparameter directly aﬀecting the output,\nas it controls the fuzzy simplicial set construction from the low dimensional\nrepresentation. It acts in lieu of the distance to the nearest neighbor used\nto ensure local connectivity. In essence this determines how closely points\ncan be packed together in the low dimensional representation. Low values\non min-dist will result in potentially densely packed regions, but will likely\nmore faithfully represent the manifold structure. Increasing the value of\nmin-dist will force the embedding to spread points out more, assisting vi-\nsualization (and avoiding potential overploting issues). We view min-dist\nas an essentially aesthetic parameter, governing the appearance of the em-\nbedding, and thus is more important when using UMAP for visualization.\nIn Figure 1 we provide examples of the eﬀects of varying the hyper-\nparameters for a toy dataset. Te data is uniform random samples from a\n3-dimensional color-cube, allowing for easy visualization of the original 3-\ndimensional coordinates in the embedding space by using the correspond-\ning RGB colour. Since the data ﬁlls a 3-dimensional cube there is no local\nmanifold structure, and hence for such data we expect larger n values to be\nmore useful. Low values will interpret the noise from random sampling as\nﬁne scale manifold structure, producing potentially spurious structure1.\n1See the discussion of the constellation eﬀect in Section 6\n23\n\nFigure 1: Variation of UMAP hyperparameters n and min-dist result in diﬀerent\n",
          "128x128 intensity matrices (one for each color channel). We treat this as\na single 49152 dimensional vector for the purposes of computing distance\nbetween images.\nMouse scRNA-seq [11] is proﬁled gene expression data for 20,921 cells\nfrom an adult mouse. Each sample consists of a vector of 26,774 measure-\nments.\nStatlog (Shuttle) [35] is a NASA dataset consisting of various data associ-\nated to the positions of radiators in the space shutle, including a timestamp.\n2See Section 5 for a description of the PenDigits dataset\n3See section 5 for details on the MNIST dataset\n25\n\nFigure 2: Variation of UMAP hyperparameters n and min-dist result in diﬀer-\nent embeddings. Te data is the PenDigits dataset, where each point is an 8x8\ngrayscale image of a hand-writen digit.\n26\n\nFigure 3: Variation of UMAP hyperparameters n and min-dist result in diﬀer-\nent embeddings. Te data is the MNIST dataset, where each point is an 28x28\ngrayscale image of a hand-writen digit.\n27\n\nTe dataset has 58000 points in a 9 dimensional feature space.\nMNIST [32] is a dataset of 28x28 pixel grayscale images of handwriten\ndigits. Tere are 10 digit classes (0 through 9) and 70000 total images. Tis\nis treated as 70000 diﬀerent 784 dimensional vectors.\nF-MNIST [63] or Fashion MNIST is a dataset of 28x28 pixel grayscale im-\nages of fashion items (clothing, footwear and bags). Tere are 10 classes\nand 70000 total images. As with MNIST this is treated as 70000 diﬀerent\n784 dimensional vectors.\nFlow cytometry [51, 9] is a dataset of ﬂow cytometry measurements of\nCDT4 cells comprised of 1,000,000 samples, each with 17 measurements.\nGoogleNews word vectors [41] is a dataset of 3 million words and phrases\nderived from a sample of Google News documents and embedded into a 300\ndimensional space via word2vec.\n",
          "embeddings. Te data is uniform random samples from a 3-dimensional color-\ncube, allowing for easy visualization of the original 3-dimensional coordinates\nin the embedding space by using the corresponding RGB colour. Low values of\nn spuriously interpret structure from the random sampling noise – see Section 6\nfor further discussion of this phenomena.\n24\n\nIn Figure 2 we provides examples of the same hyperparamter choices\nas Figure 1, but for the PenDigits dataset2. In this case we expect small\nto medium n values to be most eﬀective, since there is signiﬁcant cluster\nstructure naturally present in the data. Te min-dist parameter expands out\ntightly clustered groups, allowing more of the internal structure of densely\npacked clusters to be seen.\nFinally, in Figure 3 we provide an equivalent example of hyperparame-\nter choices for the MNIST dataset3. Again, since this dataset is expected to\nhave signifcant cluster structure we expect medium sized values of n to be\nmost eﬀective. We note that large values of min-dist result in the distinct\nclusters being compressed together, making the distinctions between the\nclusters less clear.\n5\nPractical Eﬃcacy\nWhile the strong mathematical foundations of UMAP were the motivation\nfor its development, the algorithm must ultimately be judged by its prac-\ntical eﬃcacy. In this section we examine the ﬁdelity and performance of\nlow dimensional embeddings of multiple diverse real world data sets under\nUMAP. Te following datasets were considered:\nPen digits [1, 10] is a set of 1797 grayscale images of digits entered using\na digitiser tablet. Each image is an 8x8 image which we treat as a single 64\ndimensional vector, assumed to be in Euclidean vector space.\nCOIL 20 [43] is a set of 1440 greyscale images consisting of 20 objects un-\nder 72 diﬀerent rotations spanning 360 degrees. Each image is a 128x128\nimage which we treat as a single 16384 dimensional vector for the purposes\nof computing distance between images.\nCOIL 100 [44] is a set of 7200 colour images consisting of 100 objects un-\nder 72 diﬀerent rotations spanning 360 degrees. Each image consists of 3\n",
          "from a practical point of view, a less theoretical and more computational\ndescription may be helpful for the reader. Tis description of the algorithm\nlacks the motivation for a number of the choices made. For that motivation\nplease see Section 2.\nTe theoretical description of the algorithm works in terms of fuzzy\nsimplicial sets. Computationally this is only tractable for the one skeleton\nwhich can ultimately be described as a weighted graph. Tis means that,\nfrom a practical computational perspective, UMAP can ultimately be de-\nscribed in terms of, construction of, and operations on, weighted graphs.\nIn particular this situates UMAP in the class of k-neighbour based graph\nlearning algorithms such as Laplacian Eigenmaps, Isomap and t-SNE.\nAs with other k-neighbour graph based algorithms, UMAP can be de-\nscribed in two phases. In the ﬁrst phase a particular weighted k-neighbour\ngraph is constructed. In the second phase a low dimensional layout of this\ngraph is computed. Te diﬀerences between all algorithms in this class\namount to speciﬁc details in how the graph is constructed and how the\nlayout is computed. Te theoretical basis for UMAP as described in Section\n2 provides novel approaches to both of these phases, and provides clear\nmotivation for the choices involved.\nFinally, since t-SNE is not usually described as a graph based algorithm,\na direct comparison of UMAP with t-SNE, using the similarity/probability\nnotation commonly used to express the equations of t-SNE, is given in the\nAppendix C.\nIn section 2 we made a few basic assumptions about our data. From\nthese assumptions we made use of category theory to derive the UMAP\nalgorithms. Tat said, all these derivations assume these axioms to be true.\n1. Tere exists a manifold on which the data would be uniformly dis-\ntributed.\n2. Te underlying manifold of interest is locally connected.\n3. Preserving the topological structure of this manifold is the primary\ngoal.\nTe topological theory of Section 2 is driven by these axioms, particularly\nthe interest in modelling and preserving topological structure. In particular\nSection 2.1 highlights the underlying motivation, in terms of topological\n",
          "is high dimensional, but is also amenable to the use of PCA to reduce the\ndimension of the data as a pre-processing step without losing too much\nof the important structure5. We compare the performance of UMAP, FIt-\nSNE, MulticoreTSNE, and LargeVis on PCA reductions of the Mouse scRNA\ndataset to varying dimensionalities, and on the original dataset, in Figure\n10.\nWhile all the implementations tested show a signiﬁcant increase in run-\ntime with increasing dimension, UMAP is dramatically more eﬃcient for\n4Comparisons were performed against MulticoreTSNE as the current implementation of FIt-\nSNE does not support embedding into any dimension larger than 2.\n5In contrast to COIL100, on which PCA destroys much of the manifold structure\n39\n\n(a) A comparison of run time for UMAP,\nt-SNE and LargeVis with respect to em-\nbedding dimension on the Pen digits\ndataset. We see that t-SNE scales worse\nthan exponentially while UMAP and\nLargeVis scale linearly with a slope so\nslight to be undetectable at this scale.\n(b) Detail of scaling for embedding di-\nmension of six or less. We can see that\nUMAP and LargeVis are essentially ﬂat.\nIn practice they appear to scale linearly,\nbut the slope is essentially undetectable\nat this scale.\nFigure 9: Scaling performance with respect to embedding dimension of UMAP,\nt-SNE and LargeVis on the Pen digits dataset.\n40\n\nFigure 10: Runtime performance scaling of UMAP, t-SNE, FIt-SNE and Largevis\nwith respect to the ambient dimension of the data. As the ambient dimension\nincreases beyond a few thousand dimensions the computational cost of t-SNE,\nFIt-SNE, and LargeVis all increase dramatically, while UMAP continues to per-\nform well into the tens-of-thousands of dimensions.\n41\n\nlarge ambient dimensions, easily scaling to run on the original unreduced\ndataset. Te ability to run manifold learning on raw source data, rather than\ndimension reduced data that may have lost important manifold structure in\n",
          "be used to independently generate fuzzy simplicial sets, which can then be\nintersected together to create a single fuzzy simplicial set for embedding.\nExtending UMAP to work with mixed data types would vastly increase the\nrange of datasets to which it can be applied. Use cases for (semi-)supervised\ndimension reduction include semi-supervised clustering, and interactive la-\nbelling tools.\nTe computational framework established for UMAP allows for the po-\ntential development of techniques to add new unseen data points into an\n50\n\nexisting embedding, and to generate high dimensional representations of\narbitrary points in the embedded space. Furthermore, the combination of\nsupervision and the addition of new samples to an existing embedding pro-\nvides avenues for metric learning. Te addition of new samples to an ex-\nisting embedding would allow UMAP to be used as a feature engineering\ntool as part of a general machine learning pipeline for either clustering or\nclassiﬁcation tasks. Pulling points back to the original high dimensional\nspace from the embedded space would potentially allow UMAP to be used\nas a generative model similar to some use cases for autoencoders. Finally,\nthere are many use cases for metric learning; see [64] or [8] for example.\nTere also remains signiﬁcant scope to develop techniques to both de-\ntect and mitigate against potentially spurious embeddings, particularly for\nsmall data cases. Te addition of such techniques would make UMAP far\nmore robust as a tool for exploratory data analysis, a common use case\nwhen reducing to two dimensions for visualization purposes.\nExperimental versions of some of this work are already available in the\nreferenced implementations.\n8\nConclusions\nWe have developed a general purpose dimension reduction technique that\nis grounded in strong mathematical foundations. Te algorithm imple-\nmenting this technique is demonstrably faster than t-SNE and provides\nbeter scaling. Tis allows us to generate high quality embeddings of larger\ndata sets than had previously been atainable. Te use and eﬀectiveness\nof UMAP in various scientiﬁc ﬁelds demonstrates the strength of the algo-\nrithm.\nAcknowledgements\nTe authors would like to thank Colin Weir, Rick\n",
          "cores.\nTo scale even further we were inspired by the work of John Williamson\non embedding integers [61], as represented by (sparse) binary vectors of\ntheir prime divisibility. Tis allows the generation of arbitrarily large, ex-\ntremely high dimension datasets that still have meaningful structure to be\n42\n\nFigure 11: Runtime performance scaling of t-SNE and UMAP on various sized\nsub-samples of the full Google News dataset. Te lower t-SNE line is the wall\nclock runtime for Multicore t-SNE using 8 cores.\n43\n\nFigure 12: Visualization of the full 3 million word vectors from the GoogleNews\ndataset as embedded by UMAP.\n44\n\nexplored. In Figures 13 and 14 we show an embedding of 30,000,000 data\nsamples from an ambient space of approximately 1.8 million dimensions.\nTis computation took approximately 2 weeks on a large memory SMP.\nNote that despite the high ambient dimension, and vast amount of data,\nUMAP is still able to ﬁnd and display interesting structure. In Figure 15 we\nshow local regions of the embedding, demonstrating the ﬁne detail struc-\nture that was captured.\n6\nWeaknesses\nWhile we believe UMAP to be a very eﬀective algorithm for both visualiza-\ntion and dimension reduction, most algorithms must make trade-oﬀs and\nUMAP is no exception. In this section we will brieﬂy discuss those areas or\nuse cases where UMAP is less eﬀective, and suggest potential alternatives.\nFor a number of use cases the interpretability of the reduced dimension\nresults is of critical importance. Similarly to most non-linear dimension re-\nduction techniques (including t-SNE and Isomap), UMAP lacks the strong\ninterpretability of Principal Component Analysis (PCA) and related tech-\nniques such a Non-Negative Matrix Factorization (NMF). In particular the\ndimensions of the UMAP embedding space have no speciﬁc meaning, un-\nlike PCA where the dimensions are the directions of greatest variance in\nthe source data. Furthermore, since UMAP is based on the distance between\nobservations rather than the source features, it does not have an equivalent\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_as_of_the",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_as_of_the"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "gM0uQRlnLkGXoitBzDsmQSnTKEEo2SlBmjUrQej1JUHtGjBBEIouQbopKEGjhSxBTb8lQS9QJkFdKilBlOgnQZuGL0FC/ShBycYlQXjwK0EnoCpBSlAqQTxMKkE=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "F7pPvx8wR795LSy/cUGiv8vgs78Aw4W/TzgmvwF+lr/h0mW/R6BFv0lKlr/qhjG/jDKavzjoZr9rcsi/Qh5Mv2OzVL/V8UC/WIujv/GxML+h0hS/uL0xv/8tcL8=",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "[19] Carlos Escolano, Marta R Costa-juss`a, and Jos´e AR Fonollosa. (self-\natentive) autoencoder-based universal language representation for\nmachine translation. arXiv preprint arXiv:1810.06351, 2018.\n[20] Mateus Espadoto, Nina ST Hirata, and Alexandru C Telea. Deep learn-\ning multidimensional projections.\narXiv preprint arXiv:1902.07958,\n2019.\n59\n\n[21] Mateus Espadoto, Francisco Caio M Rodrigues, and Alexandru C\nTelea. Visual analytics of multidimensional projections for construct-\ning classiﬁer decision boundary maps.\n[22] Greg Friedman et al. Survey article: an elementary illustrated intro-\nduction to simplicial sets. Rocky Mountain Journal of Mathematics,\n42(2):353–423, 2012.\n[23] Lukas Fuhrimann, Vahid Moosavi, Patrick Ole Ohlbrock, and Pierluigi\nDacunto. Data-driven design: Exploring new structural forms using\nmachine learning and graphic statics. arXiv preprint arXiv:1809.08660,\n2018.\n[24] Benoit Gaujac, Ilya Feige, and David Barber. Gaussian mixture models\nwith wasserstein distance. arXiv preprint arXiv:1806.04465, 2018.\n[25] Paul G Goerss and John F Jardine.\nSimplicial homotopy theory.\nSpringer Science & Business Media, 2009.\n[26] Mathias Hein, Jean-Yves Audibert, and Ulrike von Luxburg. Graph\nlaplacians and their convergence on random neighborhood graphs.\nJournal of Machine Learning Research, 8(Jun):1325–1368, 2007.\n[27] Harold Hotelling. Analysis of a complex of statistical variables into\nprincipal components. Journal of educational psychology, 24(6):417,\n1933.\n[28] Dmitry Kobak and Philipp Berens. Te art of using t-sne for single-cell\ntranscriptomics. Nature communications, 10(1):1–14, 2019.\n",
          "the emission of wave packets. The information about the ingoing particles is returned, but\nin a highly scrambled, chaotic and useless form. This resolves the information paradox.\nFor all practical purposes, however, the information is lost.\nUnlike the suggestion of ’t Hooft, [8]- [9], that relies on a cut-oﬀof high energy modes\nnear the horizon, the resolution of the information loss paradox I proposed here is based\non symmetries, namely supertranslation invariance of the S-matrix between the ingoing\nand outgoing particles scattered oﬀthe horizon, which by construction is unitary.\nA full treatment of the issues presented here will appear in a future publication with\nM. J. Perry and A. Strominger, [10].\nReferences\n[1] S. Hawking, “Breakdown of Predictability in Gravitational Collapse”, Phys. Rev. D\n14 (1976) 2460.\n[2] A. Almheiri, D. Marolf, J. Polchinski, J. Sully, “Black Holes: Complementarity or\nFirewalls?”, JHEP 1302 (2013) 062, [arXiv:1207.3123 [hep-th]].\n[3] A. Almheiri, D. Marolf, J. Polchinski, D. Stanford, J. Sully, “An Apologia for Fire-\nwalls”, JHEP 1309 (2013) 018, [arXiv:1304.6483 [hep-th]].\n[4] H. Bondi, M. G. van der Burg, A. W. Metzner, “Gravitational Waves in General\nRelativity. 7. Waves from Axi-symmetric Isolated Systems”, Proc. Roy. Soc. Lond.\nA 269 (1962) 21.\n[5] R. K. Sachs, “Gravitational Waves in General Relativity. 8. Waves in Asymptotically\nFlat Space-time”, Proc. Roy. Soc. Lond. A 270 (1962) 103.\n[6] A. Strominger and A. Zhiboedov, “Gravitational Memory, BMS Supertranslations\n",
          "[34] M. R¨oder, A. Both, A. Hinneburg, Exploring the space of topic coherence measures, in: Pro-\nceedings of the Eighth ACM International Conference on Web Search and Data Mining, 2015,\npp. 399–408.\n[35] N. Aletras, M. Stevenson, Evaluating topic coherence using distributional semantics, in: Pro-\nceedings of the 10th International Conference on Computational Semantics (IWCS 2013)–Long\nPapers, 2013, pp. 13–22.\n[36] J. H. Lau, D. Newman, T. Baldwin, Machine reading tea leaves: Automatically evaluating topic\ncoherence and topic model quality, in: Proceedings of the 14th Conference of the European\nChapter of the Association for Computational Linguistics, 2014, pp. 530–539.\n12\n\n[37] D. Mimno, H. Wallach, E. Talley, M. Leenders, A. McCallum, Optimizing semantic coherence\nin topic models, in: Proceedings of the 2011 Conference on Empirical Methods in Natural\nLanguage Processing, 2011, pp. 262–272.\n[38] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al., Improving language understand-\ning by generative pre-training (2018).\nAppendix A.\nBBC News and Trump’s Tweet datasets Results\n13\n\nTopic\nNo.\nTopic words\nTC\n1\ngovernment, policy, election, prime, minister, parliament, party, vote, cam-\npaign, leader\n0.7106\n2\nmarket, stock, investment, company, profit, share, growth, trade, financial,\neconomic\n0.6498\n3\ntechnology, innovation, software, hardware, device, internet, application,\ndevelopment, computer, AI\n0.8891\n4\nsport, match, team, player, coach, tournament, championship, league, score,\ngoal\n0.8856\n5\nfilm, movie, actor, director, production, release, cinema, audience, award,\ngenre\n0.5959\n6\nmusic, album, artist, song, concert, band, release, genre, chart, festival\n",
          "[12] Junyue Cao, Malte Spielmann, Xiaojie Qiu, Xingfan Huang, Daniel M\nIbrahim, Andrew J Hill, Fan Zhang, Stefan Mundlos, Lena Chris-\ntiansen, Frank J Steemers, et al. Te single-cell transcriptional land-\nscape of mammalian organogenesis. Nature, page 1, 2019.\n[13] Gunnar Carlsson and Facundo M´emoli.\nClassifying clustering\nschemes. Foundations of Computational Mathematics, 13(2):221–252,\n2013.\n[14] Shan\nCarter,\nZan\nArmstrong,\nLudwig\nSchubert,\nIan\nJohn-\nson,\nand\nChris\nOlah.\nActivation\natlas.\nDistill,\n2019.\nhtps://distill.pub/2019/activation-atlas.\n[15] Brian Clark, Genevieve Stein-O’Brien, Fion Shiau, Gabrielle Can-\nnon, Emily Davis, Tomas Sherman, Fatemeh Rajaii, Rebecca James-\nEsposito, Richard Gronostajski, Elana Fertig, et al. Comprehensive\nanalysis of retinal development at single cell resolution identiﬁes nﬁ\nfactors as essential for mitotic exit and speciﬁcation of late-born cells.\nbioRxiv, page 378950, 2018.\n[16] Ronald R Coifman and St´ephane Lafon. Diﬀusion maps. Applied and\ncomputational harmonic analysis, 21(1):5–30, 2006.\n[17] Alex Diaz-Papkovich, Luke Anderson-Trocme, and Simon Gravel. Re-\nvealing multi-scale population structure in large cohorts.\nbioRxiv,\npage 423632, 2018.\n[18] Wei Dong, Charikar Moses, and Kai Li. Eﬃcient k-nearest neighbor\ngraph construction for generic similarity measures. In Proceedings\nof the 20th International Conference on World Wide Web, WWW ’11,\npages 577–586, New York, NY, USA, 2011. ACM.\n",
          "exploration: Using topic models for the descriptive analysis of social media data, Journal of\nTechnology in Human Services 38 (1) (2020) 54–86.\n[3] A. Joshi, E. Fidalgo, E. Alegre, L. Fern´andez-Robles, Deepsumm: Exploiting topic models\nand sequence to sequence networks for extractive text summarization, Expert Systems with\nApplications 211 (2023) 118442.\n[4] R. Albalawi, T. H. Yeap, M. Benyoucef, Using topic modeling methods for short-text data: A\ncomparative analysis, Frontiers in Artificial Intelligence 3 (2020) 42.\n[5] G. Punziano, C. C. De Falco, D. Trezza, Digital mixed content analysis for the study of digital\nplatform social data: An illustration from the analysis of covid-19 risk perception in the italian\ntwittersphere, Journal of Mixed Methods Research 17 (2) (2023) 143–170.\n[6] M. Mustak, J. Salminen, L. Pl´e, J. Wirtz, Artificial intelligence in marketing: Topic modeling,\nscientometric analysis, and research agenda, Journal of Business Research 124 (2021) 389–404.\n10\n\n[7] S. Sbalchiero, M. Eder, Topic modeling, long texts and the best number of topics. some prob-\nlems and solutions, Quality & Quantity 54 (2020) 1095–1108.\n[8] D. M. Blei, A. Y. Ng, M. I. Jordan, Latent dirichlet allocation, Journal of Machine Learning\nResearch 3 (Jan) (2003) 993–1022.\n[9] C. F´evotte, J. Idier, Algorithms for nonnegative matrix factorization with the β-divergence,\nNeural Computation 23 (9) (2011) 2421–2456.\n[10] T. Hofmann, Probabilistic latent semantic indexing, in: Proceedings of the 22nd Annual In-\nternational ACM SIGIR Conference on Research and Development in Information Retrieval,\n",
          "[29] Dmitry Kobak and George C Linderman. Umap does not preserve\nglobal structure any beter than t-sne when using the same initializa-\ntion. bioRxiv, 2019.\n[30] J. B. Kruskal. Multidimensional scaling by optimizing goodness of ﬁt\nto a nonmetric hypothesis. Psychometrika, 29(1):1–27, Mar 1964.\n[31] Siu Kwan Lam, Antoine Pitrou, and Stanley Seibert. Numba: A llvm-\nbased python jit compiler. In Proceedings of the Second Workshop on\nthe LLVM Compiler Infrastructure in HPC, LLVM ’15, pages 7:1–7:6,\nNew York, NY, USA, 2015. ACM.\n[32] Yann Lecun and Corinna Cortes. Te MNIST database of handwriten\ndigits.\n[33] John A Lee and Michel Verleysen. Shif-invariant similarities circum-\nvent distance concentration in stochastic neighbor embedding and\nvariants. Procedia Computer Science, 4:538–547, 2011.\n60\n\n[34] Xin Li, Ondrej E Dyck, Mark P Oxley, Andrew R Lupini, Leland\nMcInnes, John Healy, Stephen Jesse, and Sergei V Kalinin.\nMani-\nfold learning of four-dimensional scanning transmission electron mi-\ncroscopy. npj Computational Materials, 5(1):5, 2019.\n[35] M. Lichman. UCI machine learning repository, 2013.\n[36] George Linderman.\nFit-sne.\nhttps://github.com/KlugerLab/\nFIt-SNE, 2018.\n[37] George C Linderman, Manas Rachh, Jeremy G Hoskins, Stefan\nSteinerberger, and Yuval Kluger. Eﬃcient algorithms for t-distributed\nstochastic neighborhood embedding. arXiv preprint arXiv:1712.09005,\n2017.\n[38] George C Linderman and Stefan Steinerberger. Clustering with t-sne,\nprovably. SIAM Journal on Mathematics of Data Science, 1(2):313–332,\n",
          "[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\n2017.\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\nIn International Conference on Learning Representations, 2017.\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\narXiv:1703.10722, 2017.\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\narXiv:1703.03130, 2017.\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n11\n\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\npages 152–159. ACL, June 2006.\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\n",
          "We are excited about the future of attention-based models and plan to apply them to other tasks. We\nplan to extend the Transformer to problems involving input and output modalities other than text and\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\nThe code we used to train and evaluate our models is available at https://github.com/\ntensorflow/tensor2tensor.\nAcknowledgements\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\ncomments, corrections and inspiration.\nReferences\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450, 2016.\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\nreading. arXiv preprint arXiv:1601.06733, 2016.\n10\n\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\nmachine translation. CoRR, abs/1406.1078, 2014.\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\npreprint arXiv:1610.02357, 2016.\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n",
          "expository article available online at htp://www. math. harvard. edu/˜\neriehl, 2011.\n[49] Emily Riehl. Category theory in context. Courier Dover Publications,\n2017.\n[50] John W Sammon. A nonlinear mapping for data structure analysis.\nIEEE Transactions on computers, 100(5):401–409, 1969.\n[51] Josef Spidlen, Karin Breuer, Chad Rosenberg, Nikesh Kotecha, and\nRyan R Brinkman. Flowrepository: A resource of annotated ﬂow cy-\ntometry datasets associated with peer-reviewed publications. Cytom-\netry Part A, 81(9):727–731, 2012.\n[52] David I Spivak. Metric realization of fuzzy simplicial sets. Self pub-\nlished notes, 2012.\n[53] Jian Tang. Largevis. https://github.com/lferry007/LargeVis,\n2016.\n[54] Jian Tang, Jingzhou Liu, Ming Zhang, and Qiaozhu Mei. Visualizing\nlarge-scale and high-dimensional data. In Proceedings of the 25th Inter-\nnational Conference on World Wide Web, pages 287–297. International\nWorld Wide Web Conferences Steering Commitee, 2016.\n[55] Joshua B. Tenenbaum. Mapping a manifold of perceptual observa-\ntions. In M. I. Jordan, M. J. Kearns, and S. A. Solla, editors, Advances in\nNeural Information Processing Systems 10, pages 682–688. MIT Press,\n1998.\n[56] Joshua B Tenenbaum, Vin De Silva, and John C Langford. A global\ngeometric framework for nonlinear dimensionality reduction. science,\n290(5500):2319–2323, 2000.\n[57] Dmitry Ulyanov.\nMulticore-tsne.\nhttps://github.com/\nDmitryUlyanov/Multicore-TSNE, 2016.\n[58] Laurens van der Maaten. Accelerating t-sne using tree-based algo-\nrithms. Journal of machine learning research, 15(1):3221–3245, 2014.\n",
          "models with zero-shot learning, arXiv preprint arXiv:2004.07737 (2020).\n[19] M. G. Yigezu, T. Kebede, O. Kolesnikova, G. Sidorov, A. Gelbukh, Habesha@ dravidian-\nlangtech: Utilizing deep and transfer learning approaches for sentiment analysis., in: Proceed-\nings of the Third Workshop on Speech and Language Technologies for Dravidian Languages,\n2023, pp. 239–243.\n[20] D. Angelov, Top2vec: Distributed representations of topics, arXiv preprint arXiv:2008.09470\n(2020).\n[21] Z. Zhang, M. Fang, L. Chen, M.-R. Namazi-Rad, Is neural topic modelling better than cluster-\ning? an empirical study on clustering with contextual embeddings for topics, arXiv preprint\narXiv:2204.09874 (2022).\n11\n\n[22] N. Reimers, I. Gurevych, Sentence-bert: Sentence embeddings using siamese bert-networks,\narXiv preprint arXiv:1908.10084 (2019).\n[23] O. Kolesnikova, M. G. Yigezu, A. Gelbukh, S. Abitte, G. Sidorov, Detecting multilingual\nhate speech targeting immigrants and women on twitter, Journal of Intelligent & Fuzzy Sys-\ntems (Preprint) 1–10.\n[24] M. G. Yigezu, O. Kolesnikova, A. Gelbukh, G. Sidorov, Odio-bert: Evaluating domain task\nimpact in hate speech detection, Journal of Intelligent & Fuzzy Systems (Preprint) 1–12.\n[25] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep bidirectional trans-\nformers for language understanding, arXiv preprint arXiv:1810.04805 (2018).\n",
          "2019.\n[39] Saunders Mac Lane. Categories for the working mathematician, vol-\nume 5. Springer Science & Business Media, 2013.\n[40] J Peter May. Simplicial objects in algebraic topology, volume 11. Uni-\nversity of Chicago Press, 1992.\n[41] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeﬀ\nDean. Distributed representations of words and phrases and their\ncompositionality. In Advances in neural information processing sys-\ntems, pages 3111–3119, 2013.\n[42] Kevin R Moon, David van Dijk, Zheng Wang, Scot Gigante, Daniel B\nBurkhardt, William S Chen, Kristina Yim, Antonia van den Elzen,\nMathew J Hirn, Ronald R Coifman, et al. Visualizing structure and\ntransitions in high-dimensional biological data. Nature biotechnology,\n37(12):1482–1492, 2019.\n[43] Sameer A. Nene, Shree K. Nayar, and Hiroshi Murase. Columbia object\nimage library (coil-20. Technical report, 1996.\n[44] Sameer A. Nene, Shree K. Nayar, and Hiroshi Murase. object image\nlibrary (coil-100. Technical report, 1996.\n[45] Karolyn A Oetjen, Katherine E Lindblad, Meghali Goswami, Gege Gui,\nPradeep K Dagur, Catherine Lai, Laura W Dillon, J Philip McCoy, and\nChristopher S Hourigan. Human bone marrow assessment by single\ncell rna sequencing, mass cytometry and ﬂow cytometry. bioRxiv,\n2018.\n61\n\n[46] Jong-Eun Park, Krzysztof Polanski, Kerstin Meyer, and Sarah A Te-\nichmann. Fast batch alignment of single cell transcriptomes uniﬁes\nmultiple mouse cell atlases into an integrated landscape. bioRxiv, page\n397042, 2018.\n[47] Jose Daniel Gallego Posada. Simplicial autoencoders. 2018.\n[48] Emily Riehl. A leisurely introduction to simplicial sets. Unpublished\n",
          "[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\nnetwork grammars. In Proc. of NAACL, 2016.\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n[10] Alex Graves.\nGenerating sequences with recurrent neural networks.\narXiv preprint\narXiv:1308.0850, 2013.\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, pages 770–778, 2016.\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\n9(8):1735–1780, 1997.\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\nLanguage Processing, pages 832–841. ACL, August 2009.\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\nInformation Processing Systems, (NIPS), 2016.\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\non Learning Representations (ICLR), 2016.\n",
          "networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\nAdvances in Neural Information Processing Systems, 2015.\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\narXiv:1609.08144, 2016.\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\n1: Long Papers), pages 434–443. ACL, August 2013.\n12\n\nAttention Visualizations\nIt\nis\nin\nthis\nspirit\nthat\na\nmajority\nof\nAmerican\ngovernments\nhave\npassed\nnew\nlaws\nsince\n2009\nmaking\nthe\nregistration\nor\nvoting\nprocess\nmore\ndifficult\n.\n<EOS>\n<pad>\n<pad>\n<pad>\n<pad>\n<pad>\n<pad>\nIt\nis\nin\nthis\nspirit\nthat\na\nmajority\nof\nAmerican\ngovernments\nhave\npassed\nnew\nlaws\nsince\n2009\nmaking\nthe\nregistration\nor\nvoting\nprocess\nmore\ndifficult\n.\n<EOS>\n<pad>\n<pad>\n<pad>\n",
          "model. In Empirical Methods in Natural Language Processing, 2016.\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\n2006.\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\npreprint arXiv:1608.05859, 2016.\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\nlayer. arXiv preprint arXiv:1701.06538, 2017.\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\nLearning Research, 15(1):1929–1958, 2014.\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\nInc., 2015.\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\n",
          "and Soft Theorems”, [arXiv:1411.5745 [hep-th]].\n[7] J. Polchinski, “Chaos in the Black Hole S-matrix”, [arXiv:1505.08108 [hep-th]].\n[8] G. ’t Hooft, “Black Holes, Hawking Radiation, and the Information Paradox”, Nucl.\nPhys. B (Proc. Suppl.) 43 (1995) 1.\n[9] G. ’t Hooft, “The Scattering Matrix Appraoch for the Quantum Black Hole,”Int. J.\nMod. Phys. A11 (1996) 4623, [arXiv:9607022 [gr-qc]].\n[10] S. W. Hawking, M. J. Perry and A. Strominger, in preparation.\n3\n\n",
          "Dutertre, Immanuel WH Kwok, Lai Guan Ng, Florent Ginhoux, and\nEvan W Newell. Dimensionality reduction for visualizing single-cell\ndata using umap. Nature biotechnology, 37(1):38, 2019.\n[6] Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps and spec-\ntral techniques for embedding and clustering. In Advances in neural\ninformation processing systems, pages 585–591, 2002.\n[7] Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimen-\nsionality reduction and data representation.\nNeural computation,\n15(6):1373–1396, 2003.\n[8] Aur´elien Bellet, Amaury Habrard, and Marc Sebban. A survey on\nmetric learning for feature vectors and structured data. arXiv preprint\narXiv:1306.6709, 2013.\n[9] Tess Brodie, Elena Brenna, and Federica Sallusto.\nOmip-018:\nChemokine receptor expression on human t helper cells. Cytometry\nPart A, 83(6):530–532, 2013.\n[10] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa,\nAndreas Mueller, Olivier Grisel, Vlad Niculae, Peter Pretenhofer,\nAlexandre Gramfort, Jaques Grobler, Robert Layton, Jake VanderPlas,\nArnaud Joly, Brian Holt, and Ga¨el Varoquaux. API design for machine\nlearning sofware: experiences from the scikit-learn project. In ECML\nPKDD Workshop: Languages for Data Mining and Machine Learning,\npages 108–122, 2013.\n58\n\n[11] John N Campbell, Evan Z Macosko, Henning Fenselau, Tune H Pers,\nAnna Lyubetskaya, Danielle Tenen, Melissa Goldman, Anne MJ Ver-\nstegen, Jon M Resch, Steven A McCarroll, et al. A molecular census of\narcuate hypothalamus and median eminence cell types. Nature neu-\nroscience, 20(3):484, 2017.\n",
          "Symmetrization is carried out by fuzzy set union using the probabilistic\nt-conorm and can be expressed as:\nvij =\n�vj|i + vi|j\n\u0001\n−vj|ivi|j\n(16)\nEquation 16 corresponds to forming top-rep in Algorithm 1. Unlike t-SNE,\nfurther normalization is not carried out.\nTe low dimensional similarities are given by:\nwij =\n\u0010\n1 + a ∥yi −yj∥2b\n2\n\u0011−1\n(17)\nwhere a and b are user-deﬁned positive values. Te procedure for ﬁnding\nthem is given in Deﬁnition 11. Use of this procedure with the default values\nin the UMAP implementation results in a ≈1.929 and b ≈0.7915. Seting\na = 1 and b = 1 results in the Student t-distribution used in t-SNE.\n57\n\nReferences\n[1] E Alpaydin and Fevzi Alimoglu. Pen-based recognition of handwrit-\nten digits data set. university of california, irvine. Machine Learning\nRepository. Irvine: University of California, 4(2), 1998.\n[2] Frederik Otzen Bagger, Savvas Kinalis, and Nicolas Rapin. Bloodspot:\na database of healthy and malignant haematopoiesis updated with pu-\nriﬁed and single cell mrna sequencing proﬁles. Nucleic Acids Research,\n2018.\n[3] Michael Barr. Fuzzy set theory and topos theory. Canad. Math. Bull,\n29(4):501–508, 1986.\n[4] Etienne Becht, Charles-Antoine Dutertre, Immanuel W.H. Kwok,\nLai Guan Ng, Florent Ginhoux, and Evan W Newell. Evaluation of\numap as an alternative to t-sne for single-cell data. bioRxiv, 2018.\n[5] Etienne Becht,\nLeland McInnes,\nJohn Healy,\nCharles-Antoine\n",
          "62\n\n[59] Laurens van der Maaten and Geoﬀrey Hinton. Visualizing data using\nt-sne. Journal of machine learning research, 9(Nov):2579–2605, 2008.\n[60] Laurens van der Maaten and Geoﬀrey Hinton. Visualizing data using\nt-SNE. Journal of Machine Learning Research, 9:2579–2605, 2008.\n[61] John Williamson. What do numbers look like? https://johnhw.\ngithub.io/umap_primes/index.md.html, 2018.\n[62] Duoduo Wu, Joe Yeong, Grace Tan, Marion Chevrier, Josh Loh, Tony\nLim, and Jinmiao Chen. Comparison between umap and t-sne for\nmultiplex-immunoﬂuorescence derived single-cell data from tissue\nsections. bioRxiv, page 549659, 2019.\n[63] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel\nimage dataset for benchmarking machine learning algorithms. CoRR,\nabs/1708.07747, 2017.\n[64] Liu Yang and Rong Jin. Distance metric learning: A comprehensive\nsurvey. Michigan State Universiy, 2(2):4, 2006.\n[65] Lofi A Zadeh. Information and control. Fuzzy sets, 8(3):338–353, 1965.\n63\n\n",
          "[26] C. C. Aggarwal, A. Hinneburg, D. A. Keim, On the surprising behavior of distance metrics\nin high dimensional space, in: Database Theory—ICDT 2001: 8th International Conference\nLondon, UK, January 4–6, 2001 Proceedings 8, Springer, 2001, pp. 420–434.\n[27] D. Pandove, S. Goel, R. Rani, Systematic review of clustering high-dimensional and large\ndatasets, ACM Transactions on Knowledge Discovery from Data (TKDD) 12 (2) (2018) 1–68.\n[28] M. Allaoui, M. L. Kherfi, A. Cheriet, Considerably improving clustering algorithms using\numap dimensionality reduction technique: A comparative study, in: International conference\non image and signal processing, Springer, 2020, pp. 317–325.\n[29] M. Mersha, K. Lam, J. Wood, A. AlShami, J. Kalita, Explainable artificial intelligence: A\nsurvey of needs, techniques, applications, and future direction, Neurocomputing (2024) 128111.\n[30] L. McInnes, J. Healy, J. Melville, Umap: Uniform manifold approximation and projection for\ndimension reduction, arXiv preprint arXiv:1802.03426 (2018).\n[31] M. G. Yigezu, S. Kanta, O. Kolesnikova, G. Sidorov, A. Gelbukh, Habesha@ dravidianlangtech:\nAbusive comment detection using deep learning approach, in: Proceedings of the Third Work-\nshop on Speech and Language Technologies for Dravidian Languages, 2023, pp. 244–249.\n[32] K. Lang, Newsweeder: Learning to filter netnews, in: Machine learning proceedings 1995,\nElsevier, 1995, pp. 331–339.\n[33] D. Greene, P. Cunningham, Practical solutions to the problem of diagonal dominance in ker-\nnel document clustering, in: Proceedings of the 23rd International Conference on Machine\nlearning, 2006, pp. 377–384.\n",
          "1999, pp. 50–57.\n[11] M. Grootendorst, Bertopic: Neural topic modeling with a class-based tf-idf procedure, arXiv\npreprint arXiv:2203.05794 (2022).\n[12] A. B. Dieng, F. J. Ruiz, D. M. Blei, Topic modeling in embedding spaces, Transactions of the\nAssociation for Computational Linguistics 8 (2020) 439–453.\n[13] D. Blei, J. Lafferty, Correlated topic models, Advances in Neural Information Processing Sys-\ntems 18 (2006) 147.\n[14] H. Zhao, D. Phung, V. Huynh, Y. Jin, L. Du, W. Buntine, Topic modelling meets deep neural\nnetworks: A survey, arXiv preprint arXiv:2103.00498 (2021).\n[15] S. Terragni, E. Fersini, B. G. Galuzzi, P. Tropeano, A. Candelieri, Octis: Comparing and\noptimizing topic models is simple!, in: Proceedings of the 16th Conference of the European\nChapter of the Association for Computational Linguistics: System Demonstrations, 2021, pp.\n263–270.\n[16] N. Agarwal, G. Sikka, L. K. Awasthi, Comparative study of topic modeling and word embed-\nding approaches for web service clustering, in: 2021 Thirteenth International Conference on\nContemporary Computing (IC3-2021), 2021, pp. 309–313.\n[17] J. Qiang, P. Chen, T. Wang, X. Wu, Topic modeling over short texts by incorporating word\nembeddings, in: Advances in Knowledge Discovery and Data Mining: 21st Pacific-Asia Con-\nference, PAKDD 2017, Jeju, South Korea, May 23-26, 2017, Proceedings, Part II 21, Springer,\n2017, pp. 363–374.\n[18] F. Bianchi, S. Terragni, D. Hovy, D. Nozza, E. Fersini, Cross-lingual contextualized topic\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_biorxiv_2017_acl",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_biorxiv_2017_acl"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "qTHVQOJD00BANNtAD0bPQGzy2UBjwcxAiC7SQO7az0DPfNBAnc7YQJ40zECnqtBAZZHRQA0f0kD+t9JAaGPHQDO/zkCMZM9AakraQHsQ2UDrdNJA",
          "dtype": "f4"
         },
         "y": {
          "bdata": "E/lHQSi8QkE390JBGLNHQfCzQ0Gae0ZBWdtMQRs8TUHY9ENBQ1pHQdNkRkEnSk5BgzFOQWXlTEHvKUNBI6hJQQUCQ0E2/ERBsCxDQaNvRUHOTkdB",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "• We further improve the model’s performance by eliminating non-relevant topic representative\nwords in a second layer of processing once again based on the contextual information.\nThe paper is organized as follows: a review of the most recent related works is presented in\nSection 2. The model architecture and functions of the components are discussed in Section 3.\nSection 4 covers the experimental setup, results, and analysis. Finally, the paper concludes with\nthe findings in Section 5.\n2. Related Works\nThe current state-of-the-art topic modeling methodologies can be classified into two main cat-\negories: probabilistic and embedding-based. Probabilistic models like LDA [8], NMF [9], LSA [10],\nand other variants of LDA work based on the statistical properties of data. However, these prob-\nabilistic models have a few limitations when using bag-of-words representation. The embedding-\nbased models use text embeddings and can overcome the limitations of the traditional probabilistic-\nbased models.\nIn recent years, topic modeling has shown improvement by exploiting the power of neural net-\nwork models to enhance traditional techniques, resulting in improved performance and the ability\nto capture more complex relationships within large document collections [14] and [15]. The inte-\ngration of word embeddings into classical probabilistic models has shown effective and promising\ntopic representations [16] and [17].\nThere has been a substantial surge in the development of\ntopic-modeling techniques, primarily focused on embedding-based models [12, 18, 19]. Embedding-\nbased models have achieved good performance because of their capability to capture the contextual\nmeaning and the semantic relationship among words in a document. Angelov (2020) introduced an\nadvanced topic modeling approach that utilizes clusters of pre-trained word embeddings instead of\ntraditional probabilistic topic model methods [20]. The authors achieved faster and more efficient\ntopic extraction, generating promising results with accurate topics for each cluster. Bianchi et\nal. (2020) also demonstrated the utilization of word embeddings to enhance the topic extraction\nprocess [18]. They introduced a method that leverages contextualized document embeddings, re-\nsulting in improved topic quality and coherence. The study demonstrated that contextualized word\nembeddings produce more meaningful and coherent topic representations.\n",
          "turnout\n0.5288\n2\neconomy, jobs, growth, market, trade, stock, business, investment, manu-\nfacturing, economic\n0.4969\n3\nmedia, news, journalist, report, coverage, CNN, NYTimes, article, bias,\ntruth\n0.5562\n4\nAmerica, great, country, patriotism, citizens, USA, nation, flag, indepen-\ndence, freedom\n0.7484\n5\nsecurity, border, immigration, wall, illegal, ICE, enforcement, policy, crime,\nsafety\n0.7573\n6\nmilitary, troops, veterans, defense, service, army, navy, honor, sacrifice, sup-\nport\n0.6159\n7\nhealthcare, Obamacare, insurance, policy, reform, prescription, cost, doc-\ntors, patients, coverage\n0.6844\n8\nlaw, justice, court, judge, trial, legal, crime, investigation, verdict, FBI\n0.5192\n9\nforeign policy, trade, China, tariffs, agreement, negotiation, allies, relations,\ndiplomacy, sanctions\n0.5791\n10\ntax, reform, cuts, policy, income, IRS, corporate, middle class, reduction,\nplan\n0.6121\n11\nenergy, oil, gas, production, pipeline, industry, policy, prices, renewable, coal\n0.7001\n12\neducation, schools, students, teachers, policy, funding, reform, curriculum,\nlearning, college\n0.4468\n13\nimpeachment, investigation, trial, defense, Democrats, hearing, testimony,\nwitnesses, charges, inquiry\n0.8329\n14\nCOVID-19, pandemic, virus, vaccine, response, cases, testing, treatment,\nhealthcare, guidelines\n0.7353\n15\nSecond Amendment, rights, firearms, NRA, legislation, ownership, control,\nsafety, defense, law\n0.6174\n16\ntweets, retweets, followers, media, platform, engagement, post, message,\nhashtag, account\n0.5459\n17\ninfrastructure, projects, development, funding, roads, bridges, construction,\ntransportation, investment, plan\n",
          "concerns through a structured six-step process as follows:\n1. Topic Definition: First, we identify sensitive topics in Thai culture. We look at\ncultural customs, sensitive subjects, and social rules that are important in Thai\nsociety, as well as general safety concerns.\n2. Subtopic Generation: For each topic we found, we use an LLM to create detailed\nsubtopics. We prompt the LLM with simple questions such as \"Given the sensitive\ntopic, what are some possible subtopics?\" to break down each main topic into\nsmaller and more specific issues.\n3. Text Generation: We use an LLM with carefully designed prompting techniques to\ngenerate contextually relevant content. Our prompting strategy utilizes structured\ntemplates (e.g., “You are a writer discussing {subtopic}...\") to ensure consistent\nand contextually appropriate content generation.\n4. Automated Scoring: We adopt an automated scoring system using an LLM as\na judge to evaluate the potential harm level of generated content. The scoring\nsystem utilizes a standardized prompt format: “Please evaluate the following text\n23\n\nTechnical Report\naccording to these policy guidelines, rating from 1-10...\" This approach enables\nconsistent evaluation across datasets.\n5. Binary Labeling: We select a harm threshold score of 5, with texts scoring above\nthis threshold classified as harmful (1) and those below as unharmful (0).\n6. Translation: We translate all generated and labeled texts from English to Thai using\na 4:1 ratio, using an LLM for the translation process.\nThai Sensitive \nTopic\nThai Sensitive \nSub Topic\nText / Instruction\nLLM\nDataset\nGenerate score\nLLM generate text from topic\nLabel using score\nFigure 5: Pipeline of Thai topic data generation\nInitially, we investigate direct text classification through LLM prompting (e.g., “classify the\nfollowing text\"). However, this approach is less effective than the scoring method and lacks\nthe flexibility to adjust model behaviors, resulting in significantly lower performance.\nThe complete data generation pipeline is illustrated in Figure 5. We note that during the\ndata generation process, we observe that many Thai-specific topics (shown in Table 18)\noverlap with existing WildGuard (Han et al., 2024) categories. For simplicity, we combine\n",
          "The BBC News dataset contains 2,225 documents, categorized into four distinct classes, from the\nBBC News website between 2004 and 2005 [33]. The 20newsgroup and BBC News datasets are\na collection of short and long texts. We used Trump’s tweets to represent more recent and short\ntextual data [11]. Trump’s collection of tweets contains 44,253 tweets between 2009 and 2021. All\nthese datasets are retrieved from the Kaggle repository.\n4.3. Model Evaluation\nWidely accepted and easily computable topic coherence measures, such as CV , Cnpmi, UMass,\nand Cuci, are used to evaluate the interpretability of topics.\n1) C V Coherence: The C V coherence metric evaluates the coherence and interpretability of\ntopics based on context vectors instead of relying on the co-occurrence frequency of words [34].\nThese context vectors calculate the Normalized Pointwise Mutual Information (NPMI) between a\nchosen word and the frequency counts of the top topic words within the vector. The C V topic\ncoherence measure correlates well with human judgment [34]. A C V score of 1 indicates perfect\ncoherence, whereas 0 indicates no coherence.\n2) C npmi: C npmi (Normalized Pointwise Mutual Information coherence) works by analyzing\nthe semantic relationships between words within a topic [35]. It computes NPMI between pairs of\nwords in each topic, measuring how strongly they are correlated with each other. C npmi overcomes\nthe limitation of C uci by replacing PMI with normalized PMI. The C npmi measure correlates\nbetter with human judgment [36].\nC npmi scores typically range from -1 to 1, where a score of 1 indicates perfect coherence.\nC uci [36] and U mass [37] measure topic coherence by observing how topic words co-occur\nwithin a topic in a reference corpus of text data. They do not depend on any other word embeddings\nor complex statistics like C npmi and C V. High C uci and U Mass scores indicate that the words\nwithin a topic are more coherent and have a higher likelihood of co-occurring together.\nWe computed the coherence of each topic separately, and each cluster-based topic showed an\nexcellent coherence score. These individual scores indicate that the top k words in each topic have\n",
          "4.7. Discussion\nWe have presented a novel model, an unsupervised learning algorithm designed to discover top-\nics within a semantic space that leverages the embedding of documents. We have demonstrated\nhow the semantic vector space is used for the representation of topics, enabling the computation\nof topics by identifying dense regions of highly semantically similar documents. To understand\n8\n\nTopic\nNo.\nTopic words\nTC\n1\njesus, christ, god, bible, christians, spirit, lord, church, heaven, gospel\n0.8427\n2\ncars, engine, wheels, gear, brakes, tires, bike, motorcycle, parking, driving\n0.5679\n3\nmedical, health, doctor, patient, disease, cancer, symptoms, drug, physician\n0.7243\n4\nkeys, clipper, encryption, decrypt, secure, encrypted, scheme, security, algo-\nrithm\n0.7640\n5\nbeliefs, atheist, christianity, religions, atheism, christian, faith, truth, exis-\ntence\n0.6008\n6\nmonitor, card, pc, disk, system, mac, scsi, window, program, display\n0.7010\n7\nvoltage, circuit, signal, resistor, diode, khz, impedance, analog, system, re-\nsistors\n0.6833\n8\nisrael, jewish, israeli, jerusalem, jews, palestinian, arab, gaza, zion, jordan\n0.7679\n9\nsale, price, shipping, brand, item, offer, warranty, buyer, purchased, trade\n0.6402\n10\nspace, satellite, launch, orbit, earth, spacecraft, shuttle, moon, nasa, mission\n0.5832\n11\nweapon, firearm, guns, handguns, crime, laws, amendment, firearms, govern,\nright\n0.5892\n12\nseason,game, teams , hockey, playoff, defenseman, goal, score, player,\npenalty\n0.7491\n13\nresearch, project, conference, acm, proceedings, papers, publication, journal\n0.7585\n14\nthanks, appreciate, reply, response, email, respond, welcome, advance, an-\n",
          "swer\n0.6783\n15\nbus, eisa, cards, ide, vesa, svga, isa, video, bios, motherboard\n0.5695\n16\nsunos, gcc, compile, lib, libraries, patch, login, window, unix, xdm\n0.7847\n17\ndrive, ide, disk, boot, jumper, controller, floppy, tape, dma, master\n0.6654\n18\nwindow, program, file, server, user, run, version, openwindows, ftp, xview\n0.5297\n19\nprinters, print, ink, hp, deskjet, laser, paper, printing, printer,document\n0.7899\n20\nlaw, govern, protect, legal, citizen, right, policy, control, crime, people\n0.7104\nAverage Topic Coherence\n0.6850\nTable 4: Topics, top 10 topic words, and c v individual topic coherence scores for 20 newsgroup datasets, with overall\ntopic coherence score as the average of individual scores.\nour model comprehensively, it is essential to understand the contextual importance of each word\nwithin a document and sentence from the Transformer model. The model centers on each word’s\nand sentence’s contextual meaning and contribution within its corresponding cluster or seman-\ntic space. These central concepts offer two main advantages to the model. Firstly, we employ\nSentence-Transformer’s word embedding values to extract topics based on the relevance of each\nword within its cluster using some similarity measure. Secondly, we exclude non-relevant words\nfrom the topic extraction process by utilizing similarity score values, enhancing the model’s per-\nformance. HDBSCAN identifies highly semantically similar dense and sparse sentence areas in the\nsentence vector space on the UMAP dimensionally reduced sentence vector. Those semantically\nsimilar dense areas are where we are interested in finding the underlying topics. In our finding,\nsparse sentence areas are semantically less similar to each other and also to the dense sentence\nareas, as shown in Fig 1(b). These sparse areas are considered as noise, and no significant under-\nlying topic exists, and we exclude them from the topic extraction process, as shown in Fig 1(c).\nThe minimum cluster size is the most critical hyperparameter in HDBSCAN. In our experiments,\n",
          "0.6704\n18\ntrade, negotiation, NAFTA, agreement, USMCA, exports, imports, tariffs,\nbalance, partners\n0.5642\n19\nclimate, environment, policy, Paris, emissions, energy, sustainability, con-\nservation, regulation, impact\n0.7653\n20\nelections, fraud, recount, integrity, ballots, results, dispute, claims, process,\ncertification\n0.6879\nAverage Topic Coherence\n0.6332\nTable A.6: Topics, top 10 topic words, and c v individual topic coherence scores for Trump’s Tweet datasets, with\noverall topic coherence score as the average of individual scores.\n15\n\n",
          "hypothesis of spatial locality becomes poorly defined in high-dimensional space, leading to dimin-\nished differences between different distance measures. This high-dimensional Sentence BERT vector\n3\n\nspace representation may challenge clustering algorithms [27]. Therefore, applying dimension re-\nduction techniques is the straightforward solution for this high-dimensionality challenge to get a\nbetter clustering result [28]. We employed UMAP as a dimension reduction technique that shows\nremarkable improvements in clustering documents, providing a significant milestone for the overall\ntopic extraction process [11]. We adjust UMAP’s parameters, such as the number of neighbors and\nminimum distance, to balance the preservation of global and local structures. Furthermore, using\nsome model explainability techniques may help to interpret UMAP output [29], which is not done\nin this study.\n3.3.\nDocument Clustering\nClustering is essential in our topic extraction process. We use reduced document embeddings,\nclustered based on semantic similarity, to identify and extract coherent and unique topics from a\ndocument collection. HDBSCAN is chosen for its robustness, scalability, and ability to find clusters\nof varying densities [30]. This method is particularly effective for diverse document structures and\nnoisy data, providing hierarchical insights to uncover hidden topics and subtopics across the entire\ncollection.\n3.4. Topic Extraction\nTopic modeling studies have demonstrated that the documents within a cluster exhibit a clear\nassociation with a specific topic [11]. However, it is essential to realize that the documents within\na cluster may contain multiple topics and subtopics, indicating a certain level of topic diversity\nwithin clusters. Once the HDBSCAN clustering algorithm is applied and clusters are identified,\nthe next step is detecting topic words for each cluster, building a vocabulary, and extracting topics,\nwhich involves a few steps. First, to build a vocabulary for each cluster, sentences within each\ncluster are split into individual words, and these words are mapped to their corresponding contex-\ntual embedding values, helping eliminate topic-representative words that do not have any semantic\ncontribution to the sentence. Secondly, unique candidate words are extracted from each sentence,\nand an independent vocabulary is constructed for each cluster. Subsequently, contextually non-\nrelevant unique words are eliminated from each vocabulary, resulting in a vocabulary composed of\n",
          "2\n\nResearchers have also used hybrid approaches in recent years, leading to remarkable improve-\nments in topic extraction. Grootendors (2022) and Zhang et al. (2022) adopt an innovative ap-\nproach that combines TF-IDF and word embeddings [11], [21]. This hybrid model uses BERT\nembeddings to group documents into distinct clusters and extract coherent and meaningful topics\nfrom each cluster based on TF-IDF scores.\nThe model proposed in this paper enhances the topic modeling process by leveraging contextual\ninformation from SBERT embeddings [22] of candidate topic words within each cluster [11]. Our\nnew technique leverages an end-to-end semantic-driven approach using Sentence-BERT [22, 23] to\ngenerate better topic representations, outperforming TF-IDF, probabilistic, and other methods.\nThis results in more coherent and meaningful topics for each cluster.\n3. Model Architecture\nThe model we introduce has four modules: embedding, dimension reduction, clustering, and\ntopic extraction.\nFigure 1: Overview of the proposed pipeline model architecture.\n3.1. Document Embedding\nIn this paper, a document refers to a unit of text that can be any piece of textual content\nranging from a single phrase, sentence, paragraph, or a collection of these text units or doc-\numents.\nThe initial task in the model is creating a sentence-level vector space representation.\nSentenceTransformer-BERT (SBERT) [22, 24] is used for this purpose. SBERT converts collec-\ntions of documents into high-quality sentence embeddings in a dense vector space by leveraging\nthe BERT pre-trained language model [25], which provides fixed-length vector representations. In\nthis module, any other document embedding method can be employed if it produces better vector\nrepresentations and improves the quality of document clustering. Since the clustering quality will\nimprove as new and enhanced language models continue to emerge, the performance of the model\nwill also improve; it is a potential benefit of our model.\n3.2. Dimension Reduction\nStudies have shown that the proximity to the nearest data point tends to approach the dis-\ntance to the farthest data point when the dimensionality of data increases [26]. As a result, the\n",
          "Matrix Factorization (NMF) [9], Latent Semantic Analysis (LSA) [10], and some BERT-based topic\nmodels work based on the bag-of-words approach to extract topics. Due to reliance on the bag-\nof-words technique, they suffer from the limitation that they treat all words in isolation without\nconsidering contextual relevance and relationships of words to the document. Traditional and even\nsome Transformer-based topic models [11] encounter challenges in contextual understanding at the\ntopic extraction stage, potentially leading to less accurate and meaningful topic representations\nfrom the document collection.\nIn this study, we present a novel semantic-driven topic modeling approach that leverages the\nTransformer’s ability to capture contextual information about words within the document through-\nout the end-to-end topic extraction process. We ensure that the model focuses only on the most\nrelevant words within each document, disregarding non-relevant ones. This unique feature of our\narXiv:2410.00134v1  [cs.CL]  30 Sep 2024\n\nmodel sets it apart from others and enhances its ability to extract accurate and meaningful topics\nfor each group of documents. We hypothesize that a unique word with no contextual relevance\nto the document is not a good topic representative for that document. This enables the proposed\nmodel to extract more accurate and meaningful topics for each group of documents. To the best of\nour knowledge, this semantic-driven end-to-end topic extraction approach is our innovative work.\nOur model, designed with four layers, plays a pivotal role in utilizing the contextual informa-\ntion generated by Transformers for words and sentences from the given documents during topic\nextraction. This not only allows for a deeper understanding of documents but also significantly\nimproves the quality of extracted topics. By combining these four layers and leveraging the power\nof Transformer’s contextual embeddings, our model outperforms existing topic techniques such as\nLDA [8], Embedded Topic Model (ETM) [12], Correlated Topic Model (CTM) [13], and BERTopic\n[11]. Our work makes the following contributions.\n• Developing a novel semantic-driven topic modeling technique for an end-to-end topic extrac-\ntion process.\n• We extract quality and coherent topics leveraging rich contextual information about word\nusage available within the document.\n",
          "0.7686\n7\nhealthcare, hospital, doctor, patient, treatment, disease, research, vaccine,\nmedicine, clinic\n0.7780\n8\neducation, school, student, university, teacher, curriculum, learning, exam,\ndegree, research\n0.7048\n9\nfinance, banking, interest, loan, credit, debt, mortgage, investment, rate,\naccount\n0.7113\n10\ntravel, destination, tourism, flight, hotel, vacation, trip, itinerary, tourist,\nbooking\n0.7202\n11\nenvironment, climate, pollution, conservation, wildlife, sustainability, en-\nergy, emission, ecosystem, habitat\n0.6290\n12\neconomy, growth, recession, inflation, employment, market, GDP, sector,\ntrade, investment\n0.5249\n13\nfashion, design, trend, style, collection, brand, runway, model, fabric, acces-\nsory\n0.5888\n14\nscience, research, discovery, experiment, theory, laboratory, innovation,\ntechnology, study, data\n0.6870\n15\nspace, planet, mission, satellite, NASA, astronomy, galaxy, launch, explo-\nration, rocket\n0.6750\n16\nlaw, court, legal, case, judge, lawyer, trial, justice, verdict, crime\n0.7174\n17\npolitics, election, candidate, debate, policy, government, vote, campaign,\nparty, issue\n0.6904\n18\nculture, tradition, festival, heritage, community, art, history, celebration,\ncustom, belief\n0.8849\n19\nsocial, media, platform, network, content, user, engagement, post, trend,\ndigital\n0.7712\n20\nautomotive, car, vehicle, engine, model, manufacturer, technology, design,\nperformance, fuel\n0.6570\nAverage Topic Coherence\n0.7150\nTable A.5: Topics, top 10 topic words, and c v individual topic coherence scores for BBC News datasets, with overall\ntopic coherence score as the average of individual scores.\n14\n\nTopic\nNo.\nTopic words\nTC\n1\ncampaign, election, vote, win, rally, support, candidate, primaries, poll,\n",
          "we determined that a minimum cluster size of 10 returns the best results for 20 newsgroup and\nBBCNews datasets and 8 for Trump’s Twitt dataset. We notice that larger values increase the\nlikelihood of merging unrelated sentence clusters. Using cosine similarity, we computed the topics\n9\n\nfor each identified dense area or cluster. Topics exhibiting high cosine similarity values, indicating\nclose to 1, are considered highly similar. Depending on the desired level of reduction, the users can\nset a threshold similarity score for the user-specified values to their preferences. For example in\nTable 4, we can merge topics 7 and 17 into the ’hardware’ category, and merge topics 16 and 18\ninto the ’software’ category.\n4.8. Limitation of the Study\nTraditional topic modeling techniques depend on the frequency of words. Our semantic-driven\ntopic modeling technique focuses on the meaning of words and documents instead of their surface\ncharacteristics, which is our study’s greatest strength and new paradigm shift in the topic modeling\nstudy. Our model has a limitation in detecting latent subtopics. Latent subtopics are topics that\nare not directly stated but are suggested. For example, consider the customer feedback about the\nApple Smartphone and the model identified explicit topics such as camera quality, screen size,\nbattery life, storage, and processing speed. However, our model does not detect latent subtopics\nlike the user’s overall satisfaction. This subtopic identification is a common challenge for many\ntopic modeling techniques and is an open research area.\n5. Conclusion\nWe have introduced a novel approach to topic modeling that leverages the rich contextual\ninformation provided by transformer models to generate topics from a collection of documents.\nThe model employs the SBERT to obtain sentence embeddings, reduces the dimensions of these\nsentence embeddings, identifies semantically similar dense sentence vector spaces using a density-\nbased clustering algorithm, and extracts coherent topics that represent these semantically dense\nareas or clusters. Our experiments have shown that the proposed model achieves competitive results\nand performance compared to various existing models across different datasets.\nReferences\n[1] D. M. Blei, Probabilistic topic models, Communications of the ACM 55 (4) (2012) 77–84.\n[2] M. Y. Rodriguez, H. Storer, A computational social science perspective on qualitative data\n",
          "Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and\nClustering Algorithms\nMelkamu Abay Mershaa, Mesay Gemeda yigezub, Jugal Kalitaa\naDepartment of Computer Science, University of Colorado Colorado Springs (UCCS), Colorado Springs, USA\nbInstituto Polit´ecnico Nacional (IPN), Centro de Investigaci´on en Computaci´on (CIC), Mexico city, Mexico\nAbstract\nTopic modeling is a powerful technique to discover hidden topics and patterns within a collection\nof documents without prior knowledge. Traditional topic modeling and clustering-based techniques\nencounter challenges in capturing contextual semantic information. This study introduces an inno-\nvative end-to-end semantic-driven topic modeling technique for the topic extraction process, utiliz-\ning advanced word and document embeddings combined with a powerful clustering algorithm. This\nsemantic-driven approach represents a significant advancement in topic modeling methodologies. It\nleverages contextual semantic information to extract coherent and meaningful topics. Specifically,\nour model generates document embeddings using pre-trained transformer-based language models,\nreduces the dimensions of the embeddings, clusters the embeddings based on semantic similar-\nity, and generates coherent topics for each cluster. Compared to ChatGPT and traditional topic\nmodeling algorithms, our model provides more coherent and meaningful topics.\nKeywords:\nTopic Modeling, Semantic, Cluster, Transformer-Based Embeddings, Transformer,\nTopic Extraction, Semantic-Driven, Deep Learning, Natural Language Processing.\n1. Introduction\nTopic modeling is a powerful technique used to discover hidden topics or latent thematic pat-\nterns within a collection of documents without prior knowledge [1]. Topic modeling helps extract\nsignificant and meaningful topics from documents and provides valuable insights into the docu-\nment’s ideas. Topic modeling is essential in natural language processing and machine learning for\nreasons such as data exploration and understanding [2], document organization and summarization\n[3], information retrieval [4], recommendation systems, content analysis [5], market research and\ncustomer insights [6], and textual data preprocessing [7].\nTraditional topic modeling methods such as Latent Dirichlet Allocation (LDA) [8], Non-Negative\n",
          "mat\nChunk 2\nJPEG, GIF, Quantization, Colors, Display, Image, Quality, Hardware, Palette,\nLossiness\nChunk 3\nJPEG, GIF, colors, quantization, display, hardware, image, palette, conversion,\nquality\nChunk 4\nJPEG, Compression, Huffman, Arithmetic, Coding, File, Format, Header,\nQuality, Data\nChunk 5\nJPEG, Compression, Decompression, Quality, Error, GIF, Conversion, Image,\nDegradation, Format\nTable 3: One topic in each chunk with top 10 words, chunks from 20 newsgroup datasets.\nreduced dimensions. Figure 1(b) illustrates the semantic clusters within the input dataset, high-\nlighting outliers through HDBSCAN outlier detection. Figure 1(c) presents the semantic clusters\nof the 20 newsgroup documents, excluding the outliers. Finally, the hidden topics are extracted\nfrom each cluster, and the top 10 words from each cluster are presented in Table 4.\n(a)\n(b)\n(c)\nFigure 2: (a) Dimensionality reduction of 384-dimensional sentence vectors from the 20 newsgroups dataset to 2\ndimensions with UMAP. (b) Highlighting semantically similar dense sentence areas via HDBSCAN clustering in\ndimensionally reduced sentence vectors from the 20 newsgroups dataset.\nScattered red points indicate sentences\nlabeled as noise or outliers. (c) Semantically similar dense sentence areas, excluding outlier sentences (HDBSCAN\nnoise removal capability), were identified with HDBSCAN from the 20 newsgroups dataset.\n4.6. Model Performance\nOur model exhibits several notable strengths compared to the other topic models we compared\nwith this study. The utilization of end-to-end embedding approaches for topic modeling provides\nmany advantages to our model. First, our model is adaptable to different language models since\nit depends on embedding spaces for clustering, enabling it to stay at the forefront of advances in\nembedding techniques, ensuring its continuous upgrading and scalability in line with the latest\ndevelopments in the field. Second, the most significant strength lies in cluster-based vocabulary\nconstruction and contextual similarity computation. These processes leverage the inherent con-\ntextual similarity among words and sentences within clusters, empowering the model to generate\ncoherent and meaningful topics consistently.\n",
          "unique words associated with their embeddings. In the third step, the average semantic similarity\nof each unique word within the cluster is computed by comparing it with each sentence’s semantic\ninformation. This process provides an average of representative semantic similarity values for each\ntopic word in that cluster (Equation 1). A cluster consists of a collection of n unique words, repre-\nsented as vocabulary W, accompanied by a set of N contextually similar sentences denoted as S.\nTo determine the representativeness of each word within the cluster, we calculate the average sim-\nilarity between each word and all the sentences in the cluster; we can use cosine/Jaccard/Euclidea\nsimilarity measurement, defined by:\nave cos sim( ⃗wi) = 1\nN\nN\nX\nj=1\ncos( ⃗wi, ⃗sj)\n(1)\nwhere, ⃗wi is the embedding vector of the ith word in the vocabulary W and ⃗sj is the embedding\nvector of the jth sentence in the set S.\nThe candidate topic words are organized and sorted based on the average semantic similarity values.\nThe top k words are selected from each cluster. This process enables the extraction of topics from\neach cluster with enhanced accuracy and relevance of topic words specific to that cluster. After the\ntopics are extracted, it is essential to consider how much each topic differs from others. Hence, we\n4\n\nmerge the least ranked topic with its most similar counterparts through an iterative process using\nsimilarity measures. This iterative process helps reduce the number of topics to a user-specified\nvalue. Algorithm 1 presents a high-level overview of our model.\nAlgorithm 1 Topic Extraction\n1: Input: Documents\n2: Create sentence embeddings\n3: Reduce sentence embedding dimensions\n4: Create clusters\n5: for cluster = 1, 2, ..., C do /* C is total number of cluster\n6:\nPreprocess each cluster\n7:\nBuild a vocabulary\n8:\nCreate word embeddings list\n9:\nfor word = 1, 2, ..., W do /* W is total number of words in the vocabulary\n10:\nfor sentence = 1, 2, ..., S do /* S is total number of sentences in the cluster\n",
          "4.4.2. ChatGPT\nGPT, developed for various NLP tasks such as translation, language processing, and question-\nanswering, is described in [38]. While GPT is not explicitly designed for topic modeling and lacks\nintegrated topic modeling algorithms, ChatGPT can generate topics and explanations by leveraging\nthe rich information base in its embedding space. We conducted extensive experiments through\nprogramming and conversation to compare our model with ChatGPT. We split a large dataset into\nsmaller chunks to overcome the token limit, resulting in other challenges. First, we lose critical\nlatent themes and patterns in the document. Second, ChatGPT is stateless; it does not remember\npast API interactions for each chunk, particularly in multi-turn conversations, and it is difficult to\nprocess sequential data. We broke down a similar section of the 20 newsgroup datasets into chunks\nand extracted one topic from each chunk (Table\n3). The topics generated in each chunk may\nnot provide document-wise hidden themes and patterns. ChatGPT does not use any evaluation\nmetrics like topic coherence and topic diversity to assess topic quality. ChatGPT generates granular\ntopics that may need merging or splitting, but it lacks this capability. Our model allows easy topic\nrefinement through adjustable parameters and hyperparameters.\nOur experiments revealed that while ChatGPT performs adequately for small-size input texts, it\nfalls short for large datasets and measuring topic quality and scalability. Compared to our models,\nit lacks reliability, extendability, and security for sensitive information. These limitations highlight\nthe importance of traditional algorithms and ChatGPT and the need for enhanced techniques in\ntopic modeling.\n4.5. Results\nOur model consistently achieves high topic coherence scores across all datasets, as various met-\nrics show. The model exhibits strong coherence scores when applied to preprocessed datasets. The\nresults are shown in Table 1. Experimental results demonstrate that our proposed model outper-\nforms traditional and embedding-based methods, including LDA, ETM, CTM, and BERTopic. For\na visual representation, Figure 1(a) displays the word embedding spaces of the input dataset in\n7\n\nChunks\nTopic words\nChunk 1\nJPEG, software, conversion, display, color, compression, JFIF, hardware, for-\n",
          "11:\nCompute ave cos sim wi with si\n12:\n/ ∗wi is words in a cluster\n13:\n/ ∗si is sentences in a cluster\n14:\nStore the words with score values\n15:\nend for\n16:\nSort words\n17:\nChoose top k words\n18:\nReturn chosen top k words\n19:\nend for\n20: end for\n21: mergedTopics ←∅\n22: for ti in topics do\n/ ∗ti and tj are topics\n23:\nfor tj in topics do\n24:\nIf ti ̸= tj and ti or tj is not merged\n25:\nsimScore = computeSim(ti, tj)\n26:\nif simScore ¿ threshold then\n27:\nnewTopic = merge(ti, tj)\n28:\ntag ti and tj as merged\n29:\nadd newTopic to mergedTopics\n30:\nend if\n31:\nend for\n32: end for\n33: for topic in topics do\n34:\nif topic is not tagged as merged then\n35:\nadd topic to mergedTopics\n36:\nend if\n37: end for\n38: return mergedTopics\n4. Experiments and Results\nIn this section, we briefly discuss the experimental setup, including details about the dataset\nand preprocessing procedures, the model evaluation metrics employed, the performance and results\nof our proposed model, and the results of various model comparisons.\n5\n\n4.1. Experiment setup\nWe used all-MiniLML6-v2 (MiniLM) and all-mpnet-base-v2 (MPNET), two different SBERT\nmodels, in the experiments to encode documents [22]. OCTIS (Optimizing and Comparing Topic\nModels is Simple) is an open-source Python package designed to help optimize and compare topic\nmodels [15, 31]. It comprises a suite of tools and metrics, including topic coherence. We utilized\nOCTIS to conduct the model comparison experiment and validation process.\n4.2. Datasets\nThe 20NewsGroups, BBC News, and Trump’s tweets datasets are used to validate our model.\nThe 20NewsGroups dataset comprises 16,309 news articles categorized into 20 different groups [32].\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_as_similarity_topics",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_as_similarity_topics"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "GRYxQalPJ0FSdzFBYuwrQctIJ0GKjCxBCxwnQZJCLkHRETFBifkwQUEcJ0HnhzBB6sUwQSf8LUEwsyxBm7IzQfBpL0FHmi1B",
          "dtype": "f4"
         },
         "y": {
          "bdata": "XHd0PwKtyD+NaYw/urFmP8kgxj8rCVo/c8bAP2EGWD+C0G4//f14P71cyD9szIA/FEpwP6FgPT/hrV4/tCWVP16ukD/++os/",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "for the covariance matrix CX.\nCX ≡1\nnXXT.\nConsider the matrix CX = 1\nnXXT. The ijth element of CX\nis the dot product between the vector of the ith measurement\ntype with the vector of the jth measurement type. We can\nsummarize several properties of CX:\n• CX is a square symmetric m×m matrix (Theorem 2 of\nAppendix A)\n• The diagonal terms of CX are the variance of particular\nmeasurement types.\n2 Note that in practice, the covariance σ2\nAB is calculated as\n1\nn−1 ∑i aibi. The\nslight change in normalization constant arises from estimation theory, but\nthat is beyond the scope of this tutorial.\n• The off-diagonal terms of CX are the covariance be-\ntween measurement types.\nCX captures the covariance between all possible pairs of mea-\nsurements. The covariance values reﬂect the noise and redun-\ndancy in our measurements.\n• In the diagonal terms, by assumption, large values cor-\nrespond to interesting structure.\n• In the off-diagonal terms large magnitudes correspond\nto high redundancy.\nPretend we have the option of manipulating CX. We will sug-\ngestively deﬁne our manipulated covariance matrix CY. What\nfeatures do we want to optimize in CY?\nD. Diagonalize the Covariance Matrix\nWe can summarize the last two sections by stating that our\ngoals are (1) to minimize redundancy, measured by the mag-\nnitude of the covariance, and (2) maximize the signal, mea-\nsured by the variance. What would the optimized covariance\nmatrix CY look like?\n• All off-diagonal terms in CY should be zero. Thus, CY\nmust be a diagonal matrix. Or, said another way, Y is\ndecorrelated.\n• Each successive dimension in Y should be rank-ordered\naccording to variance.\nThere are many methods for diagonalizing CY. It is curious to\nnote that PCA arguably selects the easiest method: PCA as-\nsumes that all basis vectors {p1,...,pm} are orthonormal, i.e.\n",
          "a diagonal matrix where the ith eigenvalue is placed in the iith\nposition.\nWe will now show that AE = ED.\nWe can examine the\ncolumns of the right-hand and left-hand sides of the equation.\nLeft hand side : AE = [Ae1 Ae2 ... Aen]\nRight hand side : ED = [λ1e1 λ2e2 ... λnen]\nEvidently, if AE = ED then Aei = λiei for all i. This equa-\ntion is the deﬁnition of the eigenvalue equation. Therefore,\nit must be that AE = ED. A little rearrangement provides\nA = EDE−1, completing the ﬁrst part the proof.\nFor the second part of the proof, we show that a symmetric\nmatrix always has orthogonal eigenvectors. For some sym-\nmetric matrix, let λ1 and λ2 be distinct eigenvalues for eigen-\nvectors e1 and e2.\nλ1e1 ·e2 = (λ1e1)Te2\n= (Ae1)Te2\n= e1TATe2\n= e1TAe2\n= e1T(λ2e2)\nλ1e1 ·e2 = λ2e1 ·e2\nBy the last relation we can equate that (λ1 −λ2)e1 ·e2 = 0.\nSince we have conjectured that the eigenvalues are in fact\nunique, it must be the case that e1 · e2 = 0. Therefore, the\neigenvectors of a symmetric matrix are orthogonal.\nLet us back up now to our original postulate that A is a sym-\nmetric matrix.\nBy the second part of the proof, we know\nthat the eigenvectors of A are all orthonormal (we choose\nthe eigenvectors to be normalized). This means that E is an\northogonal matrix so by theorem 1, ET = E−1 and we can\nrewrite the ﬁnal result.\nA = EDET\n. Thus, a symmetric matrix is diagonalized by a matrix of its\neigenvectors.\n5.\nFor any arbitrary m × n matrix X, the symmetric\n",
          "matrix XTX has a set of orthonormal eigenvectors\nof {ˆv1, ˆv2,..., ˆvn} and a set of associated eigenvalues\n{λ1,λ2,...,λn}.\nThe set of vectors {Xˆv1,Xˆv2,...,Xˆvn}\nthen form an orthogonal basis, where each vector Xˆvi is of\nlength √λi.\nAll of these properties arise from the dot product of any two\nvectors from this set.\n(Xˆvi)·(Xˆvj) = (Xˆvi)T(Xˆvj)\n= ˆvT\ni XTXˆvj\n= ˆvT\ni (λj ˆvj)\n= λj ˆvi · ˆvj\n(Xˆvi)·(Xˆvj) = λjδij\nThe last relation arises because the set of eigenvectors of X is\northogonal resulting in the Kronecker delta. In more simpler\nterms the last relation states:\n(Xˆvi)·(Xˆvj) =\n\u001a\nλj i = j\n0\ni ̸= j\nThis equation states that any two vectors in the set are orthog-\nonal.\nThe second property arises from the above equation by realiz-\ning that the length squared of each vector is deﬁned as:\n∥Xˆvi∥2 = (Xˆvi)·(Xˆvi) = λi\nAppendix B: Code\nThis code is written for Matlab 6.5 (Release 13) from\nMathworks8.\nThe code is not computationally efﬁ-\ncient but explanatory (terse comments begin with a %).\nThis ﬁrst version follows Section 5 by examining the\ncovariance of the data set.\nfunction [signals,PC,V] = pca1(data)\n% PCA1: Perform PCA using covariance.\n%\ndata - MxN matrix of input data\n%\n(M dimensions, N trials)\n",
          "more precise.\nX = UΣVT\nUTX = ΣVT\nUTX = Z\nwhere we have deﬁned Z ≡ΣVT.\nNote that the previous\ncolumns {ˆu1, ˆu2,..., ˆun} are now rows in UT. Comparing this\nequation to Equation 1, {ˆu1, ˆu2,..., ˆun} perform the same role\nas {ˆp1, ˆp2,..., ˆpm}. Hence, UT is a change of basis from X to\nZ. Just as before, we were transforming column vectors, we\ncan again infer that we are transforming column vectors. The\nfact that the orthonormal basis UT (or P) transforms column\nvectors means that UT is a basis that spans the columns of X.\nBases that span the columns are termed the column space of\nX. The column space formalizes the notion of what are the\npossible “outputs” of any matrix.\nThere is a funny symmetry to SVD such that we can deﬁne a\nsimilar quantity - the row space.\nXV = ΣU\n(XV)T = (ΣU)T\nVTXT = UTΣ\nVTXT = Z\nwhere we have deﬁned Z ≡UTΣ. Again the rows of VT (or\nthe columns of V) are an orthonormal basis for transforming\nXT into Z. Because of the transpose on X, it follows that V\nis an orthonormal basis spanning the row space of X. The\nrow space likewise formalizes the notion of what are possible\n“inputs” into an arbitrary matrix.\nWe are only scratching the surface for understanding the full\nimplications of SVD. For the purposes of this tutorial though,\nwe have enough information to understand how PCA will fall\nwithin this framework.\nC. SVD and PCA\nIt is evident that PCA and SVD are intimately related. Let us\nreturn to the original m × n data matrix X. We can deﬁne a\n\n9\nQuick Summary of PCA\n1. Organize data as an m×n matrix, where m is the number\nof measurement types and n is the number of samples.\n",
          "the original basis, that best re-expresses our data set?\nA close reader might have noticed the conspicuous addition of\nthe word linear. Indeed, PCA makes one stringent but power-\nful assumption: linearity. Linearity vastly simpliﬁes the prob-\nlem by restricting the set of potential bases. With this assump-\ntion PCA is now limited to re-expressing the data as a linear\ncombination of its basis vectors.\nLet X be the original data set, where each column is a single\nsample (or moment in time) of our data set (i.e. ⃗X). In the toy\nexample X is an m × n matrix where m = 6 and n = 72000.\nLet Y be another m × n matrix related by a linear transfor-\nmation P. X is the original recorded data set and Y is a new\nrepresentation of that data set.\nPX = Y\n(1)\nAlso let us deﬁne the following quantities.1\n• pi are the rows of P\n• xi are the columns of X (or individual ⃗X).\n• yi are the columns of Y.\nEquation 1 represents a change of basis and thus can have\nmany interpretations.\n1. P is a matrix that transforms X into Y.\n2. Geometrically, P is a rotation and a stretch which again\ntransforms X into Y.\n3. The rows of P, {p1,...,pm}, are a set of new basis vec-\ntors for expressing the columns of X.\nThe latter interpretation is not obvious but can be seen by writ-\ning out the explicit dot products of PX.\nPX =\n\n\np1\n...\npm\n\n\n\u0002 x1 ··· xn\n\u0003\nY =\n\n\np1 ·x1 ···\np1 ·xn\n...\n...\n...\npm ·x1 ··· pm ·xn\n\n\n1 In this section xi and yi are column vectors, but be forewarned. In all other\nsections xi and yi are row vectors.\n",
          "3. A matrix is symmetric if and only if it is orthogonally\ndiagonalizable.\nBecause this statement is bi-directional, it requires a two-part\n“if-and-only-if” proof. One needs to prove the forward and\nthe backwards “if-then” cases.\nLet us start with the forward case. If A is orthogonally di-\nagonalizable, then A is a symmetric matrix. By hypothesis,\northogonally diagonalizable means that there exists some E\nsuch that A = EDET, where D is a diagonal matrix and E is\nsome special matrix which diagonalizes A. Let us compute\nAT.\nAT = (EDET)T = ETTDTET = EDET = A\nEvidently, if A is orthogonally diagonalizable, it must also be\nsymmetric.\nThe reverse case is more involved and less clean so it will be\nleft to the reader. In lieu of this, hopefully the “forward” case\nis suggestive if not somewhat convincing.\n4. A symmetric matrix is diagonalized by a matrix of its\northonormal eigenvectors.\nLet A be a square n×n symmetric matrix with associated\neigenvectors {e1,e2,...,en}. Let E = [e1 e2 ... en] where the\nith column of E is the eigenvector ei. This theorem asserts that\nthere exists a diagonal matrix D such that A = EDET.\nThis proof is in two parts. In the ﬁrst part, we see that the\nany matrix can be orthogonally diagonalized if and only if\nit that matrix’s eigenvectors are all linearly independent. In\nthe second part of the proof, we see that a symmetric matrix\n\n11\nhas the special property that all of its eigenvectors are not just\nlinearly independent but also orthogonal, thus completing our\nproof.\nIn the ﬁrst part of the proof, let A be just some matrix, not\nnecessarily symmetric, and let it have independent eigenvec-\ntors (i.e. no degeneracy). Furthermore, let E = [e1 e2 ... en]\nbe the matrix of eigenvectors placed in the columns. Let D be\n",
          "= (PPT)D(PPT)\n= (PP−1)D(PP−1)\nCY = D\nIt is evident that the choice of P diagonalizes CY. This was\nthe goal for PCA. We can summarize the results of PCA in the\nmatrices P and CY.\n• The principal components of X are the eigenvectors of\nCX = 1\nnXXT.\n• The ith diagonal value of CY is the variance of X along\npi.\nIn practice computing PCA of a data set X entails (1) subtract-\ning off the mean of each measurement type and (2) computing\nthe eigenvectors of CX. This solution is demonstrated in Mat-\nlab code included in Appendix B.\n3 The matrix A might have r ≤m orthonormal eigenvectors where r is the\nrank of the matrix. When the rank of A is less than m, A is degenerate or all\ndata occupy a subspace of dimension r ≤m. Maintaining the constraint of\northogonality, we can remedy this situation by selecting (m−r) additional\northonormal vectors to “ﬁll up” the matrix E. These additional vectors\ndo not effect the ﬁnal solution because the variances associated with these\ndirections are zero.\n\n7\nVI. A MORE GENERAL SOLUTION USING SVD\nThis section is the most mathematically involved and can be\nskipped without much loss of continuity. It is presented solely\nfor completeness. We derive another algebraic solution for\nPCA and in the process, ﬁnd that PCA is closely related to\nsingular value decomposition (SVD). In fact, the two are so\nintimately related that the names are often used interchange-\nably. What we will see though is that SVD is a more general\nmethod of understanding change of basis.\nWe begin by quickly deriving the decomposition. In the fol-\nlowing section we interpret the decomposition and in the last\nsection we relate these results to PCA.\nA. Singular Value Decomposition\nLet X be an arbitrary n × m matrix4 and XTX be a rank r,\nsquare, symmetric m×m matrix. In a seemingly unmotivated\n",
          "cussion).\nIII. The principal components are orthogonal.\nThis assumption provides an intuitive simpliﬁca-\ntion that makes PCA soluble with linear algebra\ndecomposition techniques. These techniques are\nhighlighted in the two following sections.\nWe have discussed all aspects of deriving PCA - what remain\nare the linear algebra solutions. The ﬁrst solution is some-\nwhat straightforward while the second solution involves un-\nderstanding an important algebraic decomposition.\nV. SOLVING PCA USING EIGENVECTOR DECOMPOSITION\nWe derive our ﬁrst algebraic solution to PCA based on an im-\nportant property of eigenvector decomposition. Once again,\nthe data set is X, an m × n matrix, where m is the number of\nmeasurement types and n is the number of samples. The goal\nis summarized as follows.\nFind some orthonormal matrix P in Y = PX such\nthat CY ≡1\nnYYT is a diagonal matrix. The rows\nof P are the principal components of X.\nWe begin by rewriting CY in terms of the unknown variable.\nCY = 1\nnYYT\n= 1\nn(PX)(PX)T\n= 1\nnPXXTPT\n= P(1\nnXXT)PT\nCY = PCXPT\nNote that we have identiﬁed the covariance matrix of X in the\nlast line.\nOur plan is to recognize that any symmetric matrix A is diag-\nonalized by an orthogonal matrix of its eigenvectors (by The-\norems 3 and 4 from Appendix A). For a symmetric matrix A\nTheorem 4 provides A = EDET, where D is a diagonal matrix\nand E is a matrix of eigenvectors of A arranged as columns.3\nNow comes the trick. We select the matrix P to be a matrix\nwhere each row pi is an eigenvector of 1\nnXXT. By this selec-\ntion, P ≡ET. With this relation and Theorem 1 of Appendix\nA (P−1 = PT) we can ﬁnish evaluating CY.\nCY = PCXPT\n= P(ETDE)PT\n= P(PTDP)PT\n",
          "Pretend we gathered our toy example data above, but only\nlooked at camera A. What is an orthonormal basis for (xA,yA)?\nA naive choice would be {(1,0),(0,1)}, but why select this\nbasis over {(\n√\n2\n2 ,\n√\n2\n2 ),( −\n√\n2\n2 , −\n√\n2\n2 )} or any other arbitrary rota-\ntion? The reason is that the naive basis reﬂects the method we\ngathered the data. Pretend we record the position (2,2). We\ndid not record 2\n√\n2 in the (\n√\n2\n2 ,\n√\n2\n2 ) direction and 0 in the per-\npendicular direction. Rather, we recorded the position (2,2)\non our camera meaning 2 units up and 2 units to the left in our\ncamera window. Thus our original basis reﬂects the method\nwe measured our data.\nHow do we express this naive basis in linear algebra? In the\ntwo dimensional case, {(1,0),(0,1)} can be recast as individ-\nual row vectors. A matrix constructed out of these row vectors\nis the 2×2 identity matrix I. We can generalize this to the m-\ndimensional case by constructing an m×m identity matrix\nB =\n\n\nb1\nb2\n...\nbm\n\n=\n\n\n1 0 ··· 0\n0 1 ··· 0\n...\n...\n...\n...\n0 0 ··· 1\n\n= I\nwhere each row is an orthornormal basis vector bi with m\ncomponents. We can consider our naive basis as the effective\nstarting point. All of our data has been recorded in this basis\n\n3\nand thus it can be trivially expressed as a linear combination\nof {bi}.\nB. Change of Basis\nWith this rigor we may now state more precisely what PCA\nasks: Is there another basis, which is a linear combination of\n",
          "fashion, let us deﬁne all of the quantities of interest.\n• {ˆv1, ˆv2,..., ˆvr} is the set of orthonormal m × 1 eigen-\nvectors with associated eigenvalues {λ1,λ2,...,λr} for\nthe symmetric matrix XTX.\n(XTX)ˆvi = λiˆvi\n• σi ≡√λi are positive real and termed the singular val-\nues.\n• {ˆu1, ˆu2,..., ˆur} is the set of n × 1 vectors deﬁned by\nˆui ≡1\nσi Xˆvi.\nThe ﬁnal deﬁnition includes two new and unexpected proper-\nties.\n• ˆui · ˆuj =\n\u001a\n1\nif i = j\n0\notherwise\n• ∥Xˆvi∥= σi\nThese properties are both proven in Theorem 5. We now have\nall of the pieces to construct the decomposition. The scalar\nversion of singular value decomposition is just a restatement\nof the third deﬁnition.\nXˆvi = σi ˆui\n(3)\nThis result says a quite a bit.\nX multiplied by an eigen-\nvector of XTX is equal to a scalar times another vector.\n4 Notice that in this section only we are reversing convention from m×n to\nn×m. The reason for this derivation will become clear in section 6.3.\nThe set of eigenvectors {ˆv1, ˆv2,..., ˆvr} and the set of vec-\ntors {ˆu1, ˆu2,..., ˆur} are both orthonormal sets or bases in r-\ndimensional space.\nWe can summarize this result for all vectors in one matrix\nmultiplication by following the prescribed construction in Fig-\nure 4. We start by constructing a new diagonal matrix Σ.\n",
          "Σ ≡\n\n\nσ˜1\n...\n0\nσ˜r\n0\n0\n...\n0\n\n\nwhere σ˜1 ≥σ˜2 ≥... ≥σ˜r are the rank-ordered set of singu-\nlar values. Likewise we construct accompanying orthogonal\nmatrices,\nV =\n\u0002\nˆv˜1 ˆv˜2 ... ˆv ˜m\n\u0003\nU =\n\u0002\nˆu˜1 ˆu˜2 ... ˆu˜n\n\u0003\nwhere we have appended an additional (m−r) and (n−r) or-\nthonormal vectors to “ﬁll up” the matrices for V and U respec-\ntively (i.e. to deal with degeneracy issues). Figure 4 provides\na graphical representation of how all of the pieces ﬁt together\nto form the matrix version of SVD.\nXV = UΣ\nwhere each column of V and U perform the scalar version of\nthe decomposition (Equation 3). Because V is orthogonal, we\ncan multiply both sides by V−1 = VT to arrive at the ﬁnal form\nof the decomposition.\nX = UΣVT\n(4)\nAlthough derived without motivation, this decomposition is\nquite powerful. Equation 4 states that any arbitrary matrix X\ncan be converted to an orthogonal matrix, a diagonal matrix\nand another orthogonal matrix (or a rotation, a stretch and a\nsecond rotation). Making sense of Equation 4 is the subject of\nthe next section.\nB. Interpreting SVD\nThe ﬁnal form of SVD is a concise but thick statement. In-\nstead let us reinterpret Equation 3 as\nXa = kb\nwhere a and b are column vectors and k is a scalar con-\nstant. The set {ˆv1, ˆv2,..., ˆvm} is analogous to a and the set\n",
          "2. Subtract off the mean for each measurement type.\n3. Calculate the SVD or the eigenvectors of the covariance.\nFIG. 5 A step-by-step instruction list on how to perform principal\ncomponent analysis\nnew matrix Y as an n×m matrix.5\nY ≡1\n√nXT\nwhere each column of Y has zero mean. The choice of Y\nbecomes clear by analyzing YTY.\nYTY =\n\u0012 1\n√nXT\n\u0013T \u0012 1\n√nXT\n\u0013\n= 1\nnXXT\nYTY = CX\nBy construction YTY equals the covariance matrix of X. From\nsection 5 we know that the principal components of X are\nthe eigenvectors of CX. If we calculate the SVD of Y, the\ncolumns of matrix V contain the eigenvectors of YTY = CX.\nTherefore, the columns of V are the principal components of\nX. This second algorithm is encapsulated in Matlab code in-\ncluded in Appendix B.\nWhat does this mean? V spans the row space of Y ≡\n1\n√nXT.\nTherefore, V must also span the column space of\n1\n√nX. We\ncan conclude that ﬁnding the principal components amounts\nto ﬁnding an orthonormal basis that spans the column space\nof X.6\nVII. DISCUSSION\nPrincipal component analysis (PCA) has widespread applica-\ntions because it reveals simple underlying structures in com-\nplex data sets using analytical solutions from linear algebra.\nFigure 5 provides a brief summary for implementing PCA.\nA primary beneﬁt of PCA arises from quantifying the impor-\ntance of each dimension for describing the variability of a data\nset. In particular, the measurement of the variance along each\n5 Y is of the appropriate n×m dimensions laid out in the derivation of section\n6.1. This is the reason for the “ﬂipping” of dimensions in 6.1 and Figure 4.\n6 If the ﬁnal goal is to ﬁnd an orthonormal basis for the coulmn space of\nX then we can calculate it directly without constructing Y. By symmetry\nthe columns of U produced by the SVD of\n",
          "arbitrarily higher dimensions? Consider two sets of measure-\nments with zero means\nA = {a1,a2,...,an} , B = {b1,b2,...,bn}\nwhere the subscript denotes the sample number. The variance\nof A and B are individually deﬁned as,\nσ2\nA = 1\nn ∑\ni\na2\ni ,\nσ2\nB = 1\nn ∑\ni\nb2\ni\nThe covariance between A and B is a straight-forward gener-\nalization.\ncovariance of A and B ≡σ2\nAB = 1\nn ∑\ni\naibi\n\n5\nThe covariance measures the degree of the linear relationship\nbetween two variables. A large positive value indicates pos-\nitively correlated data. Likewise, a large negative value de-\nnotes negatively correlated data. The absolute magnitude of\nthe covariance measures the degree of redundancy. Some ad-\nditional facts about the covariance.\n• σAB is zero if and only if A and B are uncorrelated (e.g.\nFigure 2, left panel).\n• σ2\nAB = σ2\nA if A = B.\nWe can equivalently convert A and B into corresponding row\nvectors.\na = [a1 a2 ... an]\nb = [b1 b2 ... bn]\nso that we may express the covariance as a dot product matrix\ncomputation.2\nσ2\nab ≡1\nnabT\n(2)\nFinally, we can generalize from two vectors to an arbitrary\nnumber. Rename the row vectors a and b as x1 and x2, respec-\ntively, and consider additional indexed row vectors x3,...,xm.\nDeﬁne a new m×n matrix X.\nX =\n\n\nx1\n...\nxm\n\n\nOne interpretation of X is the following. Each row of X corre-\nsponds to all measurements of a particular type. Each column\nof X corresponds to a set of measurements from one particular\ntrial (this is ⃗X from section 3.1). We now arrive at a deﬁnition\n",
          "{ˆu1, ˆu2,..., ˆun} is analogous to b. What is unique though is\nthat {ˆv1, ˆv2,..., ˆvm} and {ˆu1, ˆu2,..., ˆun} are orthonormal sets\nof vectors which span an m or n dimensional space, respec-\ntively. In particular, loosely speaking these sets appear to span\n\n8\nThe scalar form of SVD is expressed in equation 3.\nXˆvi = σi ˆui\nThe mathematical intuition behind the construction of the matrix form is that we want to express all n scalar equations in just one\nequation. It is easiest to understand this process graphically. Drawing the matrices of equation 3 looks likes the following.\nWe can construct three new matrices V, U and Σ. All singular values are ﬁrst rank-ordered σ˜1 ≥σ˜2 ≥... ≥σ˜r, and the corre-\nsponding vectors are indexed in the same rank order. Each pair of associated vectors ˆvi and ˆui is stacked in the ith column along\ntheir respective matrices. The corresponding singular value σi is placed along the diagonal (the iith position) of Σ. This generates\nthe equation XV = UΣ, which looks like the following.\nThe matrices V and U are m × m and n × n matrices respectively and Σ is a diagonal matrix with a few non-zero values (repre-\nsented by the checkerboard) along its diagonal. Solving this single matrix equation solves all n “value” form equations.\nFIG. 4 Construction of the matrix form of SVD (Equation 4) from the scalar form (Equation 3).\nall possible “inputs” (i.e. a) and “outputs” (i.e. b). Can we\nformalize the view that {ˆv1, ˆv2,..., ˆvn} and {ˆu1, ˆu2,..., ˆun}\nspan all possible “inputs” and “outputs”?\nWe can manipulate Equation 4 to make this fuzzy hypothesis\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_cx_xtx_nxxt",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_cx_xtx_nxxt"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "rJkYQWUcHUG/BiRBKbYiQUltGUFL2hpBVb8YQZOyG0ERQRlB7rIjQfVuI0ExTRlB5LYaQXJFI0E2fR1B",
          "dtype": "f4"
         },
         "y": {
          "bdata": "PrJUwGesXsB3D2jAl3towLuqUMDpCVfA6+lPwDGmW8ClEk/AI9FowFx+aMCOy0/AaRRVwCjQasBX8lvA",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "10\n3.1.1\nData\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.1.2\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n3.1.3\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2\nDomain-Specific SFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2.1\nData\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2.2\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.2.3\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.3\nLong Context\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3.1\nData\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3.2\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3.3\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
          "21\n3.7\nFinal Combination Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.8\nPost-Training Configuration Summary . . . . . . . . . . . . . . . . . . . . . .\n22\n3.9\nFull Evaluation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.10 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.10.1 Data Generation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.10.2 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.10.3 Results and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4\nVision\n28\n4.1\nArchitecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n4.2\nGeneral Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n4.3\nThai OCR Enhancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n4.3.1\nData Sources: Thai Book and Thai Financial\n. . . . . . . . . . . . . .\n29\n4.3.2\nAgentic Framework for Thai VQA Data Curation\n. . . . . . . . . . .\n30\n",
          "42\n5.3.3\nUnit Vocoder\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n5.3.4\nData\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n5.3.5\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n5.3.6\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n5.4\nEnd-to-End Speech-to-Speech Evaluation . . . . . . . . . . . . . . . . . . . .\n45\n6\nConclusions\n46\n7\nAcknowledgments\n46\n3\n\nTechnical Report\n1\nIntroduction\nFoundation models are general models which can serve as the backbone in a wide range\nof AI applications involving language, vision, speech, and other modalities. There are\na number of widely popular language model families, including open1 families such as\nLlama 3 (Grattafiori et al., 2024), Qwen2.5 (Yang et al., 2024a), Phi 3 (Abdin et al., 2024)\nand proprietary families, such as GPT-4o, Claude 3, Gemini 1.5. However, although these\nmodels are multilingual and can work in a range of languages, they are developed as\nEnglish-centric. Hence, the community has considered enhancing the performance of open\nfoundation models on a small set of languages for their country or region.\nIn South East Asia (SEA), the efforts to enhance foundation language models for SEA\nlanguages include SeaLLM (Zhang et al., 2024), SEA-LION (Singapore, 2024), and\nSailor (Dou et al., 2024).\nWhen it comes to the Thai language, there are model fam-\nilies such as WangChan (Polpanumas et al., 2023), Typhoon (Pipatanakul et al., 2023),\n",
          "16\n3.4\nFunction Calling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4.1\nData\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4.2\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.4.3\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.5\nDistillation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.5.1\nTop-k Logits Distillation . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.5.2\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2\n\nTechnical Report\n3.5.3\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.6\nModel Merging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.6.1\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.6.2\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
          "4.4\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.5\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5\nAudio & Speech\n35\n5.1\nEnd-to-End Model Architecture . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n5.2\nSpeech Encoding\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n5.2.1\nSpeech Encoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n5.2.2\nData\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n5.2.3\nExperimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n5.2.4\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n5.3\nSpeech Generation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n5.3.1\nSpeech Decoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n5.3.2\nDiscrete Speech Tokens\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n",
          "5\n2.1.2\nTyphoon 1 General Corpus\n. . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.2\nGathering Diverse and High-Quality Thai Documents . . . . . . . . . . . . .\n5\n2.2.1\nCulturally Relevant Thai Text . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2.2\nHigh-Quality Text Selection . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2.3\nSynthetic Textbook . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2.4\nHigh-Educational Content . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2.5\nOther High-Quality Sources . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.3\nData Mixture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.4\nTraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.5\nEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.6\nResults and Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n3\nPost-training\n10\n3.1\nGeneral Supervised Fine Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . .\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_are_of_33",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "7_are_of_33"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "MLFywT+xcsFQPnLBxftywcjlcsGHc3LB+ahywQ==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "zVvRPkNd0T7l/sI+1K7aPnzs1z5Zo8k+xFPQPg==",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "0.785 (± 0.014)\n0.805 (± 0.013)\n0.624 (± 0.013)\n0.565 (± 0.016)\n400\n0.801 (± 0.013)\n0.780 (± 0.013)\n0.796 (± 0.013)\n0.612 (± 0.011)\n0.564 (± 0.017)\n800\n0.784 (± 0.011)\n0.767 (± 0.014)\n0.771 (± 0.014)\n0.600 (± 0.012)\n0.560 (± 0.017)\n1600\n0.754 (± 0.011)\n0.747 (± 0.013)\n0.742 (± 0.013)\n0.580 (± 0.014)\n0.550 (± 0.017)\n3200\n0.727 (± 0.011)\n0.730 (± 0.011)\n0.726 (± 0.012)\n0.542 (± 0.014)\n0.533 (± 0.017)\nTable 2: kNN Classiﬁer accuracy for varying values of k over the embedding\nspaces of Shutle, MNIST and Fashion-MNIST datasets. Average accuracy scores\nare given over a 10-fold or 20-fold cross-validation for each of PCA, Laplacian\nEigenmaps, LargeVis, t-SNE and UMAP.\n32\n\nFigure 5: kNN Classiﬁer accuracy for varying values of k over the embedding\nspaces of COIL-20 and PenDigits datasets. Accuracy scores are given for each\nfold of a 10-fold cross-validation for each of PCA, Laplacian Eigenmaps, LargeVis,\nt-SNE and UMAP. We note that UMAP produces competitive accuracy scores to\nt-SNE and LargeVis for most cases, and outperforms both t-SNE and LargeVis for\nlarger k values on COIL-20.\nvariety of uses cases, so establishing some measure of how stable UMAP\nembeddings are, particularly under sub-sampling, is of interest. In this sub-\n",
          "0.904 (± 0.007)\n0.918 (± 0.006)\n0.792 (± 0.003)\n3200\n0.828 (± 0.004)\n0.957 (± 0.005)\n0.850 (± 0.008)\n0.895 (± 0.006)\n0.786 (± 0.001)\nMNIST\n100\n0.967 (± 0.015)\n0.967 (± 0.014)\n0.962 (± 0.015)\n0.668 (± 0.016)\n0.462 (± 0.023)\n200\n0.966 (± 0.015)\n0.967 (± 0.014)\n0.962 (± 0.015)\n0.667 (± 0.016)\n0.467 (± 0.023)\n400\n0.964 (± 0.015)\n0.967 (± 0.014)\n0.961 (± 0.015)\n0.664 (± 0.016)\n0.468 (± 0.024)\n800\n0.963 (± 0.016)\n0.967 (± 0.014)\n0.961 (± 0.015)\n0.660 (± 0.017)\n0.468 (± 0.023)\n1600\n0.959 (± 0.016)\n0.966 (± 0.014)\n0.947 (± 0.015)\n0.651 (± 0.014)\n0.467 (± 0.0233)\n3200\n0.946 (± 0.017)\n0.964 (± 0.014)\n0.920 (± 0.017)\n0.639 (± 0.017)\n0.459 (± 0.022)\nFashion-MNIST\n100\n0.818 (± 0.012)\n0.790 (± 0.013)\n0.808 (± 0.014)\n0.631 (± 0.010)\n0.564 (± 0.018)\n200\n0.810 (± 0.013)\n",
          "Table 1: kNN Classiﬁer accuracy for varying values of k over the embedding\nspaces of COIL-20 and PenDigits datasets. Average accuracy scores are given\nover a 10-fold cross-validation for each of PCA, Laplacian Eigenmaps, LargeVis,\nt-SNE and UMAP.\nAs evidenced by this comparison UMAP provides largely comparable\nperfomance in embedding quality to t-SNE and LargeVis at local scales, but\nperforms markedly beter than t-SNE or LargeVis at non-local scales. Tis\nbears out the visual qualitative assessment provided in Subsection 5.1.\n5.3\nEmbedding Stability\nSince UMAP makes use of both stochastic approximate nearest neighbor\nsearch, and stochastic gradient descent with negative sampling for opti-\nmization, the resulting embedding is necessarily diﬀerent from run to run,\nand under sub-sampling of the data. Tis is potentially a concern for a\n31\n\nk\nt-SNE\nUMAP\nLargeVis\nEigenmaps\nPCA\nShutle\n100\n0.994 (± 0.002)\n0.993 (± 0.002)\n0.992 (± 0.003)\n0.962 (± 0.004)\n0.833 (± 0.013)\n200\n0.992 (± 0.002)\n0.990 (± 0.002)\n0.987 (± 0.003)\n0.957 (± 0.006)\n0.821 (± 0.007)\n400\n0.990 (± 0.002)\n0.988 (± 0.002)\n0.976 (± 0.003)\n0.949 (± 0.006)\n0.815 (± 0.007)\n800\n0.969 (± 0.005)\n0.988 (± 0.002)\n0.957 (± 0.004)\n0.942 (± 0.006)\n0.804 (± 0.003)\n1600\n0.927 (± 0.005)\n0.981 (± 0.002)\n",
          "M3Exam [62] (a benchmark developed for evaluating LLMs in a multilingual, multimodal, and\nmultilevel context). The Thai subset of M3Exam is sourced from three levels of ONET: low (grade\n6), medium (grade 9), and high (grade 12).\nModel\nThaiExam\nOthers\nONET\nIC\nTGAT TPAT-1 A-Level Average M3Exam\nXNLI\nXCOPA\nTyphoon-7B\n0.379\n0.393\n0.700\n0.414\n0.324\n0.442\n0.391\n0.421\n0.742\nSeaLLM-7B\n0.342\n0.256\n0.589\n0.336\n0.305\n0.366\n0.285\n0.401\n0.586\nOpenThaiGPT-beta-7B\n0.180\n0.278\n0.411\n0.319\n0.243\n0.286\n0.259\n0.374\n0.570\nWangChanGLM\n0.192\n0.271\n0.167\n0.172\n0.175\n0.195\n0.219\n0.431\n0.500\nSEA-LION-7B\n0.179\n0.290\n0.244\n0.198\n0.175\n0.217\n0.230\n0.377\n0.462\nLlama2-13B\n0.248\n0.241\n0.500\n0.267\n0.273\n0.306\n0.230\n0.366\n0.512\nGPT-3.5-turbo-0613\n0.416\n0.444\n0.689\n0.397\n0.355\n0.460\n0.341†\n0.447\n0.630\nGPT-4-0613\n0.531\n0.658\n0.767\n0.491\n0.564\n0.602\n0.560†\n0.623‡\n0.920\nAvg. Human [32, 33, 34]\n0.318\n-\n0.472\n0.406\n-\n-\n",
          "20\n0.901 (± 0.133)\n0.907 (± 0.064)\n0.870 (± 0.125)\n0.605 (± 0.185)\n0.663 (± 0.196)\n40\n0.857 (± 0.125)\n0.904 (± 0.056)\n0.833 (± 0.106)\n0.578 (± 0.159)\n0.620 (± 0.230)\n80\n0.789 (± 0.118)\n0.899 (± 0.058)\n0.803 (± 0.100)\n0.565 (± 0.119)\n0.531 (± 0.294)\n160\n0.609 (± 0.067)\n0.803 (± 0.138)\n0.616 (± 0.066)\n0.446 (± 0.110)\n0.375 (± 0.111)\nPenDigits\n10\n0.977 (± 0.033)\n0.973 (± 0.044)\n0.966 (± 0.053)\n0.778 (± 0.113)\n0.622 (± 0.092)\n20\n0.973 (± 0.033)\n0.976 (± 0.035)\n0.973 (± 0.044)\n0.778 (± 0.116)\n0.633 (± 0.082)\n40\n0.956 (± 0.064)\n0.954 (± 0.060)\n0.959 (± 0.066)\n0.778 (± 0.112)\n0.636 (± 0.078)\n80\n0.948 (± 0.060)\n0.951 (± 0.072)\n0.949 (± 0.072)\n0.767 (± 0.111)\n0.643 (± 0.085)\n160\n0.949 (± 0.065)\n0.951 (± 0.085)\n0.921 (± 0.085)\n0.747 (± 0.108)\n0.629 (± 0.107)\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_017_014_015",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "8_017_014_015"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "a1ArQTztKkGDvipBOR4rQakuK0GcDitB",
          "dtype": "f4"
         },
         "y": {
          "bdata": "1dqzQCfDtEC0FbVAJF20QB4WtEAwbrRA",
          "dtype": "f4"
         }
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "data or incomplete pieces of information. Such issues frequently stem from the document\nbeing parsed with an insufficient context range, leading to the extraction of text that is either\nincomplete or erroneous. Furthermore, it is also possible for the initial ground truth within\nthe dataset to inherently possess inconsistent information or omitted details.\n2. Processing via Agentic Refine Steps\n2.1) The 1st Agent iteration identifies the key points in the initial content that require\nrefinement, and examines the extracted text to pinpoint errors or ambiguities, particularly\nfocusing on incorrect numerical data or phrases, and contextually inconsistent segments.\n2.2) The 2nd Agent iteration then takes the refined content from the first round and re-\nevaluates it, guided by the logical reasoning employed previously. Re-visiting the 1st\nAgent’s output, the second iteration seeks to further eliminate subtle inaccuracies, correct\nany overlooked details, and improve the overall coherence and fidelity of the text.\n2.3) The 3rd Agent iteration (final check) performs a complete verification. References of\nboth initial and secondary refinements are made to ensure that all crucial elements are\naccurate and that any lingering issues are addressed. This additional quality assurance step\nprovides a more robust verification mechanism, thus selecting the “final content” that is\ncontextually sound and reliably corrected.\n3. Output (Corrected Content): Following these three iterative refinement steps, the system\nproduces a “final-content” that is significantly more accurate, contextually aligned, and\nready for use in downstream tasks such as Agentic TextVQA. The corrected content is now\nmore faithful to the source and more comprehensible, enabling improved performance in\nsubsequent vision-language applications.\nAn example of the Agentic Refine Ground Truth system is provided in Figure 7. This process\nis integral to the subsequent use of this content in Agentic TextVQA.\n31\n\nTechnical Report\n| **Company**                                  | **Currency** | **Current Price** | **P/B FY23F** | **Div Yield FY23F** | **Net D/E** | **แนวรับ** | **แนวต้าน** |\n",
          "We adhere to the outlined automated design framework specific to agentic systems as docu-\nmented in Hu et al. (2024) for structuring each individual agent. Thereafter, our method\n30\n\nTechnical Report\nis influenced by the Buffer of Thoughts (BoT) approach (Yang et al., 2024c), incorporating\nthe technique of routing within the meta-prompt as a central feature. Throughout the\ndevelopment stages of each generational cycle, our methodology closely mirrors the strat-\negy observed in Close-Quarters Battle (CQB), focusing on pinpointing areas that require\nrefinement and ensuring appropriate modifications are executed. Additionally, this system\nfacilitates the transfer of knowledge across different iterations, making it similar to the ToT\nframework while maintaining a maximum depth level of 3. Our method distinctly diverges\nas it includes a mechanism for assigning a self-evaluation score aimed at reducing self-bias,\na principle discussed in Xu et al. (2024).\nThis broad overview of the system’s architecture and functionality is depicted in Figure 6.\nAn exhaustive explanation of each component is provided in the subsequent sections:\n• Initial Content Acquisition Techniques: The genesis of our content relied on the\ndeployment of the most advanced open-weight models available. In our methodol-\nogy, Docling (Auer et al., 2024) played a pivotal role in content extraction, while\ntextual data was systematically retrieved using the Easy-OCR utility.,\n• Meta-Prompt-CoT Configuration:\nWe meticulously custom-designed a CoT-\nprompt strategy for each specific task, refining it through the incorporation of\nover 8 distinct variables to accommodate a wide range of requirements.,\n• Cutting-Edge Model: Subtle modifications were implemented on the Easy-OCR\nframework, which we then augmented with the TF-ID technique. This enhancement\nwas pivotal in the identification of tabular data and distinct visual elements, includ-\ning analytical charts and financial graphs. Furthermore, we used a cutting-edge\nopen-weight Vision LLM to further analyse these visual datasets.\nThis agentic process works in the following steps:\n1. Initial Input (Original Content): The pipeline is initiated with the parsed text extracted\nfrom a provided document, which we designate as the original content. It is common for\nthis original content to exhibit certain inaccuracies, which might involve incorrect numerical\n",
          "| Chow Tai Fook Jewellery Group    | HKD           | 7.4                        | 2.4                   | 9.6                             | 0.8             | 7.8            | 8.7             |\n- Ensured the \"Visa Inc\" row header matches the raw reference.\n- Corrected \"Div Yield FY23F\" for Visa Inc from 0.1 to 1.0.\n- Ensured the \"แนวรับ\" column header matches the raw reference.\n- Ensured the \"แนวต้าน\" column header matches the raw reference.\n- Corrected \"Div Yield FY23F\" for United Parcel Service Inc from 4.0 to 5.4.\n- Corrected \"แนวรับ\" for United Parcel Service Inc from 124.8 to 128.4.\n- Corrected \"แนวต้าน\" for Kering SA from 331.3 to 344.8.\nchange\nmade\ntransfer thoughts\nAgent1st\nchange\nmade\nfinal\ncontent\nAgent3rd\nchange\nmade\ntransfer thoughts & refined\nAgent2nd \nFigure 7: An Example of Agentic Refine Ground Truth\nAgentic TextVQA\nThe ultimate content chosen from Agentic Refine Ground Truth, as indicated by Section 4.3.2,\nhas been used to produce data sets consisting of question-context-answer dialogues. This\nspecific Agentic data set is generated using LlamaIndex. Subsequent refinement is achieved\nby integrating the Synthesiser-Refine technique into the process. Furthermore, our meta-\nprompt-CoT strategy is used to systematically create questions, relying exclusively on the\ncapabilities of the Typhoon-1.5X model.\nThe methodologies discussed previously are implemented using an open-source external\ndataset. In these cases, the foundational approach is preserved; however, specific modifi-\ncations are introduced. These alterations include adjusting the meta-prompt identification\nnumber and, in certain situations, opting to employ a singular agent rather than the complete\nmulti-agent configuration.\n",
          "• QA: Question-Answer sets pertinent to the interpreted material, enhanced by chain-\nof-thought (CoT) logic to foster comprehension.\n• Conversations: A simulated dialogue between a user and a virtual assistant to pro-\nduce Q&A from extracted content, QA (1-shot) and caption. The Agentic TextVQA\ntechnique in Section 4.3.2 was used.\n• Refined Content: Adapting self-reflection instruction is facilitated by labels from\nthe Agentic refine ground truth Section 4.3.2, resulting in a revised list to amend\nnumbers and specific details.\n4.3.2\nAgentic Framework for Thai VQA Data Curation\nIn dominian data-centric AI (DCAI), it emerges as a paradigm aimed at improving the\nveracity label of the data sets. This is achieved by applying an agentic framework that\nsystematically revisits the perspective through which data are analysed and interpreted,\nthereby refining the truthfulness inherent within the data. The method is tailored to tackle\nhighly intricate tasks, beginning with initial labels and adjusting them to accurately represent\nthe data.\nAgentic Refine Ground Truth\nThe framework utilizes a meta-prompt mechanism that extends the CoT (Wei et al., 2023)\nmethodology into a family tree-of-thought (ToT) (Yao et al., 2023) strategy, which systemati-\ncally distributes and oversees the execution of individual tasks among a network of diverse\nagents. These agents integrate Typhoon 1.5X with the cutting-edge model designed for each\ntask, ensuring precise and efficient results.\nMeta-Prompt-CoT\nTyphoon 1.5X\nCutting-Edge Modeln\nInitial content\nChunk  Pages / Overview\nFor Agent retrieval, each page is broken up\ninto smaller chunks. This approach ensures\nprecise and efficient access to relevant\ninformation during query processing.\nDocling\nTF-ID\ntransfer thoughts\nAgent-Grandparents (1st )\ntransfer thoughts & refined\nAgent-Parents (2nd) \nselect dominant\nAgent-Grandchildren (3rd)\nfinal content \n(markdown format)\nextract content \n(markdown format)\nFigure 6: Agentic Refine Ground Truth Framework\n",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_refined_as_refinement",
         "text": [
          "",
          "",
          "",
          "",
          "9_refined_as_refinement"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": {
          "bdata": "izRQQbwVUEFBj1BB0x5QQRc+UEE=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "AirDP4n40T9wz8Y/zhfIP3ICyT8=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -17.464437246322632,
          "y": 6.063278806209565,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": -1.0138711452484133,
          "xshift": 10,
          "y": 16.834394788742067
         }
        ],
        "height": 750,
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": -1.0138711452484133,
          "x1": -1.0138711452484133,
          "y0": -4.707837176322937,
          "y1": 16.834394788742067
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -17.464437246322632,
          "x1": 15.436694955825805,
          "y0": 6.063278806209565,
          "y1": 6.063278806209565
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Documents and Topics</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_documents(chunk_texts, embeddings=np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93f81743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLsAAAMiCAYAAACGyMH+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdB5wkZbX38VPVafLM5pxzYIlLZokSJKPii6JkEQMqgl71KgreK8GImBN4VUAUQSSDRMl5c845Tu7pUPV+zlPdPZ0n7OxO+n3vHadDdVVNT88w/d9zzmO5rusKAAAAAAAA0AfY3X0CAAAAAAAAQFch7AIAAAAAAECfQdgFAAAAAACAPoOwCwAAAAAAAH0GYRcAAAAAAAD6DMIuAAAAAAAA9BmEXQAAAAAAAOgzCLsAAAAAAADQZxB2AQAAAAAAoM8g7ALQo7z66qtiWVbej0svvbS7T6/PW7p0qZx//vkyfPhwGTRokHzgAx+Q119/vbtPCwAAAADazd/+TQEAfT3oOuyww6ShoSF129NPPy3PPfecPPPMMzJv3rxuPT8AAAAA2CeVXSeccELBqov0j9LSUhk1apTZ/r/+67/kP//5j7iu29HDAcBeeffdd9v1O2tvPr74xS9KX/CjH/0oI+hKisVi8r//+7/dck4AAAAA0GMqu8LhsGzatMl8PP/883LrrbfKrFmzzBumc845Z18dFmiXNWvWyF133ZX3Pq1sOeuss/b7OQHdbdWqVZ26DwAAAAD6bRvjwoUL5dxzz5Xjjz9e7rvvPhk2bNj+PDyQEXZ95zvfyXvf1VdfTdiFfmnChAkF75s4ceJ+PRcAAAAA6FUD6rXS64gjjpAFCxZ0x+EBAHl86UtfkoqKipzb/X6/fO1rX+uWcwIAAACAXrMa49q1a+Wkk06SDRs2dNcpAADSTJ8+Xd58800577zzZOjQoTJgwAA55ZRTzMxFrcgFAAAAgH7XxnjooYfKpZdeai7v2rXLrOz1yCOPSG1tbd7tt2/fLh/5yEdMpVcwGOzKUwEAY/To0fLTn/606Dbf/va3ZefOnQXvb+vxBx10kPQV06ZNk3/84x/dfRoAAAAA0DPCrs997nOpsCupvr5err/+evn1r3+d9zGvvvqqWQHsq1/9aleeCgAYgwcPNr+bitmxY0fBGW6XXHJJm48HAAAAAPSjNsbKykr51a9+Jddcc03BbX7wgx9IY2Nju/b34osvyg033CBz5841FRslJSUycOBAmTFjhnzoQx+SP/zhD6aqrDO0Ek1Xi5w3b54Z1FxWVialpaUyZswYOeOMM+THP/6xeVNcjGVZeT+0PWhvH/Pcc88V3Pb1118320SjUfnLX/5iBqyPHz8+9fwcd9xxcscdd5hVMtM5jiN///vf5fzzzzcDqPXrrampMVV63/zmN031XUc0NTXJ3/72N/nkJz8pBxxwgGmF0qo9XYzgwAMPlM9+9rPy6KOPiuu6nXoeb7vtttQ2Tz31lDnO5MmTpby83LzWZs+ebeYOaZtstj179qT2c+KJJxY8tr5e04/57rvv5t2uoaFBfvvb38pFF10kU6dONS1fya9Vv/YPf/jDZsXHjj6H7RWLxUwFzqc//Wk5+OCDU8+1fr9nzpxpfh7++Mc/mq+7raqmfM+1vv6T9GvQFVWPPvpo8/XpcYYPHy5nnnmmeb3p66g99Pv+0EMPyYUXXmi+b3oMPW/9mbv77rvN67cvWr9+vfn5O/3002XKlClSVVVlvnb9GdWfzZtuuknmz5/froUVCv1s/Otf/0r9A8LFF19snl/9edbnV1cY1e+zPr6Ye++9t+D+9fFtqaurkz/96U+mYld/J+trMRAIyKBBg+Twww+X6667Tt54440OPHMiy5YtkxtvvFFOPvlk8ztff9aTz53OfvzCF74gzzzzjPl5AAAAAADD7aDjjz9eU4q8H3/4wx8KPq6hocEdNWpUwcf++Mc/Lnrc1157zT366KMLPj79o6qqyv3e977nhsPhdn1NW7ZscS+77DLXsqw2911WVubecccdruM4efdV6HHTpk0rePz2PubZZ58tuO0jjzziLly40D344IOLnv/s2bPdDRs2mP2tXbvWPe6444puX1NT4z7//PPteh7vvvtud+TIke36Hs2ZM8d8PR19Tq6//np3586d7jnnnFN0/6FQyL333nsz9rl79+52nVv2xzvvvJOxn3g87v7whz80r7P2PD4YDLrXXnutW19f73aVv/zlL+1+rvV7+POf/9ycdz433nhjwcfqz+19993nDho0qOgxTjjhBPP8FrN69Wp33rx5RfdzzDHHuP/4xz8K3n/JJZd02XPY3udgb465a9cu9wtf+IIbCATa9b264IIL3OXLlxd9Dgs99pe//KX79a9/vejvsdLS0qK/a++5556Cj9XnqBD9fajHHzJkSLu+zvPOO8/dunVr0edu06ZN7oc+9KF2/V7Wj3HjxpnXKgAAAADst7BLffvb3y742Llz5xZ83F133eX6/f4OhxT6xrqtN+DLli1zx44d2+F9n3XWWW4sFsvZX3eFXd/4xjfa/UZTA4XNmze7kyZNatf21dXV7rp16wqev4YoV155ZYefQ/2e6hvkjjwn+ib50EMPbff+X3/99S4NuyKRiHv++ed3aj8zZsxIBY2dpaHCVVdd1anjX3TRRXlD2mJBz0033eTatt2u/WsAWYh+3Z35OevNYdeqVavcqVOndvhr1J+3QkFwsbCrIx/6fe2qsCsajboXX3xxh89Bf1/Nnz8/7z4XLFjgDh06tFNf2+c///lOfb8AAAAA9B37dTVGbZUrRFcAy9dupS1SOgesMy0qL7zwgpx66qkFW6O0JVFXGFu3bl2H960tQ1/+8pelp/if//mfdrfL6cpqI0aMkJUrV7Zre11g4Bvf+EbB+7U1Udv5Okq/p9re+vjjj7f7MQ8++KC89dZb7d6/tjR2JZ0t19nh3YsXL5azzz57r1r19Pvwm9/8plOPveeee4p+H/P51re+1e4WxX/+85/y9NNP573vox/9aKd+znor/d2i7YnagtdR+vN22mmnyWuvvSb7in5ftQ24K+jPsLYudpT+vjr33HNz2s51zuMHP/hB2bZtW6fORxcT0NZ4AAAAAP3Xfg27dI5QoVUXtZjn7bffzrht9erVRWd9tYfOhyn0Bl/3vXnz5k7v+yc/+YlZSbI/uP/++808nmy62uYvf/nLTu9Xv+86d0tnfe0LGux1JnDIR1+P+j3fG++8807BxRrasmjRooyZZZ1x++23y4oVK2Rf+f3vf593DpR+H/qTyy+/XDZu3Njpx0ciEfnYxz5m5sLtKzrrqr1BZiH689+ZoDtp1apVOf9ooAuW7G0wqmFeZ8MyAAAAAL3ffg27/H6/GSpc7I1PuptvvjlvwJLclw4G1zf/X/va18xA+UJ0sPymTZtyQgcdpJ6PDmPW4eK6b11JUgc8F7K34UdX0kHQn/jEJ+T73/++fOUrXyl63ukBpA5/1q9Vq+AK0cH22YOlNajS56cQPb4OpNYqi2uvvdYMNi9U4dGRN8w6CF4XEnjyySfl4YcfNivl+Xy+oosaKB1qrVUf+qHD24tJbqcfOhRbaUVXoXBAKwQ1jGppaTFhkn4fOhIItYc+Lh6P571PB4Dr86BhloaHtm0XrHbraBWODlW/7777zBBwrSrT10xbz3U6fQ4L0Z/j5GtWQ4+RI0dKb6cVpfq6LOSggw4yKz9+73vfMwtfFPt9+Itf/KLDvwM0JNPFBPQYs2bNKlpp+Oyzz8reKFYpqK8THWqvP6u6sEEh+nrcuXNn6nqh38v6M67/TdBtNRzX16MuqpGP3q+vWQAAAAD91P6c2aUOO+ywgo+/9dZbU9tt27bNDBnPt53OEHr00Ucz9quDtIsNW9fBzemKzT36wQ9+kLHtxo0b3eHDhxcc+Jw+u6u7Znbpx3PPPZex/bvvvlt0e51/pTOo0p177rntfl6eeOKJgttOmDDBzAVLt2PHDnfy5Ml5tz/kkEPa9Zzoh87zyaaD6zsyw6fYc3n11Vfn/T595jOfKbhoQWNjY8a2+poYNmxY3u19Pl/O894exRZoSJ9Npr7//e8X3PYDH/hAu+dV6c9gNh0srl9zocfoAgJJughCsQHjDzzwQMa+a2tre/3MLh0yX2hfOtsqe6EAXfCi0PZjxozJ+P3S1syu//znPxn71kU6iv1evOKKKzo9s0uPVWwGY3Nzc2pbnRX3yU9+suD2uuBCUqHX1qWXXprzXD/88MMF9/mJT3yiQ983AAAAAH2Hf3+Ha7psfCHNzc2py1q1o1Uy+Vx88cU5FRG6X22nK1TJoJUWOtcq6bHHHsu73ZAhQ0x7TzqtNvn85z+ft4pBz1lnX02dOlW6m1YXpTvwwANN5UN2xVySVlxpJUg6rXh66KGH8m6fXn2his2u0mqO4cOH51QfaaXXZz7zmZzt3333XTOzraamRtqS73us8+C0Oqg9591ZoVAo7+2azWVXUmkVir7e1q9fX7DCKvu5b4vOrtOZX9n02HPnzs247bLLLitYddeR9jqtPspXsXfMMccUnPmkz/fAgQPNZW1f9LLL/BVj2XP8qqqq5M477zRVar2RzmMrNIOusrJSfvazn+W8VvR3i1Y3vf766zmP0dfPe++9J4cccki7jp9dQaWvWf25OOKII/Ju/8orr0hnPfroowXv++Y3vyklJSUZ1bL6O+GPf/xj3u3nz59vKnWT55yvrVn3ke2oo44ylan5TJs2rV1fBwAAAIC+Z7+HXYXe+LanHSp92HWhtpk5c+bI+++/n3PfggULZPfu3aYFTt9AbtiwIe8+5s2bl7cl7vDDDzdhTT6FWi33Jx3onI8GToXCLm3ry7d9IdlfZ6E5TBrinHPOOXnvKxQKanugfo+OPfZY6YxCLZJd+f057LDD8t6ugad+vdoum97id8UVV0hXuuqqq9q9rYZNOh9PZz9l68h8NF3IYG+ebw1qCrngggvy3n7ooYdKb6WLJxR6fjXc0zAvn//3//5f3rAr+buwvWFXPvq7S79fW7duzblv6dKlpkU5PZhqr0JBmYZSJ5xwQs7to0aNMgGUDu/Plv4PG/pzli9Ivfvuu2Xy5MkmHNTgUOnvZG2VBAAAAIBuDbt0pbFCSktLU5eLDRWfPXt20aqffGGXhmw6S0krYIoN6B43blze20855ZS8b9J6ijFjxuS9vaPVQ8W2z15FUGf+FNquWAVfIXtTgVVsZtferH6YTquQxo4dm3d4tr4519eehq1aXaMVJ/pZ35zvK7pan66AqIGSfi+0Mk5Xsmvr621v4NwVz3exQePTp0+XvmZvfm91Zp/pNMgvRF+H+cIunQGng9z1dd1RhX6P6nkkw6hsS5YsaXO/WlmbL+zSQFyra7ViUisL9Wcs+VFdXd3h8wcAAADQd+33sEurqwpJtj61FXwUG7yubYiFJPeZvdR9uoqKioL3ITO01Fa8rt5nW4p9f/c1DWN16PVpp51WsFpMg1b9SK5QqYHOhRdeKJ/97GfbtWBAezzxxBPypS99qWDY2JMUq6rrzu/lvrIvf2+1pdjvrsGDB+/Vz10+hX6P7u3v0DPPPFNuuOEGs9hCPlo5p2FYMhDTgP6kk04yCzNo1W+xIBYAAABA/7BfV2PUio9iy8Gnr6ylFSr5aGtWsZabYjOfkm+8Gxsb21VdBunyN8jFFFrpsFAg2h2OPPJIeemll+Tggw9u1/ZayXLTTTeZ1UL1895WVd1yyy2mHa43BF1ttUz2xWqcQr+32vp62/N7qy2FVuBs69jpsxI7otDv0a74Haqrw+pKlIUqxLL/u6IB8Mc//nFTIac/nwAAAAD6t/0adulMGp0PU2jOS/pcmkJvcnQGUaHB9W2FMMl5Oe0dko/COtoe2ZcccMAB8uabb8q9995rKkra81xo6KODtHUId3tCvXy0ZfFrX/ua9CbFgo9ioXNvVSycKRZatef3VluKva6K7b+zlViFfo921e/QT3/602bxDx12P2XKlHY9RmeQacv5Aw880CXnAAAAAKB32q9hl66wWIgOJU6vbig0DF5t3769U/cl91msOqihoaHgfchsu8q3OpqaMWOGqWDq6IeuNthbaBWNtkw988wz5jWnwdfll1/e5owubYPU1QY746tf/WrB+3TAua5oqUFw8vkstHrk/lSsoqhYO3FvtS9/b7WlWJhWrBWysxV2hX6PduXvUP09oxWROrdMqyR1BVltcyx2zvozoC2Nmzdv7rLzAAAAANC7+Pdne8/Pfvazgvcnl51PX7Xv2WefzbuttnCNHj26QwOQNZhJBhHFAgldqTEffeOkrTKFVkJMzuPR4+RrVetsNU9P5ff7zfcg3/Ol34NNmzbJyJEjpT/QN94afCVXCV20aJFZmfE3v/lN3u11nte1117boWPoc1rota0VkX/+85+LtrF1l2KDz3X1TV0psC8ptNqoKtZ6Wmxwe7F9tqd6S2fr6XOdj7aEF1tZsxj9PZpvAQKdy6hVe/kqv+6///68FX36NeqCDsXoSo76cd1115nWxccff1y+9a1vmZA3mx7j//7v/+QrX/lKh78uAAAAAL3ffgu7rr/++oLVBVq5cNVVV2Xcdtxxx8mvfvWrvNv/7W9/kw984AM5t69atSrvG5/kSmjJ1cp05cJRo0bJxo0bc7Z74YUXzApl2UOONei67LLL8u77nXfeSYVd2hKUb26PHktDsELVUL2Rtgv94Q9/yLldv87vfve78vOf/7zgY7Ud9YILLpBbb7216Ep03UG//9kWLlwoV199dd7t//jHP2bMm5s5c6b8+te/NuHDX//617yhh7bzFps9l2358uUF79MZXvmCrmLtvvvLQQcdVLQtU6vh8rU791aHHnqoad3M18r32GOPmXbWsrKynPv+/ve/F9yn/i7cGy+//LJZqbPQ70UNrjtDV0H897//nffnX/+h4qyzzsq4XV/zWnGVr5VdV2DUsEuH0j/00EM59+tCD7/97W9T17V1+OyzzzbPjYZ1+vsk3+9lAAAAAP3TPi8F0VYlDbL0zX8h+i/12XNjTj311IJtWBqwPP/88zlv7K+55pqCFVTnnHNOxvUzzjgj73Zbt241VTnp9I3rT3/607zba8iQXilWqOVI3+Tec889ObcXWnGsN/jwhz9c8D4dLq3D1PN9PzS40bDykUcekY985CPdMrup2CwpDU2zaVD6n//8J++Hhjb5FAsROhpEFWtR06qd7GrCQlVl+9uxxx5bMOD917/+Jc8991zGbRrKaPDRW2kIU+h3i1Y86Sqa2d+ru+66K+f3WXpl3IEHHtju4+tzmk5DIK1+KuT444+Xzir0dSptPcwO/O64446CMxu1YktpxVa+nzGtXMzXlqg/Y4VeX4WOBQAAAKDv69LKLp1FlJzXojNoVqxYYYKAYjNcdFbXl7/85byzWj72sY/lrRzSN0Qahl144YXmjaAGAVpBo8OJC70B/cxnPpNxm15PrxRIp8vev/rqq6bFSvetc5YKVdZoZUF6UKeVLGvWrMm77SWXXCJPPfWUqWTSqh+9/Nprr0lvpe2b+v3TYe356DB1fSOvFRja0qiVffq8asCRrJ7SKicdRK0tR/tTsdYtrVbR4FQrV/SN9Lhx42TevHlmBcZ81SI6S0tDBZ2blfw6tdpLXzf56Gy6js5JGjFiRMH79Gfs5JNPNj8TGqLp60oDgp5AW1018HrxxRdz7tPXgAYmn/jEJ0wb24YNG+Qvf/mL9HYa1hUakK6hv76G9GdCw/xXXnklbyVT0uc+97mcKtNizj33XLPvuXPnmlBNfy/Onz+/3e3jHXHMMcfInDlz5P3338+574033jBVbtraq5Vs+v1/+OGH8+5Hf8a0OlFpNdg3vvGNvMGVVpLqKo36etJ96u8O/dkrFByPHz++018bAAAAgF7O7aDjjz9eyxK65GPgwIHumjVrCh5r9erVbmVl5V4f54Ybbsi7/wsuuGCv9/3QQw9l7PPOO+/ssudn2rRpGft+9tlnC2579dVXd/j7tXnz5pztO3qMV155xQ0EAnv9tf7mN7/J2G97n5P010qhx5x22mk520cikXa/tr7whS+Yx9x3331d8n298sor3Y5qaGhwy8vLu+T4o0ePztj3jTfeWHDbe+65J+/5XHLJJQUfo6+JdH/729+67GdCj7svFHsOOnPMs88+e6+/1okTJ7r19fXtfp139OO4447LOW/9fhfaXp+jbP/85z/3+jzOP//8jH2eccYZXfL1vfTSSx3+vgEAAADoG7ptorXOzHr66adN1Uwh+i/zxeY+tYcO79b5UYVa7To7nFldeeWVOe2ROpOms6ub9UZHHnmk/OQnP9knc7L2Ja32O++88zr0GK0k1LbLvaEr2N14440dfpwO+/785z8vXWF/rzj6oQ99yFTG9Se/+93vilbjtef1+ac//SmnvburaLXYj370o73ej1aRFZpl2B46PzF74RJdwKG9K1AW+1nVyjMAAAAA/VO3hF06iFiHUGtbWFsuvvhi027YkVae9ONoS1cwGMx7vw6V11k5+oaro7TdRsOybJWVlaadsyOhX29vt9GWv7vvvrvgjLVi9Puqb3YLDX/fl7RdqqNhgrZbaqtYZ+gbeJ2pVGgl0bboHCRt5WoPfc0XGoCvLbT5BqjvS9rS2d7XubYC9/afCW3D1ta9SZMmdfix+jvk0UcfNW20+4r+7tI2w66grZnact6Z50jn9mWHgjqn7Mknn+x0WKjzADVsBAAAANB/7dewSwe565tenSeks43a64orrjBvHI844oh2V8F85zvfkWeeecZU0hSjg5F1voxWZLVnpUQNRzTM0jlJhQaQa0CnAY5WZ7RVdabzoXS+Tm+nz99bb72VU+lWjM7e0ec+e57a/qLf+/vvv18GDx7c7sdooPePf/zDVLPp7K320NeVVoS9/fbbexVg6OvpwQcflE996lNFt9N5RvpzVmjQu3aJ7u9ZccOHDzfBclsD0bUaR1ct1BUtezsNujTU/+xnP9vuFQ/PPPNM8zPR3lAz3WmnnSY333xz3pU5k6qqqkxgm7367d7Qr02r0LQKt70/S/rzoCucHnDAAQV/N+rPi1ZotXcFW/15/P73v2+Cwn1VEQcAAACgHw6oz64s0RXs9A2fhlT6Ju7EE08s+kasGA0JksPNddDxCy+8IJs2bZIdO3aYlfW0SmvGjBnmOOeff76pGmgvbWXUyqT/+q//MoOln3jiCVm3bp1s27bNtNfpvvRNmQ5R1iCrPS02GuDoAHd9A6ihm67wpysy6nnqvnSYuVZD6BvFjoQtPZkO3tdh2/omVr9H2qaqw/r1edQh0vp6mDhxohnqr29iu6qyZG/o93TRokWmEkSrTFauXGleU1oVpd8XPUet4kunb76vvfZa07517733yuOPP26GdOvrUb9ODVv1NaLfZ60u1O91sXbdjtB9/+pXvzKVcPqa1deWDnbX42rFmA58v/766011jAZMt956a9796HmfcMIJsj/pOWm4q68NDVx0ULs+ZxrATJ8+3TyfH//4x02oN2HCBOkLNGzXcFwXvdCQVIM8fY3pqq+xWMz8btHvmy4woG21e/sz8d///d/mNaArH+o/KmzcuNFUimmlnFYk6nPckX9oaC/9mdAKT/2dpr8D9Husg/H1Z18X+dBzmDJlivnZ1++xhllt0devhrbf/va3zUq2+jtfFyHRFX41sNV2ca2M1X3p4gz69RVbZRUAAABA/2Hp4K7uPgkAQNs0PC4UBGpllwavAAAAANDfdduAegAAAAAAAKCrEXYBAAAAAACgzyDsAgAAAAAAQJ9B2AUAAAAAAIA+g7ALAAAAAAAAfQZhFwAAAAAAAPoMf3s2chxHwuGw+P1+sSxr358VACBHNBoteJ/rukXvBwAAAIDeTt/3xGIxKSkpEdu29y7s0qDrkUce6crzAwB00LZt2wret3XrVnnwwQf36/kAAAAAQHc488wzpaysbO/CLq3oSu4sEAh03dkBADrkU5/6VHefAgAAAAB0C+1m0WKsZE61V2FXsnVRgy7CLgAAAAAAAHSXtkZsMaAeAAAAAAAAfQZhFwAAAAAAAPoMwi4AAAAAAAD0GYRdAAAAAAAA6DMIuwAAAAAAANBnEHYBAAAAAACgzyDsAgAAAAAAQJ9B2AUAAAAAAIA+g7ALAAAAAAAAfQZhFwAAAAAAAPoMwi4AAAAAAAD0GYRdAAAAAAAA6DMIuwAAAAAAANBnEHYBAAAAAACgzyDsAgAAAAAAQJ9B2AUAAAAAAIA+g7ALAAAAAAAAfQZhFwAAAAAAAPoMwi4AAAAAAAD0GYRdAAAAAAAA6DMIuwAAAAAAANBnEHYBAAAAAACgzyDsAgAAAAAAQJ9B2AUAAAAAAIA+g7ALAAAAAAAAfQZhFwAAAAAAAPoMwi4AAAAAAAD0GYRdAAAAAAAA6DMIuwAAAAAAANBnEHYBAAAAAACgzyDsAgAA/drSN96Vn37269LTfP+yL8mahUv3+XG+dtpFUr+7dp8fBwAAYH8h7AIAAAAAAECf4e/uEwAAAOhuDXtq5Rdf/JasW7JCDj/jJDn/C1fKyw8+biqrPvaNL6QqoL5+7y/Ftm25679vle0bNonP75eLv/UlmXDADPnDN24VJx6Xbes3Sv2uPXLF974ukw6aJVvXbpDffvV/zH0jJ4+X3Vu2y/V/+FHq2IteflP+evvPzeXa7buksbZOfj3/3+b6f/7xmPz5ph9JpKVFPvOTm2XYuNFm+3/85LfmtpGTxsul3/2qhEpLZNX7i+We//mJRMItMnbGFPn4t74kJWWlqePo1/Pk3X81lzetWGM+J4/z2G/+LEtef0f8wYBc+/PvSUVNtXz+8A/KT19/1Nz/z5/fZfZ16qUf3W/fEwAAgM6isgsAAPR7q99fLBd/6zq58YHfyfP3/VNampoLbrtp5RqZe8aJ8u1//N6EYn/7/i/N7eGmJhOOfe3PP5OzP3OJPPOnv5vb7/3enXLqpRfKN+//tZRXV8mGZasy9jfz6MPMvvTY42ZNlUtv/oq5fffW7dJYWy/fuO+XMvf0k+Slv3vB08blq+Wq739TvvPgH8SybXnj8WclFo3Kb7/6XbnkphvkOw/9QaqHDJRHf/2njOMcfd7p5ji6v9FTJ8p1v/2+uX3npq0yeNRw+dbffiOjJk+QN594roufXQAAgP2LsAsAAEBEKgfWmOqlmmGDTaVXIeNmTpUV7yyQmz58lfzmKzfL7m07zO3b12+SI886xVweMXGc1O3aYy6vWbBEDv3APHP58A+eLE119Xn3++8/PyAl5WUmlErub96Hz0zsb6zU79ptLk+de6Dc8z93yE0fulLefPxZaaqtk82r1smAoYNl9LRJZpt5HzlbFr/yVt7jPPCj38iMow6V6Ucckrpt7gdPTjuOd94AAAC9FWEXAADo9w6Yd2TGddcVEcvKuE0roNTT//c3iUWi8vV7fiH/fd+vJBAKmtvHTJsswyeMzdpJQta+sm1asVqe+fMDpiUyaephB0pJRXnO7n7zle/KaZf/P/nW338rZ37q4vzHsHT7tOMnLHrlLTOQ/7xrr0jdNmjksKyv3c3Z34q3F0g8Fi/6NQAAAPQUhF0AAAB5VA0aYOZtqZ2btqRuDzc0muovf8Avr/zzSdm8cm3R/Uw4YLq8/dQL5vIr/3xCSitbAyylLYi/+/r35OPf/KKZldUWPf7gUSMkFo3JI7/+kwmnhk8YY2aBaWimtOVx5lGHZjxOZ4H9+eYfmVligaAX0BUTKis1rZS6/yWvvS0+v6/NxwAAAPQEDKgHAADIY8aRh8qz9zwo3z7/chk0crgZAq9OvOh8+fkXvilvPv6cGUyvQ+fzVVElffSrn5Xffe1/5ZFf/Ulqhg4ybZDpNAhbv3iF3H/7L+R++YW5LX2AfbaPXH+NfP+yL5r5X4d8YJ4ZSK/h1ZW3/bfc9c3bpKU5bKrMLr7xuozHPXTnH0xrpLZeKn8gIP/9118VPM55n79cbr/0i1IxoFrGzZrWzmcNAACg+1lusb/OEqLRqDz44INy3nnnSSAQ2D9nBgAA0AfoKolDRo8wM8Ee/sXdUr9zj3zsv70VHgEAANB+7c2nqOwCAADYh2KRiNz5+W9Iw+5aGTJmpGkjBAAAwL5D2AUAALAP6aD5r/35Z919GgAAAP0GA+oBAAAAAADQZxB2AQAAAAAAoM8g7AIAAAAAAECfQdgFAADQg9TW1so777zT3acBAADQaxF2AQAA9CBbtmyR1157rbtPAwAAoNci7AIAAOhBXNft7lMAAADo1Qi7AAAAehjLsrr7FAAAAHotwi4AAAAAAAD0GYRdAAAAAAAA6DMIuwAAAHoQZnYBAADsHcIuAACAHoaZXQAAAJ1H2AUAANCDUNkFAACwdwi7AAAAehgquwAAADqPsAsAAKAHobILAABg7xB2AQAA9DBUdgEAAHQeYRcAAEAPQmUXAADA3iHsAgAAAAAAQJ9B2AUAAAAAAIA+g7ALAACgh2FmFwAAQOcRdgEAAAAAAKDP8Hf3CQAAAKAVA+rRk61atFJeePR5ufT6yzNu37Njt7z46Aty9ifP3av9P/3AUzLz0FkyctzIots1NTTJ/b+6T7Zt3Cq2bct5l10gk2ZNlng8Lg/+/gFZu2yN+Pw+OeeS82XC9AnmMXrb68++JhVVFXLGRWea2/5w+++kduee1H53bt0pn/rva2TMpDGdO/+/PynBkpDMO/P4Tj0eANA1CLsAAAB6GNoY0dvUDB6w10GXOuWCD7Rru2f+8bSMGj9KLvnyZSaAe/APD8h1t98g81973wRhX7rtetm6YYvcc+df5Eu3flmWvrdUXnvmFSmvLJdIJJraz2U3XJG63FDbIL+75dcyeuLovf46AADdi7ALAACgB6GyCz2dVnH9/tbfmiqoA46YI6d/9IyMiq/62nr526//Knu275ayynL50FUflsHDh5hKLA2UGuoa5KyLz5G//+av8sVbvizbNm2TP/34j/LF710nd33/9/LBj50pLzzyvBx09MGmymvz2k3ywO//Lp/9zudT5zBp5qRUKDVi3MhUgLV+xTqZfvAMExgPHzNCWsIt0tIclmkHTjMfb73wpmxYvSHv1/XqM6/IYccfnhM2L5+/TJ7462MSjcRk2Khh8uGrL5RgKCgrF66QR//yL2luCpvzPPPjZ+3T5x0A0H7M7AIAAOhhqOxCT7Z1w1b5+LUXm4opDYLWrVibcf/Ddz8kMw6eaaqrjj/rBPnrL+8zt2uOG2mJyOe/+wXTWqgB0UuPvSiP/OmfcvYnzpFgSTC1jzlHHiiL3lpoLi9+Z7HMOWJOxjH0sVUDqs3lV556WQ459hBzuaW5RUrKSlLblZSGpLmxuc2vKRaLyTsvvS2Hzjs0574t67fIRZ/zvl7LtuT9V9+TaCRqAr2Pf+GTcsMPvyrbN2+TRW965wsA6H6EXQAAAD0IlV3oDUKlJeIP+GXGITNl3Yp1GfetXLRC5p5wuLmsVVZ1u2pNdZUTj5sQK+mUC06VN557TUrLy8x+0k07cLqsXrJKHMeRJe8slgMOzwy7UsdauEIWvrlATjjnJO+GTubE77/ynkyePVlKykpz7ps4Y6I8dNc/5Cdf/5EJurRNcvumbTJw6EDzoeH0xz73cZl8wJTOHRwA0OVoYwQAAOhhqOxCrwpn8wW0WS9h3UQHxldUV6Ru02Hy+nitksoWCAZkzOSxJsiybcvMBMum7Y8P/99DcukNV5i2QlVWUSbhpnBqG63qSq/0KuTlJ1+SD3/qo3nvu+dnf5HzL79AJs2cLE/e/0Ta12hlhH8AgJ6Dyi4AAIAehMou9AbhpmaJRWOy5O1FMm7q+Iz7Js6cZGZjqWXvLzXthvkCp8fvfVSOPvUY8flsee+Vd3Pun3PEgfLAb/8usw8/IOe+xvpGufdnf5ELr7lIagbVpG4fO3mcLH57kfk5Wr9yvVl5MV+1VrrVS1absGz4mOF579eqtIFDBko8FpdnH3rGJHdDRg6VXdt2ye7tu8yx7vvFvea4AICegcouAAAAAO02etIY+eMP75baXbVmQP2YSWPNgPqkcy45T/7+6/vlP4+/JOWVZfKRT+dWTK1dvlbWLF1ttp1+8Ez53fd+LVPnTMvYRq9rqJavhfGZB56S3dt3y19/cU/qtrM/ca7MPGyWLH1vifzwhtvFHwyYiqy2vPzES3LUB44peP8HP3aW/Pq7v5TSijITvOkwfK08+9CVH5Y//uhuibZEZNZhs03L5sYCw+8BAPuX5bbjnw+j0ag8+OCDct5550kgENg/ZwYAANAPvfvuu+bj0ksv7e5TAQAA6FHam0/RxggAANDDMLMLAACg8wi7AAAAehBmdgEAAOwdwi4AAIAehsouAACAziPsAgAA6EGo7AIAANg7hF0AAAA9DJVd6M/C4XB3nwIAoJcj7AIAAOhBqOxCf6YrbN1+++3dfRoAgF7O390nAAAAgExUdqE/LiX/wx/+UGpqauQb3/hGd58OAKCXI+wCAADoQajsQn+zY8cOuemmm+SCCy6QE044obtPBwDQBxB2AQAAAOgWCxYskJ/97Gfyla98RSZMmNDdpwMA6CMIuwAAAAB0y3yuV155xczoqqio6O7TAQD0IYRdAAAAPQwzu9Bf5nN973vfE9tmzSwAQNci7AIAAOhBmNmFvj6f6+abb5bzzz+f+VwAgH2GsAsAAKCHobILfRHzuQAA+wthFwAAQA9CZRf6ooceekhefvll5nMBAPYLwi4AAIAehsou9LX5XNXV1cznAgDsN4RdAAAAPQiVXegrmM8FAOguhF0AAAA9DJVd6O2YzwUA6E6EXQAAAD0IlV3oC/O5/vOf/zCfCwDQbQi7AAAAAHTpfK5bbrmF+VwAgG5D2AUAAABgr+zcuVNuuukm5nMBAHoEwi4AAIAehpld6I3zuW644QaZOHFid58OAACEXQAAAD0JM7vQG+dz3XbbbVJZWdndpwMAgEHYBQAA0MNQ2YWejvlcAICejLALAACgB6GyC71lPtd5550nJ554YnefDgAAOQi7AAAAehgqu9BTMZ8LANAbEHYBAAD0IFR2oaf65z//KS+99BLzuQAAPR5hFwAAQA9DZRd6klgsZuZzVVVVMZ8LANArEHYBAAD0IFR2oSdhPhcAoDci7AIAAACQdz7XnXfeKV/5yleYzwUA6FUIuwAAAADkzOd68cUX5fbbb2c+FwCg1yHsAgAA6GGY2YXuns+lAdett97KfC4AQK9E2AUAANCDMLML3T2f69xzz5WTTjqpu08HAIBOI+wCAADoYajswv62cOFCM5/rhhtuYD4XAKDXI+wCAADoQajswv728MMPywsvvCC33XYb87kAAH0CYRcAAEAPQ2UX9td8rh/96EdSXl4ut9xyi/h8vu4+JQAAugRhFwAAQA9CZRf2B+ZzAQD6MsIuAACAHobKLuzr+Vw//elPzXyuSZMmdffpAADQ5Qi7AAAAehAqu7A/5nPdfvvtzOcCAPRZhF0AAABAH8d8LgBAf0LYBQAAAPRhzOcCAPQ3hF0AAAA9DDO70FWYzwUA6I8IuwAAAHoQZnahq/zrX/+S559/Xm677Tapqqrq7tMBAGC/IewCAADoYajswt7O5/rxj38spaWlzOcCAPRLhF0AAAA9CJVd2Bu7du0y87nOPvtsOfnkk7v7dAAA6BaEXQAAAD0MlV3ojEWLFskdd9zBfC4AQL9H2AUAANCDUNmFzmA+FwAArQi7AAAAehgqu9BezOcCACAXYRcAAEAPQmUX2ov5XAAA5EfYBQAAAPTS+VzXX3+9TJ48ubtPBwCAHoWwCwAAAOhFmM8FAEBxhF0AAAA9DDO7kA/zuQAAaB/CLgAAgB6EmV0oNp/rrLPOklNOOaW7TwcAgB6NsAsAAKCHobIL6ZjPBQBAxxB2AQAA9CBUdiEd87kAAOg4wi4AAIAehsouMJ8LAIDOI+wCAADoQajsAvO5AADYO4RdAAAAPQyVXf3X4sWL5Sc/+QnzuQAA2AuEXQAAAD0IlV39ez7Xc889x3wuAAD2EmEXAAAA0M3zubSaq6SkRG699VbmcwEAsJcIuwAAAIBunM918803y5lnnsl8LgAAughhFwAAANANmM8FAMC+QdgFAADQwzCgvv/M59K2xerq6u4+HQAA+hTCLgAAgB42oJ6wq+/P5wqFQsznAgBgHyHsAgAA6GEIu/qm3bt3y0033cR8LgAA9jHCLgAAgB5W2YW+h/lcAADsP4RdAAAAPQyVXX3LI488Is8++yzzuQAA2E8IuwAAAHoQKrv6DuZzAQDQPQi7AAAAehgqu/rOfK4PfvCD8oEPfKC7TwcAgH6FsAsAAKAHobKr78zn+vKXvyxTpkzp7tMBAKDfIewCAAAAugjzuQAA6H6EXQAAAEAXzecKBoPM5wIAoJsRdgEAAPQwzOzqXZjPBQBAz0LYBQAA0IMws6t3WbJkifz4xz9mPhcAAD0IYRcAAEAPQ2VX7/Doo4/KM888w3wuAAB6GMIuAACAHoTKrt4xn+uOO+4Qv98vt912G/O5AADoYQi7AAAAehgqu3r+fK4zzjhDTj311O4+HQAAkAdhFwAAQA9CZVfPxXwuAAB6B8IuAACAHobKrp6H+VwAAPQehF0AAAA9CJVdPQvzuQAA6H0IuwAAAIA8mM8FAEDvRNgFAAAAZGE+FwAAvRdhFwAAQA/DzK7u9dhjj8nTTz8tt9xyi9TU1HT36QAAgA4i7AIAAOhBmNnV/fO5dC6XDqLXOV0AAKD34b/gAAAAPQyVXd03n+v000+X0047rbtPBwAA7AXCLgAAgB6Eyq7um8913XXXydSpU7v7dAAAwF4i7AIAAOhhqOzafx5//HF56qmnmM8FAEAfQtgFAADQg1DZtf/mc/30pz8V27aZzwUAQB/Df9UBAAB6GCq79q09e/bId77zHeZzAQDQRxF2AQAA9CBUdu1bzOcCAKDvI+wCAABAv5nP9eSTTzKfCwCAPo6wCwAAoLsquBzX+2w+vNudeFzcuCNOLC6WbYll2919qn1qPtdtt93GfC4AAPo4/ksPAACwH2io5cbi4sYcE2aJ4+TfLhIXNxITp6ml9UbbFstni+XXDx8zvTo4n+umm24ys7mYzwUAQP9A2AUAALAPaYWWhlduPJ6q3srmOo4p7jLbawimwZjrtoZaer9+RBMP8Nlia+gV8FH5VcTSpUvlRz/6EfO5AADoZwi7AAAA9gGt4oq3REW0iiv9die9wksDsMwEzG2JihOOSry+WZdl9IItn20+m+ouvU3bHHW/LVFT6WUH/eYzWjGfCwCA/ouwCwAAoAtpRZbTEjXVXOm3acDlROMisXhm8JUMw0w1V6ISLLGtzuzSqi4n5lV4uZYlts8nVtCXCr5MqKbzvTT0CgXM7f19Ptedd95pnhvmcwEA0D/xX38AAIAuoqFWXGdtpVVzaXjlNEdSFVxakeVEYtK4eL0JusonjzBVW6kB9TqvKxIz+0m1Meqg+oBP7IA/EZzFTNWXCbe0lTE99Ar6xVcSlP46n+s73/mOmc11+umnd/fpAACAbkLYBQAA0AV0pla8KZIaPG9CKQ2utJUxLeRq2bBT1t75L4lsqzW3+6vLpHz6aGlaucV0LdbV1MnwygESb2hODKX3iWg1l67S2BLz2hq1bTHgEyccEYnYYpcEzAwvc1wNyhxX7NJgvxpkn5zP9aUvfUmmTZvW3acDAAC6EWEXAABAF4g3ZwZd5rq2JGpbow6ob4mZyxvufiYVdKlYbZPUvrYsdb1x83rZFfZJfMIMsQIaaiXaHi1LfCbkCiTmdVkm0NKmRV250Q0GxFcS8I6vVV4NYfGVh/rFAHvmcwEAgHSEXQAAAHvJVG+lty6Go3mDrsjOOmleuaXovlxxpXnNNtnx9Lsy6MQ54jY5JrDSYCvSrC2SrgQGVood9InT2CJSogGYXyQSlbjrmiovU9FlWiojXuDVRyu8mM8FAADy4S8CAACAveAFWl6rojID5qPecHr9rEGXo0PmG8PmNm1L1Mqrtux+cZH4q8qkZfMuceOuxPY0SPO6HSbEKp04TEZcNE9KxwwWJxwTyxFT1aXHc1wRX1liZpcetzkivrKQ9MX5XDfddJOceuqpzOcCAAAZCLsAAAD2gll1MTFcXpk5WomVFuNa4aW3aUWW6US0pHLOeKl7e2W79r39kTfz3t68aqus+cGDMu5zZ0mZDrjX2WC2ZWZ56fB6J+ZrneGVWN3RzP7qQ/O5fvjDH8p1113HfC4AAJCj7w9xAAAA2Ie0TTFJV1c0pVWJ1kZLvFUS9TYNv7TKasjph0jVIZPMSopSoLuwPU2H2iq59s5HJLK91psRFo6YY5j7dF5YgXPsC/O5fvnLX8qtt95K0AUAAPIi7AIAAOgkE265rWVdTrJ9MTGry9yW/ByOmtubVm+VktGDzGyu9Iqw1D47cHytIqt9Y7k5Bw3WksfX69pOmdqnVnclhuf35vlcP/7xj2XJkiVy++23M4geAAAURBsjAABAJ2UHSCb8SrQwasuihls6uF4/6+ytTfe+KLHdDW3u11deIrYdMqsstkVXXXSjcbFCtqkm04oxrQzT2yStddGNOWIFe+e/czKfCwAAdARhFwAAQGcl2gZzrrvZ/YiWbH3otXYFXapi+mipqR4lu15Y0GapV/mM0eLE42KLhlyWdw62JW48njeI622WLVtm5nN96Utfom0RAAC0C2EXAADAvpIIqmK1jdKyaVe7HhIcVi2hodVSNnq4+KtKpWH5JolsrTWtiVqtFU+s6iiWJQOOnSFlE4Zlhm6mrVKryrLPpSMNkj3DE088YWZ03XLLLbQtAgCAdiPsAgAA6Cwra5S8bYnEXbH0c2L1Rd3GDvm9bYsEToGh1TLgmOlSuvbd1G2h0YNl14uLJLansfWQfp8MmDdLKmeOkeCIAbnnkTxG1rFMS2Uvms/1s5/9zJyzzufy+/mTFQAAtB9/OQAAAHRWItRKsmzbaxfUNkLxhsZbAZ/4SkMSGFwl0e21ObsIash17Ezx15SJr7xU3HWWhDfukrpda8xg+fSgS+lt0V31EhhQIXZiJlcyXDP3W3b+1Rx7SdbFfC4AALC3CLsAAAA6yfJlDnzXYMuNxkzYpIPi3ZaY2AG/xCMxqZw9TnY9+37OPoKDqyRQU24ut2zYIXVvrpBKp0zqfHUFj9uwaL3E65tlwHGzpHL2WBOypc7BLlB11gsqu5Lzub74xS/K9OnTu/t0AABAL0XYBQAA0EmmTVEDr8Twdw2/XMsSy3W9kKsl5gVRPltqjpwqu19a6K2S2LoDqTxgvCm6api/VhqXbRQnFhdpY9FENxKTppVbzMeIi+bJwONmZuzTfJLehflcAACgqxB2AQAA7AVtJXSSYZfO5wr4xY1ETWuhV+kVF19JUAKDKmXMVafKtoffMG2KwSFVMuCYGRKra5Lt97+Uu7JjO+185j0ZOG9W4mTMeowF9MzKLuZzAQCArsZfEwAAAHtBAy1piaau20FtW/SuaytjTNsabdsEXmUTh8u4a88Wp6nFzN7SkGztTx7OCbqyI6uBJ86W8KZd0rR0U87xo7saWlsW01sXc9oYpcdhPhcAANgXCLsAAAD2ggZZukKihlfedUssv1/cmIZcltjBgGk71G0sn1Z6RaVxxSbTgmhpq2NjuGgmVTpxmFTNmSDVh0yWNSsfTh0nqWzS8LSTSduP61WbZezbcTLme3Un5nMBAIB9hbALAABgL5lqrrQQygp5YZe5LxSQuBlab4kEfbLhl49J49KNRfenIVlo9CBTCVY1Z7z4KkpMi+KgUw6UHY+/ndrOV14iQ86a680OyxpCb7l61W29z4RdbusA+27EfC4AALAvEXYBAADsJa3aEq2YcrxqKlsH1evsLg25LBG7JChOc0Qa3l/bZtCltV0Vs8fKiFOO9vZdGkxVY9XMnWICsKYVm8RfXS6VB443tzdv2CGhoTViBX2mMsxKD7d8aeVeOltMz7Wb53M5jsN8LgAAsM/wFwYAAEAXVXc54Ujr9eS8LhOG6YqMljSv3pr3sYGh1RKoLjMxVYXPW8lxw13PmJbFipljZNCJc8z+VHBQpQQGTRN/VZnsfOpd2fnsfBOq+cpCMuz8o2TwGYeYVSGVq+FW4rK53skh+F2htrbWzOc65ZRT5Iwzzui28wAAAH1fDyhkBwAA6BthV/pQ+OS8rtQqjaGghIbnb9krGzdURv6/eTLy/x0nTmOL1L+1SmK1TRJvbJHaN1bIlr+/nLG9HqV+wVrZ8eQ7JuhS8aYW2fSX58wssCQ3njnfy4Rf3WD58uXy1a9+Va666iqCLgAAsM8RdgEAAHRl4JXd3pi6bEv13CkSGjEg8zFlIRlw7AxzWWdsHb6tXCbY1RnbaIAV0VUX09S9tTL3BFyRPa8sab0aywq3HMccY3968skn5ec//7mZz8UgegAAsD/QxggAANBFku2DSbbfFkervXRQvA6UryiVCTdcILuenW9WZAwOrpIBx84Uf1WpOE0REccVf0s8o0IsKbq7XgIDK1LzuPJskjWI3hLLdcWJOeY8UvfFnYwQbl+Jx+Ny5513ms/M5wIAAPsTf3UAAAB0ERMiaQiVXjylQVPUayfUAMpfXiJDz5or8UhU3Jaoud1J3u+zpWzS8IxWRHN7wG9mcjUs2SCx2kYpGTFQKueMl/r5azNPwLal5shpXqBl+1pbGdPCrv0xpD45n+vkk0+WD37wg/v0WAAAANkIuwAAALqSZWtpVetVyxZXErOz7LSZXpbVmomlDY4ffPqhsulPz5qZXUk6l2vDb5/KOEzFjDEy5IOHyq4XF0m8vtlUfQ3/yLEmCHNicbEDybDL2a9zu3Q+1w9+8AP54he/SNsiAADoFoRdAAAAXSlnJlbr9fR5WcnLruOYSi79XDJ6kAQHVciw846UjXf/u+hhGhavl4pZY2X8F88WsX3iLw+Jr6LE22c0Jm5J0LQ67s+w66mnnpJHH31Uvve978mAAZmzyQAAAPYXwi4AAIAu4gVYWWFX2tX0Dkedp9W8aZds+MMzEtvtDZ8PDKyUYR8+SsIbd7breM1rtkrFjNHiqwh5lWLaDunziaVHchwRn+3N7Yo7YifnibmuOU/dvqvoXK6f/exnEovFmM8FAAC6HasxAgAAdBETNqWFWxoqaUthvtURdXD8pj8/nwq6VHRXvWx/+A3xlXsVWm3xV5cldpw8fqy1Yiy9giu72qwLq7t0PtdXvvIVmTx5slx33XUEXQAAoNvx1wgAAEAXMMFWYuB86rZY3FRWmcv6f4ngy3UdiWzdLZGte3L207J5t4SGVnvzvdJmeWWzS4PSuHyz7Hx2vgQGVMigkw+UmsOnJJIvK6NlMns/prJrb79g5nMBAIAeirALAACgCzjNkYwKKp3B5YRbwy83EktVYDlRR+xQIHflRqWth36fBIZUSzRPGKYhV+nYIdK0druE1203t0V31suWv74kvrKg1ByZDJ1a46zCkVnnMZ8LAAD0VLQxAgAA7CWt6EpWbSUrp+IadCXCL52ZZa6nKsAi4q8qMwPms1VMGyV20C/lE4blPdbgUw4U/6BKccORnPt2v7wkFW0VHcnl7t18rjvuuEPmz59v5nMRdAEAgJ6Gyi4AAIC94ERiOe2LcQ2iki2LjitOY4sZGq/ti/HmaKrmavhHjpFtQb/UL1hnBsZXHDBOao6Yau6rOmiCNK3emtHqqAPstz/2Vsbsr3RaPWZZiX/L1DbIBCvtcvZ9HZ3PddNNN8lJJ50kZ555Zqf2AQAAsK8RdgEAAHSSE42Jk1VhFdd2xmhr0BVvCnuXdRVEbWWMJ+d2icSbWqRixhipOmSShIYPMK2QyQoxbXMcceGxZsXF6J5GiTWEpf6dVUXPp/KgCd6+xRXLbi3gT79srndiJcYVK1bI97//feZzAQCAHo+wCwAAoBM0lDJzupLXtT0xHDUrIiZbF839TqKtsSUzBKt7a6VsfejV1FyvktGDZcgHDxVfaTCjIqts4nBzefNfXyp6PnZJQAYcNcO7HAy0VnPZVmZllyVi+To2yYL5XAAAoDch7AIAAOggE16lBV0qPehy445EdtbL7ufmS8PSjeKvKJUBx80w1Vt6X2xXg2z5xytepVdCeMMO2f2fxWYmVza7JCiWz1f0nPT4O599X4add6T4gq1/4llpl831NvaTPZ/r5z//uUQiETOfy+/nT0cAANDz8RcLAABAB5kZXWkrL2o7YyroclzTcrj2Jw9L86otqW3q3lkpo686TYLVZbL1wdcygq6kJrN9a9ilR/BXl4vlulI5Z5wJxIppWr5JfKVpVV2WJXYg8889HX7f3vlcN998s5x44onM5wIAAL0KYRcAAEAHuI6TEVTpdV1p0UrMytI5XA0L1mYEXWa7aFx2Pfu++EqC0rhsY959ZwdR/qpSE3QpnesV3dMktW8uzxuUqcCQarGCgdb9lQYz53P5bLH8vnbP5/rCF74gM2Z4rZEAAAC9BWEXAABAB2holc6JxlOBlBuJiziuhLe0rqCYrmV7rcR3Nxbcd+Wc8a3H8dkS3rDTzNcqGTHQhFbDzj1chp55qETrmmTD75+W6Pa61PYaYg09a25qpUerJCh2VrClQVtbnn76aXnkkUeYzwUAAHotwi4AAIAO0HArXbLKygyo1/ZGESmdMDTvY2M76gvut+qQiVJ18ERzObK9TrY99qbEEsFYcFiNjPrkieKvLjPhV3BItUy8/nzZ8eS70rh8k7lfg7DySd4we63uSp/b1Tr3yy46n+sXv/iFtLS0MJ8LAAD0avwVAwAA0BGOk9HCmJrd5bjekC0Nu8YMlurDJkvtmyvatcvAwAqpOXyqmdllhwKy89n5qaBLRbbuka0Pvipjrz7dm+NVXiKWbcuIC481A+j1McluRRN0lbS2Miq9v9isLuZzAQCAvoSwCwAAoJ20eivjemvuZQbTpy7HXRl63hHtCrt8FSVSPmOMrP/dUzktkumaVmyWWDgioUFVJuhSVtAndsifCrq0eis71DJBVygz/ErHfC4AANDXEHYBAAC0kxn27k2i964nVz00V9Iu2pbXMqj3p4Vg6QYcP0uCg6okOLhSNvzhmaJBl9mnzyeBitLWoCvkF19aiNWZoEvnc/3rX/+S//3f/5WBAwcW/+IBAAB6icKDGwAAAJArETYlQy032T6YfrvfJ3bAn5rBlU/DovUSGjFAWjbtbjPoUtWHTxFfacjbf8CXEWzlDbr0tgJBl87nuvPOO+W9994zVV0EXQAAoC8h7AIAAOiA7BUO7UCgtZor5AVOpqrLsmT4BUdJxYET8u5HV1JsXrNN/AMq8h9H53D5bDOTa8Dxs2XkRce3ti6W6IwuyxSY2aVZQZclYpeFCs7oqqurk69+9asyfvx4+fKXv8wgegAA0Ofw1w0AAEAHaFWVJFZdVBoqxSJR08VoBwMSj8TEEkt85SEzvH70J06Q9ZGoNC7ekLOvyPZaCY3MX1U16AMHmpDLV14iPp8XsFmhgPgSgVpqUH36CouWmOovrSzLh/lcAACgPyDsAgAA6ABtV9RqKzcSS1y3TKWVG46aQfFaVRVvDItl2eKrKJV4c0vG8Pp0oREDpfbNlXnv05ArUFnmVXC5rqng8iWqtVzLEl9ZMCvo0ttCmbelYT4XAADoLwi7AAAAOkhbDOM6ZyuxOqMvGJBYzBGJxcXW1sPyEok3tZgKL62yCq/bnmcnllQePFHqF6zLe4xYbbO4egifiK8kJHYgEWLZtvi0dTE91NLbNPxKmxuWPp/rl7/8pTQ3N5uqLtoWAQBAX8fMLgAAgA7SaiuttEqnAZQVTMzv8tmmMksCPonuahCnOZK7E8cVN+5K2ZSReY9RNnWUqRgzbYk6CD/miiu2WDqvK20VSA3TtGUyX9CVnM81btw4uf766wm6AABAv0DYBQAA0MlB9emBlwZgvpKAuc3RG1zdxi/BUYPEV1GS83hfZakEBlTKgBMOlJIxQzLuqz5qulTMmeAFWK6GXCJWaciEX7pzJ+qKE3dMO6VpXdT+yTzzub7yla/I5ZdfLmeddda+eRIAAAB6IP55DwAAoJPsgN/MyjKVW4mWRsvnE18wJE4kKq4bF38wIMM/fIxsvOuZ1gdaIkPPP1rs0hKxS0TG/9eF0rBgrUS27ZHyySNT1V6uaYP0i+W3TUukSdH0nyotXZUxqAcz1WGWLzPsYj4XAADozwi7AAAA9rLCyyoPSbw5Ik5LzBtGb4upwrLifnPbgBMOkuDIIVL76mKTVFUfPk1CY4ZJy46oRBtiYod8Uj5jglQeaJvwTEMs0dlfGnLZZvKX2a9+6OqPpmUyMbPLiTliuZbYfpv5XAAAAIRdAAAAXUBneAUC4rqWt0qj44gTd82cLZ2ppcPkK2aNk7JpY8V1HJG4K3sW1kq01lvRUSQq4W0RqTmgWnwlPrM/E3DpPhzXC7wCGnIFzL6cqKPTu1IVXbrdnto98j+3/I8cf/zxtC0CAIB+jbALAABgL7iua8InM6MroC2HPomHY2LFY+JaMXFj4lVluab7UMSxJLyzJS3o8jgRR+qXN0jZ6DIJ1gTFdR3TEmmqu4I6lF5MeObomHqfDqx3TLimFV0rV62UH/zoB/L5z31eZs+Z3V1PBQAAQI9A2AUAALA3QVfEab2uoZZWXdm2uKGAWDGfOLYjEouL0xIXNzG5PlqfGXQlReuiUruo1rtii5SOKJeqaTUiGmxpdZffC7mcRMilFWLPPP+M/Ouxf8nN37lZBg0clKoEAwAA6K8IuwAAADoZdGmwlbrueBVeVtpl3cZjiy9oSzwaF3F8EqgOSfOm5uIHcESaNzaaFsXqWQPMfvXxvoAtblwk6sbkt3f/VprDzXLb/94mgWDAOw+d4RX07csvHQAAoEcj7AIAAOgEr40wLfjSkCmtrdHcZuZ2eYFYsgIs1hyTlh3hdh8nvKVJSkeUSXBAyGtfjLtS39wgt/z4FjnumGPlrDPO8obaJ8/L9cI2qrsAAEB/RdgFAADQQSbMai3qEjeqCVNu0KVthlqhpSsmqnhLXOqX62D6SIeOV7dktwyaO1Rc2yerV6+Sn/z2Drnm8mtk5qyZ3vEdb36XlQi9CLsAAEB/RtgFAADQAckVEpNMkKXhVrKtUe/SbCuxXTLo0pld+tHRoEvFm+MSbYjKq4tflMeee1xuvP5GGTRE53OJiC7eqDVlZgJ+IuBKOz8AAID+hrALAACgndLDK++641Vvab6knxMthMkWx3jEMfmThlxiWxJryj+Y3rBELLPKYm5Q5TiO/OGBuyQcb5H/+a/vii/gzw219LTsxHmRdQEAgH4s8ScRAAAAijEtihlBl9eymBF6JWZ3aeplhtVr0KVtjTp7a3uzNG1oKHIAkbIxlWY2V7rGlkb58dN3ypgxY+Tayz4nfr/fzAZrfZiXbGXnW63D8QEAAPoXKrsAAADawczgSsuPtAJL2we9OV2JNsbENk7cK68ybYaOK9G6iDSsqGvHMRwpG11h/jkysrNF1u/cIHe98n9y9cevktkHzm7dLv1ByYqu7HBLrzK2CwAA9EOEXQAAAG0wrYmJdkVzPVHFlbpsLnhzuhzXlZbtzeYxvlK/aU1s3tTU9kEskUBl0GxfNqpc3tz4jjy14Cm58fpvycCagYk+x+QJpJ1b6uasZMucH2kXAADofwi7AAAA2lFxldnOGPequhIhmPm/mCvRpqjsfnuHGSivNLiqnFKdancsyBavoktE9izfLfc8c680R5rlyx/8olSXVonl8zZLrraYzkpkWulD8815Onr8LvjiAQAAehnCLgAAgCJMoJWWVWm4ZVY/TK7EqBJti/VLalNBV3Lb+uW1YoXyj0ktG1thAjF/eUBsvy1bFm6SO//5Czl0/MFywox5Io2uNKyskwFzBhU+P12EMVHDpedq2d65MbMLAAD0V4RdAAAAHajq0uteVZfjtRPqjC6z+qIrLTvDeR7vitvUGoAllQwrldDAktT1VWtXy0/v/6l87KiPyuRhk1K3R+uiEo864gtpmZYXYFmplMvKbFdMz7fczPALAACgvyDsAgAAaG9Vl5Ne1eWm3eax/JZpZ2xL+fhKCda0rrqoQdlDzz0k1576Wakpqy58PmZUmJvZzphddeZrvY+wCwAA9Ef5a+oBAACQOwcrLeAylVOi87ucVPhVOrK8fftNG3avNLy67srrZPCwwTnbBqoC5nPzliZp2tgo8XDieIl9mGqz5HmmX05WldHOCAAA+hkquwAAAArIWIHR0fbF1suGDoE3N2gvoyvl4yrM5ebNTZmrNGbxlWZPjtcB946Uj62UxnX1EquPmlsD1UEpHVYiu97cntqfzvCqOWCglAwrE9fnVXllzOqKZ1Zzmet+qrsAAED/QdgFAADQjqouDbNa53ZlbpMsntLgSWdrFWtlDNQExV/mVWslWT7bhFJ2wJbKSdVetZgr4q8MSO38nZmVYK5I7eI9UjKkNBVk6WfHdsW2vVlirmNlhF/JUAwAAKA/IOwCAABoR9jlxJNVXJIWennzupKtjHq9aVNT3v0FqgMSqA5JcEDrrK4ky6ePbb2uKzMasbjEGmO55xZ1JFoflWB1UMSXGFSvgZitE8UyK728k9dyss48CwAAAL0PYRcAAEA+abOu0ofQp4/AspLXE4PjNfSKh3PDKRUaUiqBimDuHbaIE82tBGvZ0SxNW/IHZ+ZhZnVGLySz/Ilh+onh9dnVXOb80wbXAwAA9GUMqAcAAMgjfRXGjLlbqWHwmdtrRVWsIZqxOmI6bW/UNkXL1kouy7Qf2gHL20/WviK7W6RpQ6NIgXbIkmGl4gt5f8Y5cSc1hD5ZjaaxlpUV1gEAAPQXVHYBAAC0tQpjejlX8mKe/Khle3P+HWqmFXPFiSaTsEQ4lWfTaG1EmjY2FD2/kuGt87oy6rUyAi4xwVr618DcLgAA0B9Q2QUAAJAtu2orPURK3mllf85scczeX92yPaYKq5imjY3SsLqu6IB7Fd7S7M3paj3DxHHSVmFs42sCAADoqwi7AAAAsmRUcpmcKF9FVPI2K6O9sPBORcKbC8/gciLxwpVh2bsyA+hzzyQVvAEAAPRjhF0AAABtag2Rkq2A+klv1Wt20PuTKjSwRMrHVRTcixONi6/UFl+JT+wSn/c5ZJsPN7GiY3u07AhL7cLdXlukDp5P5W6tf9qlh2HeDe3ePQAAQK/GzC4AAIC22FbrYHoNkRyReNSRhpW1EtnVIr4yv5SNrjDhVfm4SgnvCEu8MXdVxmB1MDHA3qsVc9MCNF95IO+hrYDltTWmF225Is2bm0w12OAjh+cEXNpqaWWlXczrAgAA/QWVXQAAAFmyg6H065Zties4suPlrdKwql4ieyLSvKlJdr21XeIRx6y0WD2jJqeSyg75pGx0pdhBn/mwQj6zQqNZpTFoS6AyIKUjy7JORKR6+gAZdPjQvJVZLTtbJNYcM+GWWekxWXXmb71srmv1FwAAQD9BZRcAAEAb/xxoAi7Tt+itaBje2iyxhmjGNro6YtO6eqmZNVCCNSEZetwIqV9VJ7HGqGlvLBtdLrbPTs2RTx3C7NYLo6pnDpDQoBJTGWYHLCkbWSH+ioA48XjBAfPa/ugLBM05eudutV5OO38AAID+grALAAAgiwZaXgVX2qwuvyVO1Gs/jDXltiiqeDhuthPHEjtkSc2MAfn3n/jc2sbYek/piDLzkWJb4gv4JTioRCI7wxn78ZXr7aHWMEvHd/mtnKouwi4AANCfEHYBAADkoaGRG0kLu2zLtApqJZVWauUTHBgSy2eL5Wtd1dFKTedqDZy8mVodC6AGHDhQdr6xXWL1XkWZr9Qng48YJrZte/szx80Numw/UysAAED/QtgFAACQh4ZGGhQ5aaskmgqpgC0lI8ukdHS5NG9oTN3nrwxI1dQaMy/LhFtuerylvYraCundZgIpc8WrFMuex+WajM3b2EoEZdoaOeIDoyWyu8W0TGq7o+mF1BBOg67s1kWCLgAA0E8RdgEAABRgAiPLFieaFnjpyokBnww5driENzdLeFuz+Mt9Uj66wlRXJbZq7xHacauVUQ0WGlxi+h51sUXLzhNm6TwwHVBP6yIAAOinCLsAAACKMO2LQW1fdDNmeGn7YNmocvOhvPu0ostrWzTVWclRWuZy+hVzoZ0nkLs6ZN7NdDttY0wFbgAAAP0TYRcAAEB7BtYHvIH15iOeuzSiV0mVDKW8SV0F9tZ156W5lp5b1qwuAACA/oywCwAAoJ000DKhlt+r5DLVXCb3SlRyuYUemIi40gd0dSKbMoFWIlMj3AIA9BcvPfuGvPTM6+bysScfLseeONdc3rl9t7z64tuyfs0m+fR1nzC3Pf7QczL/7cWpx9bVNchJpx8jJ552dOq2cLhF7vndg7Jty04JhYJy0RXnyrARQ8RxXFm2aKXZ58Qp42TeKUdknEdDfaPceN0P5BOf+pAcNHdWxn2rlq+TB/78qMTicRk/aYxc+MmzTBV4c1NY3nzlfbPPa778Samo9FZcXvTeMrnnroekqqrCXD/gkBly+rkn7LPnsL8h7AIAANib4AsAAOwztbvr5LknXpbrb/y0+e/u92/8pcw5ZIYEgwH5828fkGmzJkl9bUNqew2M0kOjH3/3t3LQYZnB1H/+/YYMGFQtl332o7LwvaXyz78+JVd94WPy+n/ekRVL1ph/vIrH4znn8s+/PinVNZV5//v/1z8+LBdfeYGMHjdC7v7F/fL+W4tNIHbf3f+U4SOHSkNd66I2yRBOQ7vTziHg2hcY6gAAAAAAAHqkdas3ycQpY6WkNGSqsCZMGSvr12w016/92hUy9+iDCj525dI1Uj2g0gRb6dau2iAzD5xqLk+fPcVUhqkjjztELr7qAhkxemjOvpYuXGkqv6bMmJhzX1Njs0RaoiboMvs8YLKsW73RXL70mgtN+BYIZtYaaUBXmajqQtcj7AIAAAAAAD2SthyWlJakrmvI1dwYbtdjX3zmdTnmpLl591ma2KfPZ0ssFiu6Hw2yHn3g33LuR08teI6lpaGMc2xqKn6O9XWN8vLzb8n3v/MruesXfzXX0XUIuwAAAAAAQI/U2YEBu3bske1bd8rUPJVYOcvIFJq5mfDEw8/JkfMOKViJVWxZmkKOmneIXHzl+XL9jVebNsfHH3y2w/tAYczsAgAAAAAAPVJZeamEm8MZLYMlZa2VXoW89O/X5ajjDy24z+bEPmOxuNg+u2hV1zuvLzSPefm5N2XThq3y5ivvmfbEAw6Znra/ltRjtPIsvdIrn+oBVeZxSmd73fuHh9r8mtB+VHYBAAAAAIAeacyEUbJq2TrTKqgrG+q8rXETRxd9TEs4Iu++uUgOO+rAvPePmzRaFr67zFxe+O5SmTxtfMF9BUMB+dZtXzQVWF++8Wqzz09++sOpoEuFSoJSWlYiG9ZuFtd1ZcG7S2VSkX0qHWK/bNEqc3nVsrUyeOjAotujY6jsAgAAAAAAPVJlVbmcdMYxZlVFdfIZx5rbinnj5Xdl1oFTzeysfI454TD5v1//XW795s+lpDQoH7vi/L0+zw9ffKapzorF4zJp6jiZOccbgF/IeRedLn+9+2F58N7HpbyyTC667Ly9Pge0slyNHdsQjUblwQcflPPOO08CgUBbmwMAAAAAAABdqr35FG2MAAAAAAAA6DMIuwAAAAAAANBnMLMLAAAAAADsd7FYTFasWCHvv/++TJ8+XebMmdPdp4Q+grALAAAAAADsc7t37zbB1vz5803IZVmWTJ48WQ444ACZNGlSd58e+hDCLgAAAAAA0OVVWytXrjTBlgZce/bskZqaGhNsnXLKKfLpT39a/H4iCewbvLIAAAAAAMBe0TArGWxp1ZbSai0Nt774xS/KwIEDu/sU0Y8QdgEAAAAAgHaLx+OmaivZkqjtidXV1SbYOvnkk+Xqq6+magvdilcfAAAAAAAoWrW1YMECE24tX75cXNdNVW1de+21MmjQoO4+RSADYRcAAAAAAEhVba1atSpVtbVr1y5TtTV79mw58cQT5VOf+hRVW+jxeIUCAAAAANBP1dbWmlBLP5YtW2aqtiZOnChz5syRz33uczJ48ODuPkWgwwi7AAAAAADoJ1Vbq1evTlVt7dy5UyorK0074rx58+TKK6+UQCDQ3acJ7DXCLgAAAAAA+qC6urpU1dbSpUvFcRxTtaXh1mc/+1mqttBnEXYBAAAAANDLaZClVVsabGnl1o4dO0zVls7aOvbYY+WKK66gagv9BmEXAAAAAAC9TH19fWqFRK3a0hbFCRMmmKqta665RoYMGdLdpwh0G8IuAAAAAAB6eNXWmjVrUrO2tm/fLhUVFaZq65hjjpHLLrtMgsFgd58m0GMQdgEAAAAA0IM0NDRkVG3FYjEZP368qdq6+uqrZejQod19ikCPRtgFAAAAAEA3Vm2tXbs2VbW1bds2KS8vN1VbRx11lFx66aVUbQEdRNgFAAAAAMB+rNpauHChCbeWLFliqrbGjRsnc+bMkauuukqGDRvW3acI9HqEXQAAAAAA7AOu65qqreQKiVu3bjVVW7NmzZIjjjhCPvnJT0ooFOru0wT6HMIuAAAAAAC6QGNjY0bVViQSMVVbOmvriiuuMFVblmV192kCfR5hFwAAAAAAnajaWrduXapqa8uWLVJWVmaqtg477DD5xCc+QdUW0E0IuwAAAAAAaENTU1NG1VZLS4uMHTvWVG1ddtllMnz4cKq2gB6CsAsAAAAAgKyqrfXr16dWSNy8ebOp2po5c6Yceuih8vGPf1xKSkq6+zQBFEDYBQAAAADo15qbm1NVW4sXLzZVW2PGjDFVW5dccomMGDGCqi2gFyHsAgAAAAD0q6qtjRs3pqq29HJpaamp2jr44IPlYx/7GFVbQC9H2AUAAAAA6NNVW4sWLTLBln4Oh8MyevRomTNnjlx88cUycuRIqraAPoawCwAAAADQp6q2kisk6mWt0tKqLW1J/OhHP2qquAD0bYRdAAAAAIBeSau0tFpLg61k1daoUaNMsKVD5PUyVVtA/0PYBQAAAADoFVVbmzZtSlVtbdiwQUKhEFVbAHIQdgEAAAAAehyt0lqyZIm89957pmpLZ2/pfC0Nti666CIzd4uqLQD5EHYBAAAAALq9amvLli2pFRLXr18vwWBQZsyYYQbJf+QjH5GysrLuPk0AvQRhFwAAAABgv2ppaZHFixebYGvhwoWmamv48OGmauvCCy+UMWPGULUFoNMIuwAAAAAA+7Rqa+vWramqrXXr1pmqrenTp5uqrQsuuEDKy8u7+zQB9CGEXQAAAACALq3a0llbyaqtxsZGGTZsmAm2PvShD8m4ceOo2gKwTxF2AQAAAAA6TWdtJVdIXLt2bapqS1sSzzvvPKmoqOjuUwTQzxB2AQAAAADaJRKJmKotDbbSq7Y02NKqrbFjx4pt2919mgD6OcIuAAAAAEBeOmsrWbW1Zs0aU7U1bdo0qrYA9GiEXQAAAAAAiUajsnTpUhNsLViwwFRtDRkyxARb559/vpm1RdUWgN6AsAsAAAAA+qHt27enVkjUqi2fz2eqtnSQ/DnnnEPVFoBei7ALAAAAAPpJ1ZYGW1q11dDQIIMHDzZVWxpsjR8/nqotAH0GYRcAAAAA9DE7duxIVW2tWrUqVbWl4daZZ54pVVVV3X2KALDPEHYBAAAAQC8Wi8VSVVv6UV9fL4MGDTLtiBpsTZw4kaotAP0KYRcAAAAA9LKqreQKiatXrzZB1tSpU03V1hlnnCHV1dXdfYoA0K0IuwAAAACgB1dtLVu2LLVCYl1dnanaSrYjTpgwwbQoAgBaEXYBAAAAQA+xa9eu1KytlStXimVZVG0BQAcRdgEAAABAN1VtrVixIhVuadXWgAEDTLB1+umnm1lbVG0BQMcRdgEAAADAfrB79+6Mqi01ZcoUM0j+1FNPlZqamu4+RQDoEwi7AAAAAGAfVW0lV0jcs2dPqmpLg61JkyZRtQUA+whhFwAAAADsJQ2zklVbGnKpyZMnm3DrlFNOMUEXAGD/IOwCAAAAgA5WbWkbYrJqS9sTtQVRg62TTz5Zrr76avH7easFAN2F38AAAAAA0EbVloZaWrmVrNrSNkQNt77whS/IwIEDu/sUAQBpCLsAAAAAICEej5uqrWRLolZtVVdXU7UFAL0Iv6UBAAAA9OuqrQULFphwa/ny5ea2iRMnmnDr2muvlUGDBnX3KQIAOoiwCwAAAEC/qdpavXp1qmpr165dUlVVJbNnz5YTTzxRPvWpT1G1BQB9AL/JAQAAAPRJdXV1qSHyy5YtE9d1ZcKECTJnzhz57Gc/K4MHD+7uUwQA7AOEXQAAAEA/pyFQkmVZ0hs5jiOrVq1KDZJPVm3NmjVL5s2bJ1deeSVVWwDQT/DbHgAAAOgngZbJtJzWcCst40rfUsQy/6/Jl/6/WHbPC8G0aktnbWm4tXTpUhN2adWWztqiagsA+jfCLgAAAKAvB1wabjmJoKvIdioVaLnm/00aZj7H9U5XbA2/NPiy92/wpUGWztpKVm3t2LFDKisrzaytY445Ri6//HIJBAL79ZwAAD0XYRcAAADQF0OuuIZEbp7qLssLsTQA0wxLrLQgTC+4pppLbL3HFHd54ZYr4uiGjt7miu2z9lnoVV9fn1ohUau2dLB8smrrmmuukSFDhuyT4wIA+gbCLgAAAKAPceKu+chuX3TjiaArEWiZgMsEWJpemcIt0btN+OU90FxO7DURbnnVX/rYeExDMVdsv7Y6WntVtbVmzZrUConbt2+XioqKVNXWZZddJsFgcO+fGABAv0HYBQAAAPQBGmo5ca9lMclx0kOuRDuj46ZVfHlVXqkhXYkEzGRX5n9csXxewKX71nZGy9aAq7UiLB51xafX21nl1dDQkDFrKxaLybhx40zV1tVXXy1Dhw7dJ88PAKD/IOwCAAAA+gAn1jqXqzX4SuZXXrWXmc3lWub21sArUeKVQau1XK+Sy01cTlRxuY4l8Yi2MYqp9lJa5aUBmJ0VeGnV1rp161JVW9u2bZPy8nKzQuKRRx4pl1xyCVVbAIAuR9gFAAAA9HLx7KDLXNd2RO9yssrLtDcmNjThlwZe5v+1ZdGLvLRiy4Rb2raoN8Q19LJMuOVGNeDyqrhMpZcGYImAS4/TGG6QRYsXmWBryZIlpmpr7NixMmfOHLnyyitl2LBh3fckAQD6DcIuAAAAoBdLtiYmmYquZNAV9aq5TCWXuT1ZAeZK4+6o1G+PmevBcluqhwcl2uyY6yVVPvEHfSb+8vmTw+nFVG/pfiyd52Vbsmb1Olm0eL4sWLhAtmzdIhXl5TL7gNly+OGHyyc+8QkJhULd+twAAPonwi4AAACgF8sYRm+Cr8TlWPK2ZNDlhV+qdktE9myKpB4XDTvSuDPxgIRgmS2Dx5WIlNpmfFdLpEmWLF8si5ctlGUrlkg8FpPRo8eYQfKXXnKZqdrS2V7a6pjdzggAwP5E2AUAAAD0UsmVFpO0VTFxR+o+026YrPKyXImFHanbFm1zv+vXr5PnX10sm+uXy47d26SsrFxmTJspBx1wiPy/Cz8mJaGQ2H7bbG8G1CdWZDRhm3czAADdgrALAAAA6K2y58onVlZMBWCJC8lqL3HMMoupOV75bNq2Vv72zO9k6MCRMnHUdDntyAtl5mHjzOqM/mAi3ApYZsC9nZjypYdJ1nKZIfipawAA7H+EXQAAAEBfzb5yrnuztlLT6PMYOXScXHvRTanr/pBub6fFV96lZCUXAAA9DQXGAAAAQG+VlTclR2Xpaore58zt7MQNHcmpgmXeoHoNyUwFl50edOXuiAgMANDdCLsAAACAXsqETunpUjKESoVallh2IvjyWan5WiUVvvz7y3p3oMPmB4wIepd93v6Sw+ftxP68ICx9H8RdAIDuRRsjAAAA0Itp+JRckdFUXemKjK6uiigSjzri01DKFTOc3ozuilsyYEyJRJY3STzS2stYMyIoZQP90tLgSEtDXPwltlQO9IsvaIvPr6Gat0+vsqs1GNPQK72lMTswAwBgfyPsAgAAAHoxDZtcE3AlKq9MyOWayz6/LU7cMdVcTmI4vdiulPhtGTWzTJpq42ZYfWmVTwIhr9pLP1cM9JtKMBNkJQrFvKBLgy2v4kv3pcFWa4VXbvAFAEB3IOwCAAAAejkNn+K6wmIi8DLhllZ72Zb4LA28XDPPS2d5adWX43ihVvVQX9459V5glQiz7PQqrmSbYjLoSnuM7YVjAAB0N8IuAAAAoJdLBlypwEuDJ0uruUTcuFZ7afWXI66lQZcrvsRcLa0GS6Vd+jk58svc71WHede9dkmvf9FNVHC54ujh9H80/LJciUW9CjPvnMz/JkK2RHWY+UwgBgDYtwi7AAAAgD6gtaLLC6DMdZ+Ia7vmNsuyxdXQKpFwaRCmYZQXViV3ksi7TPGW7a3umBp2rymaN/crGnO8x+v22u6olV/xfGfl5txs217Y5ksGaAAAdDHCLgAAAKCvBV6moqt1jpfe5rquuHq76w2st5MVVgVbDzUw86q6XHEl5iQG4Scrt3R+V2KFRuXo/tNzs+RutaIrbclIPTetLosmAjS/zwvlUucDAMBeIuwCAAAA+hhTMaWrNOrg+rTQS8Mpj2XCL8PkV4mgyfUCLlOxlRjUFY25EoslNkxUculdWhAWj4vEHcdcLkZDLe+UMoMtPQXdfzQm4vO5EjBVYoReAIC9Q9gFAAAA9PHQy1R1mflaXsKUDL8yWheTVxL0MZGYzuXSkMxbhVGruWJxbzZXdsBV3+SYlshg0JL122Nm+3FD/GL7bdM6qfPC4uJKVFsqxRWfVnTZkpofZoIzHaRvuxL0E3oBADqPsAsAAADo40xVl2ZHdr6qrswB9VaiJTES1SouW5LFYHpbSySziivuiNQ1xeXR1xpk3TZT/uUNxk9sU1Vmy7lHVcqAKjsxo0vEr8PzbfFCs7hu70rAr8FXoh3SEQlH9DYxtwMA0FGJRYQBAAAA9K/wS9sRvQoq85FsIbREIia3ag2a4o4r4bRqLh3dpYFUS8SVx15vTAVdKj0Mq2ty5Km3G0w7ZUzndEVd87imFserGtP5Xa5Ii7ndMcdJ0vbG5hYdhN9GjyQAAFmo7AIAAACQokFX+qB5U9EVbb1BK7L0uiWWNLXEZe1WHTVf2JbdcaltdKQkaJvqsoBP53OJmQMWFcfM6dIPx/ZCL73fnxh8r+ehIVso0NruCABAWwi7AAAAAKSCLJ2bleTmBF3itTcmWiHT7ytE2xedtNUaN+2ImdUdRw3ySyhom31GHUdCftuEXFE9B0ckGEgMsk9UfoX8GpIReAEA2kbYBQAAAMCEV9o6mE6DqNR4L0ekJeZ4QZd4bY2L10Xa3O/EkQHz2M07Y/L8+03SGPZ2qOHVlNFBOXBiiQys9kkkmgi5/BqOWeZ6RuAVc6VE5+1T4QUAaAMzuwAAAACYGVrZ7YtaZZW6P+6K5VqpEGx3fVzeWBouus9xw/wyY0zQ7PuVxc2poEu1xEQWrInIX/5dJ+8sD5sATVdkbIl6wVtyllf6MP32VJIBAEDYBQAAAPRzXvti9m2tl7UyS7dRjmgFmCMbdrQOpc9n2ACfHDy5VGzblvomR3bXazNjLt3rq4ubzaqOum8dWh9N7FpzrozzMNcJvAAAxRF2AQAAAP2YrnaolVcZt5mWxtZwSldS1PZFb3v9X0tKg/nbCXXu1rQxQTl8WqlpeLQt18ztKkYDra274mYemFZy6XUnEWpFYk5rdVdilUYAAIoh7AIAAAD6cdBlWgOz8iOz2qLOykrO8ornhk3jhwWkojQ38Jo7rVRmjA0lhs2LNIS9lsSSAuFYku5LzycZseljlZ5HdnWXbgcAQCGEXQAAAEA/FE8EXelzuvLN7jKhU2JWV3JFRWX7LDn54HKZMDwgZSFLBlbacsT0Uhk2wFsDS/OoZMWYXh41uPDaWFolFvB7b02SbYo6rD55LD3XzHPf6y8fANCHsRojAAAA0M9ooGSCqDxBVzJs0tUQV2yKmLbFsUMD4vdphZWbMcervMSWo2Zqu6JIY0vmztLbDXfWxqWh2RHbTrZBZmqOuGalxg8eXpFxv170JeZ6pcsO6AAASEfYBQAAAPQjGmJlD3nXwfB6ezJoWrs1Kn9/sT61+mF5iSXnHl1pwq30OV4peToUdcqX/u/67VFZvDbS5nlt3BGTprAjZaV2Zqql7ZSEWwCADqCNEQAAAOgHdPZWOOLkBF2mnTHSGnTpPKyHX21IBV2qMezK0283tu4rq3Ir3witoN875sqN0Xafo+7Hlxac2YnLifFhrbfzLgYAUASVXQAAAMB+1tjYKIsXLzafR44cKZMmTRJ7HyY4yUH02e1/Gny1RJ2MYfSbdsakvim313DbHl0t0ZVAQKQ5o2XRlWiePMunA+pjrXO72jK0xicVpbb4EmmXPh3J8/IlUy/JH34BAJCOsAsAAADYj/bs2SMPPfSQtLS0mOtLly6VlStXyumnn75PjhfXQCtrPpdr2ha9qq5koJTcLui3Ew2ImXy2SFNLXAKOnXWnldnSmOA43tB6bYHUyrBiBlf75KSDykyIlcz8Ar60Y6dd1m2ywy8AANJRAAwAAADsR++8804q6Epat26dbNq0qcuP5VVuZQVdpp3RTa1wqNe1JbFFq7Ncy1RXTR4VyNmXroD4txcbZMHqlozgqaml8NKIjmvJ5FHBvPdVllpy2NSQnH9shZx3TIVUltkSCliiUZsGa8kKLx2Mb6eVcul1AACKobILAAAA2I927txZ8HZtaezSFRfT5m6l5nOlVXlp0OVVeLUOqo/FXDl2dpmUhcKyeF0kow1R2yDfX9Uiowf7pbrcliaTe1mpVsnlGyNm0LxmU5WlttQ1xbNaHlvZtiWzJpSYCi5LLC/osixxLW2VbP03eX9WVVfAT9gFACiOyi4AAABgPxo4cGCHbu+qoMtxc4OucERMldeehrhEHSexUqNXPTV3eokJtPJZty0qzVkLLL63qsWEY3VNjtQ2OrJhR0zqmlyJxvOfY2nQSgVdOsxeWxO1vbLEr6GXt03QXG4Nt/Q6AABtobILAAAA2I8OPvhg07YYibSmRWPGjJFRo0btu6BLMtsZNejStsXXlzTLm8uaJRITKQtZcuSMUpk0MmhCJx0unyjayhHwZ4ZgOuReA7COmD0hZHavFV2poCvoXfaOYWW0LGpbY7K1EQCAYgi7AAAAgP1owIABcuSRR8q7774r0WjUBF3HHXfcPgu6VDRrJUad0fXWshZ5eVFz6ramFleefa9JBlX5pLLMJ9GY4wVkeWjF1+adUSkJWeK3LdPqmL3SYz7aklhd7pM5E0MyYURQShKti2K5UqpVXMmgy6dVX+lBlxeKAQDQHoRdAAAAwH60cOFC+c9//pO6vmzZMgkGg3L00Ufv1X41wNKPnNvjOoy+9frqzVF55PUGqW/KHSyvgdWKTRGZNS5k2h7rGvMPn3/+/aaMcEszKi32ihWeVW+2ufD4Sikv8ZnqLW1d1JUgLcuVUMBOW4XRypjLpbfTvggA6AhmdgEAAAD7ieM48vbbb+fcvmjRImlubq2y6ggdOh+OOHmDLg2sItHWBEq3e+ClurxBV5IJoGyv4kpbG/PJruLShR016ErO2jL7Sbtfbz9mdqmUl9gSDLQGXT6f17qYDLr0vuygSyu6dFsAANqLyi4AAACgi+gsLA1+3MSHd9lLhvSTzunKF2ppCLZrd70M9uscKw13vJUHlbmcfozEvhzHC7P0cz7JOV3pQdGKjbq6YuHz100njQhIyC/SFBeZPT4kry8Nt/vr1xbISSMDJigbNcgn9WEviBs1OGCCrtSKi+KawMufnP1liYT8rfO6kq2LWtFF0AUA6CjCLgAAAKATNGhyTeDUGjq1NbcqEAhKdc0Aqd2zO+P2YDAklVU1EjcrF7pdcm4adGWfT7HgqLzEG1BfU+Ez18tCIjPGhSQUtExIpqs06oyu9dsKp2UaUOmAey/UEqmp1OO5EgzY4rO9lRf1FEJBW5IjuZJtiumrLmp1V3qFFwAAHUHYBQAAALSD43hVW9o22J5gq5DDDjtSnnv2SYl7yZYJoA6de4T4/Xv/p7lWkWk7Yb6WRjV+RFBKg5Y0RzLvP2xqSA6ZXCJuWg2ZnpdWX00bHZQpo4Jm7ldTsyPbdjcUHFyv7ZFrt0ZlxthQaiC9Vm/Zif3q9YBpYcw/nyvZypi+CiMAAB1F2AUAAAAUqZDSTEpXOSwWbmnLoFZ5adjkutqm54VjyYekPzYWGColY8+VHbvqZVhlkxwxe5hU1dRIS9Tx5mUlqp2SgVB6xVOhc9T9axgVM32T+bfTc9OmwXOPrpRn3mmU7bVxEzzNmVAiR88s9bZJrOioH8nmSTNbyxJTmRWs9MlZR5bL60vCsmlnLNWqmdQYduWlBV6bpoZnyUoy/Xr0WMk2RSsRaqW3LZqKL60ISx/8BQBAJxB2AQAAAFm0ekuro/LNw9Jgy8zLclqrvTLlpk06t2pPgyPNLY787cV60xIoUibrdpdJ2OeXs44UMflS8rHx3P1lZ17pm7dFg65ozAvdhg3wy8dOqpamFse0D6ZXUZkQyrQQts4eM6Fd2vyxgZV+OX1uhdl++56oPPhyY87x3l/VIodOKTUrLQb82sLYOjtMA65AQFfKYhA9AGDfIOwCAAAA0qqkNORKdBhm3K6VU/F4briVqubSuV0a4CQqrRIX5fUlzfLq4mYTcGmWk10hNn91i8ydXiJDq31Fw56Otk2a8zLVXsmKr8x9l4UKL8yu9WUmAzNlZpmPS9WrmQAs//lqkBYKelVp3pfkfdYgLb2aSzGfCwDQ1Qi7AAAAgET7XkRnXbmZIZeGVNGY12KoIhFXdGRVwOeFXxp0tT4oM5HS+VXJtr5igdWm7TGpLPGJWI4JiBqa4/Lce02ycnNUSgKWHDLFazXUCqh0ZsZWYnlGU4Sm7YyJKiytyPKaIr32wqaWuAys9OWETR2l+zSBly0yarDftCdq1Vi6SSOCrS2Llhdo+bOOa8KvrFZGAAC6AmEXAAAA+j0TdKUNXXeTIZfXW2hoAPXEm01mZUK9deKIgJx4UJmUBOzU3CytdNIoKFn9tWR9S7uOP6Q68We5a5kWygdebJCd9V55WVOLNwdLz++omWVZj8xMz7Qqbf5qb55WdblPDhgflDeWhWXx+og5P11x8eSDy2XC8GDOOWiQpgPkNU8zwZ6VP5nzQr9EQBUS+eDhFfLIaw2J1kyRARW2nHRwmWmP1Dlf+cIsvc8bVE/QBQDoeoRdAAAgh9eWFRfXdcyHJD+nS7zhNZUjliW2pVUptljmgzew6L1Bl87kiqTN69LwSe9/9LVGU2mVtHJTVCLRRjO/ymvtS1R4mYve9fb8KMwcF5SaqtaSLQ2qkkFXuteXhmXFpqjMO6BMxg0L5Nyv5/n3l+pk6+7kY6Py3qqwab9M0gqvR19vkMtPq5HStDZGXQhSWwwzte/neOa4kEwYHpA1W6Jmn5NHBcwqi/l+D2igpsdhCD0AYF8i7AIAACmOEzMfrpPVk5SP6cdKTO/R1ilpfYxl+cSydf6QT2zbt0/PGdjbYNe0LqYFXS0Rr0orVd0VEzNYflVa0JW0fntMdtXFJBTU4Ci7EsqVMUP8smSdVwmWbuqogAmDxgz1y/hhAQm36AB311Q8hSOFh3Ptqo/Lw6/WyydPqZaqcl9qfpb+78pNkbSgy5MedCXp16Rfy6zxodRt6UPq89LVGK3EypBevm2iMMv2Bs3r/K9BVYXfWvi0kkurxgi5AAD7AWEXAAAQx4mLE2/Jrd5KVXlpBJBYmi31tt2r6vLanfRza5WIqQpLTPjW/7Vsv6n88gKwwkOxgf3NzJpKy5ai0da5WsmgS1/7LbHUWPYczREdxm6nVizUHwnNdPTzoGqfHDWzVN5dGTbtiNpGOHdaqUwe6YVd6fTx2oY4uNpnqp/SQ7jsAGv+mhY5aFIoYx/b9uRWgxXy5vJmeWdl2FRkHTGj1Aux8tAWRG1t7PBcrcRzoCGaVnMV2j8AAPsCYRcAAP1cLBbOqeQyq8o5MYnHW2TPriUSjTRIzYCpEgxVFd6RZYttyjw02PLaGVP7031p5Vc8q/IrUSKSLwDTc0hcKnTA1Owg2ibRWdr6l6SRbizuDaLXFkYNm/Q1qm2OQb8tQ2t8eQOllxaE5aSDy1v347iybntUdtbFpaLEluljgnLu0RUmOEvOqQpHRUqC+RsFdZi7zrx69t0maUlrr8w+7+zXvYZk7bWnwQu29Ry37YnJx0+uznse2o7YHibgS4Ra+pmh8wCA7kTYBQBAP6VhUlyDLjeeFXJFxXEiEm2plwXv/FwaGzamAqoJU86X4aOOMpUuZgy3BlVayWLb5rOjlWHaCmkyLK+N0avqygyz0iu/uooJzEzgRgUZ2ic5VD51Pd4aIMUSKxnqNsnqrppyO2/YVdfkyIvvN8rBk0NSVmLLywubZUdda5Wktgwef2CpGUKfPJ4GYk1hV8pC+cPaMUMC8rGTquSdFWF5d2XukPt8A+a1ZVI/tLUyqSwkMmlkSJauj5jwTgfGZ7c2rtsWky27YjJ8YOtbAw2rigVdVrJqKxFyETgDAHoSwi4AAPoprdrKDLocU+Wlw+jV2lWPpoIu7/64rF7+gFTVTJR4PCw+f6mEQolqELMbrejwp0IuseLi6h3xiMQtW3x2QMT25QRfXSU5SD+9gsy2A2L7tF2M4Au50oMu73piwLwJo7zbWgu/tBqr8CytnfWOPP1Os6nWCkcy79PqrGUbolJR4pPSkJVx3OYWV0pD+cMiDZO05VHPZcHaFvM56Bc5fHqpDKrKreLSfZx6aLms3ho14VVVmS1TRwclFLDl8GklZmXJe/5dl/zxyFDf7MjwtOtagZaPBlta8UXlFgCgJyPsAgCgH8oeQp8ddDluXHbtWJjzON1u/tt3SjzWZK7XDJohE6dcID5/idi2barCdAU4fS/vs4OtVV0aQsVbTAilwZe5zYRiiTfMyTAqORPM/H9yAL4rllbg6LapmWKtb7TN6o+i/VP6ObNKxqtSi5ptbF/QhHFAUrG4prUCK3mDmMosrYIqJjvoSqprjJvgTPeXnmvpYZojrpQGC1dH6UytAyeFpL7JkZoKnwmbCh4/6kpJwJKDJ5eYofFJOhg+FnFlYJUvZ4i9zuQaPbj1Z0MruuwC4VswQMgFAOj5+IsPAIB+yARP2dcTQVLcjYkTC0sgWCGRlj25j00EXWrPzsWyPvCEjBl/qsTE9SqpbK+SSlshxdGqLp/4fAGxrcSfHa7jtTumrd7YFrc998W9y6a6LGtumIZ02rLpmNArxAqRMLyVAVtfXeblkqoKdCUe9+ZPJW+bNDIgq7dEZFd9niUO21BV5r3mYo6GSbnBmrYWauhUiAZl81e3yJqtUTO8fua4kGmbTA/IXl/SLO+v1opNbzj8nIkhUxmm3lqmA+m9+9Lpwz9waLmUpgVjPn/+1RQJugAAvQVhFwAA/bCqK/0dr1flFU9VdMWjzeYN9PCRR8nKpfe3ub9d2+fL6PGniOVa3iB6J2baGDVAW7fqUdmza6n4A2UyfNTRMmrsKWL7dDB9+9oKtQ3SdCeKI7Foo+zasUBcx5EBg2dJMFRpcgo91+S8LjNHLFG1pl+RL1HNlRl6NYvrC5r7AA2zktVbGhDp3Dp9TWmbno6V0xlXHte0A2qb4NqtEXl1cUvREDad7mPKaO/1Zutwuzw1ZdrqqIFS+j3rt0fNvC8NwTbtjKWGymsl2FvLw+byIVNKzOe1W6Py3qqWjHBMZ30NH+A3lWBvr8id+zVtdMAM1tdqsYyqrqzz00BM2ycBAOgt+M8WAAD9TDLYSvJaDz3xeMS80ddQqHrgVBk/+RzZuvl1iYTrTPDkZFWEeY+PSSzSaEbW+/2lpqLKcWOyZP7vJdy8w2wTaamVdaseM2/yR4w+1ms9TIVQlmzd9Jps3fSyxGMtMnDwbBk19oRUW6Kqr10jSxfc3VqRtuzv4g9UyMDBM2X0uJNNFZqRmA1m9q3DxXVeWLxFfL5QRrilt+vX6Pd7QQH6L23NiyQGc2nrnt9nm5UONaCyNJhytaJJJBIVCQVcibuWTBgRkpKQDqIPF1wtMd1xB5RKeYmdOl52dVVScuGHZCVWvoAq3aJ1LamwSyu+8tHbdQh+Plpllh50eUPnc7fTii4G0AMAehOmtQIA0M94s7Bywy+tnkrO8TLbuK4JnqbOvFjjobxBl9KVD81njcNiTRKLN0t93dpU0JVOQy2zf21l1CAqFpYNa56SlUvulYa6ddLctFU2rntGli+5N/WmX61e/mBW66UrsWi9bNv8mix+/3epQfu6zz27l0tD3QaJO1GvSicReulMMr3e+nXHTLiG/k3Dp/QcRwezJ6u7km17Gnx54ZclZUGv7mnEwIBccFyFHDolZIbS55Pc72uLw7J6c0TKSwoHXenCESejSquQSFrQVmigfEnQymhRTFcabP3C9WsO5Qm19PlhGD0AoLehsgsAgP4mPfBJf+edeIOfGYCJbNn4sll9sZDy8pEmWDKzuhKPjURq824bjzfn3LZ5w4s5t+3esVDCzTulpHSghJt3S3PTtoLH14Bs57YFJllYs+Ih06aYHJ4/ecbHJBSqSrU36vqQWn2WZIbXOz4G1/dz2uaXDI60uisYsCUa0+ouSwIBV6LRZHWXa2ZrlZbY0hLxLk8bE5SxQwPy6OuNOVVeyR8vbTvU8Eqru8YPD+Q9Bw2kkpHUjtq42Xdbxg9r3de00SFZtFYrFlvv14xq1viQlAZteWNpWCKxtPlklsjBiaowpS2a2UPp9WqhEA0AgJ6Myi4AAPqbtDe0hVuTEm+KXVeaG7cU3JW2Bw4edrCp+tLgKPlWuqJitNh2brlLzcAZmUdxHYlG6vPuO9JSJ1EzP8xbSbGYcHinrFxyXyroSg7P37D6CVM9plVr5nhO3LRqpsu+jv5Hq5fMIPq0uVXJaia9HAho5aJX6WWqvbQKKiimPVAfq0GVzvKaNCIgAyttGVqTf9L8ik2ZrzU9hFZX6aqJ6cVT89fkD5fTf1oHV/vkyJlecKs/xiMG+eXsIytkcJUvdb933W9CNq1CGzcsYGZvDR/okw8dVymjB3thmQ68168jG+2LALBvLV2xTu554Jl2b5++7Sc/8z9SW9e4j86s9+PfagAA6GdMlVOBe1KS5SGWSHnlaKmrXZWztYZZE6acL/6A94ZbAy/TemhWXwzKmPEfkPVrn061P5ZXjJKRo48zA+atRLKgQVZV9cSc/fv8pRIqGWBWbtSqq6HDDzMVZoW+oqbGrXnXbNyx9W0ZN+mDEo9FUvO5tB0yfWi9WR3SiVHd1c9pC1844qZe+hoKtUS9Qe8aeOlPh87t8tsidsg2VVxu4nHBgCulQZ8MrCqTWNyVpesjsm1P5mw8pfcFApZormR+BBILLDiOK7vq4yY00+Nv2J77WDVvjjf7S8OpITV+sw+tStOgTM9wwvCg+Ui2YSrXcs35jxvm3ZdN78sXdOmwfNoXAWDfmjZ5rPlor3sfeEYuuuDkfXpOfQV/1QEA0M+kQp7UDbYJfLQ8JPkm2czh0lUVRWTg4FmyfetbZjXEdKPGnpgKupK03dEfqDTv4qtqJsqMyssk3LJbAv4yKasYYbZxnIj47Nb2qXGTzzbD7JMVXrqS44Qp54ntC6RCtxGjj5dAsEp2bHtXwk07xHW92WL6Fn/k2BOkbk9uGJesHDPHdLXqLGQCATPDy3XEl/Y8JLdD/2VmdJmAy229HhTTrqgvQx3crq+YlphrViss0ZeniGl3jDv6MyMS1A+/JZNHBsxqidnzuSaMCEowPViyRNZti8oL85ukuUV/9kTGDi3857m2S5YEbRNy6XF0T/kqr8wiE+KaIEwH7hfKrEzVmj/PnbQvAkCH6N9Pv/vTI/La24vN5QvOmicfPOVIaWhsllt+8mfZvGWnlJeXyNe/9AkZPnRg6nFPPvuGLFu5Xj535QWmUuvwQ2bIgiWrJRjwy3e/fqVUVZab7aLRmHz2qz+ScEtEPnXd7fKL27+cCr/eXbBCAgFfanutFrvztw9IU3OLzJk5ST5/1QVip5cv9xP8ZwwAgP4mK+yybZ84cceEQLbl81r+Etvoe3UNnXRI/bYtb5hQKRAol+rqSbJn91LZvvVtKa8YIQOHzDYtjUpbCX3+EvNGXB9bWTUuo2rKzPdyQ6k36WXlw+TAuV+WPTuXmJbCAYOmSSBYaS7rYHlzypYlQ4YdYj40mNLzCId3SUXFSAmVDpRYtEka6tbmfKnllaO8x+vZmEAv0V5mBtq3nhNhF1LVTI6Gton5XWKZdsVIxDUVXrbPEl1UMRLTbSzZtCMqSzd4c7KmjA7K8AE+icZdqSzzyfFzyuQ/C5skmshlJwwPyIETvJ+R9EH0T7/dmJrPpftZuzUmJVplljX/S1sPtfLLDJEv0oKsIZcGYT7bC8UKKRh0Je7Lnt8FAL2dhlCO46Q+9Ho8Hs+5PXlfvuvDhw+XoP5LSJbde+qlrKxEfvWDL0tDY1gu/dz/yinzDpWnnntTxowcaoKoZ154S55+/k25+COn5j2/rdt3y4RxI0zw9cOf/1Wef/k9Ofu0o819gYBffv3DG+Tci79uPie3Hz5soPzi0utS259x8hFy6x1/kW9/9XIZO2qo3HT7XfLaW4vlqLmzpL8h7AIAoJ/RcCu9SUorqUSiiTu1okuDr0SboV6yAyI+V4aPOloGDz1Imho3y7rVT3jhkb5hb94uDfUbZfzks0zVmFd1ZUbVp6q9LLs8tbqiFzxldk1q2+OgoXOyzlP/THHFiSfOLXW+tlQPmCxVaa2WQ4YdaoI312nd1qsQOz/tgRl735unEH2YVnc160s78fJKBl7JFkcNmUIBkbdXN8sTbzWlHrdgTYucdFCZzNZAyxU5YEJIpo4OytbdUako8UlVua0/WiY0S1q7NZp3EL3OytJKsoawt3FNuS0nH1xuVlZMX6U0m1fxVTzkah08X3g/emwAmbKDkbaCko5su7cBTHse35nz7Kqv0VSbppW6pl9PtVy3cT37e9GZx+p1rXDSzz6fr+D19I/s+8477zwZP358zjkNHFAl5WUlcu3X7pB43JHGprA0hyMye/oEueXJl6WiolSOPGyWnDzv0KKvs2OP8P4WGjN6qNTWNbT5ujzhmIMztt+waZts3LxDvvejP5nbWyIR2bJtl/RHhF0AAPRDlu03qxOay6aay8uCbMsvcYl6fyAm2hs1dNIKK32TrdVbO7fPTwVdSS3hndJYv1EqqsZIc9N2cd2tUlk5trUV0UsJUttr9Zglxd9Rm8H0GrRp22HaEHmdr7V9y5umussfKJchww+VisrRMm3WJbJlwwvS2LBFSsuHyZgJHzCrOXrH03OwswIvoHA7Y3J1RnNbIvBKtjTq7K0XFuSuLPrKomaZMTZkZmDpS02Hz48fllnNpRxxxXLFhFf5aNh13tGVsr02bvY1cqCuGFo8wdK2Qw2pChVk6Uywd1eEpanFNStIzpnQWl2ZTg/DUPqutz/Dj70JSvbFtnt7nJ5ibwKStrbdm8cm7wsEAl16Tl21rRmN0A9+pyxcukYef+Z1uf0710hFeal8/NM3m9unTBotP/nfa+Wt95bKL37/oBx/zEGpaq1sw4YMyLiesWJ2O7ePRuMyZ9Ykuf3b10h/R9gFAEA/pAFWPBV26R+kXvilg+PdmDe3K9nemGxpbAnvkc0bXpTG+g1596lthTu2vWcqvcwxdEj9uA+Y2V0aVmlrY5LjxsRuI+zyzs02VV86Q8yJtZh2w5VL75f62tWpbXbvWiyTp31UotFGaWjYaGaLOQ1Rqa9dY0Iw5feVtP6xbYaDZx6b4fRI58uTK5kKr4AXeDU0O2bGVrbmiCvNEUcqS4u/tnVf+v+TRoSkJNCc07I4e3xIykt85kNlBhhxcR1tq0wEA3q7OBL0axDnmgUgnORnc9mRzTsj8q9X6iUac0xQ/cqbrkwfG5ATDihJbRvXoMFUYDjm6+/uMKWrjqOKVZVka2vbYo8ttq+uDD/a2rYzj00GJW0FGYWOUyjkyN6mo2FKfwlK0Ps1NYWlorzEBF1r12+RHTtrU3O8Bg+qlnPPOFZCoaA8+e/XC4Zd7aE/F1o55sv3H6pEhdeWrTtl9drNpiVSZ4LNmDpOxowaKv0Nf9kBANAPea2Laddtnxd2mbZFv7huXCxL/0yImpYsx43L6uX/kGi0cEm9Do5PBl1KA671a56U6Qdcbq7biQHxyo3HxLX1zVX72gl1lpjlL5H62rUZQZe3M0c2rn9WmtNWZNS5YetWPSqlZUNlwKAZia8lua+0lRgLPB/o37w32K0rMybpHCut8KostaU0ZOUEXnrboCpfIizS+XQiMe1bdAtXcJ17TKU8+26jWb1RB8nvWPqAPPDWEnlUp91nnI8Owddh814Qbdk6V8s2n/VNjxlEb8KBZFBgpS4v3RCTuqbE4hP62rds2bHGkuj2Mqks86c9zhK/3ycB0wrZtRUlbQUlHdm2vQEMQQmA/eWg2ZPNfK5LP/c9GTNyiEyZOFrq6htNsHXLHX+Rh594WUpLgnLtVR/eq+Mce+QBctWXbpNf/eD6vPeXhILyX1/4uHz/Z/eaUGz0yCFy3JGZYyL6C8ttxz9NRKNRefDBB01/qv7HDAAA9H6xaLMJtZRWTGlllFmp0ImZOVvpt+3asUDWrPhnwX0NGDhD6mpXSTzeknPfuIlnmuourfRKDrFXPn9pToVVW7ZvfUdWLb0/53bbDppVHrMNHnqwTDvgktQMMn2T79fh+Wlhl7Z06m3o33bv3i319fUydOhQCYVCeSu30gfLv708LI+9kblC6elzy+XgyZmvJVN15OqqjV4Als/jbzbI0vWtr1/NZ84+skImDM8dgtx2G2NuuPPjB3bl/Xo+Mq9S5kzMPF99uA7CBwCgJ2pvPkVlFwAA/bmVMR7PmI/ltTL6ROJeBYiGU1qhpSsjFqMzsuqyK66Sx/F5b9h1P3o5Wd2l1VdWoLxDlReVVWMzht8nBUNVEm7ekbO9fi2poEunhPl1TlHmG3ltk0T/pT8DTz/9tKxd663mqRVDh809XKZMLbxylVZAHTS5RAZX+2ThWi/gnTUuJKOH5P7RbaqQLBF9mekij5GItt1ZGbO00oMupf8U/eri5g6FXRqm6UqQAZ+3qqRWiSUNq/HLmq2ZCz2o4QNz3wp4I/a8KjAAAHor/tkGAIB+Siua8s2tMq2MOlje3OZ9rh4wJTW7Kx+d5aXVYNlCJQOkPDE3S8WjTd6w+OT1WHO759+oktJBMmL0cRm36ZD6MRNOz15u0Rg6/DDvgoYNgVLTDplO54i1t5USfdP8+fNTQVcy/Hrt1VektnZP3u1jcccMqFcabp12WIX5yBd0ZdPQK5S1CuLu+vS1UdNub2i9fWddXB59vUHuenKPPPxqvWzb483by+FaJvQKt7jS3OKdp/58zZtTakKwdAdODJmWy3zSV4wEAKA3orILAIB+ypsB1Loqo1l1UQfUO7oCY0CcuK7K6AVCWl8ydsIZsm7VY2YtuWzJdsh0oZKBMnz0saYFMhAol8qqcd62TjwVtGmrpBNv8Sq+2hk6jZ14ugwYPFNqdy0Vf7BChg47zHxW2moZjdSJ318mYyacJgMGzTTH8uXZvx6TwfRID7rSbdywTqqra1LXNaSNmeqpvTueGZlleRVUaugAf8b1pOEDvNemDsO//4U6aUkMsa9tdGT9tqhcdFK1DKgo3Aas1WMRLeayXBla45fLT6+W91a1SFPYlUmjAjJtdFAiMdesGJlN2y0LzD4GAKBX4C88AAD6MQ2BYomwKzn7Ku6ETXWXtjBqtZYOb9fAaPDQA6WyeoKsXHJfxiD6QvRxa1f+ywyQV8FQjUyYcp5o/UsgWJFqZ9QZYebYvlC7Wqf0LX/NgCkyYND0tBZFkWEjDpchww6VSMseCQarxPIFxPaHxJeoTss4t0QABgSD+V8HgbTbtUIqGkuvSewcrbKKxDKDLR12P3dqiby+tLUyMui35JhZZeaytkkmg64kDdzmrwrLvDnl7TioV+2lKzuecGBZxs+YnkfcccWX3vOYuB0AgN6MsAsAgH7MzOryBc08LWVWYkxcN5fFu6zBV8x1JBSqkhlzrpCG+g0SjdSbFQ8dJ3cWkPJmaLW+a9YQasvGl2XshNMkHm3OaCHUwMtx4ua2tobWBwKlGsXlvU8fq62OGmaZyq081WIMpEeS47gyZdoMWb9+fcbtoZISGTduogmCtPopPfxpDDtmHlahIe7pbblucvVRxwvKNKRKZL8ZjppZJuOGBWTV5qiUBC2ZPiYkFaV26nj5NIR1nzpgy1vs0UqrytpeG5eykCVVZT7ZVReXF+Y3yfrtUbPPo2aWyiFTWl//8TxVXN7ZMrMLANB7EXYBANDPaYWTthYmWxFNxZO2Fzox8dl6WStbWsS2dSXFuAm/KirHiCtx2bHtXWmoW9vu1REb6taZz3qsWKzZtBu2Vpq43gwvrciyA3nbGk2Q0Mb7cG/Vx2DBajOCLsS1UivummBo5MixcvSxx8vC+e9JQ0O9DBs2Qg46ZK44ll9iaRVVtY1x+derDbJuW8y0HU4eGTDBUXmJLcGA5b0s0wbPe9pfIjVyUMB8ZBs7JCDzV+eucjpioC9nhcXVm1vkxQXN0pLInycO98uW3XFpSmxX1+TIE282Sihgyazx3sqojgnnCLYAAH0LYRcAADAVVRo+JctO9LobC0s00iJvv7NEVq5aL47jyOhRQ+TggyeJ346LJX4ZPf5UWbHozxKLNaX2VV4xSgYPPUjWrnok5zgaYq1b/bh5cz1g0AyprB4vfn+p1O5eLrt2LDS3DxpygBmI7wuU5AyU12As7sTE78tf2aWtiwXbE3VVPIKufl3FFYt7bXvZbXoTJ04xH3qftivqgHYNwtI98FK9bNnlBcL6+OUbo+ZDq7ymjQnKSQeVi794UWJOcLu7wTEti8kqrnwmjPTL1NFBWbahNTweN9QvU0Zlvs61rfHVJZmLRKzakn+Q/dsrwqmwK38eR/gFAOjdCLsAAIAJkbTiKRYLtwZevpC8+s47snz5mtR26zdsk5aWiJxw/EGmfbG0bLDMOuga2b1rkcSiTVJeOUZKSgaYbcvKh0tT45aM40Sj9VK7u95crt29TEaMnmcqxbZufjW1zZ5di6W0bJiMGnui1AyclhhenzZnyImKo+2X+WZxFXmTbls6CJw38f2JhlcaWnmrEubfxtGKwnj+bfSxug9d/TAZdOU83hVZvC4ipUFbjjvAm7PVlq27Y/LEmw0m7FKTRgTk1EMrTIWYMg2KrhfO6XkdP6dMZo4Nyo66uAys9MmwxPD6pF318Zygq5hIWsVavh8JhtMDAHo7wi4AAGBo26AGXvFY2Fsl0XFk1Sqv7TDdtu17pKExLJUVZd5Ae7tFBg89OK3N0JFYPCzjJ50jWze/JvW1q01FVbh5Z86qjXp/viFGzU1bZcWSe2XsxA+aKjGt/rLSZnlpKOf3WzmrKZrWyyKVXejb9PVnwi3Hq+QqNmhdQyydV6VhUr77TBVY4uXqOm2/dhavb5GjZpZoqppaNsG85FwvTE7S8/rXaw1mlcWklZuj8uKCRpk3p8wcUwO0Vt5jh9T4zUc+a7bkn5tXyJTRrT8jdp6fi6x59QAA9DqEXQAA9HJewBRPzN3Sd8mO12eVfKdv3szqBGvLe9NtVlf05Z2Jpbf5/KUSj7eIG4tJPPluP+eYAW8lRMsxFWBiB8xcL0uPrXOx7DITUI0ce7yIO09awrtl2aI/5ezHiefOIkq3ecOLMmjIgabFUldr1HBLvwb9iMWbxS+lmYGX65g2R19WCObdFZcCc+3Ry8MtDYeSVVztrvTK3pdWcbmJVRfTZm/pMWoqbRlc7ZMdtfl/HpTOz3rktUY5ckaJVJalv9B0TL0l+uOmnzfsiGYEXUnapqiD6jujWPuktkCu3hIxKzKqSTprbEZp6mvz+TKTLdvWD9IuAEDvRtgFAEAvpG9SXScmbjyaUy2VZ+PE5+R4Hq8KxLwB9/nF0mHwaVVTyZZGDb5Gjx4pGzZsythdZWW5DBxQYy47bsxUgunj/VaJWVFRAyzTTmj2o5UqLRIIVpnqLt026eXXa+W4o0boVG8zmD4fXfFR2yW1Wkv3q0Pv/T6t8rLNMeJx3V8oo6XRiYfFckvE9mX+maPPk1Z+ZVeDoXe97rUaK9leWKxyK7uCywu6XHljaVgWrtXXqMjs8SE5aFJI4o7Ogks+ItFKqG2EOsNLf7xckZMPLpNn322SbXsK/7yt2Ro1LYUfmVeZFhh5w+u9Asbk+oy5Mqu5OmZnff5zmjo6IKcfVi6RWLls2R2VQVU+GZpWHRYM2DmVXYGs8AsAgN6Iv/YAAOhtIVc8YuZc5btP3/1rqGPeXpv/995cu5btVURpNZaWbiTnAsWjIvGoWaVQh7vbvtbQSAOm4447Tp566inZsWOXua2yskJOOP7oRFWYKz4rIFbANmGVqQrz2SaI0vldJkwzrZGl5lgjRh0rG9Y+bfazdEWT7N4Tk1Fj55mAzLs9991+qGSQCbhMcOV6E7l0GH56lZeGaboPnz/khWxm9chE1VdW4KXbmq+VlsZeVbkV70C4pTO4tIjPhGLm56H1vqffbpI3l7UGrpt3NcmuekeOne1VVOnrVI+nAZcGY+kqS31yzlEVZkXDPQ1xE5olZ26l0/vXbY/K+GH522mDuaPmjM4WU+2qi8uKjbltjMMG+OSMuZXmcijoyrTR+jPTer/fZ+UEW7ruQ3alFwAAvRFhFwAAvYRWcjnRsHlDnrfCy4mnxlKlv01PXk4bSS2WBkW+1oouDcjcmH60iOUPpUKvyspqOf/8C2Tbtk3ixOMyaNBAExQ52i6oKzC6+ibdJ2IquHQ1R9dc14quSMseaWrYLIFQlYRCNWb1xZLSwbJpwwJ57a1X5b+//mmprh4hcSci44Plsn3zG9LYsLH1LC2fDBt5pNTuWm4uVw6YJAGd3WXZiSqvqPh9IfM1uG5MopGYNDZskli0QWoGTBErpNVl2uaY1uOllUGxZvEHOtcuhv0jNTNLAye3HYFYYvVEbUMs1MrYHHbknRW5Q9zfWxWWudO0kjE5vyuthTEVfnlD7JMh0eBqv5xxeIU89HK9NIZzT7ChyTGP8Wu4pC/DtH3m215pm+H2PTHzOB1A70ukX+GIIxu2x8yMujGD/aIvZ7/OBdMPS2R3Y7xgW6X+n672qCF0epjmBV2Z2+vXr9sCANAXEHYBANALOLFIxnwrr8IrKm7GzCsNvhwzXF7DH68Syqvt8mZ16WefmakljoZjWg1ii+0PiJgqKdur9tIB9fGo2FoplZjtNXToSFOtlWRrZZe/VGLRZvM23lz3laTaEXdue0/WrPinqcpSNQOny6ixJ0lp2RB56LFNctUVH5Pq6uFmdUalKziOmXCqhJt3mYH2GsYFAhWyYe1TqSo2f6BcJkw+V8oqRpq2RZ0PlpzlpRVbSxfcJU0NXsulPn7StI/I8FFH6d4zWhf1+YnHI4UH2aNbWxS9mVltVG7pWLpka2Kxbc0sL63oc00VVmurYisN1WobHakoTSRTpjorbi76rNbrermsJPmz5G05ZkhAlqzPrLLUUGn4IL9Z8TCSuK6rLGpVlT5maI3PrHaYfS5+v8iDLzeYy6VBS04+WNsPXfn3u43mHFVFqSXnHVMpgypbk6qBFfkHdmnLoq4QmV7NpQL+3Iou/ZJKgomvDQCAPoCwCwCAHs6JRzMHuTuOODr7KjGrK721Ud+q1m96R2rXvWrCrIrhc6Rq3LHiS7TzmdlB+gbcF/QquywN0lpErIhYvtaKLq30ike1XTBgbvcG12fO3NIKLm+WViR13RFbwuGdsmrZA96g/IQ9u5ZIqKRGlq0MyJDBA2TK1PESjXpv7NOVlHqVYxqsbdrwYka7ZizaKBvXPSuTpn3Ym92l1VmuZZ6bDaufSAVd5vydmKxc8lcZOGiWBEKuaaVMD7x0v14bZO6Qfux/WlFVLOQyQZhpT217CL1ZhTFRKZW+bXW5LZWlttRnDYfX28tLvLlaOtfqxfebTfilIdHowX6pb3JS7Yo6pH7u1BIJBb3XzaSRQdleG5eddd7PooZYh08vMSFT6nxcrzorGShp9dRRM0vlPwuaU0VrGoglB8ir5ogrT7/dYFKoZNClGppdef69Jrng2KrUbaMGB2TsUL+s29a6Az2PY2fraz6zmksH2WfP6NJtQgGCLgBA30LYBQBAT29dTAuY9N271z7otoZc2nqob1RdV3avfl52LP5navPw7jUS3rNOBkw6ydwfrByuSZd5nH7oZRNy6W2xsMRNRVeJmbtlDqfzvOIxsQNedZRjactg67tvc1taIKUVVbt3LskIupI2rF8iTzzVIN/6xlWJoC4z2dBjb1z374zQKltT4+ZUVVYs0mhCO10Ncs/u5bnPnRuXPbuXytDhc80ge8sqywi3dD86iB/dRyuzNOQqFGAlh8t77YWe2sa4LFjTItGoK1PHBGXkoECihVFfr95Q+fS2waTGFsfcl05/bI6ZWWICqcamuDz1ZpO0RL1tdJ/pAZLS1RjfWdkiRyZWM9QqqeMOKDMzvMIRVwZW+STo96q2tIUxo53Y9VoLNViaMTYkowb7Ze3WqLn+4vzcBRrCZgxXbvq3fnvMPC/a5qitvKFgQD4yr8q0Y67eEjUVaodOKTGtkMVCLn2KtMJLvwYAAPoawi4AAHowU3WVxlRWJcpfUoGVeWMek3ikSXateCpnHw2b3zUfKlgxTIbM/rCEqkZ6s7lMO1iTOFrp5Q+KpRVdkUbxBUJiJdr8tE4mru2KuuKhhkVpYZcXHpkR+KnbNHzKpsHcPx5eJ1dccZkEAoFU+2LiAGYX2za9WjToUtq+qMPntXVRa3E0aNOHa5VXNFKXs73fX5E6hhliryUvycPqrDPXpaKlm2jIpR+FWhWjunZCWji1ZF2LvLyoWbbtjqdeba8sDstxB5TKIZO98EnlC7p0f68vCZuwKZ3+KIVjWnnlyqZdsVTQVcyWXTFpbomLbdumgqqpxZEdtTFTsWWJthRaZj8t4ppKruyQSe/Tx1WV+eSACV4L4quLw+06drLFcc+ODbJ4wRvSUF8r5RWVMuuAQ2XutIkyd5r3PGhWrWGb7dMlKXKfDx1EryFXTgAGAEAfQdgFAEAP5YUxrSUvWmWVDJr0ciro0uquaLNsfe8e87mYSMNW2fr+fTL6qM+J5cREEu2MoqGRE0vM6fJ7IVs8ZloXU6s36pwvHWSfqOBKsdKGiFsiAwfPknWrHzNth0lvv98gU6dOknHjRkgsnj4k3JK402K+hoa04fSF1AyabtolY9F68fnLTLARC+8x872yv/LSsqFSVTMudV3neiVXcEx/js3X34XiTtybm6b/lwgmvZUwvdUpdb5Zfw7YdIVEnWdVrJqrRUOwtOzn3ZVheez11tdTupcXNsvMsSEpSWsdbAw7sn57VMpCtowc5DP727Yns0orafueuAxPVEG1h37rdtXHZcvuiNQ1OqblMSm0NmLCt/IS73sc1uJJcSSUNQ+rJaqtg61B64yxQXl3ZWawPXyAz5z/qi2ZKy3OGS/y5mv/NvP5zNfaUC+vv/q8lFdUyNChw0yQVijEMiGXBmCdXfoRAIBegrALAIAeSldXzLiuYVdy9TltXTTBQdyEXo3bFkrzztxWvnxiTTskvGetlA4Y77Ug6vyqQLnJtDQs04ovyw5qDGVmZ2lbo52c+aXzwnQ2mJnllRjw7maes88fkukHXCZrVzws9XVrpaGpRJat/P/s3Qd8k2XXBvAru3tBacseZe8piLIEQYYg7o17MAXEgRMXgqCAvk7c+3OwBAVBRRFkyJC9R9kFSnf29zt3mjalLRRo+6Tp9fft2zbNuJOWNrmec85txQvP36DCLc9gfJWYqeu3Zp1UQZTEAoXR6UwwGi0IC6+JoKDKyM46gaDgSp52Tuixa9u3sNt8KsWgQ6XY5qhZt6+q5vJWb6n6M7fMTsob6C0Vcd45ZRdKdqa0OaxwSnWd21Mtdi4SeBn0Rhj1JvXe4LtjZACTdkQZul7UDosSdHnmW+UPY5ZvLjrElZZBmZtVI9bz87Nhdzb+2JCZO7heBrVf1T4UUaEGHD1VcOfCiBDP5eJjpAVR51nfWUSG6LFqW/5gykuqs9bvtqJT42A4nC6s22lVFWNyb+rEm9CmfpCqqPJUrOX9vLdt4NkNcut+m7p9mQXWtUWICqZWbc/CjoM29XGrRAssmRuRcmZS6HbjwN6dqJYQX2BNcr3SyihBFyu5iIioomDYRURE5Kd8q7o8J3g/l5lEOS/InZ5qlayTe87zyl1wWNNgkCHvOj1cUoUlIZcEWA4r3DqZ0xWsXii7HVlwOg1qbpdn9LcneFNhnE9QJF+T8EiCiuCQONRvciucTieef2EGhj18J/QGCbfyqnPstnQcPvAHMjOO5JxS+AvxsIjqCAmJw7Ejq3Hq5GZ1WnBoHKrX6olTyZvPCLo8K5EdG80WzxBv2ZlSAjMhM45kPlneY1ww/Cguh0va3rLg8IZ35xmQSWhoz6nOM+gMMBrMMEtrqUZD89UMOMmhCsmi5DuTs6HnBVWlydB4u9MNZxEPtwRcv6/PxPYkG0IsOrRrGIwG1fN2y5QKqqLIcqJydiRMz3LlC7qEDI9fsyMbLepa1Ewr3zArJlyPGrGep8Nmgx4dmwTj3x3Z6nrkeuOiDGrdJ1I9n0eH6XEy7ewT8k+lOZFtd2PN9ix1OSG3uOuwXc0Vu7SJp9XQ6XbDmPNYSgjVqUkIujQPzffvSQbh92wTqt681q0pvELNmfO7wEvCawnIDGfsvEhERFQRMOwiIiIqN3JepPtUDnkDMWNQVLGvxRQaC1NYFeikQsyeqQbUw2j2VIupVsZgVdXltGd4qrqkZdHtVOeVECE37HC74LTJjnF66GTAvSuvIscbIs2b/zuaNI6HPWsldm5JQ3BILCpVaQGjKQzJR9f6BF0+9+8MEpAdO7IyX/iXlXEUx4+sUYPnC5OVeTRfsKQ/S7gl1V++AdjZSHi3adMm7Nm7GyazCYkN6iIuIS7feTKyU/Hbjh9x+PQeNIprizY1u+YGWGpXS70Bep0xXzujU2alObJgdWSpai8JvUzeyrlSonY4lMHuLk9LYTEK0nLug1TKeQIaCVS8IdiZVUO+119UyOX1+a+nsc9nGPy+Y2kYeGkYmtTyzH+rGWfC3jPa+bya1baoXRbF/mP2fEGXV9JxOy5rFoJrOodh4z6rCs9kgLtUW+W29EkLbrhBBUvSBilD3WX9QmaLZWW7sGJr4T9vvqT1MMvqyg26fO0/akeHhkGq0koG7BsteY+ZXtqBfQJfi0mv5m75ksvVrVsHu3duKXDdNWvV8czqkoBLfV8YchERUcXFsIuIiMhPSTByxt5xedPcc0/yvBoOr9YGqQeWFz6zSw2V97zwNkdURVTdbnBmp8IYFOHZ1VFaCKX6yRSiqrVs6cdwev8yZCXvgMESgejEngiv2trTNinhmFQfybB6n7liEoq53T5tlk4rDh48hpUr12BwPydST3vuSXbWcaSn7kd4ZF2knd5brMdB5oYVqHIDkHJyK8IiahZ6mZCQ+Nz2RVkjvEPzVfWShHI+g+pVAFa8sOvXxb9i3959uZ8n7T+IS7t0RPUaVWF1ZiM54zDGz74JB1N2557n0rpXYUzPaXnhQ07wo8aZ57QySrDlXZNUijlsdhWGWYzBKvgq6VZCeStqZta5eKu/ZCqZ974oEoL5RpbFDM8koPINurz+2ZKVG3b1bB2CL5ekItNnwHzlSANa1wtS8668pCqsMCFBnsc2ItSAS5uE5NwPt6rAyn0cfNYrM7dktpjT5jlRWg+3HiteBV/teFOROxxKEOcNFdXHPv+afcMpaTmUsM1L1iozyWQHxvj4qmjdpj02rP9Xha8S1DZt1hz169XmLC4iIqIcDLuIiIj81RntbDIUXuZd6VQ5jUFVW+kMRjWzy2gJR1zrO5C86QfYM47nvx63C1F1uyMouqYKpbwc1lQYzDm7FbqcuW2NR/79BLb0nIqr9KPIOrETCe3vRXi11p6rc1jhkvk/BpOaGaZCMEc2nMip7JKQwOnG2+9+hUH94qFDUr7l2O3pOJm8oVgPgQyZDw2rpgKywsjpJlN4vt0dQ0ITEBPbLDcYPDMoKxh2FS/1OX78WL6gy2vjhk2IjPMEKHPWz8wXdIm/dy9Al71Xo3m1jnmVXTCokEK+nxJuZTsyYdAZYTYGqfBLHkepSMuyZ6hqr5IIveR7Ii15ZxsM72ll9DTJSiijqrZyq7lk976zVAwVPYrrrE5nFF72lZqZt9DYKCMeGhCNrQesqg0xsapZtS6qijTVPuu57VrxRlQKN+BEWv7rbJMYhCCLDg6HBH2e02TO18Y9VnU7cdEGNFJD7qWl0vN1aQHM9rlH3ssVRVoia8WbEBvpeXodHqJHms99EPL4ya6SzepYcoLYAv/MFZ9NQ3OrvCTo8mrarCUS6zdCevppVIqJREhw3m6URERExLCLiIjIb6kwyZGd73MZgi4v62XXRFVlBb0aFi8ztCwRCTCYQwuGXRIwZZ1ASGyDAqdLG6JUaUlVl87tUoPuc4OuXG6k7FqM4Mr1PYPppeLMaYXD5Qm61Dlk90GnFTo118uF73/4BV0ub4+wkK3IkjnyxWQ0hiCuakdYs1NgtoSrsEuuW3ZblJCsMCFhCQgNa4PsrJMIC6+ugi5v5ZnwBEfu3Da7wsKvc3E47Th+6lihX8tI99xBuY3Nh1cXep4tR9agUXybAqcb9CYYDSaYZL16IMuernabNBssMMkMNeSFXjanFUGmEBh9d8IsBgmwJCAqrJVQVXnltDH6XEK14e07alcVUTLTyhNwecIwqR6S4EUCGd8A5kLVjpMh/Xktg1614vJvHGA26dCibl5YKzwbhXrWos5jNOCm7hFY+l+mms8llV4yFL5BdU9QaJKQVi/thDb8tDIj935L8HXohANXtgtFptWFY6ccCDLrVHBmzzlP1UpGdb6iJFbzBHBezetY1LD89Ky8wEyquf7bK7PaoNYlAWNh1Vi+j6u0JcqbL/l2RIQHITqSIRcREVFhGHYRERH5Mb3B7Nkx0fMJdHoT3C6bmpElw+F1Tjv0BgucEjy5XTCHxSH7VMH2QFNQtHpvzzihZnHJ+SQw8w5td2WnwmAJg8NaeKBkzz6tWhxdTgf05mDVYud2ZMMtuxxKz5Uq6JKv27FnbxK279iL8U88iKR9GfnmZ52NDLWvHNcaZnO42m3RS8K16rV7IWnfYthtqQUuJ1+vFNtCBXFGgzcMyd/uKZVJ3s+9Q/ZzSVCX0/JYVNCVYUtDTOUYFUzIsHVf0ZUjVQiZaUtHbHhVbD26psB1RATH4HTWCTWbKzn9MKqEVUV4UHTOXCs7ZG8/aWU0y/oNUJVe0hYZZJQd+TxtenIbGdZUWIxBKvQqDrl+2SHwzGouCbhkDtWZc7rk/Bv32PDz6vTcSiaperqxW4Rq7VPVSG5vK6RnzpTRqINkMRc6Iyo8xIDe7UKxYFVG7noiQ/Xo3qp49/FMEaF69O/oqViUHNPh9txXuHVqjdJhuHGvrcBjIoPnV2zOwt6jeS2Vso52DYJVW2GVaANiIw2FBl4StoXlzA3zks9b1g3Csk0FW4u3HrAhLcul5ojltjzm9jPm/1k8s8pLzmcxybw0tiwSEREVhWEXERGRH5NAyjsXS+iMJrjtDvUqXgVhqrrKpdoPpUoroualSD/yn6r68jIGR8McVRPJW+bBlnrQcz16IyJrX66qveS6s0/tgz0zGUZzeKHrCI6uAzfktnRw27PhNgV72sckbNMHqRfoqoIoOwPvvPsFxo6+S71gj6/aGakpe2DNPlHkfbRYolGjbl+J3XJO8YQSBr0ZWZnHYLWmICikMqrW6IJ9u+YVuHxUTEMVXxm9c7nU/fO0Anp5W/I8nxSs5PK0Nhac22VzWFVVlXoMgoPQrFUzbPj3v9yvy5D6ek1rqRBK9G58C1bsWQi7zEHLER9RCy2rd8by3b9gzoaZyLSnw2SwoEfDwejb7A6Y9GZVxSWPn+zOKNVeQaZgNc9LKr1sDiOCTaG5Q/Stjmy1E2SIOeysOzeqmVS2goGWVHlJWOV7PqdbB6fDjbQsJxasSs9XZXX0lBOL/81Anw5hMOo9Q+m9JPez2eXBlaoqqK/7kmBw+ZYs/Lfbqh7/1olBaN8wqEAwJjsRNqxhwY6DNhWqNaphzlfNJFVznrXmrNn7cU7rpJoTJ3PEXPmDInl4TNCpQe8OF3JDr6J2d/QNusTpDKlws6mdITOtQFyMARYTkJScP/CqXz3/er2sPjs/nulgsgOrt2ehe8uQnPZfT5CVb/1nVHkJs5FBFxER0bkw7CIiIvJzMmfLmRNeSRWTfC6D6OVjnfo40zNPyRgMUzBQ9ZL7kbr3b9gyk2EJr4rQ+GY4vX95btAlJEBL2fMHzOEJSNnzO2yph86YDZb3ot8YHKOG2rvsVuiNZsm1VNukZ+6VS7Va7t+3CMeOrsEvS46hTcu6iIjwVCMZzSFo2PQO7N/zM1JOFtxBTlSKawmjMf/Ogy6XA/v3/oLM9Lx1RVdqgqo1uuPooeVqF0YJ+6rEd0B4ZG3V/ihBnO/lDyctgzX7JMIja6FK/CX55voXlD+UkNZBqz1LtQ76atS0ASIrh+LIwaMq6KpSLQZ2ZOdeZm3SHyqw8pJKratb3I3dyZvwzZrpuVVlEob9svkrFYS1qdEFdpcNeuhVqCXnyLDaVSBmURVcDmTYUhFsClMtj75VXqGWiCIDL5WJnpG1SJWXtM7lPU45pznd2JZkw+Z91gLthEJaAh0OWYlbVTmZDbr8s6ZyQi+3wTPM3eunf9KxclteK25ScrqakSU7Hp5JdkK8pFHhbXm5Oz0W+T30tqjmhF4yO1/mk+XcVfn3IS2MKvRyAgmVCs71KoqEfdFhDqzZYc29PpntFRdlVKGTVL7J4PvCRIVKNVzRO11Kq2heCptzX30/PiPU8u62SERERGfHsIuIiMjPScuibzujfK4zmNWMLFXtI1VWEn7lnC4ti5Ua9VOVXmr3QQk5ThUcrC4VTqn7V+QLujwn569ukeH38uZ0WlUrowzIl4ounTlIFWPt3bMAx46uxoGD2UhJsaNujVPYs/1HJDa52bPjoCkIVWt2w+lT2wrMx5IAKyq6IVxuSWZyqlp0Opw+sTVf0CVOndiMqOgGaNT8btXOaLJEwKgqnqR2J4/dloFtGz+GzXZafS7h2MnjG9G4xX05bXgFkwdZl4RVEiJJWOUbWOWdx60qrcIiQ5AYWUdV1aVbPbfhdLtw6PQezFr/Qb7gzObMxp875yI2rGrB9kkAq/YtRr3YZmoAvbxl2NNgcBhV1ZYEYtLiGGwKh8FgQKY9DUHuEDXEXsh6JfAKs0QWqJSSSijf6i31uDjPCLqccn88pVFzV6RjrwQvRQi25EUwMvsry+VCsNkT5Jx5G0ICr8xsF9bsyAu6vFZsyULXFj7te4U4cSIZG9atwcmTJxAVFY0WLdsgtkoczkVVBOo8e2vKgHm1o6ITsOdsfahCLyPQpXkIDhxz4LTPAHmZTXbgeMFdIYMswNpdeUGXkCH2WTY3LmkcpMJCX/K4n0pzqlZDmTNWVNAFb9VWvrJDTxujN7w7s4CLQRcREVHxMOwiIiIqN+2MTjUXy/O5WQUscEkboREumevktHkG1+e0PRpMoSrwkpfHelMQpAApOdWp5hBJECBkfte5ZKdIi+MJ6IMi4HbY4DYbPdfpkvY3IPn4OtjtLvyy5CRuuc4TSKSl7oXDnqkGy8t5g4KiUaveABzYuxBOh8ww0iG6UiNUq9nds0Mh8ld2ZaTnVaH5Sk8/iMhKDWG2RKiAwLeaKyPtIJL2L0ZGWv7dH8XJ5I1IObkVkTEN1eWkPVHCItlNUt5LNZu8nbUl0J6hdk70fp6VU23ngudre5I352wgkJ9Uddl8NhrwJYGZZB2y46K8SfWW2QDsOr4Ri7d9h/0nt6NaVF3c2HYE6sY2UbO85PHyzvGStcussFBL/vbToobRi+MpDixem4kDx+2ICDGgboLprEGXCDbrcCLVgUoROY+RW6faAqVaqsBjlfM+PVvCw4Jfl3BI3ooKuzLS0/Hrwp9gt3vWlJWViWPHjqBf/0GIio4ueHuSYxURKElFmHxbjVLpJXPKnJ7zRoYZcF+/KGzaa0VKuhPVY02oEmXAl0tScSo9/6ITYkw4npK/wk8kn3aq+yGhlrRHShgmLY87kuy5wVhESNFtpqJOvKlgZdcZbZj5vnb2qyMiIqIcDLuIiIjKCQmsnLa8cEoCL1dOr5pOPpZqK8jHQXDbMyWPUEPt4XLCEdoIn8/bjkyrG7d3C1dhl94UogbV29PPPUDeaU2HIThKze1yuyQcMqgKML3BoAKbhb+dwuUdoxASnJd+SDBnNIWoAfhSFRZTuamar5WZcVS13p1I3og9O2bBEhyD2Lh2CAqOyZnXpYfZHFnoOiyWSLVbYT46HZxOG3Zu/VrdTlFOnNoOY1gCDIYgz4B/38cWngCv0PvucqiQyTfI8lZdqa877SoEiw6pUujlI4Ki1XD6wshl0rJPqh0WQy1RqnLsVMYxTPttrGpdFFIx9t+h5Xht8GxUjaqNLFs6DPI45NwHuW0J78w5Gw6IM2boq0BOQp5sm0sFOvJzIE6mOdXbuSQlO/DVb6kYfFk4qlbytFJ6KuQKPmreQKZyhEGFPdK26EtCpTOHufvatWtbbtDl5XQ6sXvXNlx66aVFXk6quKQtUwI2md3lG4CpwfQGmQMnu08CDocnbGuVGKTuh7Q2yiyzay+PwD9bs7D/mF3NDmtRx6KqszbsLvhzZTF77rsEXtlWF9buzELaGbPo5b5LJZn8Mz1TYlUTWtaT75nnccydT+87nN634EuXPwgjIiKiovH4EBERUTnhndfl+7kuZyi7vFT27q4obYZSEiKnWR3A598vwjvfr8eV3TrhoQE1EBJkRlBULUQn9kRI5frQy6CvszCFxsIUEgOpv/KUmniHhTvV7ofHT1SCze5Cw/p5u+dZgiohOCTe01YmrZWmUBiMQTAagxAcHIvdO37A8SOrVAXXyeP/YeeWL2G3Z6jzSqValYT2BQbGS8ti5SqtVEunXJfBGKxOk3ldKSe2njXoUmsKjgV0sqNlwXIkz/wxD2k3lGBLqrEkcJI336DL6XQgKyd09FR4eT6uHl0PibHNC1z3JbV7qRCrMFKZZdAbVGB1OitZBZf/7FuUG3R5Zdsz8dPGTzwBk86zW6MvqQrLd3/OuB35aZDLbt1vyw26zpeESBIEna2lTtryvEPqZd7UwEvD8lV/SRXU1Z3yV6FJfiPXJV8LtuhgtxVeBZeVVXBXQ18SBOVdjx5BZs/nvg+GZ3aXTn3NW1nmaW30nBYeokO3liG4vVcErukchhpVjIiLNqJqpYLHhxOrmhEeLFV2njbHM4MuL/mWhQXnLSIyVIe+HULQoVEwgqQVNCfo8oZc3tZF39O8jy0REREVDyu7ygHVtuKSuntXzusL3yepntkmnhc28gSe+SURUSDTG0xwu+yevws5n0vllGeWlglunQ06ac/TGbFg4RIsWboKg/p0xK2De6q/H/bsFKQf/BdZp/bg9J4/EVw5ETH1+yDz+BbYM0/CYA6FPfMUnNaUvNs0BsGRnQKDJUyFUd46HWmVzMzMwpI/T+PW61vAYT+sTrcERaNRszthtoSpqidZrwrmJFDSG5F8bB1sObOuvCSoSj66DrXr9VefR0TWRaNmd+FQ0h/IzkpGWHgNVK/dU1WBFcY7z6wwp+1ZOOJ2IchpR6Wc9j91GZcTzpy2UNk0Tz5WO0zmnFYYmeUlQZc3hLC5rJ5ZXG4g05qGm9qNwt+752PT4VUINoagdY0uiA2vCospFBm2tALXt3LvIvx36G+0qt4Fner0Qmr2KaRmnSz0tk+kH4HDaYfJaFbhmARwsmOjWpfDjrT0NISHeYIk9XTgjLshwU/2GfOlfHf4k8qmczmR6nmMzCZ9gXlS8rnJU/SVq0F1C8ZcXwlb9ltVGNW4plkFUbI+CW+8733VqFEDW7YU3MygevXqKrA7cz5ZUSRsM8tujKqF0bMTY+5ujmqIvQvQudRjImGttxpO3nvbEj0D73Xo3NyCjbt1aqaXPI4NqplRJ8EEq91T2ZV2RvWaL6kak4Cta4sgdVmpdgsO0qufGW8waPAGhzq5f+qDvNNyGPgUj4iIqNgYdvlruOWwq52uvC9mik0FX0boDEbV0lLcJ4RERFR+6A0WOF15lT1S3eV2ySwn+diMv/9ejm9/XIAunVpi0nMjoHM74Hba1KGS5C1z4cg4nnvZtKRVcMXbEBRdByGxjWEwhyDrxC6kHliRex7r6QM4tvF7VOs0XLXOSeDlCXjc+N/7n+PuO25Eq1YtkJV1Ag5HFkJCq8Bgkt0R9TDK2vQSMHkGwEs1mLWIMMdmPZXvoE1EdF315qlb8xzcyZ3Tpf6Xc16dDpXj2qh5YGfuqrjPloGZu3/xhFq75qNltU54rOcMmL33IaciTueynqM9zgGrIzu3dVE4XE5VceUN/pxuh2olvLTuVWhTo6uq2DqZcUx9PTq4Mk5mHClw3bIGmbklAZnoVKc3qkbWLnQdTRLaqWozCbvU4+XIRpApFBvXb8aOrTtgtzsQExODyy67DHFxcZ7SIJ+HQ6qXEquZ8Nu6gtfdtr5FfX3F1my1q2JRpMopyKLP114nJMSRwKww0g7YrkFwbgWX7OZYWDue/HzIY1o5IQ516ydi946duV+rUbsmKlePx6nsdNUCq6q49AYY9XqY5HnPWZ7veFoYPbedZXOoWWI2SaByvw6YTZ5QSuaayXWbjd7QS9pqgRCLDq0bmNEy0awCMKmYtDld6j4Xp7VQ5oCt321F5UiDmtMlgZ+EfDq952dQ1ickFPPel3zhlrQwMuwiIiIqNoZdfkS2dFeDf88IuFTLgho2LO/lyKHvEAp55qODTp45qpYVz3bw8gZbFnQGE/TmgrNJiIio/FK7LuqNubsmej43YPOWrfjwk6/RoF4NvPT0IwiyGOFSg9H1sNszcfy//8sXdHllHFmv3uTvibQ32rNOFTiPI+sUrKf2IrhSPc/ukDoDlv2zBkFBFrRq0UQlBmHh1dR51d8rFci4PBVn6sW7AQbVlmhSQ+IPH/yrwG1ERNVXM77cbk/A4Dt8/lxCwxJQq/41OLB7Xk6Vlw6myLr4YMWral6V1/qDyzFrw0xc3/rBvKBL/paqSh/PsHqp0JK2wLCgKHWaVFMV2O3Q5URGzm6PIret0C3VU56PZY7WsbQktVtiw7g22JW88az3Ye2BpehSf4BqhWyWcAk2Hv4n92tN4tvjsnr9VaDmcrmg1+tVddeuHbux+b+8KqiTJ09iwYIFuOWWW9QQe6lQ8pJQplolE3q1DcGStTKDzHN6/WomdGwSoh7z5nUt2HnQjpR0F46ecuQbXC/tgdLid+YcKQloitwlUJfT2mgovA1PflZsTgesau5Z3vOfNh3bo16jBkg5eRKRUVGIiskbTO/ZWMATNnqZDUYEGc0qACuMhFtZdqcaUi9PmSw6nRpW73RKwOYZXu95c6kdJR0ub1Lohsupz4lFJWjWwemQx8LzlMxqdyI4CIiJ0ONkatHVXUIeU3mTx7d5HQsuaRSsrlMeG/neuHVuFd55H1ffx0sFYzyASUREVGwMu/yASwIue7Ya+FuwukvCL98nT2645RlezosA9eTL++RHVXUZPBVdBpNne3WnHc4se07oFcw2RyKiACFzq7xzpA4dOoz33p8Ji8WEx8YMRUxUGNwOa858JwlyXMg+tQfW1MJ3OMzjRnbK3iJ3JfS2Cko4lJaege9mL8Kkl57yHGzxmXklf3/0epP6myMVT/J3zC2Rk7QJul2IiW2GmMrNcTL5v9zLhIZXR9Ual6tqrcJe00sFlKrk0nljB58d63Q6VX0VndAOkbHNkZl+BJbgSpi77f/yBV1e/x74E9e3eRhunUEFUhIaSaBld9nw2YpJ+HvPz+qxTYxtgXs7P434iJp565Bh5i67qsbyLkHuk807L0ytD9h46B8s2f69qr6Sv9dNEzqoAGvT4ZU5FWUF2ZzZqnpMQsG+zW7HJXWuxJHU/ahTuTHqx7bMbVmUten1nsq0vbv2FbgeGe6+d+9eNGzYULXreXdh9IYmlzUPQbPaQThwzIaocANiI/O+3xaTAa0TPd9Luezuw3b1FhKkQ4u6FrV7o7qbqlJMgprCn1d4q7gkyCkqpMl22JDtkJ0LCw+JwiLCERIepu6nBGJCQiGD+nnLf53ydXmTKq9Qs0VVf3m/X5k2J6w+lVxCbtEuVYayeYPD0+aoTne74da7VSuw06lT59PpXLmD7707P0qhoHyfLGa9GobfroEZ/+6wIvl08eahyS6QMvw+LESfOzvMbNTn7r54ZpVcYbteEhERUdEYdmlIzYGwZnqqsLynOR1w2bJyq7vkqL3bKTO77Go3rTP31lazK/Ty5MgEndGkZqHIdQi9yQKdvOn0ntAr26ECL9m9i4iIyjc5uJGalokPP/oIx48fx7333IWaVWPVq3D52+DWyc6MLhhMwWoHx+zTSedz5QVPMlgQHFM3JwjTYca7n+HBe29HcHBI3k6R8ndK3uSATG6FigzRL3h9zduOwMnkjUhN2YOQsHjP4Hm9DHzKCbNywgzPkO5zH6iRWVoGg0W9RVoi1GmRwZUKPW94UDSy5e+ibyuoTof/+/ct/LlrXu5pO49vwOuLR+OFAV+oqhsJxCToyl2YcLuRbs0bJm+zZ+FU5nH8svnL3FBL3kuVVue6fXFz+1FITj+MhVu+KdByGRtaVYVjwaZQFQDVimmEWpUaIsISo27PE/jJga68cEg95oWQ6i8hOwnKt0LN48q5OakDjwk3ICpMvmdS3eSZT+X7WHjeA4nVzOrN+7mxiDlbXvI1T8hVdBWSVGRl2LLhPCPkkp9bu8uZG1ydjYReFoMJFqMpXxuh3eXA6WynCrwk+Eq3OmD3Jlk5YZaEX9KCqO6T+j83HG4nsmwu1cqY/3H07NSoihXlPknVodvTuujSOdXjKtVkUeF6dG8drIb/W60u/L3Jisyz7Jcgj7fsglkp0qC+p1JtZsxpadSfWdUllV8cTk9ERHReGHZpRI5yu6zpuVVbclTYZcuEWw4vyosUpx0ue7Y6Gi+VXCr0ynkRIefVqRcyOZVc8mZwQCdH8eU0qeIyBam2SDhsapctvcmsrlfCNblO+ToREZVPVqsV33zzDVb+8w/uuP0mtGndSp0ufyecNpndpVO/+yXkUjs4moJhCs5rAzsXgzlMDaO3puxXn+uNwYhtNli1/Mnb73+tRFyVWDRp3MhzAQm09CYYZUB+zkEZCa7UoPciqnZk9lflKi3VW0koLPS5vF5ffLRiogqfvCRY6N7w2nyztzy7Lzrx186fClzH0bQD2HRkJepWblrga56qobTcgfZy3dmOLOw4tqHQ6q3dyZvQtGqHnN0bC35dht377vqoKrQl4PJWkOVcRloovWrUrIaUk/mH/RsMBtSunTf3S0IayUokmPEtFpfARrr+pA1RXa8axp5753LX4GkpLbpCy3ObOfO4zhHKSDVXpjw/OeNxzJZWRodNraEwmTYrlh/ahp2njqB+TFV0q9lEnTfLYVMtjCHys5lz2/I4pdukYl6CpLySKGlTTM225z7yVqdTBV9LdhzFh//sRlJKFprGR+KuDnVRKzosLxyUjMulg8OtgzHnMZAsTloOzQZpcXQh0+6GyWBQuy6GBxuQWM2IDbvPHtjFRnmCLgkIpXLL+/hKQOnL+/0hIiKi4mPYpVlFl0/Q5XLAme0JoeSFisuakbsDo1uqvOQZlXqi5fJUgakngp6jf2oWlwxmzTmCLvO55JmsS+aLmCye0EtCNLdDDR0WLrWlt7wQ8mxRT0RE5YNU6/z888+YO3cuBg8ejBlvvqna3XPbC2WWlikIbmmd0+nVkHinPRN6vRFRtS9H6oF/4LTm7QgoB0dkJ185v6/QuCbIOrk773adNhWcyU6NJ0+lYu6CJZj08jN5FUA+OxyqoM0goZhZxQzyNy8rKxNJSQdgMhlRrWo8dCo9KF67V15P45kTvPJ/JvdR58qbXymXC9IZMGHAF/hi5RRsPrwSsWHV0KfZbWhRrVPu5STkUoGVGqBfeDhxLPUg6lZqknObEgjJgPIs1Xboy5ETVBnlcS2E93S5vsJkWFPzXfbMwEw9ZKrCK0+9hrWRmZmNPTv3qCqkkJAQdOnSBcHBwWc8PjoEmXW5lUoS/Jz5LVDhV+7Deo6ARVUfeSqQ5P255knJz0GGPbtAxZZUeUkw5RtyyYc2l0N97XhmCl7463ssTcq/O2P7hER81PdhVdkl1ynnDTPJboeecEtaN9OsWeo0k8EIpzsv6PKt7lq9/ySemCfhpMeqAyex9Vgq/ndtO4SorSU91XRqppb6N+jZFiHIpFf1dZkOl3oMgowyJN8Fme1vMRiQknH2n+8mNc2IDjeodkWDtE3mhIpnDryXFkdWdREREZ0/hl0aUK2LhQVdUs1lzcitwPIMmnfCaU33PPOTNg41qN4FZ2Y6nFmnYYqpBr3RqJ75esMrtzsbxqAw9bHT6YAhKAxuuw0u6D1hmAq8ZHi9hGQcAkFEVB6sXLkSn3zyidppb9q0aTCbc1rLjLITo1T9eqp99AaprpKDHrac8CtEhVlGSziqXzoSp3YthvV0EsxhVRBZs7MKy5K3zoM1NUldV0T19nDZbbClHsq7cbdT7eIYFt8S097+BMMeugsWi+fvibqNM8IdFaLl2LNnD3777Tc4nZ71RUREoF+/fggPD8+pAnPnzpnatm07kpOTERUVhcaNGyMoqPhVyG69AY4zwiEJOKpF1cG4K9/03IbThiyZtZVD2hIz7HnhX1xELew/ua3AdW8/tg6NE9qe9fYlEEm3pqj3DeNa46+d8wqEYY3i2qj3aw/8Weh1RAZVUrsryt98mTmlKrl9go9CIw+dDu0uaYPmrZoiOysbMdGVEBbkaeMsjAQnZnV8zBN8STefZ7fJnO9EYRlNTmWXHFdTgdhZ2hgLIy2ZEjyd2bZodcjjb80X7skML6nWUp+73Rgy7384mF5w985Vh3fi6y3LcEezrrkz21JtWYiwBKu2wuycfkS5/gi9XoVb3rsmg+ol6JIfv6/X7Stwl9OsDizacQRXNohXhYkut1y/53shlVxmvQEZVgmopF3SmFOZZkew2lJRD7vLpSq8ChMdrke7+kFq/pnRKLtKeh5g+TbLBgC+QZfBoMud50VERETnh2FXGcvdKTGHy5qVr6JLnnk5stJUdZaEXDKkXp7+OTNT1ZMxe8ZpHFv0thpor+iNiG7bH+ENOqonvNK6aAgJV5fVu0NU+6LTmgWDJUS1RaqAy2DMrfAyBIVq9VAQEVEx7Ny5E++++y5q1qyJiRMnqpDoTNKm6LJLFW/OHKKcHQbl9760C7rNEnjZYQqJQVzz61WooAIy+ZvkcqBqh/vgcljVPC4Jrw4se6PgQtxOzJnzIxo1bID6ifXzbtuQP5CSqi5vQCMB1h9//JEbdInU1FQsX74cV155Zc75dHA4HJg7dx5OnDiRe76tW7di0KBBBSqUiiK7Q56Lb4ugqjSypfkMmXejRlS9QsOuTFveTK7CSK1PavbJ3NqzUHM4rm87FAs3f4Xj6YcQYg5H6xpd0Ci+LZJSdiHTXvj1RQRHq6HnsuNiqCVCPT4mg0X9fZeg7kTmUVQOiYPeVHCGmcViUW/ns2OfBF+ewvC8y3jbUHPv20XuAGh3OjwthWdESll2W26oJWQjgR+2rcA3m/9Gmi0Ll9VorJ4TFRZ0ea04tAPXNeqEYKM5NyRS4ZY5GI6cfky5XTnN7vT8fMj8LqtDgi6p/HIgNbvwar7j6dk4mekN3TwhYJBJdiHVwea0q7lnYRaTCtEkAJOgKtvpQphZHjMD6lbXY0cSYPe5+mCzDrd0j0REqM9mDvJk3KiD8YzqOGkJPbOdkYiIiIqPYVcZk6Pl+XZhzJm74WldlDlenhcrruw0TwBmy1TnkxcfJ1fPQeau1WdcoQOnVs2CJbYWjKHRMIVFw5mZBkNIpLqsziDzIOR2zOpFjLzwMRg8VV/qRY4MuOdW1kREfufo0aN47733VOvimDFjEB8fX+R5PTO65KBGVr4KLwm6XNKi6HKqnXrlNJfLc9BFtUbJpiY54YbM6fKW9cjHjqxT+W4jOdWJZev2YOqUh3NuVA+DMdhT7uNdh1R5+WyCIvdBAq8zHThwoECg5xt0ibS0NGzatAnt2rUr1uNl0BtygqK8YM2oy/80xzfIkeDr790LsHrfEvV565pdUKdyUyzbPb/AdcuujGeS65LAw60DTmcl5/va+j+3o0XnRrim1f2qekx2UZTvkbQ++s7bOlOV8BpqXXJ+Vdml2uVCsHjr/2HRlm/UrK+YkCoY0ukJXJbYX13Gu+tgSSmp5wRSCSWBltXnAJ9Xpl12YcwfdH2x8U9MWPZ/uaftSjkKS87BuaJUDYtW1y9rDsn5uXO65Hbl+Y3v7dkhz4bksfIOppfblEDskloxWH8opcB1N46LxOoDJ7DteDqCDHocSctCcoYNVcKCMKhZdTSsEoFUqw1RFjMccMHoggq9MuwuRATpVaDVt1MQNu5y4GSqC7FRenRpHpobdMk/P0/IVfDxlmouVnQRERFdHIZdZUyOoOd+nDO3Qr2X6i4ZOi9fz5nXpd5LZZcbOPLL27CnHC7yejP3rkNk025wZKbCEByuQjOp2pLL68wyj8UGnZTan7m7kdzOOZ5MEhFR2UlPT1ftirt378b999+Phg0bFuty8oJfZjNKuCVzGz0nynD6EPW5p6rYCb1BQi9zTuujbHjiqS5Wf2zk75C009XpgmPrvsi9bmkR+/pvK8Y99Ygafu7ZAdhTcZR3+3o1yN5XUVVZZ54urYuFOXmy6KqewhgNZjgdWXlrkt2K4RkgfmYw9MO6dzF/02e5n+9K3ojL6vVHh9q9sHLvotzTG8W1RbOqHfO1P0qQ41sldqZdGw6gxWX1ERUSi0On9mD5ntnYc2ILTAaTamUMMoYg25G3E6Raq06Ppgnt1WMaZolUFUky8P+/g8sxZ8OHeY9J5jFMW/Io6sY2Q9XI2gUq2ko6/Dpf8thIK6K0KJ5ZzSVtkzK3S3Zc9G01lUquTzf+UeC6rGfZkVGqt65t2FF9LMFZkIS7OT+PVpcNbrcpN7iTdUgoFiwtv7lr8bzv36Qq1h5Mwar9np81g06HqxrF46fNh7DtWF6Lq9eJTBu2LtmMkZc3QMuEaBV4RQaZYXO5EKz6Q92eNk8dEB2hQ79OnnmpIsRsUBVgRbWAetoWPa2iREREdHGYcpQhdUTZ91Cj98me931O+4m3zVF21BKpW/86a9CVe90yI8Xp8OzeJC9sctpUPF/Pm5PhmQGiz/u4JO8kERFdEKmA+v7777F06VLccccdGDp06AVdj94YpMIoCb28v/vVTC2Z5SUbnUhll8uhxkD67lTnK6ZuN1UVdnLHIjiyT2PZrhB06dkaterUU7ss+lZziZOnTmPbjj1ql8hatWohMTFR/S2qVKkSEhIScPhw/r9hzZs3z/d55cqVC19HTMx53Xez0aKqp3yZ9Ca1y6GQiilhtWdh8bbvClz+n72L1HyvS2r3xMGUPQg1RyAuojqs9kysOfA7th1dq66jedVOaFb1knwBT9KpXWpXxhrRieo0NUfK5cSS7d/j0Ok9ntt1OLH+4N8It0SpXRu9lXQWQzD6N78TlcMSVMuj/P2WKjX52Ft55kvaHP/aORc3th0JwxkHrOT7pgUZ9K9CrkIqueQ5igyRz5SKdp/nQVJdJUGXPH7HMvPvKHk2nas3wqh2fREfFpV7msPthDmnkk9uQq5bqrmEQadHltOBIIM57zlPzgeyo+LILg2QlJKJncfTUCsmDMfTrJi3pejnXXIPftyYhPa1KqlB/y6d57YcbhdMeqkudMMsfYnq+yHz13JuTM53ZtClBv1Lu6qnrZSIiIhKBsOuMlSgNcD7qffJTe67nN2tZM6K0wnbifztHoUJrtog54i87K4kw+zlWmSibO6NFHLDJdeuQEREF0Z+Zy9evBjfffcd+vfvjxkzZqjqqYshfz9k50RvRZe3tVFVOullMxOLZ+deOT2nslgn8UDOhHI5IBJVpxui6/bA/qRD2LFqJiaOHQJ9Ies6dOQ4Fi5aotothVSkSbglOwKK3r17Y/Xq1di7d68aqt+kSRP15kvCMWlZ9G1lDAsLQ9OmTc/rfktVk9lggc2ZN/TcaDTDZrPmC4LSrCkFQjFhd1qRYU1T1VMbDi7D6ayTqBpVBzZHNrYcyRsjcDBlNzJsqbikdi+czDiqqsRScloZQ4wRiHZ6Ko6Opx3MDbp8ye376tf8DrSqcbnnbzjcqnXRIrPQvH/LCyHfqyBTwco5k8/OmGVBZnJJyGUvpNJNfq6kOksqr3x3WxQSfkmVl/fU9vH18MeBzfnOI8FRs9iaWHvU8xjKzoqPXnI1OlStj0hLXsWUsDocMJvzntaqdtCcx0KqrOTnWnZ4NBkMamaXVHB5fu49z4qqR4UgNiwIGVYHVh8oWFGod1g9s1FzrvNoWrY0sarcVwVV0hUsO1OqHzHP9XoeA9+nXfJv68IH/RMREVHxMewqY/JCw7sTo8zQkjBL3ns+9zwJl7kqsGVBbw6F025Ts7i8Mh06BBnkKGHedUY0uwJBsbVVi6IxxLMDk+zAmHtdamesvNvIF3Dl3DYREZW9devW4cMPP0SbNm3wxhtvnNfug8WRV9El7fESfMl+hTnxgl4ve/Se9fIOhxNvzHgHj48bUyCAk1ZI2XVxzb+/5gZdvsPlW7ZsicjISBVwXXrppeqtKEajEa1bt8aSJXmhmQytz8zMLPaAei+LKTh/2KWX9jaDCvYkDJOvx4TGITasGo6nH8x32ajgyjiYsgv/9+9buaedeR4vqbhqX/sKLNzyTW7QJTJOZ8Ph3AezIUhVOxXHmv1/qLBLhtEHm0Jyq6+l3bFzYj+sP7gs3/nl/nSvf41neL0PCfrKqo3R4XKqmVyFhVwOpwvZTpsKtHzJz55DZmo5bOryvoa1vQpbThzMrfCSMOjB1leib702SEo7gZTsTDSISYA55/mMXI/Bp8JQ1iGBmreKSm/wHPyT5zzyZjEa1GD5cLMxJ/zSIdRiVAPmo4LMOJVtQ5BRD7tDj2qRhYSItnTU3LkYB+p1R3ZoLGrHhKoKLu9aPbsp6lWIJu2MlpyZWyEWCbVyvp8mQ06rIxEREZU2/sUtY77bseuMOfMkdHro5EWDzDsxB6sjh56wyg1DWDTCEtupsEqeU32wKxxWl7f23oK4viMR2aw7XE6H2oVRvqV6k7SwGFTQpQI0n23hdaa8J8ZqZ0ZWdhERlTmpcnriiSdURdeECRMwZMiQEg+6fHkGxwfBYAmDwRTi2TFRDU0/+9OAL7/6Bj2v6IH4+DjP3yiZiyTXYw6DPmfHx1On8g+y9yrq9MLIbo3Lli3LF5plZ2fjr7/+wvlSgdaZs8NMYbkVUia9RVU/3dlxnAqHvOS0G9oOx1875xXrdmRYvMygSkrZmf8LGWZYLaeQaj2FelWaIzwouhjXlY7IoBiEmGWdnvWHWaJgMQahfc0eal3BJs/uydEhVTC25zR13Wfeb6kIKwuZditSrZn5gi4JlqTCKyU7A6m2zNygSwIumdElLYwp1kzVtugbdMnlZKh8dHAo3r/qQTze8RoMa9MHH/UdqoIuUT28EprF1sgNuoTVVbBdUiq3vFTlVs6sNhFklLDWBZvTibAgo/ppkIHyEnBJRVZ0kKfFMcxiRKdaldAkznPwMPf2QiphT6N+qLb3L1Q+vhm3t62tnkNFB5tzwjRPdCxPq7wtjCZDXtDl+ZxPu4mIiMoKy3rKmBroKzsQydFGeaFhNMNtt6qQy5ntUF/Xu+XpWTYMwRFwZqUhKL4+4noPxeL5c5AYfQqRcTUR2ayH2oFRb7J4tpiXI+5utxpOL0fr1a5b5mBVSSYDi1UrhMGYb5csCcWIiKjsSJveBx98oHYalJlc1atXL/M1qIMhZ8x1Kmy+444dO7F9x268/PI90J9lI5PY2NgCM7nkxb93DpfMIpNB8+Hh4QgJCSnyccnKKthWKLs5SoWXVH6dDwmJpCVRZkF5d2qU02ROloQPEn41q9YJkwf/iFX7lsDqyEaLap0QERyDL1ZOKdZtVI2sg/CgSFU55vANXjIt0IXYEWoOU22Gt7YbjS9WT0VadtHhX9OEDup6zBIk5uzEKOQ0izEEN7UbgWta3odTmcdRPaoeQixycCuPnF/me5X2ASx5PNNt2QXCKmlVzDpjHpcKuGw22N32fNVmajMeNXfMBYfTqS7nJWFW15r5W1yLIpeVkGzP6WN4c80C/HdsP6qHx2B4u764sk5LdR6d3qnm0uVMd0CoxYRMqx1hhmCEBxmRlu1QQ+Ml7JL2xahgM6xOl/r40e4NsXzfSWw+clo9rifSrTiVHYTK9e7C5cdWYe+ir9DstvtUdZmEWiEmCY89Q+hlWwT5OFj6G3N45nIx7CIiIiorDLvKmIRPEjK5bJ4n9TqpwnLLrosO6IPC4MrOgM4cpIIp2VFRFxqp2h4tcfXwR0oMJox4EEFBOUei5Um8qgozQS+XkSeTak5LsGpbUUGXJVSdpm5XPs6hQjLuwkhEVCYkyPniiy/w33//4b777kOzZs3gT3Lb6HMG1ktANW36DLzwwgtnDbpE+/btMX/+fBVKebVo0ULN3Nq8eTP++ecfdX0SGMisLmlnVBupuN3qMiaTSe1AWRj5mm9lTLHvj06nwh+Zq+UNYMzGYFU5JsPq5Tpl+Lzo2eh6z1pcdlWtlVilOdYn5W8bPFOQKRTXtn5QtT3K3K5lu+fnfTHDjMSWtVE1qq76tHHVdni+/6fYe2KrCtx2J2/GrPXv5+7mWK9yM1zb+mGE5gRY8rdcBu2b9OZ8w+ZlqL0MsD+zGk/CMakIK+32RQm60qxZKqTKO82dL/ySGEsquo5mnMbkf2Zj8d7/1Lr61G2FoW36qGHwZ9th8XwdTDuJh395H6etng19tp48hOGLZuLT/sNxSdX66jSTwQ27U6++x1LtFWLWq/sia4kMNiHDJmvXwWLQI9Pu9FRpGWQHT6BfkwT0bhjvmTcmg+R1nsDKoGuB7etX48s3XsQtD4xEdHw8dDo3wiwmVS0mJPyS2/AK8ZknRkRERKWPf3k1IEGTBFUuu1U9qZLZXG5dtvpcAi84bXDZsqGXKi05n8OOn/9YiR6d2yM0popqxVDHRdURXBmCqofOZM5pi5QnxjoYLMGqNVJVdHmrvHKO+Ho/JyKi0iVhzrx58/DLL7/gpptuwj333FMu2sfff/99DB48WO2meC7x8fG47rrrsH379tzdGKViTaq5fNsQJWyQIfRRUVEq3JLzSwgoFWChoXkHY3xJYHYhYZe3mivEFIYMW1ruaRZp87NLu5tVfT3MHKkG1UsVmLQxGvQmXNfmYWw/ul61FvqSoKp3k1sRag5Hi+qdVcAkBrd+EMHmMPyzZ5GaCxZqSMSQXiMRZJS/u6rGR71vWb2z+rhJQgdcnjgA2478i+iQWDSIaw2j3gijwaRuX8Kh3L/XOQP3zwy+PF+T1rlgta6ykGGz5gu6pKoq1ZaVGyZK4JVmz4bVYcdTS7/C8oPbvefE7B2rVFB2X6ueiAoKzavw0uW8z6n2kspC3+lvngopnQqZCgvzftu3MTfo8pJg6rNNS3PDLmm1DLMEIcPmUm2nqsJKXZUeNocL4RYj7C43suwOhMq8LZNbzeKyO1xwuvSwG3wH67tV2GXU69Ch46VIrFsPX783Hb0HDkb7jh3Vro/IaYX0hl5CKrxY1UVERFS2GHZpxBM26eCyZ3uGp0oYJdVctmy45YmdtDfKIGGHXZXcL129EZPGj4LRIEfDPdehxn3pPEcf5RO1HbzR5DkKL0+WpaLLFAS90ZQvaGPQRURUuuTFuwQ9X375JXr27Kl2WDzfVjytbNy4EUeOHMHDDz9c7MtERESgXbt2+U6TXRkLI7O5fCUnJ6u3ouZ+/fjjj7jiiivUbZwpNTVVnUdCOQnGziQBkoRT3sBL/t4GmUNhcJqQbc/wtDSaQ2FyWmB3ZsPutKFGVCJev24e3l46HpsOr1QVX3ERNXFL+0fQKK6154+v29M6qA5Y6fTqa7d0GK3Cmdd3/A/VKlfPH2qqwMagwi4JreIjaqBqZG01aP7MME/+rku4pcIvXcHZmvK5DL+XkKusglPZcfHM+VxpPkGXVHMt3LMeM9YswO6Uo4Vex5L9G9Vb3ag43NfyCtSI8LS5ng+j3oBQcxDUI6nTqbCtMCez0vKFX3aXSw2mz7A71fB8CeYiLRZVwZVl91SlmSzSjiqVafJ1F0w53xfPkHvvtelyT5PwqmaNanjs+Zfwxfv/w/4dW3HTHUMQHmTJt8OiVHTJYHoiIiIqW+XjmXeAUq2HBgOcclRSnkzJE9tgE1wy98Jp8wRZBhO+/24err9mACxhkZ4t4nMun3Pc1zOjSyq6cnYckn2vdbIjk0/IpZ5oW0LyDcgnIqKSJ617UhnVuHFjTJkypcg5Vf5IhsK/+eabePXVVy/6ukoq3Dt+/LjapXHQoEG5p0nYIKGZPNZC/vY1b94cHTt2LDzwskQgy5aeO8NLqrikmkpmddkc2TAapLIqDBaXzIFyqF0Ox/R8A1n2TGRYT6vdG4uUE2RJ6KX+0xkQLBsBSCQjlT4qECs8lJLKbAm/5LKyHgm3zqzgyr0fepNat7yVdXWgDJ73JXO2VGtfzuyt/47vx6O/fVZgh8XCSBg2+Z85mHrFnTDJRjkSSLncWHl4B9Yc3YMwUxC61WyKGhEFqwrl+k9nZ6g5WZHmELSJq4PPNy0tcL5LqzVU55VwTFgdNgQHmVQVl9XhUgGXfF1uX0IrCbmsTif0DlfOZQyqgl7uokveXJ7AyxNu5hxs9D4L0xnw8CNj8NevC/H6S8/hkUcfQ1RUtJoDFmr2XD8RERGVPYZdGvMEXBFwO6yqjVGeWakh8lLZ5XbjxPHj2LxjN+6642bo3J4Sf51PaZdnTpe89+y6KNd35tHk3CH25aB1hoiovDp48CDeffddBAcHY/z48bkD2suTt956C7fffjsiIyMv+roSExOxatWqfEPLL9SxY8dUFZe3umvPnj25QZeQ29iwYQOqVq2KmjVrFri8BElhlkhk22WXQKs6TZeze6EMhbc7rOp0KeaRsMkEz2zMEEskKoXGeQ4y5f7tVYVdOS12eS2Hwm6XGWTmfLs8ql0sc4Iw+VhVeMlMzUKqtooKuCSwK+2ZXGfjW9UlvDstiiy7DfN3/VusoMvrZHY6VhzagSaVPRs0fL15Gf4+uC3367/u3YCH2/RGy7jaMOmkBdCQG655WyjlOr7durzAdTeMqYrrG3VSgVx4TiW7XFbe9Dm7JpoNElCqvRNVkCVtifIz4jZ6WhgdLs9lnC65nAtu6bfMqahX30u9Z36XzOQy5IRgva/qi/oNGuDl557Bgw8/jLatWvJ5FxERkYYYdvkB1cYog+qNFriddrhVZZdDnf7RF1/jnrvuhDEo/HyuMGenR1PB8IuIiErU6dOnMXPmTBXIPPDAA6hTpw7Ko9WrV6uZW507dy6R65O2Qu8g+pLg2+63d+/eQs+zb9++QsMuIWtRLYsui6rmkpZFdb06PSymYPXmyqnscrgd6mOdzgW3S5XxFLw+daK0JeYFWSePHkVCfIIafu8Jp3Iqrotz/yQIk+qunDcJX/xBYd8/3+DJ5nIg22dHxfO93uOZqVjuE3R5q8Xm7VyD+jEJuafJLDCL0YQYmW2aM5x+xSHvXLA8EnJJxZbsBplvzS439JJMeVtBjXqEmMywOZyqddHu9KzHqEKs8747qoKreZNGeH3qFLzyyivYuW0rbrzxRj4HIyIi0oh/PJOivNDLp6pr397dSMvIRPPmLTzti97BsL5Du3KOGquqLrUzo5G7LBIRlQEJhr755husXLkSd911F9q2bYvySgbGf/DBB6rtsiSFh4erMPB8mM1m2Gz5w5Nq1arlm8llseRVTvkq6nRfahi8OQxOl1OFXjKTy9veqFoKfSq7vDwD1D1/e1V4ofaIKRhinDh+SlWXSVhVGNUG563wUu2LnttT1V7lJBTxzLDKH2J2r9Ws0CqrokirYoNKVdXHh9NP5Y5n8NLbXUjdcQCnWmSoQEoqv9Ye3aNCtnoy86tFT/y0e02h1y3X5+Wt5lIfq9H3BVMss9Gg3oRnnpenoksqvOTycjd976u0J8o1ylwuVd2VM7De+/2zhIfjpZdeUruvPvPMM3jiiSfKVSszERFRoGAq4qfkSdN778/Egw89DEPOzkVERKQ9l8uFn3/+GXPmzMG1116rhs+Xl6CiKNOmTcN9991X5K6IF6pVq1b4448/in1+aQGVYfQSIEqlnFdKSoqa0VW/fn1UqVIFjRo1wpYtW9T3wstgMKBhw4bFvi0Jm6TSSzikmstpV1VdTrejQDWTOhjlW95VxLf72JFjqFqtmmo9VO1uObO8vK2M5fHnxLMboj53J0b5XOZaydB6YdYb0Sa+Lh5u3RsfbFicr8WxKCa9QbU9bji2T7VAnsll1CFm6yk8u/RrRAaF5ttxcVfKUUz4+/+QWUQ1mczxKoy0nfry7pzoSwVXJTBLXh6j2267DWvXrsWYMWPw6KOPom7duhd/xURERFRsDLv8lMweke3Zi2rHICKisvfPP//gk08+weWXX47p06erKqTyTnaNlMqT0qhMk/BJHiOZryWVcLVr11Zh1S+//AKnM6/NLD4+Hs2aNVN/8xwOB06cOJHvejIyMrBp0yb11qlTJzWMvk+fPmom2MmTJ9V8tPbt21/wrDFV7eVTjSWVXp5ZTa7cqi5vAOYNrNTOirkD6D1h1snjKWjTsh1CzAV3hizPpH0wU+aK5jAb8sKuYKNU4jlwZ4tuuLp+O2xMPoBpq37CgbT830Nfp6wZmLNjFZYl5W9fzKXTIb2SBWHJVpyOLRgQFhV0RZiDMbxdX/WxzNPyVnWpwO6MXS9lDlhpa926NV544QVV6dW7d2/1M0tERERlg2GXH5In1NJO8txzz2m9FCIiArBjxw41fL5WrVpqp0JpzwsEUjEl7Vavv/56qd2GzDA7c47ZddddpyqzZPfHGjVqqKoXb4gkw+d9g7AzScAlIVr16tXVW2nwhlfn69ChQ6qNMdBYDCY1iN7byimf2/QONRdLQqRQkwUZdiuig8PQsVoD7Dx1BO+sXXjW69ycnHTWr5+oHYaELSlIjw0q9jo/6PsQakXGqo+DZCyEz/p9q+qkMq2sBv5LEDt58mS8/fbb+O+//zBq1CiYTNwZm4iIqLQx7PJD0vLRokULxMTEaL0UIqIK7ejRo3jvvfdUu9zYsWNVBVIgkRldw4YNQ1BQ8QOFkiAVWB07diz0a+eqlpPKr1OnTiEuLg7+RirQfGeLBQoJisLMQUizZeWe5vlcZp45VZgk0m3ZqkXx9mZd1UD5H7b/k68F0Zf5HPNFbaEmGG0uNb/LZdIXaEl0nTHpq350AmpGeHZAlfVIe6U6r06HoJz1eUk1WlkyGo0YPny4en43evRotVtroP0uISIi8jfa7WNNRT6Jl4HHt956q9ZLISKqsGRg+1tvvYVJkybhhhtuwLPPPhtwL04XLVqkBr83bdpU66XkI5VeZ6uck90PIyIiynRNJG1/RoSYLPkCsHBzkKqS8gZMUUGhqn1Q3h5o3Qs/3fAk/m/gaNSK8FRbedWJrIKuNQr/uavjc96TNUIRcyC9wHm61mySG7B52xcf6zhIrUnCNt8wK9QUpIbK+4Zscl+00LVrVzz22GOqtXHFihWarIGIiKiiYGWXn5GBx7169VJDeomIqGzZ7XZ8//33WLp0Ke644w4MHToUgSg5ORk//vijGkzvbyTM6tevH5YvX479+/cXGBYv87r88W+kzCQL9PY0aQ2UWWUZ9mz1uYRLEZZgZDvsyHLYYIAe4aZg2F0uZDqs0Ll1qBkZiw/7PYS5O9Zg+6nDSIyKR/daTVX746H0k/graau6Lgmpbmh8KTpWbYD31i3CxuP7kVI1BPWWH0Ny3fzhZo9azfFQ695YfWSXCuC61GyiWimlgivY5FmjrE1O853NJUPpJfzSkrTeSkWlvElb4z333KN+5omIiKhkMezyI1lZWepIu+zsRUREZUcClcWLF+O7775D//791e9h2d0vUO+rzBCSdip/DWekcksGenvnYG3btk3N8ZLZXv66q93hw4eRkJCAQCfD6qU1UGZ0yRB/EWQ0qYopCb2yHTY1wN6kD4bD7VK7M+r0Otzc9DK4XJ5h/063G06XE89edj12pxzFkYzTaBCdoHZelO7EV7vfhjRrFv4+uA3f//cZglNsyIryVGvVjozFZTUawWIwo1ZUbG5QJqGXd4dF7xwxb9WZOk2nR7gl2C92xJS2YWllnD17tqr0ko9lUyIiIiIqOQy7/IgMCb7xxhvVbAciIiob69atw4cffog2bdrgjTfeKPP5VVpUEDdp0gSJiYkoD2Tge3kY+i5hV3lYZ0mQNsBIvUFVc0m4JSQACzGZVXWV1WlXb1LZpYIotxlOuGB3uuBweQbbw2BAMMxoWaU2WqodMN2eOVxuz8dhpmBc16gT9IMzsHj+QhypGolLqtbHQ22uVMGWhFbSymgxGHNDLm/wJm2MvqGWSW9UM8b8IejyNXDgQLXZwuOPP65mevlbSzEREVF5xlTFT8jW6d5ydiIiKn179+5VOyzKbmkTJkyoEJUVEshIBVtp7r5YUR08eLDChF1CgiMJnSRckoouGUgvVVsyHytYb1bthE6XS4VeEm7pXDoYjVJpZVLnk+5UGW4vAZecTwIuibtckne5PePnJZq6uctVOLF4HYZdMw4WiwUGvQFGtVump1Uxdwi90ayG0vvO55J2RlmjVKP5q0aNGqlKy5deegnt2rXDtdde63ehHBERUXnEsMtPfPDBByro4hMcIqLSdeLECfU7V4bQy0wumaFTEciOkjJw/9FHHw3YFk2tg8TWrVujotHr9CpQkmoqVdHlsMOZ094o7YQhes9Qe2lhdLidKuCScEvOIyGV54xnv41Ol3XG5lVr0bl7V/W5PFcy6HSqTVGqtnzncnlJ1ZcEbrI+fycbMrz88sv49NNP8fzzz6vWRn+cS0dERFSeMOzyAzKANyUlBS1atNB6KUREAT0XUdrFN27ciHvvvRfNmjVDRfLtt9+iU6dOardDKnkyW6wizOwqii6nukreZB6XVHPZnfLeob4uFVdmGNVsr1xuqNBL3mSWnKe6S/7zfM1zxUD3nldg2sTJao6b4YyqLl8SbElbo2eumP+HXL5kSP2QIUOwevVqjBkzBuPGjUPt2rW1XhYREVG5xbDLD0gbzQMPPKD1MoiIApLD4cC8efPwyy+/4KabbqqQVbT79u3DypUr8dprr2m9lICVnZ2NkJAQrZfhF6TVUN6CjJ4NEaSaS1V0uWVml7QqunKDLAmvZBfHswmNtiAqMgonjh5DwhmtonJ5mSEms8HkfXknrYy1atXCiy++iAEDBqBnz55aL4mIiKhcKl+HvQKQVBjIrlPyxIaIiEqOvMj+888/1eBn2clPdljs2rVrhQu6JOyTkEsqRaR6hKgsyb83CaGCTRaEmYMRFRSK6KAwRFhC1NB4aX+UlkNpR5S2RE/lll7N25L33re+/fvh1/kLVeWYtE2Gm4PV9cgOjvJ5IARdXrGxsZgyZQo2bdqk3su/YSIiIjo/fNar8Qux999/X7XTEBFRydm8eTNGjx6NLVu2qBeLMvS5ou50+9lnn6n2r/j4eK2XEtAtsoG+i2dJB2ASbJnVXC0LQs1BCLcEqwBMwisViAWHqffet84dOmLr5s2w6I0q8JJwK5CDa/l9NXLkSDUHTn6XHTt2TOslERERlSsV85m/n5CKA5kZU6lSJa2XQkQUMDvivfPOO6qdbPz48WqnxYps+/bt2LZtm5oFRKU7nL4iz+sqCxJsdezYEcuXL8dll12GiqJHjx5ITEzEc889p/4dd+jQQeslERERlQus7NKIlKR/9dVXuPXWW7VeChFRuSebfEydOlW1Kt5999144oknKnzQZbfb8cYbb6jdFwO5AsZfhtNXPWOWFJW8fv364aeffkJFU7NmTfX77eeff8bMmTPVzqpERER0dgy7NCLDkmXoKIfZEhFdOKvVik8//RRPP/00unXrhokTJ6JOnTpaL8svvPfeexg8eDCrh8sAw66yIQG2jIA4efIkKhppk5Xfc9HR0Xj88ceRmpqq9ZKIiIj8GsMujWZ7yK5gAwcO1HopRETlklQ2zJ8/X820kfax6dOno02bNlovy682P5EZP9zJrWww7Co7FbW6S0iFpgTYd911l9pwQmYSEhERUeEYdmngyy+/xI033lhhhyUTEV2Mf/75B8OGDcPp06dVyNWrVy+26fnIzs7GW2+9hTFjxmi9lAo1s4sbAJSNTp06qbldUuFVUTVu3BivvvoqPvroI/zwww8V+rEgIiIqCsOuMnbq1CmsX78eXbt21XopRETlyo4dOzB27FisXLlSvdC7+eabYTabtV6W35Gg6/bbb0dERITWS6kwbDYbd2MsI3KgsGnTptiwYQMqssjISNW2LfMKX3jhBRVyExERUR6WFpWxDz74APfccw+rEIiIiuno0aN49913VfWChF2soCna6tWrVfBy6aWXar0UolIjYyA+/PBDtGzZEhWZXq9XG3LIAYDRo0erWV4yzJ6IiIgYdpWpAwcOqKGqFf3JGRFRcaSnp+OTTz7B7t27cf/996Nhw4ZaL8nvHy85oDJlyhStl1LhHnduNlO2qlevrirlMzIyEBoaioquQ4cOqFWrFl566SUMGjQIPXr00HpJREREmmMbYxmSyoQHHnhA62UQEfk1u92Or7/+Wg1gbtu2rQpvGHSd27Rp01QoyBf/ZT+vi8Ppy96VV16JRYsWab0MvxEXF4epU6di7dq1eOONN+BwOLReEhERkaYYdpXhzljh4eGoXbu21kshIvJL0qb466+/YsSIEQgLC8OMGTPQsWNHrZdVLvz111+quog7UpY97sSoje7du2PJkiVaL8Pv5pnJxhQy00zeHz9+XOslERERaYZhVxm9gJPWknvvvVfrpRAR+aV169Zh5MiRSEpKwuuvv47+/fvDYDBovaxyQQZUf/HFF3j44Ye1XkqFDbsSEhK0XkaFIxsCVKtWDTt37tR6KX5Hdqh95JFH8Oyzz6o5fkRERBURw64yOuLepEkTVKpUSeulEBH5lb179+KJJ57A4sWLMWHCBAwZMoS72p0nafMcPnw4LBaL1kupsGGXhC6kzaD62bNna70MvySdBPK7Yd68efj444/VgVciIqKKhGFXKZOZCV999RVuu+02rZdCROQ3Tpw4gVdffRUzZ87E0KFDVctNVFSU1ssqdxYuXKiGdcsBFdLGkSNH1LwkKnuNGjXCnj171A6kVFBwcLCq7pK28CeffBJpaWlaL4mIiKjMcDfGUiZH1GRXHO7UREQEZGVl4fPPP1dzDO+77z40a9ZM6yWVW8nJyZg1a5YaTE/aHtQym81aL6PC6tKlC5YuXYqePXtqvRS/pNPpcN1116lgUDb9GDVqFDf8ICKiCoGVXaVMjrjLNtBERBU9EPjxxx8xevRoNGjQQO0WxqDrwklL0qRJk9TjaTKZtF5OhcXWMO316dMHCxYs0HoZfk9+377yyitqhixbP4mIqCJg2FXK2rVrp3bHISKqqGHAn3/+qXZYlI9lh8WuXbuqagO6cHPmzFE7riUmJmq9lApN2sJkp2XSTkREBEJDQ3H48GGtl+L3pFVc2sePHTuGF198EdnZ2VoviYiIqNQw7CIiolKxefNmVXm0ZcsWvPbaaxg8eDDD/xIaiC4D/TkL0j++F1WrVtV6GRXe1Vdfjblz52q9jHJBr9erFvIrrrhC/X6WHXCJiIgCEV91EBFRiTp48CDeeecdNatw/PjxqFy5stZLChgulwuTJ0/Go48+CoPBoPVyKjyGXf6hTZs2arMLp9PJfxfF1KlTJ9SpUwcvvfQSrr32WnTr1k3rJREREZUohl1ERFQiUlJS8OGHH6oWmQceeEC9kKKS9e233+LSSy9FjRo1tF4K5YRdMvibtK9Wat++PVatWoWOHTtqvZxyIz4+HlOnTlUzFP/77z889NBDrL4lIqKAwTbGUrRn01pMfmgwfv7sLa2XQkRUaqxWKz799FM8/fTTqjpg4sSJDLpKwd69e7Fy5Uq1sxr5B1Z2+Y8BAwawlfECyAYXUilav3599V52eSUiIgoEPHxTima/PxmDHngM9Vtdku/0377/GH/88AlMZgsat++CQQ8+roY1z/ngNfz723yYg4JwyZWD0fOm+zRbOxFRcVrqZBc0eYEpbTDTp0/n4PlS3M1yypQpqi2Uj7H/kCrGKlWqaL0MAhAbGwu73a4qTGUQO53/rpayU64ctLj//vvRunVrrZdERER0UVjZVYpOHklCQu36+U47lrQHf//0DZ6cOR9PzJyP3Zv+xa4Nq7BtzTLs3/Yfnv3sV4x7exaWzvoMJw5zaCgR+ad//vkHw4cPV7vRyQ6LvXr1YghTiqRyrnfv3qrtiPyHzIhi25f/6Nu3L+bPn6/1MsqtunXrqs1EfvjhB3z++edqB10iIqLyqsKGXfIH/Md3JuKFIb0x4Y5eWDbva3X68gXf4bWh12HSQ9dg0z+/I+1UMv73+N3qPDPG3I7Uk8fzXY/T4cC3055TX3/p7quwcfkSdfonL4/BiSNJePGuPtj13+rc81epXgfjP1wAc1AwbNmZsGVnITQyGo3aXYbhr30KvcGAzPRU6PR6WIJDyvhRISI6ux07dmDs2LFqNo60K950002qDYZKz/bt29Xj3q9fP62XQj4YBPifyy67DH/99Re/NxchNDQUEyZMUCGuVJKmp6drvSQiIqILUmEPR6aeTEZwaLgKnrLSU/HszV3Rodc16mt7Nv2LGYt3qODpoxdGonXXq9DpqutV++Gir97FtUOfyr2eZfO+Qvrpk3j6k4VIOX4YU4bfgMebtMadT07BzvUr8di7sxEWFVPg9h/p00yFXVfccC+q1mmQe/rQbnXV+xtHPV/o5YiItHD06FG8++676kWkhF2sMCobNptNDY9+8cUXWTnnZ9gu538koJENAzZt2oRmzZppvZxyS37XyIGMJk2aqN/3Y8aMUTO9iIiIypMKG3ZFVopFUGgYJj84SLUhZGWkwZqVob7WvHNPFXSJ1YvnImnXVvz23cdwOZ1IqJP/j/3W1cvQdfAd6olBdJWqSGzeXoVlzS+94qy3//rPG1XV2BuP3Ip2VwxAzYbN1elv/b4bxw/uw/TRt6FF516IiuULSiLSjhzV/+STT7B79241x6Vhw4ZaL6lCef/999VA+pgYHvzwNxxO75+uvvpqfPHFFwy7SkCLFi3wyiuvqLC9e/fu6N+/v9ZLIiIiKrYKG3bt3rgGf//0LUa98RVCwiMw/vrOuV+Ljk3I/Tg4LALjZ87PDb8Kk+9o+zmOvJ8+cQzHkvaifssOCI+ujCYdumDvlnUqeMvOzEDNBs0QW60WajZshqRdWxh2EZEmZNDz999/j6VLl+KOO+7A0KFDtV5ShfPff/+pAeh87P037EpIyHu+QP6hdu3a6t9NZmYmQkI4DuJiRUdHY9KkSSp4l+Br9OjRsFgsWi+LiIjonCrszK6sjHSEhEWooOvw3h2qBdGNgjMe6jVvh7/nf6s+lgHy//6ef/Bpw7aXqtBMpCQfVcPm6zQpegcbu82Kz18dpyrJZN7Xnk1rkVCnIU6fOI5vXn8GToddhV6Hdm9DfK3EEr/fRERnI22Kv/76qxo+HxYWpobPd+zYUetlVTjZ2dl46623VPsQ+W/YVa1aNa2XQYWQDTPk9xiVDIPBgAcffBCXX365CrsOHjyo9ZKIiIjOqcJWdjVs0wn//Pw9nr2lO+Jq1lEVVRmnTxU4382jX8Tnkx5X87pCwyNxy9iX8339sgG34OiBPWrQvTwZONesrcoJNdDzpvsx6cFB0EGHtlcMUFVeQqq8XrjzSugNRlxx433qvEREZWXdunWYOXMm2rZtq+ZEBQUFab2kCuvNN99UFXURERFaL4WKcPjwYbVDJvmfK664Ao899phqaaSS3QBAdmx8+eWX1Uwv+ZyIiMhf6dzF2LJG2llmzZqFQYMGcdctIqIAs3fvXrzzzjuIjY3FPffcw6HbGpOdLhcvXozHH39c66XQWUiFy+TJk9WBLvI/EsjcfPPNqFOnjtZLCciNM15//XWEh4fjgQce4L8BIiIqU8XNpypsGyMRUUV34sQJTJw4UVVzDRs2TLXMMejSfkMA+X6MGDFC66XQOcixQr7I918DBw7EnDlztF5GQDKbzapyrlatWmq3xpMnT2q9JCIiogIqbBsjEVFFlZWVhc8//xwbN27Efffdx13L/Ii0j0qlBAdr+7diFMWTxpo0aaLm3snRX3YllI5+/fqpHXrHjx+vZnq1bNlS6yURERHlYmUXEVEF4XA48OOPP6r2qwYNGqhghUGX/5CdL2VTgNati97khPynKrJSpUpaL4POQnbK7tKlC/7880+tlxLQEhMTVTvvt99+iy+//JJBMBER+Q2GXUREAU5efMgLPmmNk49lh8WuXbuqF4PkH1JSUvDVV1/hoYce0nopVMydGBMSErReBp1Dnz59sGDBAq2XEfAkpH/xxRfV35enn34aGRkZWi+JiIiIYRcRUSDbtGkTHnnkEWzZsgWvvfYaBg8eDKORHez+ZsqUKRg+fDgsFovWS6Fihl3VqlXTehl0DjKDUHaVPXr0qNZLCXhy8OTWW2/Fddddp+Z47dq1S+slERFRBcewi4goACUlJakj7DKg+amnnsL999/POVB+auHChahevbqaMUTlAyu7yo/+/ftj7ty5Wi+jwmjVqpWq8nrzzTdZVUdERJpi2EVEFGDtcFIlJC807r77bjzxxBOoXLmy1suiIiQnJ2P27Nm45557tF4KnYfDhw+zsqucaN++PdasWQOXy6X1UioMmWcnc7x2796NV199FTabTeslERFRBcSwi4goAFitVnzyySeqmqt79+6YOHEi6tSpo/Wy6Cxkvo28EJQNA9haWv5CypiYGK2XQcWg1+vRtm1bFXhR2ZHfaUOHDkWnTp3U7zgJiImIiMoSwy4ionJMqhV++uknjBw5ElWrVsX06dPRpk0brZdFxSAVXc2bN0e9evW0XgpdYIhC5aeVUVq6qezJjpiPP/64am38+++/tV4OERFVIHymRkRUTv3zzz9qqHlaWpraYbFXr17cYbEczXxasmSJGuhM5S9g5r+z8iU+Ph5ZWVk4ffq01kupkGQm4dSpU/Hbb7/h3XffhdPp1HpJRERUATDsIiIqZ3bs2KF2u1q1apVqV7zppptgMpm0XhadR1gi82weffRRGAwGrZdD5+n48eOIjY3Vehl0nq666ioOTNeQ7DQ7fvx4tbHDuHHj1HxJIiKi0sQhIURE5cTRo0fVUXEhYZdUK1D5880336Bz586oUaOG1kuhCyCzh7gTY/lspxs1ahRuvPFGVuZp6Oqrr0bDhg1Va+OwYcPQrFkzrZdEREQBimEXEZGfS09PV8Pn9+zZg/vvvx8NGjTQekl0gfbu3YvVq1fjtdde03opdIEOHjyo5uNR+SLVr4mJidi6dSsaN26s9XIqNAm7pLr15ZdfRqtWrXDDDTcwgCQiohLHNkYiIj9lt9vx9ddfq5YP2U1MAhIGXeWXw+HAlClT1PeTL+zKd2UXw67yaeDAgZg1a5bWyyAA4eHhKuySnYSfffZZZGZmar0kIiIKMAy7iIj8jNvtxq+//qqGz4eFhanh8x07dtR6WXSRpDqvT58+iIuL03opdBFY2VV+1a1bV4WV2dnZWi+FABX633HHHSqElNZ8qV4mIiIqKQy7iIj8yLp16zBixAgkJSXhjTfeQP/+/TnEPABs27YNO3fuRN++fbVeCl0kGawdHR2t9TLoAvXo0QOLFy/WehnkQyqXJ0yYgGnTpmHhwoVaL4eIiAIEwy4iIj+Z5SQDe+VF2AsvvIAhQ4YgKChI62VRCbDZbOpFnOy+yPbFwMDvY/l15ZVXYtGiRVovg85QuXJl1aq/ZcsW9V7a+ImIiC4GB9QTEWkoOTkZH3zwATIyMtTOVNWrV9d6SVTC3n//fVx33XWIiYnReilUAnPX9HoeJyzPQkJCVLCyf/9+1KxZU+vlkA+j0YiRI0fit99+w5gxYzB+/Hi2fRMR0QVj2EVEpAEZxvvFF19g06ZNuPfee7n9eoDasGEDjh8/jqFDh2q9FCoB8r2sUqWK1sugiyQzoubMmaMOMJD/6d69O+rVq4fnn39ezfTizEoiIroQPDxJRFTGlSE//PCDOmot26+//vrrDLoCVFZWFv73v/9h9OjRWi+FSnA4fbVq1bReBl0k+Z27efNm9fuY/JNU3U2dOlW1nEr1s8vl0npJRERUzjDsIiIqox0Wly5dqnZYFLLDYpcuXTj7J4C9+eabuPPOOxEREaH1UqiEyE5+CQkJWi+DLpL83r300kuxbNkyrZdCZyFzK5966inVdvrYY4+pzSGIiIiKi2EXEVEpk1bFRx55BFu3bsWUKVMwePBgNZuEAtfKlSvhdDrRqVMnrZdCJejQoUOs7AoQ/fr1w/z587VeBhUjmBw0aBDuuecetYmLVOQREREVB19tERGVkqSkJLz77rtqILL36DQFvvT0dHz44YeqBYcCL+xiZVdgiI6OhsFgUJuE8Hez/2vUqBEmTZqEl156Ce3bt8e1117LymgiIjorVnYREZUwabWQCi5pY7v77rvxxBNP8MVUBSJz2B544AEVclJgSU1NZVtqAOnfvz/mzZun9TKomOTf3iuvvIK0tDRMmDBBzUUkIiIqCsMuIqISkp2djU8++QRPP/202k1q4sSJqFOnjtbLojIkc9nCw8PRunVrrZdCpYTVJIHjkksuwT///KNmKlL5oNfrcdddd6Fv375qo5e9e/dqvSQiIvJTDLuIiC6S7BL1008/YdSoUWqez/Tp09GmTRutl0UaVPR99dVXeOihh7ReCpUCu93OWXsBRtoYW7VqhX///VfrpdB5klbG5557TrWL//rrr1ovh4iI/BDDLiKii7BiEC9HvgAAPkZJREFUxQoMGzZMtVXIDos9e/Zk5UcFJJUhr732GkaMGAGLxaL1cqgUHD16FPHx8Vovg0rYgAEDMHfuXK2XQRegSpUqKuz677//VPu4w+HQeklERORHGHYREV2AHTt2YOzYsVi9erUamnvTTTfBZDJpvSzSyMKFC1GjRg00btxY66VQKTl48CCH0wegqlWrqllscsCCyh+ptpTdjps3b47Ro0fj2LFjWi+JiIj8BOvxiYjOs7pDdlgUEnax0oOOHz+OOXPmYNq0aVovhUrR4cOHVTBCgadPnz745ZdfcN1112m9FLpAUlVdv3591dooG8O0a9dO6yUREZHGWNlFRFQM6enpeOuttzB58mRVxfXMM88w6CLVviiVfVJRwHlOge3QoUMMuwJUt27d8Pvvv2u9DLpItWrVUjshyw6bH330kZqnSUREFRfDLiKicwyl/vrrrzFu3Di0bdtWzWVq0KCB1ssiPzF79my0aNEC9erV03opVMoYdgUus9msds7dtm2b1kuhixQcHIxnn31W7Yr7xBNPqBZVIiKqmBh2EREVUbEjOzzJwHF50vzmm2+iY8eOWi+L/GyG05IlS3DLLbdovRQqAxkZGQgLC9N6GVRKBg4cqMJrKv9kkxhpSb3jjjvUgaqtW7dqvSQiItIAwy4iojOsXbtWhVwSZsgOT/369YNez1+XlEfaY6SlVV5IGQwGrZdDRBcpMTERBw4cQHZ2ttZLoRLStGlTTJw4ETNnzsSsWbPUQSwiIqo4+OqNiCjH3r178fjjj6tqnRdeeAF33nkngoKCtF4W+SFpbb3ssstQvXp1rZdCZcBqtXK31Qqge/funN0VYKKiovDqq68iOTkZL774IsNMIqIKhGEXEVV48iTYe/R32LBhGDNmjHqCTFRUKLpmzRpce+21Wi+FynAnxoSEBK2XQaXsyiuvVLsyUmCRyux7770XvXr1UpuJSAUfEREFPm4dRUQVVmZmJr744gts2rRJPRFu1qyZ1ksiP+dwONQmBU8//bSaC0MVJ+zicPrAJzPZ5EBHUlISqzYDkMzdrF27Nl5++WUMHjxY7cJJRESBi5VdRFQhA4sffvhBVXA1bNhQzeVi0EXF8fHHH+Oqq65CXFyc1kuhMiTz+xh2VZxB9XPmzNF6GVRK4uPjMWXKFKxevRrTpk1TzweIiCgwMewiogpDhtMuXboUw4cPV5/PmDEDXbp0YYUOFcu2bduwa9cu9O3bV+ulUBljZVfF0bJlS2zcuJEhSACT+Xtjx45Fo0aN1HsZZUBERIGHYRcRVQjSqvjII4+owEKO6koLg9HITm4qHpvNpqoAHn30UYajFdChQ4c4s6uCkH/f0u62YsUKrZdCpax3794YOXKkakuXOYxERBRYGHYRUUCT2SvyRHbu3Ll46qmncN999yEkJETrZVE589577+H6669HTEyM1kshDcgObvy9UXH069cPP/30k9bLoDJQp04ddQBs9uzZ+PTTT1UFOBERBQaGXUQUkFJSUtQT2DfffBP33HMPHn/8cVSuXFnrZVE5tH79epw4cQLdu3fXeilEVAYqVaqkQg/5d0+BT4Ls559/HhaLBU8++STS0tK0XhIREZUAhl1EFHAVGJ988omq5pJwYuLEiWr3JaILkZWVhbffflttV08V92cgKChI62VQGevfvz+ruypY++qNN96IW2+9VbWrb9++XeslERHRRWLYRUQBweVyqRcmo0aNQrVq1TB9+nS0adNG62VROSeVgUOGDEF4eLjWSyENh9NzXlfF453bxba2ikV2ZpaDZO+++64af0BEROUXwy4iKvfkBcmwYcNU64HssNizZ08OEaeLtnLlSjidTvWilyr2cHruxFjxyAYmTZs2VW3MVLFERUVh0qRJ6t/+Sy+9pCrGiYio/GHYRUTllrQZyLbhq1evVk9Mb7rpJrWlONHFSk9Px4cffogRI0ZovRTSGMOuimvgwIFqcDlVPAaDAQ888IAahyBt7LLZDRERlS9GrRdARHS+jhw5onbHExJ2xcfHa70kCjCvv/46HnzwQe7ARyrs6tChg9bLIA1Ur15dbXYi4XdYWJjWyyENXHrppWrHRqnwuuGGG9ClSxetl0RERMXEsIuIyg15wfHxxx9j7969uP/++9GgQQOtl0QB6I8//kBERARatWql9VLIT2Z2MVCvuHr37o1Fixbhmmuu0XoppBGZ2Td16lR1EGTDhg3qQIi0uRIRkX9jGyMR+T273Y6vv/4a48aNQ7t27fDaa68x6KJSIVUc8rMmL2aIhM1m426MFVi3bt3w22+/ab0M0pjZbMZjjz2GevXqqd0aT5w4ofWSiIjoHBh2EZHfkl2wfv31VzU3SXbDk53xOCycSvPnbfLkyernzWKxaL0cIvIDEnTKDr87d+7UeinkB6666iq1Ic5TTz2FdevWab0cIiI6C4ZdROSX1q5dq0KHgwcPqtaBfv36Qa/nrywqPb/88gtq1aqFxo0ba70U8qPWac5to0GDBnFQPeWS6i6pMP/uu+/wxRdfqAMlRETkf/jKkYj8iszjevzxx7FkyRK88MILuPPOO9lCRKXu+PHjmDt3Lu6++26tl0J+Nq+LOzFSw4YNsWfPHtXSSiRCQ0PVcxQ5CCdVXhKMExGRf+F0RSLyC8nJyfjggw+QkZGhWgRkFyyisiBH5SdNmoQxY8Zw6DAV2ImRYReJrl27qs0revXqpfVSyE/odDrcfPPNWL9+vdoZWt4SExO1XhYREeVgZRcRaSozMxPvvfceXnzxRfTv318dKWXQRWVp1qxZaNmyJerWrav1UsjPMOwirz59+uDnn3/Wehnkh+Tvx8svv4y33noLP/30k9bLISKiHAy7iEgTDocDP/zwg6qmadSokZrL1axZM62XRRWMzIT7/fff1dF5ojMx7CIv2SQlLCxMtbYSnSkmJkbN8dq3bx8mTpwIq9Wq9ZKIiCo8hl1EVOYtY0uXLsXw4cPV5zNmzECXLl1UOwBRWXK5XGr3RdlG3mAwaL0c8kNHjhxBXFyc1ssgPzFgwADMmTNH62WQn5K/Iw8//DAuu+wyjB49WoXlRESkHQ4nIaIys2nTJrz//vto2rQppkyZwl3OSFNfffWVelHCtlk6WwWq2WzWehnkJ9q2bYuZM2fC6XQyIKciyd+VOnXq4KWXXlJVw/I5ERGVPVZ2EVGpS0pKwtNPP612u5Ndi+677z4GXaQp2Vlt7dq1uPbaa7VeCvlxFSqRL6lA7tChA1auXKn1UsjPVatWDVOnTsWff/6Jt99+WwWkRERUthh2EVGpSUlJURVcMrT1nnvuweOPP47KlStrvSyq4KRaR34ux40bx/ZZKlJaWpqa00TkSzZSkQM3ROdisVjwxBNPoEaNGqpd/tSpU1oviYioQmEbIxGVuOzsbHz99ddYs2YN7r77brRu3VrrJRHl+vjjj9G3b19UqVJF66WQH+NweipMbGysCswluIiOjtZ6OVROAtKGDRuq4EtmerVo0ULrJRERVQis7CKiEh34PW/ePIwaNUrNQZo+fTqDLvIrW7duxe7du3HVVVdpvRTycwy7qCgSls+fP1/rZVA5Ur9+fbVbo8yKlIOBbJMmIip9DLuIqESsWLECw4YNQ3p6utphsWfPnmwRI79is9lUACvtJPzZpHNh2EVFkYHjy5YtY2BB5yUsLAwvv/yyqgx85plnkJGRofWSiIgCGsMuIroo27dvx5gxY7B69WpMmjQJN910E0wmk9bLIirg3XffxQ033MDWIyoWhl1UFKPRiMaNG2Pjxo1aL4XKGTnQctttt2Hw4MEYO3asqjQmIqLSwZldRHRBjhw5gvfee099LJUy8fHxWi+JqEjr16/HyZMn0a1bN62XQuXEsWPHONeNinT11Vfj888/R/PmzbVeCpVDMuLhhRdewEsvvYTevXujT58+Wi+JiCjgMOwiovMibYoy4Hvv3r24//770aBBA62XRHRWWVlZauv3yZMna70UKkecTqeq4CEqTK1atXD8+HFkZmYiJCRE6+VQOSS7U8vfJfn7tGHDBjXv1Gw2a70sIqKAwTZGIioWu92uhqqOGzcO7dq1U4NWGXRReSAz5IYMGYLw8HCtl0LlBGcxUXHIbMpFixZpvQwqxyRQHz58OC655BI1EkKq5omIqGQw7CKic77okyfz8mRMwoI333wTHTt21HpZRMXyzz//qJ9h/szS+UhJSUFUVJTWy6ByEHYtXrxY62VQAOjatSsee+wxTJgwAcuXL9d6OUREAYFhFxEVae3atRgxYoQa1Dxt2jT069cPej1/bVD5abn96KOPVFBLdD44nJ6KIygoCAkJCdizZ4/WS6EAUL16dUydOhVLlixRM1FdLpfWSyIiKtf4qpWICpB5XI8//rh6wiUDVO+8805YLBatl0V0XuRFw4MPPsh5OnRBYZeEGETnMnDgQMyePVvrZVAABajjx49HXFycGhshVaZERHRhOHmViHIlJyfj/fffVwN3hw0bpo4yEpVHv//+OyIjI9GqVSutl0LlNOxq0aKF1sugcqBx48aqvV/mWppMJq2XQwEUojZs2FAdeJTnY82aNdN6SURE5Q4ru4hIhVtSMv/iiy9iwIABqpqLQReVV6dOncI333yjqrqILsThw4dZ2UXFotPp0KVLFyxdulTrpVCAadSokdqt8fPPP8f//d//ceMMIqLzxLCLqAJzOBz44YcfMHbsWHV0+vXXX+fRQyrX5MWA7BQ6cuRItt7SBTt27BhiY2O1XgaVE1dddRV+/vlnrZdBAUg2Bnr55ZeRkZGB5557DllZWVoviYio3GDYRVRBAwE5Ci2Du+Wo9PTp03H55Zerj4nKs19++QW1a9dWR8SJLuZ3pMFg0HoZVE5Iy7TMWjpy5IjWS6EAJBsDDRkyRFXejx49Ws1VJSKic2PYRVTBbNy4EY888gi2bduGKVOm4JprroHRyPF9FBjVOHPnzsVdd92l9VKoHGOrEF0ICSLmzZun9TIogLVr1w4TJkxQVfiLFi3SejlERH6Pr3CJKoikpCS8++67CA0NxVNPPYXKlStrvSSiEg0oJk2ahDFjxjC8pYty4sQJVKpUSetlUDkMIj7++GO4XC5ViUNUGqS9Wg5UvvXWW9iwYQNGjBjBjRGIiIrAVwREAU62rZ45cyaOHz+uBnZLixdRoPnxxx/Vzot169bVeikUADsxcjg9nS8JuNq0aYPVq1ejQ4cOWi+HApgc0JG5lEuWLFEHeMaPH4+4uDitl0VE5HcYdhEFqOzsbHz99ddYs2YN7r77brRu3VrrJRGVWtXiH3/8galTp2q9FAqQsKtatWpaL4PKof79+6uKG4ZdVBZ69OiBxMREPP/887jzzjtxySWXaL0kIiK/wjprogAjLRQyN2TUqFGoXr26Gj7PoIsC+eddtmZ/9NFHOVCcSgQru+hCxcfHqwNNp0+f1nopVEHUrFlTHeiR3UClil/+JhIRkQfDLqIAsmLFCgwbNgzp6emYMWMGevbsyR0WKaB99dVX6NKliwp2iUrC4cOHWdlFF+yqq67CggULtF4GVSCyE+gzzzyD6OhoPPbYYwxbiYhyMOwiCgDbt29XcxukZVGGdN90000cWEoBb8+ePVi7di0GDx6s9VIogCQnJyMmJkbrZVA5dfnll+PPP//krp5UpuTApvwtlLEVEnht3rxZ6yUREWmOM7uIyrEjR46oHRblSc64ceM4oJQqDIfDoXakkqPZrF6kksbd9OhCyYGm+vXrY8uWLWjSpInWy6EKpnHjxnj11Vfx0ksvqRleEoDxbyQRVVR8NkdUDnnbFF977TXcfPPN6gU/gy6qSD7++GP069cPVapU0XopFEBk3g1fGNLFGjhwIGbPnq31MqiCioyMxMSJE1U744QJE9QcOSKiiohhF1E5Yrfb1YwiqeJq3769CrsaNGig9bKIytTWrVuxe/du9OnTR+ulUIA5fvw4YmNjtV4GlXN16tRRs98YMpCW1anS0igz5EaPHo19+/ZpvSQiojLHsIuoHJDZH4sWLcLw4cMRERGBN998Ex07dtR6WURlzmazYdq0aWr3RVbgUEmTgII7MVJJuOKKK/Drr79qvQyq4Dp06IDnnntOtf0vWbJE6+UQEZUphl1Efk4GcI8YMQKHDh1SL/KldYvzZKiieuedd3DjjTeqXaeIStrBgwe5EyOViF69ejHsIr8g7f5Tp05VzyffeOMNNfOSiKgi4CtmIj+1d+9ePP744/jtt9/wwgsv4M4774TFYtF6WUSaWbduHU6dOoVu3bppvRQKUKzsopISEhKiWmLZPkb+wGg0ql27mzVrpt5LyzYRUaDjboxEfrjt/fvvv4/MzEwMGzYM1atX13pJRJrLyspSVV2TJ0/WeikU4JVdVatW1XoZFCCuvvpqzJkzR40gIPIHPXv2RGJiotrY6J577kG7du20XhIRUalh2EXkJyTc+vzzz7F582bce++96ugbEXlMnz4dQ4YMQXh4uNZLoQCWkpLCFlkqMfJ3/O2331ZtY1JZQ+QPateurdoaZcfGjRs34o477uB4DCIKSPzNRqQxeRL8/fffq7Lyxo0b4/XXX2fQReRjxYoV6j03ZaCywI0PqCR/ljp37oy//vpL66UQ5RMcHKwG14eFheHJJ59Eamqq1ksiIipxDLuINNxh8Y8//lDtDXJEbcaMGbj88sv5QovIR1paGj7++GO1SQNRaR94YHUDlTTZVGb+/PlaL4OoAHm+ed111+H222/HuHHjsHXrVq2XRERUovisjkgDUjb+yCOPYPv27aqU/JprrmGLA1Eh5N/Hgw8+qI5CE5UmGdgsu5YRlaSoqCj1950DwclfNW3aVLU0fvDBB5g1a5bWyyEiKjEMu4jKUFJSEp5++mn89NNP6v19993HF/FERfj999/V/KRWrVppvRSqIMPpq1WrpvUyKAANGDAA8+bN03oZRGcNZSdNmqRCWdkBPDs7W+slERFdNIZdRGU09HjKlCl466231O43jz32GCpVqqT1soj81qlTp/DNN9/ggQce0HopVEEcPnwYCQkJWi+DAlCHDh2wcuVKNb6AyF9JG7cchJUdG0ePHo0DBw5ovSQioovCvimiUiRHxr7++musWbMGd999N1q3bq31koj8nrwgnDx5MkaOHAmLxaL1cqiCOHToELp27ar1MigAGQwGVaEqzwXatWun9XKIzqpTp06oU6cOXnrpJVx77bXo1q2b1ksiIrogrOwiKgVOp1O1LIwaNQrVq1fH9OnTGXQRFdPPP/+MunXrolGjRlovhSpY2MXKLiotV199NebOnav1MoiKJT4+Xs3MXLVqlXoOKxt4EBGVNwy7iErYihUr1A6L6enpaodFKQfnDotExXPs2DE1027IkCFaL4UqmNTUVERERGi9DApQEqTK8wLZYZaoPDCZTHj00UfRoEEDjB07FsnJyVoviYjovDDsIiohsrPimDFjVJuCDPm86aab1BMFIip++6L825F/R9ydlLTAAxNUmvr06aMqV4nK28/tiBEj1MZKa9eu1Xo5RETFxrCL6CIdOXIEzz//vJrNNW7cOAwdOhRhYWFaL4uo3Pnhhx/UXBuZFUJUlux2OwNWKnUyE+6PP/7QehlE501GC7z22mvq7/Rnn33GzRaIqFxg2EV0EXO5ZHdF2WXxlltuwTPPPIO4uDitl0VULiUlJWHp0qXq3xJRWTt69KiaUUNUmsxmswrzt27dqvVSiM5baGgoJkyYoLoWnnzySdWWS0Tkzxh2EV3kUVrZNa5+/fpaL4WoXAfH8u9IZoPI1udEZe3gwYMcTk9lYuDAgZg9e7bWyyC64FZvGdMhB6ZkjteOHTu0XhIRUZH4qoLoIrYSb9asmdbLICr3vvrqKxUcy86lRFo4fPgwqlatqvUyqAJITExU4Wp2drbWSyG6YM2bN8crr7yCt99+W+0+TkTkjxh2ERGRZnbv3o3169fjmmuu0XopVIEdOnSIYReVme7du+P333/XehlEFyU6OlpVZcsYgpdffhlWq1XrJRER5cOwi4iINOFwODB16lTVvshd8EhLDLuoLPXq1Qu//PKL1ssgKpEuhwcffFBVZ48ePVpVLRIR+QuGXUREpImPPvoI/fv3R5UqVbReClVwGRkZ3EWXyoz8rEVFRamKGKJA0LlzZ4wfP161Nv71119aL4eISGHYRRXCyeOHsObvsjuKunPzGuzZvqHMbo+ovNmyZQv27NmD3r17a70UIiJNBtXPmTNH62UQlRipjpVq7WXLlqndymXzGSIiLTHsogrh5PHD+PfvhWV2ezu3/Iu9O/4rs9sjKk9krsf06dPZvkh+8/NoMpm0XgZVMC1btsTGjRtVOzdRoDCbzXjsscdQp04dtVvjyZMntV4SEVVgDLvIr/2+4Cu8+vgteHH0tVj91wLYrNl4afR1OJy0W338wiPX4OC+7bnnT005gedHDkTa6ZM4fSoZzw0fgN3b1+Otl4di87pl+OKd57Fl/d+Y9vx96vwb//0Trz9zN1wuV76qrClPD8HMqY+q6//pm7fV6XO/fhNzv35LfTz7i2mY/eX0Qq/r9/lf4pcfZ2LOVzOwdOG3ZfyIEfm/d955BzfeeKMabkvkDzsxJiQkaL0MqmAk6O/YsSNWrFih9VKISlzfvn0xdOhQPPnkk1i3bp3WyyGiCsqo9QKIinJgz1YVcI2e8BHsdismP3EbGrXoiEG3j8KcL6ejVr2maNGuG6rVapB7mYioSujR7zYs+P59OOxW9BhwO+o2aImhT76F3+Z/iVsffFadb8Xvc7HqrwVYPOcT3Pbw89Dr8+e+SXu24sHHpsFoNOH5EQPRc+AQXDnoHkx56k40aNoOG9f8ibEvfwZLUHCB66peuyGyszJgCQpBlytvKPPHjcifyZPe06dPo1u3blovhSg37OJwetJCv3791G52l112mdZLISpxiYmJeO2119Qcr82bN+Pmm29mNTcRlSlWdpHf2rV1LZq17QKT2YKQ0AiMeelTBIeEo2nry9Rpq5f9jD7XeqqqfHXueS0O7duOowf34rKe1xV63dfc/ghmff66Cs8knCpMaFikCqwiY2KRkZ6igq2rbx6G918bg4G3jlCfF/e6iAjIzMxUVV2yYxORv5Ddwxh2kRYqVaqkXvyfOHFC66UQldpmDC+++KL6+KmnnkJ6errWSyKiCoRhF/k13yNAYeFRMBg9xYh2qxVutxuuQoZful0uOBx2OJ0O9XFh5OvCZrMW+vUmrTqfcaVuz/mt2dAbDPkud67rIiKPGTNm4K677uKud+RXWNlFWld3/fTTT1ovg6hUn8vfcsstuP7669Wszp07d2q9JCKqIBh2kd+q16g1Nq5ZCrvNqtoCXxt/B9JTT6lB80aTCZf3ug5zv/lfgcv9Nv8L1G3YCnUbtlSti0IqwaQV0uv7jybjhrsfx4Hdm4s9SD4rIw3zv3sXDz/5Fub/3zvq86Ku68zbI6roZC6NPOG95JJLtF4KUT6HDh3izC7SjHdulxzAIwpkrVq1UlVeslPj/PnztV4OEVUADLvIb9Wo0whtLr1Szcma+vRd6NH/dhgMRsz75n+4+pYRuPzKG7B769p8YdWJY4ewbPEP6HPtvarFcdni79Vp8dXrISPtND7/37P4d/kiVfXVskMPDLptFL79cCKcxdgNSYK1Dpf3Q+3EZmh/eV/1eVHXJS2NK36bwwH1RADS0tLw8ccfY/jw4VovhaiA7OxshISEaL0MqqCMRiOaNWuG9evXa70UojJp3ZU5Xnv27MGrr74Km82m9ZKIKIDp3MU4lGS32zFr1iwMGjSI23MTEdF5ef7559Xfj5YtW2q9FKICHnnkEbz++utaL4MqsKSkJMycORPPPuvZRIeoIli6dCm+/fZbjB8/ntW1RHReiptPsbKLiIhKze+//46YmBgGXeSXsrKyEBQUpPUyqIKrXr06UlJSOLybKpQuXbrg8ccfV62Ny5Yt03o5RBSAGHYREVGpOHXqlDpq+8ADD2i9FKIih9OzooD8Qe/evbFw4UKtl0FU5kHv1KlT8ccff6jdmp2FbDxFRHShGHYREVGJkw75yZMnY8SIETCbzVovh6jI4fTciZH8Qbdu3fDbb79pvQyiMmexWPDkk0+iWrVqGDdunKpyJCIqCcYSuRYiIiIfCxYsQN26ddGoUSOtl0J01rBLKguItCbttDVq1MDOnTuRmJio9XKIytyAAQPQsGFDNcMuKipK6+UQUQBgZRcREZWoo0ePqm3FhwwZovVSiM6KlV3kTwYOHIjZs2drvQwizTRo0EDtTkpEVBIYdhERUYm3L44ZMwZGI4uHyf9ndsXHx2u9DCJFqlr27NkDm82m9VKIiIjKPYZdRERUYn744Qe0bt0aderU0XopROckoQJ3YyR/m90lu9gSERHRxWHYRUREJULmbPz555+4+eabtV4KEVG53ZXxl19+0XoZRH4l22rF8GenYMC9j2q9FCIqRxh2ERHRRZPtwqV98dFHH4Vezz8t5P/S09MREhKi9TKI8gkPD1dvMk+OiDzmLVkGi8WMuR9MxsEjx/HcGx9c9HXeNe5FLP93Y4msj4j8E1+REBHRRfvqq69U+41sHU5UXuZ1cTg9+euudHPnztV6GUR+I+nwcdSvXUN9XC0+Fs+NulfrJRFROcDpwUREdFF27dqF9evXY9KkSVovhajYuBMj+as2bdpg5syZqmLWYDBovRyiUiOVVc++8T4iw8MwuE83DOx5OR6f9DY27diN8NAQTB0/Atv27MfrH36tzp98KgU9OrXDe1/PwkeTnsKNw55CreoJ2LxjD7KtNrz/yuOoU6Mq9iYdxriJbyL55Gk0rFsTU8aPQEhwEKZ99A2+W/AbaldPwMGjxwus58DhYzmXS0FoSDDeeHqUOu+fq9bhxTc/RkZmNnp2bodnRtzNKnaicoD/SomI6II5HA5MnToV48aNg06n03o5RMXGsIv8lfwu7dChA1auXKn1UohK3bbd+/HZ1Gdw84BeePPT71C7ejwWfz4DQ2+/FhPf+QxXde2EUXfdiCcfvhPjhw7Jd9n9h47CZrdj3szXMKDnZfh67q/q9EdenIaRd92IJV++iYS4yvhm3q9Yv2UHFvy+Aos+m4Z3X3oMu/YdLLCWrbv24sFbrsGiz6bjuqu6Y9pH36rTX/7fpyr4WvrN/3Di1Gls3rm3jB4dIroYrOwiIqIL9uGHH6qWm9jYWK2XQnTeYddll12m9TKICtW/f391IKFTp05aL4WoVDWuVxtBFov6+K3PvkdYSDAW/bkSbjcQHOw5vSiHjiXjhn5XqI8Ta1XHb8vXID0zC/9u3IYXZ3ykTrfa7aoazOly4couHXJvqzBtmzXCCzM+wiv/+xRbdu1Fj0vbqtO7d2yDCTM+xKBeXfDCmPsRFRFego8AEZUWhl1ERHRBtmzZgn379uG+++7TeilE5+3IkSOIi4vTehlEhapcubJqYzx16hSio6O1Xg5RqUmIq5T7sbQcfjhpPKrHVynWZTu2aqrCMS+32w273Y7qCVWw4OPX8533g2/mnPP6Jr37OWpVi8fUp0Zg2Zr/MPNbz2XGPXAbdu5Lwu8r/sXgh57Ap1OeKfYaiUg7bGMkIqLzZrVaMX36dLX7ItsXqby24JrNZq2XQVSkvn37Yv78+Vovg6jMdGzdDF/OXpg7P+uLWb+c93VER0aoAGzpynXq88V/r8aq9ZvRvkVjVTEms70ys7ILvaxUhckAfHleM+Pjb9XOjxI6X3HbcDVD7N4br0aDOjWxhW2MROUCwy4iIjpv77zzDm666SZERUVpvRSi8yZH/4n8XefOnbFs2TL+vFKFMfa+W7Dv4BH0uHUYhj4zGQ3q1ryg63nz+TFqGP2Vd4zEx9/9hJrV4tGycX306dpRnXbXoy+iaYO6BS437I7r8PYXP6hwq2pcLOIrV1KbRAy/43rcNPxpdbrJYEDXS1qXwL0lotKmcxfjL6iUg86aNQuDBg2CyWQq9UUREZH/WrduHebMmYNnnnlG66UQXZDU1FS89tprmDBhgtZLITqrGTNmoFu3bmjevLnWSyEiIvILxc2nWNlFRETFlpmZqaq6Ro8erfVSiC4Yd2Kk8mLgwIGYPXu21ssg0kS21Yrhz07BgHsf1XopRFQOMewiIqLzqjK4++67ERYWpvVSiC4Ywy4qL2rWrInk5GR1oIGoopm3ZBksFjPmfjBZzc967o0P4A9Op2Xg0x8WaL0MIjoHhl1ERFQsK1asgF6vR4cOHbReCtFFYdhF5UnPnj2xaNEirZdBVOaSDh9H/do11McyOP65UffCH6SmZ+CzHxl2Efk7o9YLICIi/5eWloaPP/4Yr7+efytvovIadvXo0UPrZRAVO+waN26camkkChTL/92IZ994H5HhYbiqa0es27ITm3bsVrseTh0/Atv27MfrH36tzpt8KgU9OrXDe1/PwkeTnsKNw55CreoJ2Lxjj9pd8f1XHkedGlWxN+kwxk18E8knT6Nh3ZqYMn4E1m/ZqW5HwrJtu/ZjcJ9uSM/IxIq1m2AyGfHR5PGoHB2F9Vt24Kkp7yEjMwuXtGqKl8Y+gO9//h2zFi5Va9i9/yAeum0wunVsg953jlI7Ot4y8ll8Oe15jR9JIioKK7uIiOicpk6dioceegjBwcFaL4Xooh07dgxVqlTRehlExRIUFISEhATs2bNH66UQlahtu/fjs6nPIPnUadSuHo/Fn8/A0NuvxcR3PsNVXTth1F034smH78T4oUPyXW7/oaOw2e2YN/M1DOh5Gb6e+6s6/ZEXp2HkXTdiyZdvIiGuMr6Z92vu7bz9wqP4+ZPXMeOT/0PDerXUx62a1Mf3C36H3eHAyOdfx+tPj1SXPZFyGov/Xq0u+9fq9Zj56hP4/u1X1A6PNavGYeGn09CgTg0GXUR+jpVdRER0Vr/99htiYmLQsmVLrZdCVCKcTieMRj4FovI3qH7UqFFaL4WoxDSuVxtBFgve+ux7hIUEY9GfK+F2A8HBlrNe7tCxZNzQ7wr1cWKt6vht+RqkZ2bh343b8OKMj9TpVrtdVYM1qldbfS63I2+iXfNG6n29WtVx8MgxVbW1J+mwGoYvsrKtOHDoKMLDQhETFaEuVzXOok4novKDz/SIiKhIJ0+exLfffotp06ZpvRSiEuGWV1JE5Uzjxo3x5ptvqu3Wz7bNOlF5khBXSb2XlsMPJ41H9fjiVdx2bNVUhWO+v9fl30b1hCpY8PHrBdole1zaNvdzqcjyhl6eywI2mwMdWzfDNzNeyHfZ/5u/BP17dM477wXcRyLSDtsYiYioUPLkcfLkyRg5ciTMZrPWyyEqESkpKYiKitJ6GUTnRafToUuXLli61DM/iCiQSND05eyF6uMDh4/hi1m/nPd1REdGqABs6cp16nNpQ1y1fnOxLptYu7qq5Nq6a19uyLVr/8Eizx9kMcNqs5/3GomobDHsIiKiQi1YsAD16tVDo0aecn+iQMCdGKm8uuqqq/Dzzz9rvQyiEjf2vluw7+AR9Lh1GIY+MxkN6ta8oOt58/kxaq7WlXeMxMff/YSa1eKLdbngIAumPfsIRr80XQ2fX/L3asRXjiny/LExUWrg/fVDx1/QOomobOjcxajnl7LQWbNmYdCgQSydJiKqAI4ePYoXXngBb7zxBmcbUUBZtGgRrFYr+vfvr/VSiM7b008/jaFDhyI+vngv4omIiAJNcfMpVnYREVE+cgxk0qRJGDt2LIMuCsjKrmrVqmm9DKILMmDAAMybN0/rZRAREfk9hl1ERJTP999/j7Zt26J2bc8ORkSB5PDhw0hISNB6GUQXpF27dlizZg1cLpfWSyEiIvJrDLuIiChXUlIS/vrrL9x0001aL4WoVBw7dgyxsbFaL4Poguj1enUwYtWqVVovhYiIyK8x7CIiIsXpdKr2xUcffVS9oCIK1DZdg8Gg9TKILhhbGYmIiM6Nr2aIiEj58ssv0aNHD84zooBVjD15iPxeXFwcsrOzkZKSovVSiIiI/BbDLiIiwq5du7BhwwYMHDhQ66UQlZoTJ06gUqVKWi+D6KJdddVV+Pnnn7VeBhERkd9i2EVEVME5HA5MnToV48aNg06n03o5RKW6E2PVqlW1XgbRRbv88svx559/slqRiIioCAy7iIgquJkzZ6oZMBzaTYGOYRcFCpPJhAYNGmDLli1aL4WIiMgvMewiIqrA5IXS/v370bt3b62XQlQmYVdCQoLWyyAqEdJ2Pnv2bK2XQURE5JcYdhERVVBWqxXTp09Xuy+yfZEqgsOHD3MDBgoYtWvXVj/TMqyeiIiI8mPYRURUQb3zzju4+eabERUVpfVSiMpEcnIyYmJitF4GUYnp2bMnfv31V62XQURE5HcYdhERVUBr165FamoqunTpovVSiMqUXs+nPhQ4GHYREREVjs/4iIgqmMzMTLz77rt45JFHtF4KUZlxuVxs16WAExISojYX2bdvn9ZLISIi8isMu4iIKhiZ03X33XcjLCxM66UQlZnjx49zx1EKSBxUT0REVBDDLiKiCmT58uUwGAzo0KGD1kshKlMyyJs7MVIgatq0KbZu3QqHw6H1UoiIiPwGwy4iogpCZnR98sknGD58uNZLISpzBw8e5E6MFJCkPbdz587466+/tF4KERGR32DYRURUQUydOhUPP/wwgoKCtF4KUZljZRcFsn79+mH+/PlaL4OIiMhvMOwiIqoAlixZgsqVK6NFixZaL4VIs8quqlWrar0MolIRFRUFk8mkZtMRERERwy4iooB38uRJfPfdd7j//vu1XgqRZlJSUhAdHa31MohKTf/+/TFv3jytl0FEROQXGHYREQUwt9uNyZMnY+TIkTCbzVovh0jz2UZEgUo2Hlm5ciVcLpfWSyEiItIcwy4iogAmM1wSExPRsGFDrZdCpBnZpU6v51MeCmyy026rVq3w77//ar0UIiIizfGZHxFRgDpy5AgWLFiAO++8U+ulEGnq2LFjqFKlitbLICp1V199NebOnav1MoiIiDTHsIuIKIDbF8eOHQuj0aj1cog0dejQIVSrVk3rZRCVOtlxND09HWlpaVovhYiISFMMu4iIAtD333+Pdu3aoXbt2lovhUhzhw8fViEAUUXQp08f/Pzzz1ovg4iISFMMu4iIAsyBAwfw119/4cYbb9R6KUR+gZVdVJF07doVf/zxh9bLICIi0hTDLiKiAOJ0OlX74rhx4ziQm8gn7GJlF1UUsvNunTp1sHXrVq2XQkREpBm+EiIiCiBffPEFevTogapVq2q9FCK/kZqaioiICK2XQVRmBg4ciNmzZ2u9DCIiIs0w7CIiChC7du3Cf//9p17kEFF+Op1O6yUQlZnExEQcPHgQ2dnZWi+FiIhIEwy7iIgCgMPhwNSpU1X7Il/UE+Wx2+3ckZQqpO7du+O3337TehlERESaYNhFRBQAZs6ciauvvhqxsbFaL4XIrxw9ehTx8fFaL4OozPXq1QsLFy7UehlERESaYNhFRFTObd68We3A2Lt3b62XQuR3pJWLw+mpIgoLC0N0dDSSkpK0XgoREVGZY9hFRFSOyTyWGTNmYOzYsVovhcgvHT58mBs2UIUlFb8cVE9ERBURwy4ionLsnXfewc0334yoqCitl0Lklw4dOsSwiyqsli1bYtOmTWquIxERUUXCsIuIqJz6999/kZaWhi5dumi9FCK/xbCLKjLZsKRTp05Yvny51kshIiIqUwy7iIjKoczMTLz33nt45JFHtF4KkV/LyMhQs4uIKqp+/fph/vz5Wi+DiIioTDHsIiIqh3799Vfcc889fBFPRERnFRMTo94nJydrvRQiIqIyw7CLiKicDh1u37691ssg8mtWqxVms1nrZRD5RXXXTz/9pPUyiIiIygzDLiIiIgrYnRgTEhK0XgaR5mRu1z///AO32631UoiIiMoEwy4iIiIKSAy7iDwMBgOaNWuG9evXa70UIiKiMsGwi4iIiALSwYMHuRMjkU/7++zZs7VeBhERUZlg2EVEpIH0tBRMf/1R/G/GE1ovhSigK7sYdhF5VK9eHSkpKUhPT9d6KURERKWOYRcRkQZ+W/Ij6tRtgoeHv1Ii1/fl51ORcoo7bRH5OnToENsYiXz07t0bCxcu1HoZREREpY5hFxGRBk6cOIKq1eqU2PXdcttoREVXLrHrIwoE2dnZCAkJ0XoZRH6je/fu2Lt3r9bLICIiKnXG0r8JIqKK66+l8/Drom8BtxvtL+mJfgPuxJLF32P5sgXq7fqbhqFnrxtyz79/33Z89cXryMrKQFRUZdxz/zMID4/CiuULseCnT2G329Cl69Xo0/e2fLfz5Lgb8OTT70FvMGDmexNw/NghBIeE4b4Hn0PlyqxsISIiwGKxYPTo0Vovg4iIqNQx7CIiKiUHk3Zj0cKv8fiT78BoMuONKaNRu05j9LjiWuzfuw3NW16Ktu265btM0oFduPHmEep8P3z3Dn5b/D2uHnQPvv1qOl545SuYTGY15+vSzn0RERlT4DaXL/sZcfG1MHzUZBWQyecDBt5VhveayD9kZWUhKChI62UQERERkQYYdhERlZKtW9agbbvuqsJKdLq0D7ZsWoWmzToUeZn6DVviu2/fQvKxQ0hK2oVuPa5Rp8tlPv14orq+h4a9BIsluNDLJ9ZvgT9+fwGhoeFo0aozOna6spTuHZH/D6fnvC4iIiKiiokzu4iISpUu34duuM967i8+fQ0tWnbG089/hNuHjMs9XdoZ+/W/A8ePHcTEFx9EdnZmoZevVbshHh//NuLia+CbL6fhj99mldxdISpnw+m5EyMRERFRxcSwi4iolDRq3Ab/rvkd2VmZcDocWPH3L2jcpP1ZLyMhlszYcrvd+ObL6WpGV+rpk3jhubtRpUoN9O1/B8wWC5KPHy708tL6+M/yhWjXvgeu7HMzNm9eVUr3jsi/MewiIiIiqrjYxkhEVEqqVa+HnlfegFdffkhVdLXvcAWaNb/krJcZeM19+PSjiTBbgtCq9WXQQadmc0k74ksT7lED6Js07YBq1esWevlu3a/BzPdfwO+//QiLJQS33j6mlO4dkf+HXR06FN0yTERERESBS+eW8oFzsNvtmDVrFgYNGgSTyVQ2KyMiIiK6QI899hief/55DqknyjH85cfx2tgJsJjN5zzvwWOH8cH3n+PZhx7FTY/ehyfvewQtGjQp1u1M+/xd9OrUDU3qNcSHP3yBm/sORnBQ4XMmiYiIzldx8ym2MRIREVHAsdlsDLqIfMx4cmKxgi5RrUqCCrouxMjbHlBBl/hw1pfIsmZf0PUQERFdDIZdRERERER+RpovXvngDVx533Xoee9gfDX/B3V6anoa7npqOHrccw0GjbgDSUcO5btcUV9vOrCzev/GZ+/gzieH4vrRd6PzbX3xf7/MxgPPj0H3uwdh5CtPqttdsX417nl6RLHW893CObh21BB1W7+vWqYqwTZs36zeHzx6GL0fuAErNqxBnwdvyL2uwaPuxOpN60r9MSQiooqLM7uIiIgooKSnpyMkJETrZRBdlORTJxAeEoaf3/1WBVhdhgzA4J798P2iuahXozY+enEGflz8E77/da6qpvI619edLpcKn7bNW4Hl61bhlscewJ+fzENCbBz6D70F/+3Ycl7rEf9u2YCd81fBYDDgnW8/Vqd9Pfl9XHZHP8yZ8TliIqNhtdmw68BeRISG4fjJE2jbpGWpP4ZERFRxMewiIiKigHL48GHuxEjlXmxMZYSFhmHQiNvhcDqRlpGOjKxMtGvWCp9P/A4RYRHo2bErrrnCEzh5nevrJ1JOokPzNurjhnUS1fvq8Z5/L7Wr1VShVkghM7aKWo+Q25Gg62wG9bgKPy1dhNjoSrjq8iug0+ku8hEiIiIqGtsYiYiIKOB2YmTYReXdmk3r8e3Ps/D5xHcw/+2vkVA5Tp3evH4T/DjtE9StXgvPvz0Jn8/9v3yXO9fXq8RUxuVtOuZ+Xi0uId/Xi9q7qqj1CKkKO5dBPfpiwZ+/4tcVf2BAt97FfBSIiIguDMMuIiIiCigMuygQpGemIyIsXL3t2Lcbh5OPQnKoV2dOV+2J/bteifuvuwN/rV2R73Ln+npJr+dsgswW1b4oalWtATfcqnVSAjkiIqLSxLCLiIiIAgrDLgoEnVp1UC1/3YZcrQbDN6/fGKdST+G2Addj3h8L1ZD46V+8h6E335Pvcuf6ekmv52z6demFG8fei6SjniH5darWxOVtO5XIeoiIiM5G5y6qVtmH3W7HrFmzMGjQIJhMpnOdnYiIiEgzjz76KF5++WU+ZyHyIw6nA7eMewAvjxyPxJp1tV4OERGVU8XNp1jZRURERAHF4XAw6KIK7cMfvkBWdtZ5X+7Ln77DH6uWlfh60jMzcPkd/dGqUTMGXUREVCa4GyMREREFjGIUrBMFvA9nfYlBV/RFcCG7Kp7NLf2uK5X1hIWEYvkXP5fKdRMRERWGlV1EREQUMNLS0hAeHq71Mog0c9Oj9+Hg0cPo/cANalbWXU8NR6/7rsUNY+7BnoP71XnGvvYsHpowFlcPuxVX3DMYK//7N/f0+X/+qj6e+/sv6PPgDehy5wC8+3+fqNM27dyKgcNvQ9chV2PkK0/CarNqeE+JiIiKxrCLiIiIAgaH01NF9/Xk91EtLgG/vPstXnl/Gq64pAsWvf89HrxhCMZMflqd59jJ4zh2Mhlz3vwCL40cj8emPp/vOo6dOI7JH72Jrye9ry47e8kCFXRN/+J9DLvlPvzx8RxUiorGsrUrNbqXREREZ8ewi4iIiAIGwy6iPMvXr8KNVw1SH/e45HIcOX5Mzc9au+U/DOjeR53esUVb2Bx2pKSezr3c2q3/4ZLmbRAVEQmL2awCtMSaddClbSe8+eUH+HTON7j/+jvVdRIREfkjhl1EREQUMBh2EeWn0+kKzLVzOp3Qn3H62S4XERYOi9mCW/tfh7eeehUGvQF3PPEwNmzfXGrrJiIiuhgMu4iIiChgMOwiAoLMFlhtNnRs2Q7/98scddofq/9GXOVYhIeGoXXj5vh+0Vx1+ooNa2A2mVUVl1frRs3xz3//qmovu8OOWx97AJt3bceNY+/FqdQUFXp1bd8Zazav1+w+EhERnQ13YyQiIqKAcezYMVSpUkXrZRBpql+XXiqY+nLSu3jmzYn46McvER0ZhSmPvqC+nhAbjyPHj6L/0FuQkZWJiY94Znl5VakUi9F3PKSG2kvYdduA69GkXgMMv+U+jJn0jDpP1SrxGHbzPZrcPyIionPRuYuxR7fdbsesWbMwaNAgmEymc14pERERkRamTp2K0aNHa70MIr8muy7KvK2+l/fUeilERETnpbj5FNsYiYiIKGAw6CIiIiIitjESEREREVUgr419XuslEBERlSpWdhERERERERERUcBg2EVERERERERERAGDYRcREREREREREQUMhl1EREQUEPYd2oPbHh2E5998TOulEBEREZGGGHYRERFRQHjn6zdw7ZU349lhr+Y7/Z8Ny/Dv5lXq4x8WfY0J/3tCoxUSERERUVlg2EVEREQB4eDRA0is1bDA6Ss3/I21OWEXEREREQU+hl1ERERU5txuNybPnID+D3RB3/svx7cLPlenp6afxv1P34I+93bGDaOuQtLR/QUu+78vp6Lf/Zery373y5fqtCkfvaRCretH9sGCpbNzz/vJj+/hrS+mqNv6bPYH6rSkw/tw71M3o/sdbfHlvI/UaU6nEy+985S63kFDr8C6LWvK6JEgIiIiopJmLPFrJCIiIjqH5FPHER4SgTlv/47UjNPoddclGHjFdZj167eoU6M+3nvhS8xZ8p36fNitY3Mv98fKX/H32qX48a3FyLZm4abR/dG6cTuMuWs81m1ZjXH3PovmDVrlnv/Oa+5X1x8SFIrbB96r2hiXrl6CtT/uRkraKVw3ojdu6X+XCs0kaPvpvT+xdfcmPDl1FH54c5FGjw4RERERXQyGXURERFTmYmOqIDQkDNeP6qOqqtIyUpGZlYE2TTvgq58+QWRYJHp07I2re1yX73ISdF3T8waYTWb1dmXnfli+7k/Uq9mg2BVlJqMZwUEh6i3LmqVO/3zuTOzYuxXb9mxWn59OSymFe01EREREZYFhFxEREZU5GRj//cKv8OmrPyAiLBLdbm+jTm9WvyW+ef0nLPv3d7z49nj06zoIN/cfkv/COp3PhzoVYBWXnP/6q27NOyHnstWq1MDTD72MDi0uvej7RkRERETa4swuIiIiKnMZmWkID41QQdfOfdtwJPmQCq2mfPiial+8qstA3HPdw6qSy1en1per1ka7w470jDQs/GseOrW6/Ky3FWQOgs1uPet5JOSSVkaXy6XaG2d+91aJ3E8iIiIiKnus7CIiIqIyd0nLy/Djom9w5d0dUad6PTSt3wKnUk+qKq5HJw3Fl/M+RkhQCJ4bPinf5bp16IUtuzbimqFXqCqtu659qNAdGH1d1rY7hk64E2Eh4ap1sjAyz+tlGVD/QBdYzJZ8c8KIiIiIqHzRuYtR+2+32zFr1iwMGjQIJpOpbFZGRERERERERER0nvkU2xiJiIiIiIiIiChgMOwiIiIiIiIiIqKAwbCLiIiIiIiIiIgCBsMuIiIiIiIiIiIKGAy7iIiIiIiIiIgoYDDsIiIiIiIiIiKigMGwi4iIiIiIiIiIAgbDLiIiIiIiIiIiChgMu4iIiIiIiIiIKGAw7CIiIiIiIiIiooDBsIuIiIiIiIiIiAIGwy4iIiIiIiIiIgoYDLuIiIiIiIiIiChgMOwiIiIiIiIiIqKAwbCLiIiIiIiIiIgCBsMuIiIiIiIiIiIKGAy7iIiIiIiIiIgoYDDsIiIiIiIiIiKigMGwi4iIiIiIiIiIAgbDLiIiIiIiIiIiChgMu4iIiIiIiIiIKGAw7CIiIiIiIiIiooDBsIuIiP6/nTtGYRAKoig6ioj734t7ExQNBqxCEsFY5HFOM8WfYupb/AIAAEghdgEAAAAQQ+wCAAAAIIbYBQAAAEAMsQsAAACAGGIXAAAAADHELgAAAABiiF0AAAAAxBC7AAAAAIjRnVnatu0553m++x4AAAAAeHF0qaNTXYpdy7I85ziOZ9YBAAAA4BZ7p+r7/u17s33LYVW1rmtN01Rd11XTNL++EQAAAAA+2hPWHrqGYai2ba/FLgAAAAD4Bz6oBwAAACCG2AUAAABADLELAAAAgBhiFwAAAAAxxC4AAAAAYohdAAAAAMQQuwAAAACoFA/0laRiLWFCXAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x750 with 1 Axes>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_document_datamap(chunk_texts, embeddings=np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6eb610f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_as_in_the",
          "1_of_as_is",
          "2_huang_zhao_zhu",
          "3_as_of_the",
          "4_biorxiv_2017_acl",
          "5_as_similarity_topics",
          "6_cx_xtx_nxxt",
          "7_are_of_33",
          "8_017_014_015",
          "9_refined_as_refinement"
         ],
         "xaxis": "x",
         "y": [
          "0_as_in_the",
          "1_of_as_is",
          "2_huang_zhao_zhu",
          "3_as_of_the",
          "4_biorxiv_2017_acl",
          "5_as_similarity_topics",
          "6_cx_xtx_nxxt",
          "7_are_of_33",
          "8_017_014_015",
          "9_refined_as_refinement"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "+v//////7z/2B60PPZzrP27OP/LM/ec/EmLDkffq6z9aeu6f7VLsP/2Aioqwpes/wk6FOQTR6j+j974d5ojgP3JJj+MX4+E/GCmzr1se7D/2B60PPZzrPwIAAAAAAPA/24N1MUnF5T/5o0hCQlnsPzByR947xuo/IcyPMUEa6j+tDQl3wtztP0+JLyJObuI/qNQYo3/74T+EMT1xqIHrP27OP/LM/ec/24N1MUnF5T/7///////vPzdB5SVLs+I/TP0WjsLl7D/z5OkGwi/hPwbRtKacYuU/GoY0k2aQ2T8Z8B/kdJvbP8w1HSVBR+Q/EmLDkffq6z/5o0hCQlnsPzdB5SVLs+I/AAAAAAAA8D/TYvEq9XToPzNJ0X2/5ew/3NLBdLm26z8Medy65cHdP7bnGRNbads/5Y2Q9blj7D9aeu6f7VLsPzByR947xuo/TP0WjsLl7D/TYvEq9XToP/v//////+8/BNQSoKA05z8GNZ14bOTpPzDsnnSqeeE/K2Wvo7YE4j9cl2Jh9gjpP/2Aioqwpes/IcyPMUEa6j/z5OkGwi/hPzNJ0X2/5ew/BNQSoKA05z8AAAAAAADwP4J11Il/Sek/1rVNLc/W3D/USxUwfOrZP5Ad3VXHbuw/wk6FOQTR6j+tDQl3wtztPwbRtKacYuU/3NLBdLm26z8GNZ14bOTpP4J11Il/Sek/////////7z+SMLnVi53iPx6nkTuSOt8/LajOciqv6j+j974d5ojgP0+JLyJObuI/GoY0k2aQ2T8Medy65cHdPzDsnnSqeeE/1rVNLc/W3D+SMLnVi53iPwIAAAAAAPA/K5vtp+271z9+OR/TLMTeP3JJj+MX4+E/qNQYo3/74T8Z8B/kdJvbP7bnGRNbads/K2Wvo7YE4j/USxUwfOrZPx6nkTuSOt8/K5vtp+271z8AAAAAAADwP/7Ywa8YqNo/GCmzr1se7D+EMT1xqIHrP8w1HSVBR+Q/5Y2Q9blj7D9cl2Jh9gjpP5Ad3VXHbuw/LajOciqv6j9+OR/TLMTeP/7Ywa8YqNo/////////7z8=",
          "dtype": "f8",
          "shape": "10, 10"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix</b>",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26312def",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2eef5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>-1_the_is_as_are</td>\n",
       "      <td>[the, is, as, are, this, of, that, all, how, by]</td>\n",
       "      <td>[P is an orthonormal matrix. Why is this assum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0_as_in_the_are</td>\n",
       "      <td>[as, in, the, are, is, of, typhoon2, only, mod...</td>\n",
       "      <td>[Training\\nBased on our experiments, although ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1_of_as_is_are</td>\n",
       "      <td>[of, as, is, are, xj, in, 𝑠0, the, that, one]</td>\n",
       "      <td>[neighbor of Xi.\\nIn essence, by creating a cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2_huang_zhao_zhu_liu</td>\n",
       "      <td>[huang, zhao, zhu, liu, jiang, 2024, wu, zhang...</td>\n",
       "      <td>[Chen.\\nToolACE: Winning the Points of LLM Fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>3_as_of_the_scaling</td>\n",
       "      <td>[as, of, the, scaling, in, are, is, not, by, t...</td>\n",
       "      <td>[sampled or had their dimension reduced by PCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4_biorxiv_2017_acl_david</td>\n",
       "      <td>[biorxiv, 2017, acl, david, 2016, 2020, gelbuk...</td>\n",
       "      <td>[[18] Nal Kalchbrenner, Lasse Espeholt, Karen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5_as_similarity_topics_subtopics</td>\n",
       "      <td>[as, similarity, topics, subtopics, the, simil...</td>\n",
       "      <td>[we determined that a minimum cluster size of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6_cx_xtx_nxxt_of</td>\n",
       "      <td>[cx, xtx, nxxt, of, xˆvi, is, ˆv1, are, ˆv2, as]</td>\n",
       "      <td>[more precise.\\nX = UΣVT\\nUTX = ΣVT\\nUTX = Z\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7_are_of_33_as</td>\n",
       "      <td>[are, of, 33, as, sailor, and, 21, dou, post, 23]</td>\n",
       "      <td>[16\\n3.4\\nFunction Calling . . . . . . . . . ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8_017_014_015_013</td>\n",
       "      <td>[017, 014, 015, 013, 005, 002, 023, 951, 003, ...</td>\n",
       "      <td>[Table 1: kNN Classiﬁer accuracy for varying v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9_refined_as_refinement_cot</td>\n",
       "      <td>[refined, as, refinement, cot, is, corrected, ...</td>\n",
       "      <td>[We adhere to the outlined automated design fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                              Name  \\\n",
       "0      -1     23                  -1_the_is_as_are   \n",
       "1       0     90                   0_as_in_the_are   \n",
       "2       1     40                    1_of_as_is_are   \n",
       "3       2     36              2_huang_zhao_zhu_liu   \n",
       "4       3     22               3_as_of_the_scaling   \n",
       "5       4     20          4_biorxiv_2017_acl_david   \n",
       "6       5     17  5_as_similarity_topics_subtopics   \n",
       "7       6     14                  6_cx_xtx_nxxt_of   \n",
       "8       7      6                    7_are_of_33_as   \n",
       "9       8      5                 8_017_014_015_013   \n",
       "10      9      4       9_refined_as_refinement_cot   \n",
       "\n",
       "                                       Representation  \\\n",
       "0    [the, is, as, are, this, of, that, all, how, by]   \n",
       "1   [as, in, the, are, is, of, typhoon2, only, mod...   \n",
       "2       [of, as, is, are, xj, in, 𝑠0, the, that, one]   \n",
       "3   [huang, zhao, zhu, liu, jiang, 2024, wu, zhang...   \n",
       "4   [as, of, the, scaling, in, are, is, not, by, t...   \n",
       "5   [biorxiv, 2017, acl, david, 2016, 2020, gelbuk...   \n",
       "6   [as, similarity, topics, subtopics, the, simil...   \n",
       "7    [cx, xtx, nxxt, of, xˆvi, is, ˆv1, are, ˆv2, as]   \n",
       "8   [are, of, 33, as, sailor, and, 21, dou, post, 23]   \n",
       "9   [017, 014, 015, 013, 005, 002, 023, 951, 003, ...   \n",
       "10  [refined, as, refinement, cot, is, corrected, ...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [P is an orthonormal matrix. Why is this assum...  \n",
       "1   [Training\\nBased on our experiments, although ...  \n",
       "2   [neighbor of Xi.\\nIn essence, by creating a cu...  \n",
       "3   [Chen.\\nToolACE: Winning the Points of LLM Fun...  \n",
       "4   [sampled or had their dimension reduced by PCA...  \n",
       "5   [[18] Nal Kalchbrenner, Lasse Espeholt, Karen ...  \n",
       "6   [we determined that a minimum cluster size of ...  \n",
       "7   [more precise.\\nX = UΣVT\\nUTX = ΣVT\\nUTX = Z\\n...  \n",
       "8   [16\\n3.4\\nFunction Calling . . . . . . . . . ....  \n",
       "9   [Table 1: kNN Classiﬁer accuracy for varying v...  \n",
       "10  [We adhere to the outlined automated design fr...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88ff5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map doc_id -> list of its chunk topics\n",
    "doc_chunk_topics = defaultdict(list)\n",
    "\n",
    "for doc_id, topic in zip(doc_ids, chunk_topics):\n",
    "    doc_chunk_topics[doc_id].append(topic)\n",
    "\n",
    "# Map doc_id -> top topic (the most common topic number in its chunks)\n",
    "doc_top_topic = {}\n",
    "\n",
    "for doc_id, topics in doc_chunk_topics.items():\n",
    "    top_topic = Counter(topics).most_common(1)[0][0]  # get the most frequent topic\n",
    "    doc_top_topic[doc_id] = top_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6fa813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'495fb9ae-61b7-45cd-9062-ef93cdba65aa': 1, 'd21282d0-6699-43b7-bc19-32e41ac54a99': 0, '12b22df8-a310-4c67-82e1-e0a8a9b60d48': 0, '2664dd5f-aa91-4c08-b30a-57b41e94e600': 5, '4b46efdf-0db0-42e2-af04-c03cd2d9058a': 6, '43531378-8340-494d-80d5-a5388e654029': 1, '3fecf9b1-d101-41cf-862c-433d3c4ffe58': -1, 'b21ef601-e9b2-4354-95f5-1d83ae6f4a3a': 0}\n"
     ]
    }
   ],
   "source": [
    "print(doc_top_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba27f0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'495fb9ae-61b7-45cd-9062-ef93cdba65aa': 1,\n",
       " 'd21282d0-6699-43b7-bc19-32e41ac54a99': 0,\n",
       " '12b22df8-a310-4c67-82e1-e0a8a9b60d48': 0,\n",
       " '2664dd5f-aa91-4c08-b30a-57b41e94e600': 5,\n",
       " '4b46efdf-0db0-42e2-af04-c03cd2d9058a': 6,\n",
       " '43531378-8340-494d-80d5-a5388e654029': 1,\n",
       " '3fecf9b1-d101-41cf-862c-433d3c4ffe58': -1,\n",
       " 'b21ef601-e9b2-4354-95f5-1d83ae6f4a3a': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_top_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5a9af5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'495fb9ae-61b7-45cd-9062-ef93cdba65aa': Counter({1: 27,\n",
       "          3: 22,\n",
       "          4: 8,\n",
       "          8: 4,\n",
       "          -1: 1,\n",
       "          0: 1}),\n",
       " 'd21282d0-6699-43b7-bc19-32e41ac54a99': Counter({0: 63,\n",
       "          2: 24,\n",
       "          7: 6,\n",
       "          9: 4,\n",
       "          -1: 2,\n",
       "          1: 2,\n",
       "          5: 1}),\n",
       " '12b22df8-a310-4c67-82e1-e0a8a9b60d48': Counter({0: 13, 2: 12, -1: 1, 8: 1}),\n",
       " '2664dd5f-aa91-4c08-b30a-57b41e94e600': Counter({5: 16, 4: 5, -1: 1}),\n",
       " '4b46efdf-0db0-42e2-af04-c03cd2d9058a': Counter({6: 14, -1: 12}),\n",
       " '43531378-8340-494d-80d5-a5388e654029': Counter({1: 11}),\n",
       " '3fecf9b1-d101-41cf-862c-433d3c4ffe58': Counter({-1: 2, 4: 2}),\n",
       " 'b21ef601-e9b2-4354-95f5-1d83ae6f4a3a': Counter({0: 13, 4: 5, -1: 4})}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_distribution = {\n",
    "    doc_id: Counter(topics) for doc_id, topics in doc_chunk_topics.items()\n",
    "}\n",
    "\n",
    "doc_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c530542",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_top_topic = {}\n",
    "\n",
    "for doc_id, topic_counts in doc_topic_distribution.items():\n",
    "    top_topic = topic_counts.most_common(1)[0][0]\n",
    "    doc_top_topic[doc_id] = top_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd2a0990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495fb9ae-61b7-45cd-9062-ef93cdba65aa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d21282d0-6699-43b7-bc19-32e41ac54a99</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12b22df8-a310-4c67-82e1-e0a8a9b60d48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664dd5f-aa91-4c08-b30a-57b41e94e600</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4b46efdf-0db0-42e2-af04-c03cd2d9058a</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43531378-8340-494d-80d5-a5388e654029</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3fecf9b1-d101-41cf-862c-433d3c4ffe58</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b21ef601-e9b2-4354-95f5-1d83ae6f4a3a</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Top Topic\n",
       "495fb9ae-61b7-45cd-9062-ef93cdba65aa          1\n",
       "d21282d0-6699-43b7-bc19-32e41ac54a99          0\n",
       "12b22df8-a310-4c67-82e1-e0a8a9b60d48          0\n",
       "2664dd5f-aa91-4c08-b30a-57b41e94e600          5\n",
       "4b46efdf-0db0-42e2-af04-c03cd2d9058a          6\n",
       "43531378-8340-494d-80d5-a5388e654029          1\n",
       "3fecf9b1-d101-41cf-862c-433d3c4ffe58         -1\n",
       "b21ef601-e9b2-4354-95f5-1d83ae6f4a3a          0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(doc_top_topic, orient=\"index\", columns=[\"Top Topic\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "563f97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chunk_indices = defaultdict(list)\n",
    "for idx, doc_id in enumerate(doc_ids):\n",
    "    doc_chunk_indices[doc_id].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f63388bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc_chunk_indices.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949ba7",
   "metadata": {},
   "source": [
    "### Try to generate topic label for cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdd050",
   "metadata": {},
   "source": [
    "Not work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c088e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from api.agentic.core import call_llm\n",
    "\n",
    "\n",
    "def generate_document_topic_title(\n",
    "    doc_id, topic_counter, top_n=5, chunk_texts_per_topic=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive topic title for a single document.\n",
    "\n",
    "    Parameters:\n",
    "    - doc_id: str, document ID\n",
    "    - topic_counter: Counter {topic_id: count}\n",
    "    - top_n: int, number of top topics to consider\n",
    "    - chunk_texts_per_topic: dict {topic_id: [list of example chunk texts]} for the whole corpus or doc\n",
    "\n",
    "    Returns:\n",
    "    - topic_title: str, generated by LLM\n",
    "    \"\"\"\n",
    "\n",
    "    total_chunks = sum(topic_counter.values())\n",
    "    top_topics = topic_counter.most_common(top_n)\n",
    "    print(top_topics)\n",
    "\n",
    "    coverage = sum(count for _, count in top_topics) / total_chunks\n",
    "\n",
    "    method = \"keyword\"\n",
    "    if method == \"example_text\":\n",
    "        example_texts = []\n",
    "        for topic_id, _count in top_topics:\n",
    "            texts = chunk_texts_per_topic.get(topic_id, [])\n",
    "            # Take a few representative snippets (e.g., 3 per topic)\n",
    "            example_texts.extend(texts[:3])\n",
    "\n",
    "        # 3. Build prompt for LLM\n",
    "        prompt = f\"\"\"\n",
    "    You are an expert topic summarization AI.\n",
    "\n",
    "    Your task is to generate a **single, concise, and comprehensive topic title** that accurately represents the overall themes in a document that covers multiple related topics.\n",
    "\n",
    "    # Instructions:\n",
    "    1. Carefully read the provided content snippets extracted from the document’s dominant topics.\n",
    "    2. Identify the key themes and concepts that unify the snippets.\n",
    "    3. Synthesize these into one clear, professional topic title that reflects the document as a whole.\n",
    "    4. Follow all formatting and style rules strictly.\n",
    "\n",
    "    # Formatting & Style Rules:\n",
    "    - The title must summarize all key themes collectively.\n",
    "    - Use clear and professional language.\n",
    "    - Keep the title concise: no more than 8-10 words.\n",
    "    - Use Title Case (capitalize major words).\n",
    "    - Avoid generic, vague, or filler phrases such as:\n",
    "    \"Summary of\", \"Document about\", \"Overview of\", \"Introduction to\", etc.\n",
    "    - Do not use punctuation at the end of the title (no periods, exclamation marks).\n",
    "    - Include technical terms where appropriate to preserve meaning.\n",
    "    - The title should be a noun phrase or a succinct descriptive phrase, not a full sentence.\n",
    "\n",
    "    # Example Inputs and Outputs:\n",
    "\n",
    "    **Input:**\n",
    "    Snippets:\n",
    "    - \"Deep learning techniques improve medical imaging analysis accuracy.\"\n",
    "    - \"Neural networks are used for automated tumor detection.\"\n",
    "    - \"AI models can predict disease progression using imaging data.\"\n",
    "\n",
    "    **Output:**\n",
    "    AI-Powered Medical Imaging Analysis\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Input:**\n",
    "    Snippets:\n",
    "    - \"The history of computer programming languages from Assembly to Python.\"\n",
    "    - \"Key milestones in software development over the decades.\"\n",
    "    - \"Evolution of coding practices and paradigms.\"\n",
    "\n",
    "    **Output:**\n",
    "    Evolution of Programming Languages\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Input:**\n",
    "    Snippets:\n",
    "    - \"Renewable energy sources reduce carbon emissions globally.\"\n",
    "    - \"Solar and wind power technologies are becoming more affordable.\"\n",
    "    - \"Sustainable energy policies drive green innovation worldwide.\"\n",
    "\n",
    "    **Output:**\n",
    "    Global Trends in Renewable Energy Technologies\n",
    "\n",
    "    ---\n",
    "\n",
    "    # Now, generate the topic title for the following snippets:\n",
    "\n",
    "    The document’s dominant topics cover approximately {coverage:.0%} of its content.\n",
    "\n",
    "    Snippets:\n",
    "    {chr(10).join(f\"- {text}\" for text in example_texts)}\n",
    "\n",
    "    Topic Title:\n",
    "    \"\"\"\n",
    "    else:\n",
    "        # Use keywords from get_topic\n",
    "        topic_words_list = [word for word, _ in topic_model.get_topic(top_topics[0][0])]\n",
    "        keywords = \", \".join(topic_words_list)\n",
    "        prompt = f\"\"\"\n",
    "    You are an expert topic summarization AI.\n",
    "\n",
    "    Your task is to generate a **single, concise, and comprehensive topic title** that accurately represents the overall themes in a document, based on a set of important keywords extracted from its dominant topics.\n",
    "\n",
    "    # Instructions:\n",
    "    1. Carefully read the provided keywords for each dominant topic in the document.\n",
    "    2. Identify the overarching themes or concepts these keywords suggest.\n",
    "    3. Synthesize these into one clear, professional topic title that reflects the document as a whole.\n",
    "    4. Follow all formatting and style rules strictly.\n",
    "\n",
    "    # Formatting & Style Rules:\n",
    "    - The title must summarize the key themes collectively.\n",
    "    - Use clear, professional language.\n",
    "    - Keep the title concise: no more than 8-10 words.\n",
    "    - Use Title Case (capitalize major words).\n",
    "    - Avoid generic or filler phrases like:\n",
    "    \"Summary of\", \"Document about\", \"Overview of\", \"Introduction to\", etc.\n",
    "    - Do not use punctuation at the end of the title.\n",
    "    - Use important technical terms or keywords where appropriate.\n",
    "\n",
    "    # Example Inputs and Outputs:\n",
    "\n",
    "    **Input:**\n",
    "    Keywords:\n",
    "    - Deep Learning, Medical Imaging, Tumor Detection, Neural Networks, Disease Prediction\n",
    "\n",
    "    **Output:**\n",
    "    AI-Powered Medical Imaging and Tumor Detection\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Input:**\n",
    "    Keywords:\n",
    "    - Programming Languages, Software Development, Coding Paradigms, Assembly, Python\n",
    "\n",
    "    **Output:**\n",
    "    Evolution of Programming Languages and Coding Paradigms\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Input:**\n",
    "    Keywords:\n",
    "    - Renewable Energy, Solar Power, Wind Power, Carbon Emissions, Green Innovation\n",
    "\n",
    "    **Output:**\n",
    "    Global Trends in Renewable Energy Technologies\n",
    "\n",
    "    ---\n",
    "\n",
    "    # Now, generate the topic title for the following keywords:\n",
    "\n",
    "    The document’s dominant topics cover approximately {coverage:.0f}% of its content.\n",
    "\n",
    "    Keywords:\n",
    "    {keywords}\n",
    "\n",
    "    Topic Title:\n",
    "    \"\"\"\n",
    "\n",
    "    # 4. Call the LLM\n",
    "    topic_title = call_llm(prompt).strip()\n",
    "\n",
    "    return topic_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "762f921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab6125ae03249d99f8557d6153bc4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 27), (3, 22), (4, 8)]\n",
      "[(0, 63), (2, 24), (7, 6)]\n",
      "[(0, 13), (2, 12), (-1, 1)]\n",
      "[(5, 16), (4, 5), (-1, 1)]\n",
      "[(6, 14), (-1, 12)]\n",
      "[(1, 11)]\n",
      "[(-1, 2), (4, 2)]\n",
      "[(0, 13), (4, 5), (-1, 4)]\n"
     ]
    }
   ],
   "source": [
    "chunk_texts_per_topic = defaultdict(list)\n",
    "for chunk_text, topic_id in zip(chunk_texts, chunk_topics):\n",
    "    chunk_texts_per_topic[topic_id].append(chunk_text)\n",
    "\n",
    "doc_topic_titles = {}\n",
    "\n",
    "for doc_id, topic_counter in tqdm(list(doc_topic_distribution.items())):\n",
    "    title = generate_document_topic_title(\n",
    "        doc_id, topic_counter, top_n=3, chunk_texts_per_topic=chunk_texts_per_topic\n",
    "    )\n",
    "    doc_topic_titles[doc_id] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54986480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'495fb9ae-61b7-45cd-9062-ef93cdba65aa': 'Mathematical Symbols And Variables Analysis',\n",
       " 'd21282d0-6699-43b7-bc19-32e41ac54a99': 'Model Only Configuration',\n",
       " '12b22df8-a310-4c67-82e1-e0a8a9b60d48': 'It appears the provided keywords are not in a standard format that can be used to generate a meaningful topic title. The keywords seem to be fragmented and lack coherence, making it challenging to identify overarching themes or concepts.\\n\\nHowever, based on the fragments provided, some possible interpretations could involve concepts related to \"type\" (from \"t, y, p, h, o, o, n\"), \"models\" (from \"m, o, d, e, l\"), and potentially \"online\" or \"only\" (from \"o, n, l, y\"). Without a clear and direct set of keywords, it\\'s speculative to synthesize these into a single title.\\n\\nGiven the constraints and aiming for a professional and clear title, but acknowledging the limitations of the input:\\n\\nModel Interpretations And Online Types',\n",
       " '2664dd5f-aa91-4c08-b30a-57b41e94e600': 'Similarity In Topics And Subtopics Analysis',\n",
       " '4b46efdf-0db0-42e2-af04-c03cd2d9058a': 'Variable Coding Structures And Patterns Analysis',\n",
       " '43531378-8340-494d-80d5-a5388e654029': 'Mathematical Symbols And Variables Analysis',\n",
       " '3fecf9b1-d101-41cf-862c-433d3c4ffe58': 'Analysis Of This And That Completely',\n",
       " 'b21ef601-e9b2-4354-95f5-1d83ae6f4a3a': 'Modern Typing Models And Online Trends'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da738d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3051eb4ec56b4411bdd154c0e1a88bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the, of, to, and, in, is, we, for, thai, as, on, with, data, model, that, this, by, are, from, dataset, our, models, an, be, typhoon2, english, umap, al, speech, performance, et, set, can, typhoon, training, audio, table, using, instruct, it, language, or, which, text, instruction, fuzzy, sne, state, te, th\n",
      "arxiv, and, https, url, in, language, for, preprint, of, org, zhang, abs, 2023, conference, li, models, wang, neural, liu, learning, on, 2024, computational, linguistics, large, proceedings, the, association, processing, chen, pages, 2021, yang, pp, machine, international, yu, with, wei, 2020, information, systems, wu, 2022, 2018, daniel, lin, zhou, 2019, 2017\n",
      "the, of, is, this, in, matrix, we, that, to, are, be, pca, and, basis, data, by, an, can, for, vectors, set, what, but, all, from, along, principal, will, not, where, eigenvectors, covariance, how, equation, each, it, if, with, orthonormal, let, two, our, variance, orthogonal, have, or, one, as, column, figure\n",
      "topic, the, and, topics, words, to, cluster, of, model, in, each, for, semantic, sentence, modeling, coherence, document, we, within, embeddings, our, word, documents, is, from, based, extraction, that, contextual, end, are, process, as, with, embedding, clustering, this, similarity, clusters, models, coherent, score, collection, on, it, vector, meaningful, dense, policy, scores\n",
      "findings, setup, experimental, results, speech, data, and, 10, et, al, 42, families, thai, 2024, 28, general, end, high, foundation, models, sea, 22, are, 36, as, languages, 12, language, quality, 20, evaluation, such, model, sources, post, training, distillation, range, 46, architecture, there, 35, 41, 33, to, 23, 21, 17, vision, 38\n",
      "014, 013, 015, 002, 017, 016, largevis, 011, 967, 006, 003, accuracy, sne, fold, umap, for, of, embedding, 20, over, and, 100, eigenmaps, 023, 966, 230, 004, 085, 767, 005, 973, 007, 564, 957, 012, 949, 1600, 400, 778, 962, 800, 3200, grade, scores, classiﬁer, mnist, validation, varying, m3exam, pendigits\n"
     ]
    }
   ],
   "source": [
    "for topic_id in tqdm(list(topic_model.get_topics())):\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "\n",
    "    topic_words = [word for word, _ in topic_model.get_topic(topic_id)]\n",
    "    print(\", \".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdf568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
